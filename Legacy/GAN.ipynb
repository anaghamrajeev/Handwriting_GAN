{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"Copy of Letter GAN.ipynb","provenance":[{"file_id":"https://github.com/Amogh13246831/Handwriting-GAN/blob/master/Letter%20GAN.ipynb","timestamp":1587134559417}]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3mm-b9-ewROy","colab_type":"text"},"source":["<h1>Handwriting Letter GAN</h1>\n","\n","<h3>Links</h3>\n","<ul>\n","    <li><a href=https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/>cGAN Code</a></li>\n","    <li><a href=https://keras.io/getting-started/functional-api-guide/>Keras Functional API</a></li>\n","</ul>"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"gIlQgpkPwRO0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5cde3046-ef53-4c41-f598-f2dea48648c1","executionInfo":{"status":"ok","timestamp":1587120637277,"user_tz":-330,"elapsed":7964,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["import numpy as np\n","from numpy.random import *\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import Adam\n","import tensorflow as tf\n","from emnist import *\n","from skimage import data, io, transform\n","import matplotlib.pyplot as plt\n","\n","tf.test.gpu_device_name()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"wW7Ie8QtwRO7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"bb6a4460-d22e-4ef2-81ce-80c521b1b1a6","executionInfo":{"status":"ok","timestamp":1587120656062,"user_tz":-330,"elapsed":26736,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["list_datasets()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading emnist.zip: 536MB [00:15, 37.4MB/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["['balanced', 'byclass', 'bymerge', 'digits', 'letters', 'mnist']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"nKNjeKSWwRPB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":333},"outputId":"ed8c8fd5-2908-45c2-f771-d01346b4f1bc","executionInfo":{"status":"ok","timestamp":1587124949084,"user_tz":-330,"elapsed":2386,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["images, labels = extract_training_samples('balanced')\n","print(images.shape, labels.shape)\n","plt.imshow(images[908])\n","print(labels[908])\n","# ind = np.where(labels==8)\n","ind = []\n","for i in range(10):\n","  ind.extend(np.where(labels == i)[0])\n","print(labels[ind])\n","images, labels = images[ind], labels[ind]\n","print(images.shape, labels.shape)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["(112800, 28, 28) (112800,)\n","33\n","[0 0 0 ... 9 9 9]\n","(24000, 28, 28) (24000,)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAPgklEQVR4nO3dfYxc9XXG8ed4/bLBYLB5cYwxXgImQNLWOBtTBI1IaRAhrQyFItySmJRoaQNN0qZVCVUVFCoVNbyIqBHIvJo2dRoaCEayWsBEICuKwxoZY2OIHccONotdy7zT2Du7p3/sBS2w98wy7875fqTVzNwzd+/R2M/emfube3/m7gLwm29CuxsA0BqEHUiCsANJEHYgCcIOJDGxlRubbFO8W1NbuUkglV/rTe33fTZWra6wm9m5km6R1CXpDne/Pnp+t6bqNDu7nk0CCKzxVaW1mt/Gm1mXpO9K+qykUyQtNrNTav19AJqrns/sCyVtcfet7r5f0vclLWpMWwAarZ6wz5b0wqjHO4pl72JmfWbWb2b9g9pXx+YA1KPpR+Pdfam797p77yRNafbmAJSoJ+w7Jc0Z9fiYYhmADlRP2J+UNM/MjjOzyZIukbSiMW0BaLSah97cvWJmV0n6H40Mvd3l7hsb1hmAhqprnN3dV0pa2aBeADQRX5cFkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IImWTtmc1oSusGwTxpxh9x1eqTSyGyTFnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcvQEmdHeH9Zcvmh/WXz0+/pvbc8PTYX34zTfDOt7PJk2O691T4vqxR8f1V98I65WdL5YX3cN1a1VX2M1sm6TXJQ1Jqrh7byOaAtB4jdizf9rd9zTg9wBoIj6zA0nUG3aX9LCZrTWzvrGeYGZ9ZtZvZv2D2lfn5gDUqt638We6+04zO0rSI2b2nLs/MfoJ7r5U0lJJmmYzmnPkAUBVde3Z3X1ncbtb0gOSFjaiKQCNV3PYzWyqmR3y9n1J50ja0KjGADRWPW/jZ0p6wMze/j3/4e7/3ZCuDjB2yCFhfddZ8fno/3n2rWH9r375lbB+2L//rLw4PBSueyCbcNBB8RNOOLa09MuLpoer7vtw/G+2+JNrwvp/PR9/t+KE6w4urQ1tfD5ct1Y1h93dt0r6nQb2AqCJGHoDkiDsQBKEHUiCsANJEHYgCU5xbYChPfF5QCf965Fh/Rs9F4b13WfEw0CHrwiGcV55NVy3k008ZnZY33HR3LD+uSWrS2u3H/6TcN0tg9PC+sOvfTysDw/Flw9/8yOHlta6n40vLV7rKbDs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZG6HKuKdv3BLWt61fENYfv+iGsP6Z3X9XWjvuW2vDdX1wf1hvppcvOz2s93zp52H9iZ4bw/qG/eWXgz7rvr8N15237JWw7pu2hvXjK+vCerMuFx1hzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDO3gFsOK7P7IqnDz7ik7tKa10fPipct/LCjnjjdeqaXn7J5s/99ePhul+Z0R/WH3ijJ6zffNtFpbV5t+ebBps9O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTh7C/hQPG3yYZuqXCe8iiVzf1pau/+oT8crVxlnrzYtcmXBiWF9y4XdpbXbpj8UrnvF9kVhfdsd8baPvq98LP03cRy9mqp7djO7y8x2m9mGUctmmNkjZra5uI0nuwbQduN5G3+PpHPfs+xqSavcfZ6kVcVjAB2satjd/QlJe9+zeJGkZcX9ZZLOb3BfABqs1s/sM919oLj/kqSZZU80sz5JfZLUrfjzH4DmqftovLu7pNKr57n7UnfvdffeSYpP6ADQPLWGfZeZzZKk4nZ341oC0Ay1hn2FpCXF/SWSHmxMOwCapepndjNbLuksSUeY2Q5J35R0vaQfmNnlkrZLuriZTR7whuNx9iOffDms7x3aF9bnd28vrX33U+XzgEvS7K3xqOnAn50c1i/seyys331Y+Tnplz53abhuZWnpoSBJ0owH42viD7fxmvidqGrY3X1xSensBvcCoIn4uiyQBGEHkiDsQBKEHUiCsANJmLdw6thpNsNPMw7iv5dNjAdFXn1oblhf9VvLS2tv+WC47mP/d3RY//0PvRjWt1Ymh/VLHrqqtPbRb2worUk5T0Ot1xpfpdd875jnTLNnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkuJR0B/BKJazv/1E87fKGk8ovRf2JyR8K171wanx67dr98Tj6pT/9Ulg/+aaB0lqFcfSWYs8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzt4Bqp3PPnhwPKVzV/mEPOqy+O/5kA+H9UtWlp+PLkknf7t8HF2SKttfCOtoHfbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+wt0DVtWljf88cfC+vX9JVfF16SfntyV2lt0OPpoqs5eGv575akoYFd8S9o4bwEiFXds5vZXWa228w2jFp2rZntNLN1xc95zW0TQL3G8zb+HknnjrH8ZnefX/ysbGxbABqtatjd/QlJe1vQC4AmqucA3VVmtr54mz+97Elm1mdm/WbWP6h9dWwOQD1qDfutko6XNF/SgKQby57o7kvdvdfdeydpSo2bA1CvmsLu7rvcfcjdhyXdLmlhY9sC0Gg1hd3MZo16eIGkeO5dAG1XdZzdzJZLOkvSEWa2Q9I3JZ1lZvMluaRtkq5oYo8db/j3Tg3rPTc+F9bvnXVDWH9+ML72+6lrvlBas58cGq77sQvi3u646pawftnpXwzrc/+p/Hx537glXFdVzrWvdr19vFvVsLv74jEW39mEXgA0EV+XBZIg7EAShB1IgrADSRB2IAlOcR2nicfMLq29+Y/xtMfXzXo0rG+txNMif/k78eWc5z5Qfrnm4V2/iLe9Jx42nPOtFWF91cLbwvqlN/xpaW3b+gXhut174n1Rz91bw3pl4KWwng17diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IIs84u8XTHk889piw/quL55TWVp9SeqEeSdLT+6eG9S/+6C/C+olL14X1yltvhfXI4fetD+tn/2Hc2+0L7g3ryz9afhns+48+MVz322vPCeuawL7qg+DVApIg7EAShB1IgrADSRB2IAnCDiRB2IEkzFs4pe40m+Gn2dkt295oE3uODeub/7l0BitJ0t2n3V1aG6ryN/PKW78c1o9dvj2sV3bsDOvNNHFu+fcLJGnXH8TfT3jlpPJaz8p4OrApm+PpoCs7XwzrGaeLXuOr9JrvHfNLJezZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJA+p8dpsypbQ28JefCNf9kz9/LKx/59D+sL781d7S2uNXnh6uO/tna8N6ZV883txOle3l16SXpMPvrFKvZ9t1rIv3q7pnN7M5ZvZjM3vWzDaa2VeL5TPM7BEz21zcxt9KAdBW43kbX5H0dXc/RdLvSrrSzE6RdLWkVe4+T9Kq4jGADlU17O4+4O5PFfdfl7RJ0mxJiyQtK562TNL5zWoSQP0+0Gd2M+uRdKqkNZJmuvtAUXpJ0sySdfok9UlStw6qtU8AdRr30XgzO1jSDyV9zd1fG13zkbNpxjzrwN2Xunuvu/dOUvkBNgDNNa6wm9kkjQT9e+5+f7F4l5nNKuqzJO1uTosAGqHq23gzM0l3Strk7jeNKq2QtETS9cXtg03pcJThBeXnS1535T3hutMm/Dqs/9GT8SWTZ98yqbQ2YXV8qedWnkYMlBnPZ/YzJH1e0jNm9vb/6ms0EvIfmNnlkrZLurg5LQJohKphd/fVkspmWGjPlSgAfGB8XRZIgrADSRB2IAnCDiRB2IEkOusU1yrTKg93d5XW/ubBL4TrHrYp/t3HPbojrFd+FdQZR8cBgD07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTRWePsVcarux5/urR2wuryMXhJ8qGhsF4ZjuvAgY49O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0Vnj7NUEY+HOODkQYs8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lUDbuZzTGzH5vZs2a20cy+Wiy/1sx2mtm64ue85rcLoFbj+VJNRdLX3f0pMztE0loze6So3ezuNzSvPQCNMp752QckDRT3XzezTZJmN7sxAI31gT6zm1mPpFMlrSkWXWVm683sLjObXrJOn5n1m1n/oPbV1SyA2o077GZ2sKQfSvqau78m6VZJx0uar5E9/41jrefuS9291917J2lKA1oGUItxhd3MJmkk6N9z9/slyd13ufuQuw9Lul3Swua1CaBe4zkab5LulLTJ3W8atXzWqKddIGlD49sD0CjjORp/hqTPS3rGzNYVy66RtNjM5ktySdskXdGUDgE0xHiOxq+WNNbk5isb3w6AZuEbdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSTM3Vu3MbP/lbR91KIjJO1pWQMfTKf21ql9SfRWq0b2Ntfdjxyr0NKwv2/jZv3u3tu2BgKd2lun9iXRW61a1Rtv44EkCDuQRLvDvrTN2490am+d2pdEb7VqSW9t/cwOoHXavWcH0CKEHUiiLWE3s3PN7Hkz22JmV7ejhzJmts3Mnimmoe5vcy93mdluM9swatkMM3vEzDYXt2POsdem3jpiGu9gmvG2vnbtnv685Z/ZzaxL0s8lfUbSDklPSlrs7s+2tJESZrZNUq+7t/0LGGb2KUlvSLrX3T9eLPsXSXvd/friD+V0d//7DuntWklvtHsa72K2olmjpxmXdL6ky9TG1y7o62K14HVrx559oaQt7r7V3fdL+r6kRW3oo+O5+xOS9r5n8SJJy4r7yzTyn6XlSnrrCO4+4O5PFfdfl/T2NONtfe2CvlqiHWGfLemFUY93qLPme3dJD5vZWjPra3czY5jp7gPF/ZckzWxnM2OoOo13K71nmvGOee1qmf68Xhyge78z3X2BpM9KurJ4u9qRfOQzWCeNnY5rGu9WGWOa8Xe087WrdfrzerUj7DslzRn1+JhiWUdw953F7W5JD6jzpqLe9fYMusXt7jb3845OmsZ7rGnG1QGvXTunP29H2J+UNM/MjjOzyZIukbSiDX28j5lNLQ6cyMymSjpHnTcV9QpJS4r7SyQ92MZe3qVTpvEum2ZcbX7t2j79ubu3/EfSeRo5Iv8LSf/Qjh5K+vqIpKeLn43t7k3Sco28rRvUyLGNyyUdLmmVpM2SHpU0o4N6+zdJz0har5FgzWpTb2dq5C36eknrip/z2v3aBX215HXj67JAEhygA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk/h9q76fG98962wAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"M-Kqph4MwRPG","colab_type":"code","colab":{}},"source":["def define_discriminator(input_shape=(28, 28, 1), n_classes=47):\n","    # label input and embedding\n","    label_in = Input(shape=(1, ))\n","    emb = Embedding(n_classes, 50)(label_in)\n","    label_h = Dense(input_shape[0] * input_shape[1])(emb)\n","    re_label_h = Reshape((input_shape[0], input_shape[1], 1))(label_h)\n","    # image input\n","    image_in = Input(shape=input_shape)\n","    # combine inputs\n","    merge = Concatenate()([image_in, re_label_h])\n","    # convnet\n","    h1 = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(merge)\n","    r1 = LeakyReLU(alpha=0.2)(h1)\n","    h2 = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(r1)\n","    r2 = LeakyReLU(alpha=0.2)(h2)\n","    # fully connected net\n","    fl = Flatten()(r2)\n","    dr = Dropout(0.4)(fl)\n","    # output\n","    out = Dense(1, activation='sigmoid')(dr)\n","    # define and compile model\n","    model = Model([image_in, label_in], out)\n","    opt = Adam(lr=2e-4, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"azTw_unnwRPL","colab_type":"code","colab":{}},"source":["def define_generator(latent_dim, n_classes=47):\n","    # label input and embedding\n","    label_in = Input(shape=(1, ))\n","    emb = Embedding(n_classes, 50)(label_in)\n","    label_h = Dense(7*7)(emb)\n","    re_label_h = Reshape((7, 7, 1))(label_h)\n","    # noisy image input\n","    noise_in = Input(shape=(latent_dim,))\n","    noise_h = Dense(128*7*7)(noise_in)\n","    noise_r = LeakyReLU(alpha=0.2)(noise_h)\n","    re_noise_r = Reshape((7, 7, 128))(noise_r)\n","    # combine inputs\n","    merge = Concatenate()([re_noise_r, re_label_h])\n","    # upsampling\n","    u1 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(merge)\n","    r1 = LeakyReLU(alpha=0.2)(u1)\n","    u2 = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(r1)\n","    r2 = LeakyReLU(alpha=0.2)(u2)\n","    # output\n","    out = Conv2D(1, (7, 7), activation='tanh', padding='same')(r2)\n","    # define model\n","    model = Model([noise_in, label_in], out)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CLPznA0ewRPQ","colab_type":"code","colab":{}},"source":["def define_gan(gen, dis):\n","    # discriminator shouldn't be trainable\n","    dis.trainable = False\n","    # get generator inputs and outputs\n","    gen_noise, gen_label = gen.input\n","    gen_output = gen.output\n","    # feed to discriminator\n","    gan_output = dis([gen_output, gen_label])\n","    # define and compile GAN model\n","    model = Model([gen_noise, gen_label], gan_output)\n","    opt = Adam(lr=2e-4, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy', optimizer=opt)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T4VQMOFWwRPW","colab_type":"code","colab":{}},"source":["def prepare_inputs(images, labels):\n","    X = np.expand_dims(images, axis=-1)\n","    X = X.astype('float32')\n","    X = (X-127.5) / 127.5\n","    return [X, labels]\n","    \n","def generate_real_samples(images, labels, n_samples):\n","    rand_index = randint(0, images.shape[0], n_samples)\n","    X, labels = images[rand_index], labels[rand_index]\n","    y = np.ones((n_samples, 1))  # discriminator target label\n","    return [X, labels], y\n","\n","def generate_latent_noise(latent_dim, n_samples, n_classes=47):\n","    xin = randn(latent_dim * n_samples)\n","    xin = xin.reshape(n_samples, latent_dim)\n","    labels = randint(0, n_classes, n_samples)  #  generator class label\n","    return xin, labels\n","\n","def generate_fake_samples(gen, latent_dim, n_samples):\n","    zin, lin = generate_latent_noise(latent_dim, n_samples)\n","    images = gen.predict([zin, lin])\n","    y = np.zeros((n_samples, 1))  # discriminator target label\n","    return [images, lin], y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z7tYgvI1wRPd","colab_type":"code","colab":{}},"source":["def train_gan(gen, dis, gan_model, images, labels, latent_dim, n_epochs=100, batch_size=128):\n","    batch_per_epoch = int(images.shape[0] / batch_size)\n","    half_batch = int(batch_size / 2)\n","    # enumerate epochs\n","    for i in range(n_epochs):\n","        for j in range(batch_per_epoch):\n","            # train discriminator on real images\n","            [X_real, labels_real], y_real = generate_real_samples(images, labels, half_batch)\n","            d_loss1, _ = dis.train_on_batch([X_real, labels_real], y_real)\n","            # train discriminator on generated images\n","            [X_fake, labels_fake], y_fake = generate_fake_samples(gen, latent_dim, half_batch)\n","            d_loss2, _ = dis.train_on_batch([X_fake, labels_fake], y_fake)\n","            # prepare generator input\n","            [zin, label_in] = generate_latent_noise(latent_dim, batch_size)\n","            # invert labels for fake samples (prevent vanishing gradients)\n","            y_gan = np.ones((batch_size, 1))\n","            # update generator loss\n","            g_loss = gan_model.train_on_batch([zin, label_in], y_gan)\n","            # output losses\n","            print('Epoch {}, batch {}/{}:\\tDiscriminator: real loss {}, fake loss {}\\tGenerator: loss {}'\n","                  .format(i+1, j+1, batch_per_epoch, d_loss1, d_loss2, g_loss))\n","    # save the models\n","    gen.save('generator.h5')\n","    dis.save('discriminator.h5')\n","    gan_model.save('gan.h5')    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ghFC5NrwRPh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"29391637-db06-4b94-bc65-fc96b3ff7c9d","executionInfo":{"status":"ok","timestamp":1587120657470,"user_tz":-330,"elapsed":28066,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["latent_dim = 100\n","images, labels = prepare_inputs(images, labels)\n","print(images.shape, labels.shape)\n","dis = define_discriminator()\n","gen = define_generator(latent_dim)\n","gan_model = define_gan(gen, dis)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(24000, 28, 28, 1) (24000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DUcQtwfPwRQD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"c931c40b-2c2d-4c88-e140-262a59a80dee","executionInfo":{"status":"ok","timestamp":1587120657471,"user_tz":-330,"elapsed":28057,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["print(\"\\nDiscriminator\\n\")\n","dis.summary()\n","print(\"\\nGenerator\\n\")\n","gen.summary()\n","print(\"\\nGAN\\n\")\n","gan_model.summary()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["\n","Discriminator\n","\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 1, 50)        2350        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1, 784)       39984       embedding[0][0]                  \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 28, 28, 1)    0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 28, 28, 2)    0           input_2[0][0]                    \n","                                                                 reshape[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 14, 14, 128)  2432        concatenate[0][0]                \n","__________________________________________________________________________________________________\n","leaky_re_lu (LeakyReLU)         (None, 14, 14, 128)  0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 7, 7, 128)    147584      leaky_re_lu[0][0]                \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 7, 7, 128)    0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 6272)         0           leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 6272)         0           flatten[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 1)            6273        dropout[0][0]                    \n","==================================================================================================\n","Total params: 198,623\n","Trainable params: 0\n","Non-trainable params: 198,623\n","__________________________________________________________________________________________________\n","\n","Generator\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 6272)         633472      input_4[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 1, 50)        2350        input_3[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 6272)         0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1, 49)        2499        embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 7, 7, 128)    0           leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 7, 7, 1)      0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 7, 7, 129)    0           reshape_2[0][0]                  \n","                                                                 reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose (Conv2DTranspo (None, 14, 14, 128)  264320      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 14, 14, 128)  0           conv2d_transpose[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 128)  262272      leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 28, 28, 128)  0           conv2d_transpose_1[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 28, 28, 1)    6273        leaky_re_lu_4[0][0]              \n","==================================================================================================\n","Total params: 1,171,186\n","Trainable params: 1,171,186\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","\n","GAN\n","\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","input_3 (InputLayer)            [(None, 1)]          0                                            \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 6272)         633472      input_4[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 1, 50)        2350        input_3[0][0]                    \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 6272)         0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1, 49)        2499        embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","reshape_2 (Reshape)             (None, 7, 7, 128)    0           leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 7, 7, 1)      0           dense_2[0][0]                    \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 7, 7, 129)    0           reshape_2[0][0]                  \n","                                                                 reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose (Conv2DTranspo (None, 14, 14, 128)  264320      concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 14, 14, 128)  0           conv2d_transpose[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 128)  262272      leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 28, 28, 128)  0           conv2d_transpose_1[0][0]         \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 28, 28, 1)    6273        leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","model (Model)                   (None, 1)            198623      conv2d_2[0][0]                   \n","                                                                 input_3[0][0]                    \n","==================================================================================================\n","Total params: 1,369,809\n","Trainable params: 1,171,186\n","Non-trainable params: 198,623\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9-40IwDjwRQH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"be77cd5c-34bc-4aaa-8a5b-45f5049e0f96","executionInfo":{"status":"ok","timestamp":1587123978252,"user_tz":-330,"elapsed":1505187,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["print(images.shape, labels.shape)\n","train_gan(gen, dis, gan_model, images, labels, latent_dim, n_epochs=100, batch_size=100)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Epoch 80, batch 42/240:\tDiscriminator: real loss 0.10748331993818283, fake loss 0.17649637162685394\tGenerator: loss 9.630956649780273\n","Epoch 80, batch 43/240:\tDiscriminator: real loss 0.12926998734474182, fake loss 0.23684574663639069\tGenerator: loss 9.953667640686035\n","Epoch 80, batch 44/240:\tDiscriminator: real loss 0.12063834816217422, fake loss 0.104895681142807\tGenerator: loss 9.698787689208984\n","Epoch 80, batch 45/240:\tDiscriminator: real loss 0.13513506948947906, fake loss 0.07771632820367813\tGenerator: loss 8.472524642944336\n","Epoch 80, batch 46/240:\tDiscriminator: real loss 0.08828702569007874, fake loss 0.19883199036121368\tGenerator: loss 9.860851287841797\n","Epoch 80, batch 47/240:\tDiscriminator: real loss 0.12106513977050781, fake loss 0.31075426936149597\tGenerator: loss 9.002596855163574\n","Epoch 80, batch 48/240:\tDiscriminator: real loss 0.13068830966949463, fake loss 0.33483847975730896\tGenerator: loss 10.384827613830566\n","Epoch 80, batch 49/240:\tDiscriminator: real loss 0.16145536303520203, fake loss 0.1389891654253006\tGenerator: loss 11.566423416137695\n","Epoch 80, batch 50/240:\tDiscriminator: real loss 0.15418437123298645, fake loss 0.1395762860774994\tGenerator: loss 9.75448989868164\n","Epoch 80, batch 51/240:\tDiscriminator: real loss 0.13570259511470795, fake loss 0.23126918077468872\tGenerator: loss 10.501847267150879\n","Epoch 80, batch 52/240:\tDiscriminator: real loss 0.23496048152446747, fake loss 0.14969497919082642\tGenerator: loss 8.96744441986084\n","Epoch 80, batch 53/240:\tDiscriminator: real loss 0.12325988709926605, fake loss 0.272134006023407\tGenerator: loss 7.119044303894043\n","Epoch 80, batch 54/240:\tDiscriminator: real loss 0.1532166451215744, fake loss 0.21290302276611328\tGenerator: loss 9.395400047302246\n","Epoch 80, batch 55/240:\tDiscriminator: real loss 0.1043669730424881, fake loss 0.09562189131975174\tGenerator: loss 7.5450334548950195\n","Epoch 80, batch 56/240:\tDiscriminator: real loss 0.09401819109916687, fake loss 0.243865504860878\tGenerator: loss 8.116196632385254\n","Epoch 80, batch 57/240:\tDiscriminator: real loss 0.2020328938961029, fake loss 0.11828820407390594\tGenerator: loss 8.622560501098633\n","Epoch 80, batch 58/240:\tDiscriminator: real loss 0.12455037981271744, fake loss 0.24801909923553467\tGenerator: loss 8.539482116699219\n","Epoch 80, batch 59/240:\tDiscriminator: real loss 0.19126079976558685, fake loss 0.1779012233018875\tGenerator: loss 9.159719467163086\n","Epoch 80, batch 60/240:\tDiscriminator: real loss 0.18662086129188538, fake loss 0.30241772532463074\tGenerator: loss 9.203570365905762\n","Epoch 80, batch 61/240:\tDiscriminator: real loss 0.168287456035614, fake loss 0.14873652160167694\tGenerator: loss 7.661200046539307\n","Epoch 80, batch 62/240:\tDiscriminator: real loss 0.042911358177661896, fake loss 0.22459788620471954\tGenerator: loss 8.257067680358887\n","Epoch 80, batch 63/240:\tDiscriminator: real loss 0.10008146613836288, fake loss 0.18961121141910553\tGenerator: loss 7.885373115539551\n","Epoch 80, batch 64/240:\tDiscriminator: real loss 0.17665275931358337, fake loss 0.12339088320732117\tGenerator: loss 8.088196754455566\n","Epoch 80, batch 65/240:\tDiscriminator: real loss 0.1093713566660881, fake loss 0.23726026713848114\tGenerator: loss 7.714031219482422\n","Epoch 80, batch 66/240:\tDiscriminator: real loss 0.16189923882484436, fake loss 0.19646526873111725\tGenerator: loss 7.110072612762451\n","Epoch 80, batch 67/240:\tDiscriminator: real loss 0.18950706720352173, fake loss 0.1125788688659668\tGenerator: loss 6.530149459838867\n","Epoch 80, batch 68/240:\tDiscriminator: real loss 0.06909158080816269, fake loss 0.11808624118566513\tGenerator: loss 6.680001258850098\n","Epoch 80, batch 69/240:\tDiscriminator: real loss 0.07379144430160522, fake loss 0.2883971929550171\tGenerator: loss 8.09482479095459\n","Epoch 80, batch 70/240:\tDiscriminator: real loss 0.10995651036500931, fake loss 0.20274409651756287\tGenerator: loss 8.41046142578125\n","Epoch 80, batch 71/240:\tDiscriminator: real loss 0.20528686046600342, fake loss 0.1120099127292633\tGenerator: loss 6.990234375\n","Epoch 80, batch 72/240:\tDiscriminator: real loss 0.08165746927261353, fake loss 0.2225947231054306\tGenerator: loss 7.658939838409424\n","Epoch 80, batch 73/240:\tDiscriminator: real loss 0.08899350464344025, fake loss 0.3159266710281372\tGenerator: loss 8.285694122314453\n","Epoch 80, batch 74/240:\tDiscriminator: real loss 0.19977901875972748, fake loss 0.047377392649650574\tGenerator: loss 7.314861297607422\n","Epoch 80, batch 75/240:\tDiscriminator: real loss 0.10253342986106873, fake loss 0.1462005376815796\tGenerator: loss 7.434813022613525\n","Epoch 80, batch 76/240:\tDiscriminator: real loss 0.0645206868648529, fake loss 0.2913595139980316\tGenerator: loss 8.781224250793457\n","Epoch 80, batch 77/240:\tDiscriminator: real loss 0.15986186265945435, fake loss 0.09693506360054016\tGenerator: loss 9.509376525878906\n","Epoch 80, batch 78/240:\tDiscriminator: real loss 0.16163194179534912, fake loss 0.2058912217617035\tGenerator: loss 9.742318153381348\n","Epoch 80, batch 79/240:\tDiscriminator: real loss 0.12566621601581573, fake loss 0.2386365681886673\tGenerator: loss 9.330753326416016\n","Epoch 80, batch 80/240:\tDiscriminator: real loss 0.1442985087633133, fake loss 0.17986367642879486\tGenerator: loss 9.670083999633789\n","Epoch 80, batch 81/240:\tDiscriminator: real loss 0.16183273494243622, fake loss 0.16272090375423431\tGenerator: loss 9.722150802612305\n","Epoch 80, batch 82/240:\tDiscriminator: real loss 0.11073701828718185, fake loss 0.17237962782382965\tGenerator: loss 9.640413284301758\n","Epoch 80, batch 83/240:\tDiscriminator: real loss 0.13933347165584564, fake loss 0.15757231414318085\tGenerator: loss 8.823699951171875\n","Epoch 80, batch 84/240:\tDiscriminator: real loss 0.0788053497672081, fake loss 0.12587299942970276\tGenerator: loss 8.489603042602539\n","Epoch 80, batch 85/240:\tDiscriminator: real loss 0.08800407499074936, fake loss 0.2149105966091156\tGenerator: loss 9.307526588439941\n","Epoch 80, batch 86/240:\tDiscriminator: real loss 0.12031501531600952, fake loss 0.21296706795692444\tGenerator: loss 9.3993501663208\n","Epoch 80, batch 87/240:\tDiscriminator: real loss 0.15686316788196564, fake loss 0.3781524896621704\tGenerator: loss 8.780765533447266\n","Epoch 80, batch 88/240:\tDiscriminator: real loss 0.15368957817554474, fake loss 0.2125522941350937\tGenerator: loss 10.896210670471191\n","Epoch 80, batch 89/240:\tDiscriminator: real loss 0.183492511510849, fake loss 0.11108125746250153\tGenerator: loss 10.932251930236816\n","Epoch 80, batch 90/240:\tDiscriminator: real loss 0.11680185049772263, fake loss 0.28956055641174316\tGenerator: loss 12.309287071228027\n","Epoch 80, batch 91/240:\tDiscriminator: real loss 0.11302368342876434, fake loss 0.230606347322464\tGenerator: loss 10.719085693359375\n","Epoch 80, batch 92/240:\tDiscriminator: real loss 0.16386514902114868, fake loss 0.21636377274990082\tGenerator: loss 9.050634384155273\n","Epoch 80, batch 93/240:\tDiscriminator: real loss 0.21094222366809845, fake loss 0.16884081065654755\tGenerator: loss 7.079524517059326\n","Epoch 80, batch 94/240:\tDiscriminator: real loss 0.10712392628192902, fake loss 0.16843990981578827\tGenerator: loss 6.488139629364014\n","Epoch 80, batch 95/240:\tDiscriminator: real loss 0.1603020876646042, fake loss 0.23352138698101044\tGenerator: loss 7.13273811340332\n","Epoch 80, batch 96/240:\tDiscriminator: real loss 0.1267857700586319, fake loss 0.24210567772388458\tGenerator: loss 7.843961238861084\n","Epoch 80, batch 97/240:\tDiscriminator: real loss 0.09995915740728378, fake loss 0.12038740515708923\tGenerator: loss 8.404199600219727\n","Epoch 80, batch 98/240:\tDiscriminator: real loss 0.14374443888664246, fake loss 0.203073650598526\tGenerator: loss 8.071059226989746\n","Epoch 80, batch 99/240:\tDiscriminator: real loss 0.11242254078388214, fake loss 0.12241201102733612\tGenerator: loss 8.730545043945312\n","Epoch 80, batch 100/240:\tDiscriminator: real loss 0.08232837915420532, fake loss 0.10505613684654236\tGenerator: loss 8.32819938659668\n","Epoch 80, batch 101/240:\tDiscriminator: real loss 0.14042919874191284, fake loss 0.12080968916416168\tGenerator: loss 8.59457778930664\n","Epoch 80, batch 102/240:\tDiscriminator: real loss 0.07500138878822327, fake loss 0.1808927357196808\tGenerator: loss 8.503605842590332\n","Epoch 80, batch 103/240:\tDiscriminator: real loss 0.12144455313682556, fake loss 0.12031717598438263\tGenerator: loss 6.963240146636963\n","Epoch 80, batch 104/240:\tDiscriminator: real loss 0.12168340384960175, fake loss 0.1252569854259491\tGenerator: loss 7.193321704864502\n","Epoch 80, batch 105/240:\tDiscriminator: real loss 0.11798308044672012, fake loss 0.1271216869354248\tGenerator: loss 6.800291538238525\n","Epoch 80, batch 106/240:\tDiscriminator: real loss 0.12095719575881958, fake loss 0.3618263900279999\tGenerator: loss 9.050806045532227\n","Epoch 80, batch 107/240:\tDiscriminator: real loss 0.1308785378932953, fake loss 0.18946979939937592\tGenerator: loss 12.173606872558594\n","Epoch 80, batch 108/240:\tDiscriminator: real loss 0.13288472592830658, fake loss 0.2167501449584961\tGenerator: loss 11.02437973022461\n","Epoch 80, batch 109/240:\tDiscriminator: real loss 0.19379588961601257, fake loss 0.17533284425735474\tGenerator: loss 8.273993492126465\n","Epoch 80, batch 110/240:\tDiscriminator: real loss 0.130768820643425, fake loss 0.07109831273555756\tGenerator: loss 8.044693946838379\n","Epoch 80, batch 111/240:\tDiscriminator: real loss 0.08733899891376495, fake loss 0.20730942487716675\tGenerator: loss 8.811031341552734\n","Epoch 80, batch 112/240:\tDiscriminator: real loss 0.07446645945310593, fake loss 0.09115417301654816\tGenerator: loss 8.81476879119873\n","Epoch 80, batch 113/240:\tDiscriminator: real loss 0.13948214054107666, fake loss 0.18945176899433136\tGenerator: loss 7.6845703125\n","Epoch 80, batch 114/240:\tDiscriminator: real loss 0.12903821468353271, fake loss 0.17909227311611176\tGenerator: loss 6.465943813323975\n","Epoch 80, batch 115/240:\tDiscriminator: real loss 0.10578467696905136, fake loss 0.22326460480690002\tGenerator: loss 7.054938793182373\n","Epoch 80, batch 116/240:\tDiscriminator: real loss 0.11293017119169235, fake loss 0.13293641805648804\tGenerator: loss 8.651503562927246\n","Epoch 80, batch 117/240:\tDiscriminator: real loss 0.11267521232366562, fake loss 0.19573692977428436\tGenerator: loss 8.596246719360352\n","Epoch 80, batch 118/240:\tDiscriminator: real loss 0.21175889670848846, fake loss 0.16333851218223572\tGenerator: loss 11.006041526794434\n","Epoch 80, batch 119/240:\tDiscriminator: real loss 0.0905480608344078, fake loss 0.2189738154411316\tGenerator: loss 11.089930534362793\n","Epoch 80, batch 120/240:\tDiscriminator: real loss 0.08279095590114594, fake loss 0.19067013263702393\tGenerator: loss 10.983508110046387\n","Epoch 80, batch 121/240:\tDiscriminator: real loss 0.16304165124893188, fake loss 0.2749485671520233\tGenerator: loss 9.689868927001953\n","Epoch 80, batch 122/240:\tDiscriminator: real loss 0.25756627321243286, fake loss 0.16947609186172485\tGenerator: loss 7.930690288543701\n","Epoch 80, batch 123/240:\tDiscriminator: real loss 0.14426805078983307, fake loss 0.28225553035736084\tGenerator: loss 8.592501640319824\n","Epoch 80, batch 124/240:\tDiscriminator: real loss 0.14907249808311462, fake loss 0.169285848736763\tGenerator: loss 8.796895027160645\n","Epoch 80, batch 125/240:\tDiscriminator: real loss 0.12037555873394012, fake loss 0.2566072344779968\tGenerator: loss 11.070096015930176\n","Epoch 80, batch 126/240:\tDiscriminator: real loss 0.11511888355016708, fake loss 0.21396975219249725\tGenerator: loss 10.57634162902832\n","Epoch 80, batch 127/240:\tDiscriminator: real loss 0.16885921359062195, fake loss 0.19049163162708282\tGenerator: loss 8.436772346496582\n","Epoch 80, batch 128/240:\tDiscriminator: real loss 0.15660089254379272, fake loss 0.17603610455989838\tGenerator: loss 8.76492977142334\n","Epoch 80, batch 129/240:\tDiscriminator: real loss 0.17863227427005768, fake loss 0.10580866038799286\tGenerator: loss 6.36041259765625\n","Epoch 80, batch 130/240:\tDiscriminator: real loss 0.09665010124444962, fake loss 0.10517188161611557\tGenerator: loss 7.286461353302002\n","Epoch 80, batch 131/240:\tDiscriminator: real loss 0.08767175674438477, fake loss 0.22604137659072876\tGenerator: loss 7.441979885101318\n","Epoch 80, batch 132/240:\tDiscriminator: real loss 0.07838708907365799, fake loss 0.14621399343013763\tGenerator: loss 7.377035617828369\n","Epoch 80, batch 133/240:\tDiscriminator: real loss 0.07482708245515823, fake loss 0.27056029438972473\tGenerator: loss 9.242420196533203\n","Epoch 80, batch 134/240:\tDiscriminator: real loss 0.1577652394771576, fake loss 0.09689834713935852\tGenerator: loss 10.284276962280273\n","Epoch 80, batch 135/240:\tDiscriminator: real loss 0.08075172454118729, fake loss 0.15761247277259827\tGenerator: loss 9.748390197753906\n","Epoch 80, batch 136/240:\tDiscriminator: real loss 0.11388179659843445, fake loss 0.06826376914978027\tGenerator: loss 9.2689847946167\n","Epoch 80, batch 137/240:\tDiscriminator: real loss 0.13820558786392212, fake loss 0.1632142812013626\tGenerator: loss 9.025825500488281\n","Epoch 80, batch 138/240:\tDiscriminator: real loss 0.06875430792570114, fake loss 0.32952582836151123\tGenerator: loss 11.032735824584961\n","Epoch 80, batch 139/240:\tDiscriminator: real loss 0.13451172411441803, fake loss 0.12290306389331818\tGenerator: loss 12.394124984741211\n","Epoch 80, batch 140/240:\tDiscriminator: real loss 0.15555913746356964, fake loss 0.2683454751968384\tGenerator: loss 10.953030586242676\n","Epoch 80, batch 141/240:\tDiscriminator: real loss 0.11878841370344162, fake loss 0.32942038774490356\tGenerator: loss 10.153766632080078\n","Epoch 80, batch 142/240:\tDiscriminator: real loss 0.17742232978343964, fake loss 0.16919463872909546\tGenerator: loss 7.9270195960998535\n","Epoch 80, batch 143/240:\tDiscriminator: real loss 0.18633393943309784, fake loss 0.23433135449886322\tGenerator: loss 8.603972434997559\n","Epoch 80, batch 144/240:\tDiscriminator: real loss 0.08819562941789627, fake loss 0.15004462003707886\tGenerator: loss 9.296696662902832\n","Epoch 80, batch 145/240:\tDiscriminator: real loss 0.17073623836040497, fake loss 0.09311805665493011\tGenerator: loss 8.057387351989746\n","Epoch 80, batch 146/240:\tDiscriminator: real loss 0.129782035946846, fake loss 0.21295326948165894\tGenerator: loss 8.778736114501953\n","Epoch 80, batch 147/240:\tDiscriminator: real loss 0.08054985851049423, fake loss 0.34352338314056396\tGenerator: loss 9.984967231750488\n","Epoch 80, batch 148/240:\tDiscriminator: real loss 0.19248420000076294, fake loss 0.20011520385742188\tGenerator: loss 9.796073913574219\n","Epoch 80, batch 149/240:\tDiscriminator: real loss 0.14364054799079895, fake loss 0.08400900661945343\tGenerator: loss 10.324728012084961\n","Epoch 80, batch 150/240:\tDiscriminator: real loss 0.15081752836704254, fake loss 0.1116957888007164\tGenerator: loss 9.448458671569824\n","Epoch 80, batch 151/240:\tDiscriminator: real loss 0.0922260507941246, fake loss 0.2944841682910919\tGenerator: loss 9.908576011657715\n","Epoch 80, batch 152/240:\tDiscriminator: real loss 0.13772813975811005, fake loss 0.161641463637352\tGenerator: loss 11.305450439453125\n","Epoch 80, batch 153/240:\tDiscriminator: real loss 0.10605515539646149, fake loss 0.2135569006204605\tGenerator: loss 10.248861312866211\n","Epoch 80, batch 154/240:\tDiscriminator: real loss 0.16052952408790588, fake loss 0.1960725039243698\tGenerator: loss 11.148829460144043\n","Epoch 80, batch 155/240:\tDiscriminator: real loss 0.1286012977361679, fake loss 0.17381103336811066\tGenerator: loss 9.77474594116211\n","Epoch 80, batch 156/240:\tDiscriminator: real loss 0.10174955427646637, fake loss 0.20972444117069244\tGenerator: loss 8.81606674194336\n","Epoch 80, batch 157/240:\tDiscriminator: real loss 0.15164321660995483, fake loss 0.13915514945983887\tGenerator: loss 8.398626327514648\n","Epoch 80, batch 158/240:\tDiscriminator: real loss 0.1126987561583519, fake loss 0.22763502597808838\tGenerator: loss 8.790842056274414\n","Epoch 80, batch 159/240:\tDiscriminator: real loss 0.14411699771881104, fake loss 0.08973130583763123\tGenerator: loss 9.546120643615723\n","Epoch 80, batch 160/240:\tDiscriminator: real loss 0.12596946954727173, fake loss 0.2273261845111847\tGenerator: loss 10.020262718200684\n","Epoch 80, batch 161/240:\tDiscriminator: real loss 0.12044858932495117, fake loss 0.1383383572101593\tGenerator: loss 10.616750717163086\n","Epoch 80, batch 162/240:\tDiscriminator: real loss 0.09584638476371765, fake loss 0.31672659516334534\tGenerator: loss 9.782835006713867\n","Epoch 80, batch 163/240:\tDiscriminator: real loss 0.11155864596366882, fake loss 0.20738984644412994\tGenerator: loss 9.307626724243164\n","Epoch 80, batch 164/240:\tDiscriminator: real loss 0.210235133767128, fake loss 0.21946121752262115\tGenerator: loss 8.709988594055176\n","Epoch 80, batch 165/240:\tDiscriminator: real loss 0.14673557877540588, fake loss 0.2597641050815582\tGenerator: loss 9.9981689453125\n","Epoch 80, batch 166/240:\tDiscriminator: real loss 0.16106754541397095, fake loss 0.1704557240009308\tGenerator: loss 11.208876609802246\n","Epoch 80, batch 167/240:\tDiscriminator: real loss 0.17171859741210938, fake loss 0.2063252031803131\tGenerator: loss 9.812363624572754\n","Epoch 80, batch 168/240:\tDiscriminator: real loss 0.13056360185146332, fake loss 0.14762865006923676\tGenerator: loss 10.1758394241333\n","Epoch 80, batch 169/240:\tDiscriminator: real loss 0.09186026453971863, fake loss 0.1403779834508896\tGenerator: loss 8.923563957214355\n","Epoch 80, batch 170/240:\tDiscriminator: real loss 0.14484111964702606, fake loss 0.17436380684375763\tGenerator: loss 7.8686065673828125\n","Epoch 80, batch 171/240:\tDiscriminator: real loss 0.0964592769742012, fake loss 0.1223723441362381\tGenerator: loss 6.257662773132324\n","Epoch 80, batch 172/240:\tDiscriminator: real loss 0.0814332589507103, fake loss 0.32075515389442444\tGenerator: loss 6.183470249176025\n","Epoch 80, batch 173/240:\tDiscriminator: real loss 0.19539248943328857, fake loss 0.16010552644729614\tGenerator: loss 6.194460868835449\n","Epoch 80, batch 174/240:\tDiscriminator: real loss 0.15657271444797516, fake loss 0.20536048710346222\tGenerator: loss 7.477315902709961\n","Epoch 80, batch 175/240:\tDiscriminator: real loss 0.08040155470371246, fake loss 0.2391367405653\tGenerator: loss 7.540592670440674\n","Epoch 80, batch 176/240:\tDiscriminator: real loss 0.11638698726892471, fake loss 0.1796361804008484\tGenerator: loss 7.1023454666137695\n","Epoch 80, batch 177/240:\tDiscriminator: real loss 0.22320786118507385, fake loss 0.17444965243339539\tGenerator: loss 8.808419227600098\n","Epoch 80, batch 178/240:\tDiscriminator: real loss 0.09932014346122742, fake loss 0.24292811751365662\tGenerator: loss 9.441226959228516\n","Epoch 80, batch 179/240:\tDiscriminator: real loss 0.11216334998607635, fake loss 0.3123924732208252\tGenerator: loss 9.481636047363281\n","Epoch 80, batch 180/240:\tDiscriminator: real loss 0.18033622205257416, fake loss 0.13439081609249115\tGenerator: loss 7.707352161407471\n","Epoch 80, batch 181/240:\tDiscriminator: real loss 0.20104706287384033, fake loss 0.08864819258451462\tGenerator: loss 6.836660385131836\n","Epoch 80, batch 182/240:\tDiscriminator: real loss 0.06162051111459732, fake loss 0.2697356641292572\tGenerator: loss 8.210738182067871\n","Epoch 80, batch 183/240:\tDiscriminator: real loss 0.08354765921831131, fake loss 0.24365867674350739\tGenerator: loss 10.68382453918457\n","Epoch 80, batch 184/240:\tDiscriminator: real loss 0.18219316005706787, fake loss 0.337316632270813\tGenerator: loss 9.576427459716797\n","Epoch 80, batch 185/240:\tDiscriminator: real loss 0.1803426295518875, fake loss 0.18253442645072937\tGenerator: loss 10.155875205993652\n","Epoch 80, batch 186/240:\tDiscriminator: real loss 0.1768503189086914, fake loss 0.2704624831676483\tGenerator: loss 9.626618385314941\n","Epoch 80, batch 187/240:\tDiscriminator: real loss 0.22107315063476562, fake loss 0.16513915359973907\tGenerator: loss 10.1984224319458\n","Epoch 80, batch 188/240:\tDiscriminator: real loss 0.15201106667518616, fake loss 0.13730841875076294\tGenerator: loss 10.512173652648926\n","Epoch 80, batch 189/240:\tDiscriminator: real loss 0.21011213958263397, fake loss 0.2638932764530182\tGenerator: loss 7.731845855712891\n","Epoch 80, batch 190/240:\tDiscriminator: real loss 0.09837548434734344, fake loss 0.1765143722295761\tGenerator: loss 7.5126118659973145\n","Epoch 80, batch 191/240:\tDiscriminator: real loss 0.1395297646522522, fake loss 0.16542522609233856\tGenerator: loss 8.543853759765625\n","Epoch 80, batch 192/240:\tDiscriminator: real loss 0.1526251584291458, fake loss 0.2260441780090332\tGenerator: loss 9.043600082397461\n","Epoch 80, batch 193/240:\tDiscriminator: real loss 0.14339779317378998, fake loss 0.3011666238307953\tGenerator: loss 10.316109657287598\n","Epoch 80, batch 194/240:\tDiscriminator: real loss 0.20667824149131775, fake loss 0.14517222344875336\tGenerator: loss 7.371431827545166\n","Epoch 80, batch 195/240:\tDiscriminator: real loss 0.11285693943500519, fake loss 0.19846513867378235\tGenerator: loss 7.084163665771484\n","Epoch 80, batch 196/240:\tDiscriminator: real loss 0.15171951055526733, fake loss 0.2059222161769867\tGenerator: loss 8.194989204406738\n","Epoch 80, batch 197/240:\tDiscriminator: real loss 0.14259691536426544, fake loss 0.30013778805732727\tGenerator: loss 10.013773918151855\n","Epoch 80, batch 198/240:\tDiscriminator: real loss 0.11768512427806854, fake loss 0.1269412636756897\tGenerator: loss 10.609668731689453\n","Epoch 80, batch 199/240:\tDiscriminator: real loss 0.175194650888443, fake loss 0.2924599349498749\tGenerator: loss 9.958979606628418\n","Epoch 80, batch 200/240:\tDiscriminator: real loss 0.13378913700580597, fake loss 0.10645870119333267\tGenerator: loss 9.01565170288086\n","Epoch 80, batch 201/240:\tDiscriminator: real loss 0.13132907450199127, fake loss 0.3164474368095398\tGenerator: loss 10.89086627960205\n","Epoch 80, batch 202/240:\tDiscriminator: real loss 0.12158067524433136, fake loss 0.16609396040439606\tGenerator: loss 11.15910530090332\n","Epoch 80, batch 203/240:\tDiscriminator: real loss 0.22924837470054626, fake loss 0.2991405427455902\tGenerator: loss 8.297690391540527\n","Epoch 80, batch 204/240:\tDiscriminator: real loss 0.09060893207788467, fake loss 0.12744294106960297\tGenerator: loss 7.261587142944336\n","Epoch 80, batch 205/240:\tDiscriminator: real loss 0.16702067852020264, fake loss 0.1509033590555191\tGenerator: loss 10.422843933105469\n","Epoch 80, batch 206/240:\tDiscriminator: real loss 0.16142258048057556, fake loss 0.2700254023075104\tGenerator: loss 13.785412788391113\n","Epoch 80, batch 207/240:\tDiscriminator: real loss 0.1212177574634552, fake loss 0.19990241527557373\tGenerator: loss 14.522793769836426\n","Epoch 80, batch 208/240:\tDiscriminator: real loss 0.2236921489238739, fake loss 0.166640505194664\tGenerator: loss 11.379253387451172\n","Epoch 80, batch 209/240:\tDiscriminator: real loss 0.062404122203588486, fake loss 0.265830397605896\tGenerator: loss 13.5557279586792\n","Epoch 80, batch 210/240:\tDiscriminator: real loss 0.16762672364711761, fake loss 0.16703304648399353\tGenerator: loss 11.401633262634277\n","Epoch 80, batch 211/240:\tDiscriminator: real loss 0.21404461562633514, fake loss 0.15519943833351135\tGenerator: loss 10.856439590454102\n","Epoch 80, batch 212/240:\tDiscriminator: real loss 0.12446808069944382, fake loss 0.41819462180137634\tGenerator: loss 8.528975486755371\n","Epoch 80, batch 213/240:\tDiscriminator: real loss 0.1739829182624817, fake loss 0.09638521075248718\tGenerator: loss 8.768939018249512\n","Epoch 80, batch 214/240:\tDiscriminator: real loss 0.12555107474327087, fake loss 0.13021788001060486\tGenerator: loss 7.736486911773682\n","Epoch 80, batch 215/240:\tDiscriminator: real loss 0.09408273547887802, fake loss 0.2432442605495453\tGenerator: loss 7.890225410461426\n","Epoch 80, batch 216/240:\tDiscriminator: real loss 0.12397292256355286, fake loss 0.28576597571372986\tGenerator: loss 7.613050937652588\n","Epoch 80, batch 217/240:\tDiscriminator: real loss 0.17645245790481567, fake loss 0.14020130038261414\tGenerator: loss 10.651886940002441\n","Epoch 80, batch 218/240:\tDiscriminator: real loss 0.11993895471096039, fake loss 0.2640429735183716\tGenerator: loss 12.552552223205566\n","Epoch 80, batch 219/240:\tDiscriminator: real loss 0.1791820526123047, fake loss 0.26335886120796204\tGenerator: loss 14.389948844909668\n","Epoch 80, batch 220/240:\tDiscriminator: real loss 0.16880246996879578, fake loss 0.21796683967113495\tGenerator: loss 13.791647911071777\n","Epoch 80, batch 221/240:\tDiscriminator: real loss 0.1477229744195938, fake loss 0.10940071195363998\tGenerator: loss 11.89599895477295\n","Epoch 80, batch 222/240:\tDiscriminator: real loss 0.14499101042747498, fake loss 0.21694785356521606\tGenerator: loss 10.187973976135254\n","Epoch 80, batch 223/240:\tDiscriminator: real loss 0.1629510074853897, fake loss 0.24127304553985596\tGenerator: loss 9.866460800170898\n","Epoch 80, batch 224/240:\tDiscriminator: real loss 0.10455905646085739, fake loss 0.16679368913173676\tGenerator: loss 9.191904067993164\n","Epoch 80, batch 225/240:\tDiscriminator: real loss 0.16643142700195312, fake loss 0.07464602589607239\tGenerator: loss 9.338695526123047\n","Epoch 80, batch 226/240:\tDiscriminator: real loss 0.07637355476617813, fake loss 0.3530380129814148\tGenerator: loss 9.519648551940918\n","Epoch 80, batch 227/240:\tDiscriminator: real loss 0.1487697958946228, fake loss 0.18558503687381744\tGenerator: loss 10.575366020202637\n","Epoch 80, batch 228/240:\tDiscriminator: real loss 0.12432973086833954, fake loss 0.13531209528446198\tGenerator: loss 11.328024864196777\n","Epoch 80, batch 229/240:\tDiscriminator: real loss 0.129897341132164, fake loss 0.31251421570777893\tGenerator: loss 12.094761848449707\n","Epoch 80, batch 230/240:\tDiscriminator: real loss 0.1906142234802246, fake loss 0.10790731757879257\tGenerator: loss 10.83728313446045\n","Epoch 80, batch 231/240:\tDiscriminator: real loss 0.1721053272485733, fake loss 0.12989072501659393\tGenerator: loss 9.834510803222656\n","Epoch 80, batch 232/240:\tDiscriminator: real loss 0.09418866783380508, fake loss 0.16775695979595184\tGenerator: loss 10.371014595031738\n","Epoch 80, batch 233/240:\tDiscriminator: real loss 0.08864852786064148, fake loss 0.15002480149269104\tGenerator: loss 9.93754768371582\n","Epoch 80, batch 234/240:\tDiscriminator: real loss 0.08386127650737762, fake loss 0.1787809580564499\tGenerator: loss 8.419403076171875\n","Epoch 80, batch 235/240:\tDiscriminator: real loss 0.11357942223548889, fake loss 0.26589611172676086\tGenerator: loss 9.794205665588379\n","Epoch 80, batch 236/240:\tDiscriminator: real loss 0.1592516452074051, fake loss 0.3077846169471741\tGenerator: loss 10.693984031677246\n","Epoch 80, batch 237/240:\tDiscriminator: real loss 0.19916141033172607, fake loss 0.16008684039115906\tGenerator: loss 11.307317733764648\n","Epoch 80, batch 238/240:\tDiscriminator: real loss 0.2023545205593109, fake loss 0.24429233372211456\tGenerator: loss 10.424098014831543\n","Epoch 80, batch 239/240:\tDiscriminator: real loss 0.12210600078105927, fake loss 0.18552787601947784\tGenerator: loss 10.771631240844727\n","Epoch 80, batch 240/240:\tDiscriminator: real loss 0.08520876616239548, fake loss 0.18354715406894684\tGenerator: loss 11.322176933288574\n","Epoch 81, batch 1/240:\tDiscriminator: real loss 0.12323669344186783, fake loss 0.2139294594526291\tGenerator: loss 11.382899284362793\n","Epoch 81, batch 2/240:\tDiscriminator: real loss 0.17444251477718353, fake loss 0.21900074183940887\tGenerator: loss 9.483168601989746\n","Epoch 81, batch 3/240:\tDiscriminator: real loss 0.12759116291999817, fake loss 0.14887522161006927\tGenerator: loss 10.563976287841797\n","Epoch 81, batch 4/240:\tDiscriminator: real loss 0.08495242148637772, fake loss 0.22787436842918396\tGenerator: loss 8.274030685424805\n","Epoch 81, batch 5/240:\tDiscriminator: real loss 0.22689397633075714, fake loss 0.0848810076713562\tGenerator: loss 8.055769920349121\n","Epoch 81, batch 6/240:\tDiscriminator: real loss 0.17942900955677032, fake loss 0.3227868378162384\tGenerator: loss 7.438584804534912\n","Epoch 81, batch 7/240:\tDiscriminator: real loss 0.07720161229372025, fake loss 0.24474768340587616\tGenerator: loss 9.605010032653809\n","Epoch 81, batch 8/240:\tDiscriminator: real loss 0.1198912262916565, fake loss 0.18844398856163025\tGenerator: loss 9.661737442016602\n","Epoch 81, batch 9/240:\tDiscriminator: real loss 0.18037749826908112, fake loss 0.2553667426109314\tGenerator: loss 10.68687629699707\n","Epoch 81, batch 10/240:\tDiscriminator: real loss 0.1486937552690506, fake loss 0.14348477125167847\tGenerator: loss 10.934893608093262\n","Epoch 81, batch 11/240:\tDiscriminator: real loss 0.2019932121038437, fake loss 0.2035888284444809\tGenerator: loss 9.092009544372559\n","Epoch 81, batch 12/240:\tDiscriminator: real loss 0.1315997689962387, fake loss 0.22487720847129822\tGenerator: loss 8.943994522094727\n","Epoch 81, batch 13/240:\tDiscriminator: real loss 0.1100706085562706, fake loss 0.20835724472999573\tGenerator: loss 9.026747703552246\n","Epoch 81, batch 14/240:\tDiscriminator: real loss 0.11326470971107483, fake loss 0.24968837201595306\tGenerator: loss 10.311152458190918\n","Epoch 81, batch 15/240:\tDiscriminator: real loss 0.19928878545761108, fake loss 0.1382272094488144\tGenerator: loss 8.393082618713379\n","Epoch 81, batch 16/240:\tDiscriminator: real loss 0.16805480420589447, fake loss 0.18536853790283203\tGenerator: loss 6.302062511444092\n","Epoch 81, batch 17/240:\tDiscriminator: real loss 0.08772511780261993, fake loss 0.31248652935028076\tGenerator: loss 6.961018085479736\n","Epoch 81, batch 18/240:\tDiscriminator: real loss 0.12876668572425842, fake loss 0.15284329652786255\tGenerator: loss 8.11404037475586\n","Epoch 81, batch 19/240:\tDiscriminator: real loss 0.2031790018081665, fake loss 0.11661072075366974\tGenerator: loss 8.758360862731934\n","Epoch 81, batch 20/240:\tDiscriminator: real loss 0.09878318756818771, fake loss 0.16868694126605988\tGenerator: loss 7.167870998382568\n","Epoch 81, batch 21/240:\tDiscriminator: real loss 0.09085363149642944, fake loss 0.2104606181383133\tGenerator: loss 7.444400787353516\n","Epoch 81, batch 22/240:\tDiscriminator: real loss 0.13971351087093353, fake loss 0.3137120008468628\tGenerator: loss 9.813523292541504\n","Epoch 81, batch 23/240:\tDiscriminator: real loss 0.14329630136489868, fake loss 0.24300438165664673\tGenerator: loss 12.187507629394531\n","Epoch 81, batch 24/240:\tDiscriminator: real loss 0.31181469559669495, fake loss 0.24979566037654877\tGenerator: loss 10.716583251953125\n","Epoch 81, batch 25/240:\tDiscriminator: real loss 0.10292835533618927, fake loss 0.154502734541893\tGenerator: loss 10.471280097961426\n","Epoch 81, batch 26/240:\tDiscriminator: real loss 0.16597415506839752, fake loss 0.19116485118865967\tGenerator: loss 12.427072525024414\n","Epoch 81, batch 27/240:\tDiscriminator: real loss 0.11413036286830902, fake loss 0.23380790650844574\tGenerator: loss 13.605015754699707\n","Epoch 81, batch 28/240:\tDiscriminator: real loss 0.14515814185142517, fake loss 0.08323907852172852\tGenerator: loss 12.230168342590332\n","Epoch 81, batch 29/240:\tDiscriminator: real loss 0.11491464823484421, fake loss 0.23060940206050873\tGenerator: loss 10.870647430419922\n","Epoch 81, batch 30/240:\tDiscriminator: real loss 0.1516677737236023, fake loss 0.3252798318862915\tGenerator: loss 10.428632736206055\n","Epoch 81, batch 31/240:\tDiscriminator: real loss 0.1643088310956955, fake loss 0.11256370693445206\tGenerator: loss 9.304956436157227\n","Epoch 81, batch 32/240:\tDiscriminator: real loss 0.1278512328863144, fake loss 0.20595711469650269\tGenerator: loss 10.839585304260254\n","Epoch 81, batch 33/240:\tDiscriminator: real loss 0.15362605452537537, fake loss 0.18315763771533966\tGenerator: loss 10.281235694885254\n","Epoch 81, batch 34/240:\tDiscriminator: real loss 0.14879626035690308, fake loss 0.3238278329372406\tGenerator: loss 8.128127098083496\n","Epoch 81, batch 35/240:\tDiscriminator: real loss 0.15904633700847626, fake loss 0.27419453859329224\tGenerator: loss 8.154473304748535\n","Epoch 81, batch 36/240:\tDiscriminator: real loss 0.23254328966140747, fake loss 0.12425609678030014\tGenerator: loss 6.607112407684326\n","Epoch 81, batch 37/240:\tDiscriminator: real loss 0.14196224510669708, fake loss 0.19727981090545654\tGenerator: loss 6.895965576171875\n","Epoch 81, batch 38/240:\tDiscriminator: real loss 0.14635935425758362, fake loss 0.2890603542327881\tGenerator: loss 9.268294334411621\n","Epoch 81, batch 39/240:\tDiscriminator: real loss 0.11309599131345749, fake loss 0.11327437311410904\tGenerator: loss 9.81528091430664\n","Epoch 81, batch 40/240:\tDiscriminator: real loss 0.09714427590370178, fake loss 0.24568864703178406\tGenerator: loss 9.628615379333496\n","Epoch 81, batch 41/240:\tDiscriminator: real loss 0.1033996120095253, fake loss 0.3245680332183838\tGenerator: loss 10.32675552368164\n","Epoch 81, batch 42/240:\tDiscriminator: real loss 0.14464960992336273, fake loss 0.2135535478591919\tGenerator: loss 13.434941291809082\n","Epoch 81, batch 43/240:\tDiscriminator: real loss 0.20854784548282623, fake loss 0.25551941990852356\tGenerator: loss 11.021465301513672\n","Epoch 81, batch 44/240:\tDiscriminator: real loss 0.11726680397987366, fake loss 0.2248646318912506\tGenerator: loss 10.65176010131836\n","Epoch 81, batch 45/240:\tDiscriminator: real loss 0.10822974145412445, fake loss 0.1858116090297699\tGenerator: loss 10.595353126525879\n","Epoch 81, batch 46/240:\tDiscriminator: real loss 0.2509436309337616, fake loss 0.2659648060798645\tGenerator: loss 10.548988342285156\n","Epoch 81, batch 47/240:\tDiscriminator: real loss 0.10988304018974304, fake loss 0.17275531589984894\tGenerator: loss 10.212482452392578\n","Epoch 81, batch 48/240:\tDiscriminator: real loss 0.17891067266464233, fake loss 0.22059878706932068\tGenerator: loss 13.678956031799316\n","Epoch 81, batch 49/240:\tDiscriminator: real loss 0.1133367270231247, fake loss 0.15583133697509766\tGenerator: loss 13.746260643005371\n","Epoch 81, batch 50/240:\tDiscriminator: real loss 0.1325487196445465, fake loss 0.16164003312587738\tGenerator: loss 13.397522926330566\n","Epoch 81, batch 51/240:\tDiscriminator: real loss 0.10709970444440842, fake loss 0.18497677147388458\tGenerator: loss 13.228654861450195\n","Epoch 81, batch 52/240:\tDiscriminator: real loss 0.13621214032173157, fake loss 0.2037254124879837\tGenerator: loss 13.33373737335205\n","Epoch 81, batch 53/240:\tDiscriminator: real loss 0.10108373314142227, fake loss 0.17433929443359375\tGenerator: loss 13.048186302185059\n","Epoch 81, batch 54/240:\tDiscriminator: real loss 0.10044776648283005, fake loss 0.12137249112129211\tGenerator: loss 12.609711647033691\n","Epoch 81, batch 55/240:\tDiscriminator: real loss 0.1708465963602066, fake loss 0.22371113300323486\tGenerator: loss 10.252291679382324\n","Epoch 81, batch 56/240:\tDiscriminator: real loss 0.13542823493480682, fake loss 0.2268471121788025\tGenerator: loss 10.460528373718262\n","Epoch 81, batch 57/240:\tDiscriminator: real loss 0.1386495977640152, fake loss 0.06918920576572418\tGenerator: loss 11.199451446533203\n","Epoch 81, batch 58/240:\tDiscriminator: real loss 0.11575817316770554, fake loss 0.16936592757701874\tGenerator: loss 13.556967735290527\n","Epoch 81, batch 59/240:\tDiscriminator: real loss 0.17727309465408325, fake loss 0.22129513323307037\tGenerator: loss 13.666703224182129\n","Epoch 81, batch 60/240:\tDiscriminator: real loss 0.08875072747468948, fake loss 0.17123690247535706\tGenerator: loss 12.499117851257324\n","Epoch 81, batch 61/240:\tDiscriminator: real loss 0.1026146337389946, fake loss 0.16399118304252625\tGenerator: loss 14.69092082977295\n","Epoch 81, batch 62/240:\tDiscriminator: real loss 0.15741771459579468, fake loss 0.34208282828330994\tGenerator: loss 14.153877258300781\n","Epoch 81, batch 63/240:\tDiscriminator: real loss 0.14217936992645264, fake loss 0.3406996428966522\tGenerator: loss 13.733240127563477\n","Epoch 81, batch 64/240:\tDiscriminator: real loss 0.1961199939250946, fake loss 0.1454884111881256\tGenerator: loss 13.312854766845703\n","Epoch 81, batch 65/240:\tDiscriminator: real loss 0.16471385955810547, fake loss 0.19825637340545654\tGenerator: loss 11.810155868530273\n","Epoch 81, batch 66/240:\tDiscriminator: real loss 0.2221577763557434, fake loss 0.3746801018714905\tGenerator: loss 12.089700698852539\n","Epoch 81, batch 67/240:\tDiscriminator: real loss 0.09395187348127365, fake loss 0.17544837296009064\tGenerator: loss 11.337580680847168\n","Epoch 81, batch 68/240:\tDiscriminator: real loss 0.20474357903003693, fake loss 0.1309252381324768\tGenerator: loss 11.037646293640137\n","Epoch 81, batch 69/240:\tDiscriminator: real loss 0.10909035056829453, fake loss 0.34564208984375\tGenerator: loss 12.315799713134766\n","Epoch 81, batch 70/240:\tDiscriminator: real loss 0.14326325058937073, fake loss 0.18077203631401062\tGenerator: loss 13.214159965515137\n","Epoch 81, batch 71/240:\tDiscriminator: real loss 0.1472981572151184, fake loss 0.264459490776062\tGenerator: loss 12.250349044799805\n","Epoch 81, batch 72/240:\tDiscriminator: real loss 0.17106226086616516, fake loss 0.13767822086811066\tGenerator: loss 9.453064918518066\n","Epoch 81, batch 73/240:\tDiscriminator: real loss 0.2312799096107483, fake loss 0.15611329674720764\tGenerator: loss 9.267963409423828\n","Epoch 81, batch 74/240:\tDiscriminator: real loss 0.13399776816368103, fake loss 0.11032775789499283\tGenerator: loss 10.568367958068848\n","Epoch 81, batch 75/240:\tDiscriminator: real loss 0.10232982039451599, fake loss 0.10704126209020615\tGenerator: loss 11.749842643737793\n","Epoch 81, batch 76/240:\tDiscriminator: real loss 0.06497778743505478, fake loss 0.16732753813266754\tGenerator: loss 10.982321739196777\n","Epoch 81, batch 77/240:\tDiscriminator: real loss 0.09468219429254532, fake loss 0.2598661780357361\tGenerator: loss 11.191946029663086\n","Epoch 81, batch 78/240:\tDiscriminator: real loss 0.07529251277446747, fake loss 0.09638156741857529\tGenerator: loss 13.052238464355469\n","Epoch 81, batch 79/240:\tDiscriminator: real loss 0.16747599840164185, fake loss 0.21618644893169403\tGenerator: loss 13.705347061157227\n","Epoch 81, batch 80/240:\tDiscriminator: real loss 0.2648520767688751, fake loss 0.1857246458530426\tGenerator: loss 8.057840347290039\n","Epoch 81, batch 81/240:\tDiscriminator: real loss 0.1261690855026245, fake loss 0.22524616122245789\tGenerator: loss 8.110692977905273\n","Epoch 81, batch 82/240:\tDiscriminator: real loss 0.1815589964389801, fake loss 0.10842834413051605\tGenerator: loss 8.265847206115723\n","Epoch 81, batch 83/240:\tDiscriminator: real loss 0.07084889709949493, fake loss 0.3842891752719879\tGenerator: loss 10.062357902526855\n","Epoch 81, batch 84/240:\tDiscriminator: real loss 0.0980316698551178, fake loss 0.22150270640850067\tGenerator: loss 11.48376750946045\n","Epoch 81, batch 85/240:\tDiscriminator: real loss 0.1457929015159607, fake loss 0.19531795382499695\tGenerator: loss 11.905284881591797\n","Epoch 81, batch 86/240:\tDiscriminator: real loss 0.16962078213691711, fake loss 0.1295655220746994\tGenerator: loss 10.867554664611816\n","Epoch 81, batch 87/240:\tDiscriminator: real loss 0.1234387457370758, fake loss 0.33286774158477783\tGenerator: loss 9.123656272888184\n","Epoch 81, batch 88/240:\tDiscriminator: real loss 0.10617513954639435, fake loss 0.11766067147254944\tGenerator: loss 8.424700736999512\n","Epoch 81, batch 89/240:\tDiscriminator: real loss 0.13580887019634247, fake loss 0.11763569712638855\tGenerator: loss 7.9635396003723145\n","Epoch 81, batch 90/240:\tDiscriminator: real loss 0.07775402814149857, fake loss 0.25328055024147034\tGenerator: loss 9.449860572814941\n","Epoch 81, batch 91/240:\tDiscriminator: real loss 0.1100732609629631, fake loss 0.2814507782459259\tGenerator: loss 12.837657928466797\n","Epoch 81, batch 92/240:\tDiscriminator: real loss 0.1588265597820282, fake loss 0.14780844748020172\tGenerator: loss 11.941262245178223\n","Epoch 81, batch 93/240:\tDiscriminator: real loss 0.1941128373146057, fake loss 0.18188777565956116\tGenerator: loss 10.758404731750488\n","Epoch 81, batch 94/240:\tDiscriminator: real loss 0.0724470242857933, fake loss 0.30580469965934753\tGenerator: loss 12.060288429260254\n","Epoch 81, batch 95/240:\tDiscriminator: real loss 0.1703547239303589, fake loss 0.17873847484588623\tGenerator: loss 9.903462409973145\n","Epoch 81, batch 96/240:\tDiscriminator: real loss 0.1547631472349167, fake loss 0.05757908523082733\tGenerator: loss 8.53126049041748\n","Epoch 81, batch 97/240:\tDiscriminator: real loss 0.11940824240446091, fake loss 0.2623082101345062\tGenerator: loss 7.50901985168457\n","Epoch 81, batch 98/240:\tDiscriminator: real loss 0.08199496567249298, fake loss 0.07234656065702438\tGenerator: loss 7.275765895843506\n","Epoch 81, batch 99/240:\tDiscriminator: real loss 0.15107285976409912, fake loss 0.18363754451274872\tGenerator: loss 9.614995002746582\n","Epoch 81, batch 100/240:\tDiscriminator: real loss 0.07135897874832153, fake loss 0.15504872798919678\tGenerator: loss 9.8785982131958\n","Epoch 81, batch 101/240:\tDiscriminator: real loss 0.10997007042169571, fake loss 0.20047713816165924\tGenerator: loss 12.225215911865234\n","Epoch 81, batch 102/240:\tDiscriminator: real loss 0.123833067715168, fake loss 0.18806694447994232\tGenerator: loss 12.249137878417969\n","Epoch 81, batch 103/240:\tDiscriminator: real loss 0.13313810527324677, fake loss 0.2382490336894989\tGenerator: loss 11.232813835144043\n","Epoch 81, batch 104/240:\tDiscriminator: real loss 0.11771000176668167, fake loss 0.17273788154125214\tGenerator: loss 13.023425102233887\n","Epoch 81, batch 105/240:\tDiscriminator: real loss 0.12858860194683075, fake loss 0.2686774432659149\tGenerator: loss 10.820560455322266\n","Epoch 81, batch 106/240:\tDiscriminator: real loss 0.14974650740623474, fake loss 0.21651417016983032\tGenerator: loss 12.575898170471191\n","Epoch 81, batch 107/240:\tDiscriminator: real loss 0.1801283210515976, fake loss 0.13556347787380219\tGenerator: loss 10.755741119384766\n","Epoch 81, batch 108/240:\tDiscriminator: real loss 0.10486462712287903, fake loss 0.17284181714057922\tGenerator: loss 9.843467712402344\n","Epoch 81, batch 109/240:\tDiscriminator: real loss 0.08079671859741211, fake loss 0.226199671626091\tGenerator: loss 10.387909889221191\n","Epoch 81, batch 110/240:\tDiscriminator: real loss 0.15052781999111176, fake loss 0.21686102449893951\tGenerator: loss 12.695120811462402\n","Epoch 81, batch 111/240:\tDiscriminator: real loss 0.11261314153671265, fake loss 0.31301602721214294\tGenerator: loss 13.323433876037598\n","Epoch 81, batch 112/240:\tDiscriminator: real loss 0.1310126632452011, fake loss 0.08851558715105057\tGenerator: loss 10.437156677246094\n","Epoch 81, batch 113/240:\tDiscriminator: real loss 0.2456628829240799, fake loss 0.21527451276779175\tGenerator: loss 9.958392143249512\n","Epoch 81, batch 114/240:\tDiscriminator: real loss 0.1584513783454895, fake loss 0.22738438844680786\tGenerator: loss 9.97238540649414\n","Epoch 81, batch 115/240:\tDiscriminator: real loss 0.11014729738235474, fake loss 0.27294161915779114\tGenerator: loss 10.151806831359863\n","Epoch 81, batch 116/240:\tDiscriminator: real loss 0.16046252846717834, fake loss 0.18219101428985596\tGenerator: loss 10.373405456542969\n","Epoch 81, batch 117/240:\tDiscriminator: real loss 0.16805051267147064, fake loss 0.1072610467672348\tGenerator: loss 9.214305877685547\n","Epoch 81, batch 118/240:\tDiscriminator: real loss 0.16189521551132202, fake loss 0.1829737275838852\tGenerator: loss 8.296095848083496\n","Epoch 81, batch 119/240:\tDiscriminator: real loss 0.07813306152820587, fake loss 0.1271175742149353\tGenerator: loss 9.317509651184082\n","Epoch 81, batch 120/240:\tDiscriminator: real loss 0.05194544419646263, fake loss 0.2026824951171875\tGenerator: loss 9.542052268981934\n","Epoch 81, batch 121/240:\tDiscriminator: real loss 0.15440860390663147, fake loss 0.185123011469841\tGenerator: loss 11.026049613952637\n","Epoch 81, batch 122/240:\tDiscriminator: real loss 0.09868782013654709, fake loss 0.22228676080703735\tGenerator: loss 12.35047721862793\n","Epoch 81, batch 123/240:\tDiscriminator: real loss 0.11952564865350723, fake loss 0.3007611930370331\tGenerator: loss 14.135699272155762\n","Epoch 81, batch 124/240:\tDiscriminator: real loss 0.24837236106395721, fake loss 0.2968021035194397\tGenerator: loss 10.384944915771484\n","Epoch 81, batch 125/240:\tDiscriminator: real loss 0.197864830493927, fake loss 0.11193636059761047\tGenerator: loss 11.408321380615234\n","Epoch 81, batch 126/240:\tDiscriminator: real loss 0.1469842493534088, fake loss 0.31140604615211487\tGenerator: loss 9.364022254943848\n","Epoch 81, batch 127/240:\tDiscriminator: real loss 0.15949352085590363, fake loss 0.1402624249458313\tGenerator: loss 8.635467529296875\n","Epoch 81, batch 128/240:\tDiscriminator: real loss 0.07943738251924515, fake loss 0.11481321603059769\tGenerator: loss 8.737150192260742\n","Epoch 81, batch 129/240:\tDiscriminator: real loss 0.13130639493465424, fake loss 0.1177622377872467\tGenerator: loss 9.178210258483887\n","Epoch 81, batch 130/240:\tDiscriminator: real loss 0.08285505324602127, fake loss 0.1723652333021164\tGenerator: loss 8.776866912841797\n","Epoch 81, batch 131/240:\tDiscriminator: real loss 0.08800606429576874, fake loss 0.2374921441078186\tGenerator: loss 9.865372657775879\n","Epoch 81, batch 132/240:\tDiscriminator: real loss 0.11045995354652405, fake loss 0.38176101446151733\tGenerator: loss 9.342546463012695\n","Epoch 81, batch 133/240:\tDiscriminator: real loss 0.19099141657352448, fake loss 0.1712050586938858\tGenerator: loss 11.461514472961426\n","Epoch 81, batch 134/240:\tDiscriminator: real loss 0.17510972917079926, fake loss 0.1679122895002365\tGenerator: loss 10.938726425170898\n","Epoch 81, batch 135/240:\tDiscriminator: real loss 0.1562747061252594, fake loss 0.14395254850387573\tGenerator: loss 13.565446853637695\n","Epoch 81, batch 136/240:\tDiscriminator: real loss 0.10583226382732391, fake loss 0.2269950658082962\tGenerator: loss 12.275294303894043\n","Epoch 81, batch 137/240:\tDiscriminator: real loss 0.12805497646331787, fake loss 0.44772469997406006\tGenerator: loss 12.210075378417969\n","Epoch 81, batch 138/240:\tDiscriminator: real loss 0.2569781243801117, fake loss 0.1402529776096344\tGenerator: loss 9.97925090789795\n","Epoch 81, batch 139/240:\tDiscriminator: real loss 0.21238049864768982, fake loss 0.13607312738895416\tGenerator: loss 8.499078750610352\n","Epoch 81, batch 140/240:\tDiscriminator: real loss 0.07518690824508667, fake loss 0.36425530910491943\tGenerator: loss 10.905543327331543\n","Epoch 81, batch 141/240:\tDiscriminator: real loss 0.1283993124961853, fake loss 0.17967194318771362\tGenerator: loss 13.142041206359863\n","Epoch 81, batch 142/240:\tDiscriminator: real loss 0.21462669968605042, fake loss 0.11539537459611893\tGenerator: loss 10.574601173400879\n","Epoch 81, batch 143/240:\tDiscriminator: real loss 0.09164813905954361, fake loss 0.15615509450435638\tGenerator: loss 8.911195755004883\n","Epoch 81, batch 144/240:\tDiscriminator: real loss 0.1452905535697937, fake loss 0.24502365291118622\tGenerator: loss 6.858259201049805\n","Epoch 81, batch 145/240:\tDiscriminator: real loss 0.08480419218540192, fake loss 0.2755638062953949\tGenerator: loss 8.243375778198242\n","Epoch 81, batch 146/240:\tDiscriminator: real loss 0.18418428301811218, fake loss 0.15635362267494202\tGenerator: loss 10.146177291870117\n","Epoch 81, batch 147/240:\tDiscriminator: real loss 0.15403476357460022, fake loss 0.12896966934204102\tGenerator: loss 11.429021835327148\n","Epoch 81, batch 148/240:\tDiscriminator: real loss 0.09265473484992981, fake loss 0.2187328189611435\tGenerator: loss 11.55357551574707\n","Epoch 81, batch 149/240:\tDiscriminator: real loss 0.07321452349424362, fake loss 0.20589502155780792\tGenerator: loss 14.719417572021484\n","Epoch 81, batch 150/240:\tDiscriminator: real loss 0.17560173571109772, fake loss 0.2006218582391739\tGenerator: loss 11.440703392028809\n","Epoch 81, batch 151/240:\tDiscriminator: real loss 0.20558924973011017, fake loss 0.11978483200073242\tGenerator: loss 8.720256805419922\n","Epoch 81, batch 152/240:\tDiscriminator: real loss 0.11245686560869217, fake loss 0.23213371634483337\tGenerator: loss 8.695934295654297\n","Epoch 81, batch 153/240:\tDiscriminator: real loss 0.1522858589887619, fake loss 0.09464762359857559\tGenerator: loss 8.435863494873047\n","Epoch 81, batch 154/240:\tDiscriminator: real loss 0.09093400835990906, fake loss 0.19970661401748657\tGenerator: loss 8.642240524291992\n","Epoch 81, batch 155/240:\tDiscriminator: real loss 0.13708852231502533, fake loss 0.2914489209651947\tGenerator: loss 10.274197578430176\n","Epoch 81, batch 156/240:\tDiscriminator: real loss 0.13679495453834534, fake loss 0.13296860456466675\tGenerator: loss 11.441431045532227\n","Epoch 81, batch 157/240:\tDiscriminator: real loss 0.16564859449863434, fake loss 0.15135180950164795\tGenerator: loss 11.365545272827148\n","Epoch 81, batch 158/240:\tDiscriminator: real loss 0.1530829221010208, fake loss 0.12870055437088013\tGenerator: loss 10.998435974121094\n","Epoch 81, batch 159/240:\tDiscriminator: real loss 0.08646000921726227, fake loss 0.28993478417396545\tGenerator: loss 10.485396385192871\n","Epoch 81, batch 160/240:\tDiscriminator: real loss 0.13216768205165863, fake loss 0.12058386206626892\tGenerator: loss 10.639498710632324\n","Epoch 81, batch 161/240:\tDiscriminator: real loss 0.15858621895313263, fake loss 0.15117871761322021\tGenerator: loss 10.58668327331543\n","Epoch 81, batch 162/240:\tDiscriminator: real loss 0.13224709033966064, fake loss 0.21005922555923462\tGenerator: loss 10.838632583618164\n","Epoch 81, batch 163/240:\tDiscriminator: real loss 0.14487765729427338, fake loss 0.387025386095047\tGenerator: loss 9.408103942871094\n","Epoch 81, batch 164/240:\tDiscriminator: real loss 0.11222938448190689, fake loss 0.09515891224145889\tGenerator: loss 8.712093353271484\n","Epoch 81, batch 165/240:\tDiscriminator: real loss 0.1435023844242096, fake loss 0.32103630900382996\tGenerator: loss 8.744344711303711\n","Epoch 81, batch 166/240:\tDiscriminator: real loss 0.16356125473976135, fake loss 0.1395278424024582\tGenerator: loss 8.304795265197754\n","Epoch 81, batch 167/240:\tDiscriminator: real loss 0.13494032621383667, fake loss 0.2867145836353302\tGenerator: loss 8.480966567993164\n","Epoch 81, batch 168/240:\tDiscriminator: real loss 0.13396520912647247, fake loss 0.10931862890720367\tGenerator: loss 8.162189483642578\n","Epoch 81, batch 169/240:\tDiscriminator: real loss 0.10705182701349258, fake loss 0.18389074504375458\tGenerator: loss 8.695741653442383\n","Epoch 81, batch 170/240:\tDiscriminator: real loss 0.13779523968696594, fake loss 0.13703647255897522\tGenerator: loss 9.728370666503906\n","Epoch 81, batch 171/240:\tDiscriminator: real loss 0.07513639330863953, fake loss 0.1198267713189125\tGenerator: loss 10.60368537902832\n","Epoch 81, batch 172/240:\tDiscriminator: real loss 0.08402466773986816, fake loss 0.1924976408481598\tGenerator: loss 9.9146089553833\n","Epoch 81, batch 173/240:\tDiscriminator: real loss 0.09638229012489319, fake loss 0.16435471177101135\tGenerator: loss 10.437494277954102\n","Epoch 81, batch 174/240:\tDiscriminator: real loss 0.1394290328025818, fake loss 0.2713299095630646\tGenerator: loss 10.360815048217773\n","Epoch 81, batch 175/240:\tDiscriminator: real loss 0.15574178099632263, fake loss 0.26763972640037537\tGenerator: loss 11.087319374084473\n","Epoch 81, batch 176/240:\tDiscriminator: real loss 0.21348220109939575, fake loss 0.19548213481903076\tGenerator: loss 10.037471771240234\n","Epoch 81, batch 177/240:\tDiscriminator: real loss 0.17191970348358154, fake loss 0.18429231643676758\tGenerator: loss 10.737024307250977\n","Epoch 81, batch 178/240:\tDiscriminator: real loss 0.09373879432678223, fake loss 0.09096162766218185\tGenerator: loss 10.844128608703613\n","Epoch 81, batch 179/240:\tDiscriminator: real loss 0.10404423624277115, fake loss 0.19245938956737518\tGenerator: loss 9.09261703491211\n","Epoch 81, batch 180/240:\tDiscriminator: real loss 0.22470968961715698, fake loss 0.23256903886795044\tGenerator: loss 7.216497898101807\n","Epoch 81, batch 181/240:\tDiscriminator: real loss 0.15625090897083282, fake loss 0.2906108796596527\tGenerator: loss 8.511127471923828\n","Epoch 81, batch 182/240:\tDiscriminator: real loss 0.12905733287334442, fake loss 0.2590555250644684\tGenerator: loss 8.166934967041016\n","Epoch 81, batch 183/240:\tDiscriminator: real loss 0.14845283329486847, fake loss 0.18379682302474976\tGenerator: loss 6.751162528991699\n","Epoch 81, batch 184/240:\tDiscriminator: real loss 0.31929847598075867, fake loss 0.28026995062828064\tGenerator: loss 12.256452560424805\n","Epoch 81, batch 185/240:\tDiscriminator: real loss 0.16610412299633026, fake loss 0.1973370611667633\tGenerator: loss 11.403237342834473\n","Epoch 81, batch 186/240:\tDiscriminator: real loss 0.10005733370780945, fake loss 0.20078732073307037\tGenerator: loss 11.940962791442871\n","Epoch 81, batch 187/240:\tDiscriminator: real loss 0.09580864012241364, fake loss 0.19189457595348358\tGenerator: loss 12.612813949584961\n","Epoch 81, batch 188/240:\tDiscriminator: real loss 0.17437762022018433, fake loss 0.246306911110878\tGenerator: loss 13.053754806518555\n","Epoch 81, batch 189/240:\tDiscriminator: real loss 0.12087550759315491, fake loss 0.17071013152599335\tGenerator: loss 12.020003318786621\n","Epoch 81, batch 190/240:\tDiscriminator: real loss 0.17676283419132233, fake loss 0.28192389011383057\tGenerator: loss 11.62747573852539\n","Epoch 81, batch 191/240:\tDiscriminator: real loss 0.1500171720981598, fake loss 0.2070247232913971\tGenerator: loss 11.491771697998047\n","Epoch 81, batch 192/240:\tDiscriminator: real loss 0.13744594156742096, fake loss 0.21274656057357788\tGenerator: loss 13.407654762268066\n","Epoch 81, batch 193/240:\tDiscriminator: real loss 0.16411830484867096, fake loss 0.23397746682167053\tGenerator: loss 14.965961456298828\n","Epoch 81, batch 194/240:\tDiscriminator: real loss 0.14805151522159576, fake loss 0.3079397678375244\tGenerator: loss 14.76733112335205\n","Epoch 81, batch 195/240:\tDiscriminator: real loss 0.19704629480838776, fake loss 0.12438105791807175\tGenerator: loss 12.302939414978027\n","Epoch 81, batch 196/240:\tDiscriminator: real loss 0.14502792060375214, fake loss 0.1561570167541504\tGenerator: loss 11.129255294799805\n","Epoch 81, batch 197/240:\tDiscriminator: real loss 0.12968403100967407, fake loss 0.1507776528596878\tGenerator: loss 10.939260482788086\n","Epoch 81, batch 198/240:\tDiscriminator: real loss 0.08794641494750977, fake loss 0.03412638604640961\tGenerator: loss 10.937230110168457\n","Epoch 81, batch 199/240:\tDiscriminator: real loss 0.07663635909557343, fake loss 0.24488811194896698\tGenerator: loss 10.401816368103027\n","Epoch 81, batch 200/240:\tDiscriminator: real loss 0.09650406241416931, fake loss 0.22809089720249176\tGenerator: loss 10.874194145202637\n","Epoch 81, batch 201/240:\tDiscriminator: real loss 0.19008418917655945, fake loss 0.18995808064937592\tGenerator: loss 14.058248519897461\n","Epoch 81, batch 202/240:\tDiscriminator: real loss 0.13711795210838318, fake loss 0.27391988039016724\tGenerator: loss 11.517995834350586\n","Epoch 81, batch 203/240:\tDiscriminator: real loss 0.12839828431606293, fake loss 0.1301039159297943\tGenerator: loss 13.64400863647461\n","Epoch 81, batch 204/240:\tDiscriminator: real loss 0.13047677278518677, fake loss 0.17370474338531494\tGenerator: loss 12.499455451965332\n","Epoch 81, batch 205/240:\tDiscriminator: real loss 0.07097829878330231, fake loss 0.2357557713985443\tGenerator: loss 9.586529731750488\n","Epoch 81, batch 206/240:\tDiscriminator: real loss 0.13585971295833588, fake loss 0.2632189691066742\tGenerator: loss 11.84682846069336\n","Epoch 81, batch 207/240:\tDiscriminator: real loss 0.16052454710006714, fake loss 0.06879130005836487\tGenerator: loss 11.940908432006836\n","Epoch 81, batch 208/240:\tDiscriminator: real loss 0.0900283083319664, fake loss 0.18715792894363403\tGenerator: loss 12.899397850036621\n","Epoch 81, batch 209/240:\tDiscriminator: real loss 0.11703771352767944, fake loss 0.2707451581954956\tGenerator: loss 12.330902099609375\n","Epoch 81, batch 210/240:\tDiscriminator: real loss 0.18477411568164825, fake loss 0.0974266454577446\tGenerator: loss 9.286124229431152\n","Epoch 81, batch 211/240:\tDiscriminator: real loss 0.09018804877996445, fake loss 0.24962104856967926\tGenerator: loss 9.906344413757324\n","Epoch 81, batch 212/240:\tDiscriminator: real loss 0.13670185208320618, fake loss 0.2259766012430191\tGenerator: loss 10.634376525878906\n","Epoch 81, batch 213/240:\tDiscriminator: real loss 0.1421208530664444, fake loss 0.13582439720630646\tGenerator: loss 10.241442680358887\n","Epoch 81, batch 214/240:\tDiscriminator: real loss 0.15409095585346222, fake loss 0.20837409794330597\tGenerator: loss 10.451763153076172\n","Epoch 81, batch 215/240:\tDiscriminator: real loss 0.2105388641357422, fake loss 0.18738824129104614\tGenerator: loss 10.932438850402832\n","Epoch 81, batch 216/240:\tDiscriminator: real loss 0.14555644989013672, fake loss 0.2966988682746887\tGenerator: loss 11.326908111572266\n","Epoch 81, batch 217/240:\tDiscriminator: real loss 0.17314769327640533, fake loss 0.0741584524512291\tGenerator: loss 11.087207794189453\n","Epoch 81, batch 218/240:\tDiscriminator: real loss 0.0755450427532196, fake loss 0.16926412284374237\tGenerator: loss 9.46278190612793\n","Epoch 81, batch 219/240:\tDiscriminator: real loss 0.08981376886367798, fake loss 0.22800180315971375\tGenerator: loss 10.723194122314453\n","Epoch 81, batch 220/240:\tDiscriminator: real loss 0.17570258677005768, fake loss 0.2298841029405594\tGenerator: loss 8.525773048400879\n","Epoch 81, batch 221/240:\tDiscriminator: real loss 0.15053080022335052, fake loss 0.49267062544822693\tGenerator: loss 10.692547798156738\n","Epoch 81, batch 222/240:\tDiscriminator: real loss 0.19517174363136292, fake loss 0.138316348195076\tGenerator: loss 11.36773681640625\n","Epoch 81, batch 223/240:\tDiscriminator: real loss 0.23638586699962616, fake loss 0.07010521739721298\tGenerator: loss 8.177828788757324\n","Epoch 81, batch 224/240:\tDiscriminator: real loss 0.16430427134037018, fake loss 0.34221160411834717\tGenerator: loss 8.562790870666504\n","Epoch 81, batch 225/240:\tDiscriminator: real loss 0.1160818487405777, fake loss 0.30369940400123596\tGenerator: loss 12.078459739685059\n","Epoch 81, batch 226/240:\tDiscriminator: real loss 0.18923419713974, fake loss 0.19493728876113892\tGenerator: loss 11.587040901184082\n","Epoch 81, batch 227/240:\tDiscriminator: real loss 0.14667557179927826, fake loss 0.20041774213314056\tGenerator: loss 9.727058410644531\n","Epoch 81, batch 228/240:\tDiscriminator: real loss 0.18238449096679688, fake loss 0.19555479288101196\tGenerator: loss 8.529317855834961\n","Epoch 81, batch 229/240:\tDiscriminator: real loss 0.11226333677768707, fake loss 0.18240013718605042\tGenerator: loss 9.036670684814453\n","Epoch 81, batch 230/240:\tDiscriminator: real loss 0.09403083473443985, fake loss 0.27612510323524475\tGenerator: loss 10.997087478637695\n","Epoch 81, batch 231/240:\tDiscriminator: real loss 0.12268412858247757, fake loss 0.17506136000156403\tGenerator: loss 11.368178367614746\n","Epoch 81, batch 232/240:\tDiscriminator: real loss 0.1391020119190216, fake loss 0.16967010498046875\tGenerator: loss 9.728724479675293\n","Epoch 81, batch 233/240:\tDiscriminator: real loss 0.16881392896175385, fake loss 0.15081124007701874\tGenerator: loss 10.358241081237793\n","Epoch 81, batch 234/240:\tDiscriminator: real loss 0.15311044454574585, fake loss 0.18451614677906036\tGenerator: loss 9.241545677185059\n","Epoch 81, batch 235/240:\tDiscriminator: real loss 0.08609939366579056, fake loss 0.3992671072483063\tGenerator: loss 9.408756256103516\n","Epoch 81, batch 236/240:\tDiscriminator: real loss 0.12362976372241974, fake loss 0.1921597123146057\tGenerator: loss 12.051278114318848\n","Epoch 81, batch 237/240:\tDiscriminator: real loss 0.22692763805389404, fake loss 0.23405101895332336\tGenerator: loss 12.118924140930176\n","Epoch 81, batch 238/240:\tDiscriminator: real loss 0.1687917560338974, fake loss 0.21651610732078552\tGenerator: loss 9.744138717651367\n","Epoch 81, batch 239/240:\tDiscriminator: real loss 0.11603894829750061, fake loss 0.288926899433136\tGenerator: loss 9.798741340637207\n","Epoch 81, batch 240/240:\tDiscriminator: real loss 0.15511088073253632, fake loss 0.410599023103714\tGenerator: loss 10.619519233703613\n","Epoch 82, batch 1/240:\tDiscriminator: real loss 0.2710151672363281, fake loss 0.10687290132045746\tGenerator: loss 10.179781913757324\n","Epoch 82, batch 2/240:\tDiscriminator: real loss 0.13613003492355347, fake loss 0.14841803908348083\tGenerator: loss 10.733026504516602\n","Epoch 82, batch 3/240:\tDiscriminator: real loss 0.0929454118013382, fake loss 0.22541026771068573\tGenerator: loss 12.454914093017578\n","Epoch 82, batch 4/240:\tDiscriminator: real loss 0.150032639503479, fake loss 0.22575165331363678\tGenerator: loss 11.962908744812012\n","Epoch 82, batch 5/240:\tDiscriminator: real loss 0.09353405982255936, fake loss 0.21172618865966797\tGenerator: loss 12.644808769226074\n","Epoch 82, batch 6/240:\tDiscriminator: real loss 0.13165630400180817, fake loss 0.10130463540554047\tGenerator: loss 13.039716720581055\n","Epoch 82, batch 7/240:\tDiscriminator: real loss 0.11775826662778854, fake loss 0.25449347496032715\tGenerator: loss 9.774685859680176\n","Epoch 82, batch 8/240:\tDiscriminator: real loss 0.09968530386686325, fake loss 0.21343375742435455\tGenerator: loss 10.099581718444824\n","Epoch 82, batch 9/240:\tDiscriminator: real loss 0.1676371693611145, fake loss 0.23568937182426453\tGenerator: loss 9.447714805603027\n","Epoch 82, batch 10/240:\tDiscriminator: real loss 0.1744033396244049, fake loss 0.1420239359140396\tGenerator: loss 8.641230583190918\n","Epoch 82, batch 11/240:\tDiscriminator: real loss 0.1057567372918129, fake loss 0.05283736065030098\tGenerator: loss 9.499363899230957\n","Epoch 82, batch 12/240:\tDiscriminator: real loss 0.07787356525659561, fake loss 0.3096415102481842\tGenerator: loss 8.647224426269531\n","Epoch 82, batch 13/240:\tDiscriminator: real loss 0.16667227447032928, fake loss 0.16299603879451752\tGenerator: loss 10.35615348815918\n","Epoch 82, batch 14/240:\tDiscriminator: real loss 0.14006415009498596, fake loss 0.19060859084129333\tGenerator: loss 10.836325645446777\n","Epoch 82, batch 15/240:\tDiscriminator: real loss 0.11752071976661682, fake loss 0.0738605335354805\tGenerator: loss 12.961256980895996\n","Epoch 82, batch 16/240:\tDiscriminator: real loss 0.11407241970300674, fake loss 0.18537485599517822\tGenerator: loss 11.562945365905762\n","Epoch 82, batch 17/240:\tDiscriminator: real loss 0.12358055263757706, fake loss 0.18396587669849396\tGenerator: loss 8.794474601745605\n","Epoch 82, batch 18/240:\tDiscriminator: real loss 0.10792623460292816, fake loss 0.2741551697254181\tGenerator: loss 8.324281692504883\n","Epoch 82, batch 19/240:\tDiscriminator: real loss 0.1739915907382965, fake loss 0.21114866435527802\tGenerator: loss 7.675351142883301\n","Epoch 82, batch 20/240:\tDiscriminator: real loss 0.1590946763753891, fake loss 0.13281111419200897\tGenerator: loss 11.238151550292969\n","Epoch 82, batch 21/240:\tDiscriminator: real loss 0.09369280934333801, fake loss 0.21389572322368622\tGenerator: loss 11.802018165588379\n","Epoch 82, batch 22/240:\tDiscriminator: real loss 0.09366805851459503, fake loss 0.07342715561389923\tGenerator: loss 12.542415618896484\n","Epoch 82, batch 23/240:\tDiscriminator: real loss 0.11593034118413925, fake loss 0.30498361587524414\tGenerator: loss 11.894774436950684\n","Epoch 82, batch 24/240:\tDiscriminator: real loss 0.12146342545747757, fake loss 0.1482393890619278\tGenerator: loss 10.956491470336914\n","Epoch 82, batch 25/240:\tDiscriminator: real loss 0.14543499052524567, fake loss 0.09895451366901398\tGenerator: loss 10.523326873779297\n","Epoch 82, batch 26/240:\tDiscriminator: real loss 0.12376738339662552, fake loss 0.20907211303710938\tGenerator: loss 10.430987358093262\n","Epoch 82, batch 27/240:\tDiscriminator: real loss 0.07299342751502991, fake loss 0.1885230392217636\tGenerator: loss 12.024950981140137\n","Epoch 82, batch 28/240:\tDiscriminator: real loss 0.14263205230236053, fake loss 0.07091231644153595\tGenerator: loss 10.337597846984863\n","Epoch 82, batch 29/240:\tDiscriminator: real loss 0.12600961327552795, fake loss 0.30931633710861206\tGenerator: loss 10.574760437011719\n","Epoch 82, batch 30/240:\tDiscriminator: real loss 0.15938988327980042, fake loss 0.4195435643196106\tGenerator: loss 12.190218925476074\n","Epoch 82, batch 31/240:\tDiscriminator: real loss 0.16598090529441833, fake loss 0.0525277815759182\tGenerator: loss 12.858979225158691\n","Epoch 82, batch 32/240:\tDiscriminator: real loss 0.0907815620303154, fake loss 0.25451695919036865\tGenerator: loss 11.890824317932129\n","Epoch 82, batch 33/240:\tDiscriminator: real loss 0.1441580355167389, fake loss 0.14103473722934723\tGenerator: loss 10.430034637451172\n","Epoch 82, batch 34/240:\tDiscriminator: real loss 0.16084785759449005, fake loss 0.14750263094902039\tGenerator: loss 7.075972080230713\n","Epoch 82, batch 35/240:\tDiscriminator: real loss 0.12144681811332703, fake loss 0.21444198489189148\tGenerator: loss 7.65566349029541\n","Epoch 82, batch 36/240:\tDiscriminator: real loss 0.18586833775043488, fake loss 0.29784542322158813\tGenerator: loss 10.678946495056152\n","Epoch 82, batch 37/240:\tDiscriminator: real loss 0.14537915587425232, fake loss 0.13538028299808502\tGenerator: loss 11.22677230834961\n","Epoch 82, batch 38/240:\tDiscriminator: real loss 0.10557705163955688, fake loss 0.17344661056995392\tGenerator: loss 12.980185508728027\n","Epoch 82, batch 39/240:\tDiscriminator: real loss 0.12745684385299683, fake loss 0.207301065325737\tGenerator: loss 11.517403602600098\n","Epoch 82, batch 40/240:\tDiscriminator: real loss 0.11650779843330383, fake loss 0.14625678956508636\tGenerator: loss 9.975427627563477\n","Epoch 82, batch 41/240:\tDiscriminator: real loss 0.11611169576644897, fake loss 0.14580650627613068\tGenerator: loss 10.376437187194824\n","Epoch 82, batch 42/240:\tDiscriminator: real loss 0.15364272892475128, fake loss 0.18493793904781342\tGenerator: loss 10.326374053955078\n","Epoch 82, batch 43/240:\tDiscriminator: real loss 0.12457845360040665, fake loss 0.09274505823850632\tGenerator: loss 9.631478309631348\n","Epoch 82, batch 44/240:\tDiscriminator: real loss 0.10249999910593033, fake loss 0.23633937537670135\tGenerator: loss 11.015430450439453\n","Epoch 82, batch 45/240:\tDiscriminator: real loss 0.07924985140562057, fake loss 0.2691774070262909\tGenerator: loss 9.899699211120605\n","Epoch 82, batch 46/240:\tDiscriminator: real loss 0.1009463518857956, fake loss 0.15834271907806396\tGenerator: loss 12.8577241897583\n","Epoch 82, batch 47/240:\tDiscriminator: real loss 0.16574926674365997, fake loss 0.17387309670448303\tGenerator: loss 13.357662200927734\n","Epoch 82, batch 48/240:\tDiscriminator: real loss 0.09022512286901474, fake loss 0.18596459925174713\tGenerator: loss 13.565390586853027\n","Epoch 82, batch 49/240:\tDiscriminator: real loss 0.25010859966278076, fake loss 0.16779731214046478\tGenerator: loss 9.783435821533203\n","Epoch 82, batch 50/240:\tDiscriminator: real loss 0.07689480483531952, fake loss 0.30757391452789307\tGenerator: loss 10.6504487991333\n","Epoch 82, batch 51/240:\tDiscriminator: real loss 0.09358350932598114, fake loss 0.1026509553194046\tGenerator: loss 9.460674285888672\n","Epoch 82, batch 52/240:\tDiscriminator: real loss 0.15147411823272705, fake loss 0.21704967319965363\tGenerator: loss 9.061209678649902\n","Epoch 82, batch 53/240:\tDiscriminator: real loss 0.1231110692024231, fake loss 0.20824508368968964\tGenerator: loss 8.635160446166992\n","Epoch 82, batch 54/240:\tDiscriminator: real loss 0.1530034989118576, fake loss 0.25138455629348755\tGenerator: loss 9.83920669555664\n","Epoch 82, batch 55/240:\tDiscriminator: real loss 0.19842472672462463, fake loss 0.14854225516319275\tGenerator: loss 10.051461219787598\n","Epoch 82, batch 56/240:\tDiscriminator: real loss 0.15566660463809967, fake loss 0.2019481211900711\tGenerator: loss 10.405511856079102\n","Epoch 82, batch 57/240:\tDiscriminator: real loss 0.14528806507587433, fake loss 0.1413687914609909\tGenerator: loss 11.4220552444458\n","Epoch 82, batch 58/240:\tDiscriminator: real loss 0.12375963479280472, fake loss 0.10697674006223679\tGenerator: loss 10.142333030700684\n","Epoch 82, batch 59/240:\tDiscriminator: real loss 0.06983862072229385, fake loss 0.2838820517063141\tGenerator: loss 9.87425422668457\n","Epoch 82, batch 60/240:\tDiscriminator: real loss 0.17553550004959106, fake loss 0.17684118449687958\tGenerator: loss 8.868080139160156\n","Epoch 82, batch 61/240:\tDiscriminator: real loss 0.2273087352514267, fake loss 0.22060905396938324\tGenerator: loss 8.537125587463379\n","Epoch 82, batch 62/240:\tDiscriminator: real loss 0.11120516061782837, fake loss 0.2026127576828003\tGenerator: loss 10.439985275268555\n","Epoch 82, batch 63/240:\tDiscriminator: real loss 0.11830969154834747, fake loss 0.19629737734794617\tGenerator: loss 9.063470840454102\n","Epoch 82, batch 64/240:\tDiscriminator: real loss 0.1580393761396408, fake loss 0.17337709665298462\tGenerator: loss 8.775668144226074\n","Epoch 82, batch 65/240:\tDiscriminator: real loss 0.15391844511032104, fake loss 0.19728007912635803\tGenerator: loss 9.756651878356934\n","Epoch 82, batch 66/240:\tDiscriminator: real loss 0.1378619223833084, fake loss 0.22579307854175568\tGenerator: loss 8.044153213500977\n","Epoch 82, batch 67/240:\tDiscriminator: real loss 0.12997806072235107, fake loss 0.16117018461227417\tGenerator: loss 7.589191436767578\n","Epoch 82, batch 68/240:\tDiscriminator: real loss 0.11460158973932266, fake loss 0.14826759696006775\tGenerator: loss 7.184617519378662\n","Epoch 82, batch 69/240:\tDiscriminator: real loss 0.09662417322397232, fake loss 0.04931465536355972\tGenerator: loss 6.46185302734375\n","Epoch 82, batch 70/240:\tDiscriminator: real loss 0.06362167000770569, fake loss 0.19889888167381287\tGenerator: loss 7.400893688201904\n","Epoch 82, batch 71/240:\tDiscriminator: real loss 0.08575476706027985, fake loss 0.14749008417129517\tGenerator: loss 7.988095283508301\n","Epoch 82, batch 72/240:\tDiscriminator: real loss 0.0918940007686615, fake loss 0.17179414629936218\tGenerator: loss 8.535856246948242\n","Epoch 82, batch 73/240:\tDiscriminator: real loss 0.12180093675851822, fake loss 0.12460760772228241\tGenerator: loss 7.404951572418213\n","Epoch 82, batch 74/240:\tDiscriminator: real loss 0.15456491708755493, fake loss 0.3528904616832733\tGenerator: loss 7.96455192565918\n","Epoch 82, batch 75/240:\tDiscriminator: real loss 0.09356065839529037, fake loss 0.1457023024559021\tGenerator: loss 9.775299072265625\n","Epoch 82, batch 76/240:\tDiscriminator: real loss 0.1303362250328064, fake loss 0.1584625095129013\tGenerator: loss 10.572314262390137\n","Epoch 82, batch 77/240:\tDiscriminator: real loss 0.10104772448539734, fake loss 0.19506779313087463\tGenerator: loss 11.960188865661621\n","Epoch 82, batch 78/240:\tDiscriminator: real loss 0.12682916224002838, fake loss 0.23331844806671143\tGenerator: loss 11.860125541687012\n","Epoch 82, batch 79/240:\tDiscriminator: real loss 0.13805639743804932, fake loss 0.14041517674922943\tGenerator: loss 12.50680923461914\n","Epoch 82, batch 80/240:\tDiscriminator: real loss 0.0732623040676117, fake loss 0.19334767758846283\tGenerator: loss 12.98937702178955\n","Epoch 82, batch 81/240:\tDiscriminator: real loss 0.24208477139472961, fake loss 0.16442665457725525\tGenerator: loss 9.49979305267334\n","Epoch 82, batch 82/240:\tDiscriminator: real loss 0.1324208378791809, fake loss 0.22217071056365967\tGenerator: loss 8.232205390930176\n","Epoch 82, batch 83/240:\tDiscriminator: real loss 0.13963326811790466, fake loss 0.17942087352275848\tGenerator: loss 9.020220756530762\n","Epoch 82, batch 84/240:\tDiscriminator: real loss 0.16271664202213287, fake loss 0.3166912794113159\tGenerator: loss 9.139007568359375\n","Epoch 82, batch 85/240:\tDiscriminator: real loss 0.1279027909040451, fake loss 0.09306082129478455\tGenerator: loss 9.606420516967773\n","Epoch 82, batch 86/240:\tDiscriminator: real loss 0.12582272291183472, fake loss 0.053857192397117615\tGenerator: loss 11.49534797668457\n","Epoch 82, batch 87/240:\tDiscriminator: real loss 0.1033438965678215, fake loss 0.280312180519104\tGenerator: loss 12.909933090209961\n","Epoch 82, batch 88/240:\tDiscriminator: real loss 0.09859346598386765, fake loss 0.21806731820106506\tGenerator: loss 15.900160789489746\n","Epoch 82, batch 89/240:\tDiscriminator: real loss 0.10591639578342438, fake loss 0.24430400133132935\tGenerator: loss 14.348786354064941\n","Epoch 82, batch 90/240:\tDiscriminator: real loss 0.1897471398115158, fake loss 0.14258624613285065\tGenerator: loss 13.307011604309082\n","Epoch 82, batch 91/240:\tDiscriminator: real loss 0.20632319152355194, fake loss 0.25275295972824097\tGenerator: loss 10.8739013671875\n","Epoch 82, batch 92/240:\tDiscriminator: real loss 0.14627282321453094, fake loss 0.2053648829460144\tGenerator: loss 10.65496826171875\n","Epoch 82, batch 93/240:\tDiscriminator: real loss 0.17038102447986603, fake loss 0.12047319114208221\tGenerator: loss 10.533885955810547\n","Epoch 82, batch 94/240:\tDiscriminator: real loss 0.16246898472309113, fake loss 0.19998954236507416\tGenerator: loss 11.123753547668457\n","Epoch 82, batch 95/240:\tDiscriminator: real loss 0.06882848590612411, fake loss 0.26001548767089844\tGenerator: loss 13.360725402832031\n","Epoch 82, batch 96/240:\tDiscriminator: real loss 0.0753483846783638, fake loss 0.13884440064430237\tGenerator: loss 12.674600601196289\n","Epoch 82, batch 97/240:\tDiscriminator: real loss 0.16884028911590576, fake loss 0.09813451021909714\tGenerator: loss 9.85892391204834\n","Epoch 82, batch 98/240:\tDiscriminator: real loss 0.17666637897491455, fake loss 0.17287692427635193\tGenerator: loss 11.309913635253906\n","Epoch 82, batch 99/240:\tDiscriminator: real loss 0.10139331221580505, fake loss 0.18818822503089905\tGenerator: loss 13.205982208251953\n","Epoch 82, batch 100/240:\tDiscriminator: real loss 0.07183852791786194, fake loss 0.25709083676338196\tGenerator: loss 13.555842399597168\n","Epoch 82, batch 101/240:\tDiscriminator: real loss 0.23409517109394073, fake loss 0.12549465894699097\tGenerator: loss 14.671545028686523\n","Epoch 82, batch 102/240:\tDiscriminator: real loss 0.12894567847251892, fake loss 0.3026246130466461\tGenerator: loss 11.971114158630371\n","Epoch 82, batch 103/240:\tDiscriminator: real loss 0.08796987682580948, fake loss 0.1757737398147583\tGenerator: loss 12.862329483032227\n","Epoch 82, batch 104/240:\tDiscriminator: real loss 0.12351413816213608, fake loss 0.157806858420372\tGenerator: loss 11.674510955810547\n","Epoch 82, batch 105/240:\tDiscriminator: real loss 0.11277700215578079, fake loss 0.22011497616767883\tGenerator: loss 12.080401420593262\n","Epoch 82, batch 106/240:\tDiscriminator: real loss 0.14695462584495544, fake loss 0.19282662868499756\tGenerator: loss 12.402504920959473\n","Epoch 82, batch 107/240:\tDiscriminator: real loss 0.1883796751499176, fake loss 0.10782245546579361\tGenerator: loss 10.258458137512207\n","Epoch 82, batch 108/240:\tDiscriminator: real loss 0.08367078006267548, fake loss 0.18908809125423431\tGenerator: loss 10.742454528808594\n","Epoch 82, batch 109/240:\tDiscriminator: real loss 0.1309482455253601, fake loss 0.3800233006477356\tGenerator: loss 11.688014030456543\n","Epoch 82, batch 110/240:\tDiscriminator: real loss 0.19154998660087585, fake loss 0.23767761886119843\tGenerator: loss 16.005172729492188\n","Epoch 82, batch 111/240:\tDiscriminator: real loss 0.15150614082813263, fake loss 0.11080507189035416\tGenerator: loss 14.460787773132324\n","Epoch 82, batch 112/240:\tDiscriminator: real loss 0.19171541929244995, fake loss 0.057984817773103714\tGenerator: loss 12.695378303527832\n","Epoch 82, batch 113/240:\tDiscriminator: real loss 0.1164083257317543, fake loss 0.36407431960105896\tGenerator: loss 10.721631050109863\n","Epoch 82, batch 114/240:\tDiscriminator: real loss 0.09596293419599533, fake loss 0.25350573658943176\tGenerator: loss 11.397181510925293\n","Epoch 82, batch 115/240:\tDiscriminator: real loss 0.1981375813484192, fake loss 0.10657735913991928\tGenerator: loss 7.992949962615967\n","Epoch 82, batch 116/240:\tDiscriminator: real loss 0.25967276096343994, fake loss 0.2697071135044098\tGenerator: loss 9.101806640625\n","Epoch 82, batch 117/240:\tDiscriminator: real loss 0.08998394012451172, fake loss 0.3498864769935608\tGenerator: loss 11.501508712768555\n","Epoch 82, batch 118/240:\tDiscriminator: real loss 0.13839302957057953, fake loss 0.18325844407081604\tGenerator: loss 12.062808990478516\n","Epoch 82, batch 119/240:\tDiscriminator: real loss 0.15143540501594543, fake loss 0.24177394807338715\tGenerator: loss 10.67920207977295\n","Epoch 82, batch 120/240:\tDiscriminator: real loss 0.2607235014438629, fake loss 0.1863560825586319\tGenerator: loss 11.242269515991211\n","Epoch 82, batch 121/240:\tDiscriminator: real loss 0.07900303602218628, fake loss 0.1865537315607071\tGenerator: loss 11.347761154174805\n","Epoch 82, batch 122/240:\tDiscriminator: real loss 0.11064605414867401, fake loss 0.22514958679676056\tGenerator: loss 9.600290298461914\n","Epoch 82, batch 123/240:\tDiscriminator: real loss 0.18588772416114807, fake loss 0.10732053965330124\tGenerator: loss 9.279070854187012\n","Epoch 82, batch 124/240:\tDiscriminator: real loss 0.06931152194738388, fake loss 0.3490445017814636\tGenerator: loss 10.875690460205078\n","Epoch 82, batch 125/240:\tDiscriminator: real loss 0.22432219982147217, fake loss 0.28686580061912537\tGenerator: loss 10.215605735778809\n","Epoch 82, batch 126/240:\tDiscriminator: real loss 0.1961176097393036, fake loss 0.1309153139591217\tGenerator: loss 11.821634292602539\n","Epoch 82, batch 127/240:\tDiscriminator: real loss 0.157708078622818, fake loss 0.22287026047706604\tGenerator: loss 9.613511085510254\n","Epoch 82, batch 128/240:\tDiscriminator: real loss 0.11749803274869919, fake loss 0.22576425969600677\tGenerator: loss 9.591196060180664\n","Epoch 82, batch 129/240:\tDiscriminator: real loss 0.16949130594730377, fake loss 0.28569328784942627\tGenerator: loss 9.869475364685059\n","Epoch 82, batch 130/240:\tDiscriminator: real loss 0.15843981504440308, fake loss 0.19913730025291443\tGenerator: loss 10.580018043518066\n","Epoch 82, batch 131/240:\tDiscriminator: real loss 0.15092241764068604, fake loss 0.21351419389247894\tGenerator: loss 10.865596771240234\n","Epoch 82, batch 132/240:\tDiscriminator: real loss 0.10951884090900421, fake loss 0.12471342086791992\tGenerator: loss 10.908661842346191\n","Epoch 82, batch 133/240:\tDiscriminator: real loss 0.12130556255578995, fake loss 0.12352116405963898\tGenerator: loss 9.32922649383545\n","Epoch 82, batch 134/240:\tDiscriminator: real loss 0.10471376776695251, fake loss 0.12641645967960358\tGenerator: loss 8.045038223266602\n","Epoch 82, batch 135/240:\tDiscriminator: real loss 0.08972344547510147, fake loss 0.22180934250354767\tGenerator: loss 9.397953033447266\n","Epoch 82, batch 136/240:\tDiscriminator: real loss 0.18017317354679108, fake loss 0.30717432498931885\tGenerator: loss 11.092510223388672\n","Epoch 82, batch 137/240:\tDiscriminator: real loss 0.13512545824050903, fake loss 0.1058512032032013\tGenerator: loss 11.435094833374023\n","Epoch 82, batch 138/240:\tDiscriminator: real loss 0.1450868546962738, fake loss 0.167782261967659\tGenerator: loss 8.278130531311035\n","Epoch 82, batch 139/240:\tDiscriminator: real loss 0.10208888351917267, fake loss 0.13199704885482788\tGenerator: loss 8.768656730651855\n","Epoch 82, batch 140/240:\tDiscriminator: real loss 0.11334589123725891, fake loss 0.2640940845012665\tGenerator: loss 9.673508644104004\n","Epoch 82, batch 141/240:\tDiscriminator: real loss 0.12058889120817184, fake loss 0.0959189310669899\tGenerator: loss 10.828307151794434\n","Epoch 82, batch 142/240:\tDiscriminator: real loss 0.10079792886972427, fake loss 0.21926303207874298\tGenerator: loss 11.916586875915527\n","Epoch 82, batch 143/240:\tDiscriminator: real loss 0.11315938830375671, fake loss 0.21835832297801971\tGenerator: loss 12.203834533691406\n","Epoch 82, batch 144/240:\tDiscriminator: real loss 0.130320742726326, fake loss 0.10448505729436874\tGenerator: loss 11.832653999328613\n","Epoch 82, batch 145/240:\tDiscriminator: real loss 0.1432275027036667, fake loss 0.2046613246202469\tGenerator: loss 11.750094413757324\n","Epoch 82, batch 146/240:\tDiscriminator: real loss 0.2188062220811844, fake loss 0.13176259398460388\tGenerator: loss 10.187738418579102\n","Epoch 82, batch 147/240:\tDiscriminator: real loss 0.10350093990564346, fake loss 0.3771182894706726\tGenerator: loss 12.0438232421875\n","Epoch 82, batch 148/240:\tDiscriminator: real loss 0.0926537960767746, fake loss 0.28879812359809875\tGenerator: loss 16.018596649169922\n","Epoch 82, batch 149/240:\tDiscriminator: real loss 0.20366694033145905, fake loss 0.07802878320217133\tGenerator: loss 13.53553581237793\n","Epoch 82, batch 150/240:\tDiscriminator: real loss 0.22284474968910217, fake loss 0.15752220153808594\tGenerator: loss 11.219531059265137\n","Epoch 82, batch 151/240:\tDiscriminator: real loss 0.0782296359539032, fake loss 0.339049756526947\tGenerator: loss 12.881583213806152\n","Epoch 82, batch 152/240:\tDiscriminator: real loss 0.17234300076961517, fake loss 0.30357983708381653\tGenerator: loss 10.129962921142578\n","Epoch 82, batch 153/240:\tDiscriminator: real loss 0.15829035639762878, fake loss 0.08512819558382034\tGenerator: loss 7.071946620941162\n","Epoch 82, batch 154/240:\tDiscriminator: real loss 0.19856376945972443, fake loss 0.25340843200683594\tGenerator: loss 9.664137840270996\n","Epoch 82, batch 155/240:\tDiscriminator: real loss 0.09335319697856903, fake loss 0.33714744448661804\tGenerator: loss 12.349032402038574\n","Epoch 82, batch 156/240:\tDiscriminator: real loss 0.16014502942562103, fake loss 0.19743041694164276\tGenerator: loss 13.296481132507324\n","Epoch 82, batch 157/240:\tDiscriminator: real loss 0.2936306595802307, fake loss 0.16279460489749908\tGenerator: loss 9.611534118652344\n","Epoch 82, batch 158/240:\tDiscriminator: real loss 0.13082155585289001, fake loss 0.25961461663246155\tGenerator: loss 8.92084789276123\n","Epoch 82, batch 159/240:\tDiscriminator: real loss 0.13220316171646118, fake loss 0.15093840658664703\tGenerator: loss 11.309898376464844\n","Epoch 82, batch 160/240:\tDiscriminator: real loss 0.20707888901233673, fake loss 0.11450938880443573\tGenerator: loss 13.681857109069824\n","Epoch 82, batch 161/240:\tDiscriminator: real loss 0.0855238139629364, fake loss 0.21209082007408142\tGenerator: loss 12.953487396240234\n","Epoch 82, batch 162/240:\tDiscriminator: real loss 0.08066309988498688, fake loss 0.3425289988517761\tGenerator: loss 12.706652641296387\n","Epoch 82, batch 163/240:\tDiscriminator: real loss 0.17706409096717834, fake loss 0.12745538353919983\tGenerator: loss 9.893898010253906\n","Epoch 82, batch 164/240:\tDiscriminator: real loss 0.1960473209619522, fake loss 0.20620761811733246\tGenerator: loss 11.11058235168457\n","Epoch 82, batch 165/240:\tDiscriminator: real loss 0.07520453631877899, fake loss 0.20289741456508636\tGenerator: loss 11.299351692199707\n","Epoch 82, batch 166/240:\tDiscriminator: real loss 0.14063727855682373, fake loss 0.26135265827178955\tGenerator: loss 11.721213340759277\n","Epoch 82, batch 167/240:\tDiscriminator: real loss 0.2597576677799225, fake loss 0.16141517460346222\tGenerator: loss 11.244978904724121\n","Epoch 82, batch 168/240:\tDiscriminator: real loss 0.10625389218330383, fake loss 0.23798395693302155\tGenerator: loss 11.092768669128418\n","Epoch 82, batch 169/240:\tDiscriminator: real loss 0.06534893065690994, fake loss 0.1509757786989212\tGenerator: loss 11.743014335632324\n","Epoch 82, batch 170/240:\tDiscriminator: real loss 0.16711682081222534, fake loss 0.26755639910697937\tGenerator: loss 10.458669662475586\n","Epoch 82, batch 171/240:\tDiscriminator: real loss 0.14356572926044464, fake loss 0.16659602522850037\tGenerator: loss 9.549126625061035\n","Epoch 82, batch 172/240:\tDiscriminator: real loss 0.14468692243099213, fake loss 0.20822347700595856\tGenerator: loss 8.552874565124512\n","Epoch 82, batch 173/240:\tDiscriminator: real loss 0.16646121442317963, fake loss 0.16467106342315674\tGenerator: loss 12.493779182434082\n","Epoch 82, batch 174/240:\tDiscriminator: real loss 0.0971701443195343, fake loss 0.15522880852222443\tGenerator: loss 12.217243194580078\n","Epoch 82, batch 175/240:\tDiscriminator: real loss 0.11640395224094391, fake loss 0.10831928998231888\tGenerator: loss 10.619592666625977\n","Epoch 82, batch 176/240:\tDiscriminator: real loss 0.11446176469326019, fake loss 0.21824520826339722\tGenerator: loss 9.49331283569336\n","Epoch 82, batch 177/240:\tDiscriminator: real loss 0.1231946349143982, fake loss 0.1968250274658203\tGenerator: loss 10.690074920654297\n","Epoch 82, batch 178/240:\tDiscriminator: real loss 0.12086518108844757, fake loss 0.1370019018650055\tGenerator: loss 10.12696647644043\n","Epoch 82, batch 179/240:\tDiscriminator: real loss 0.14929622411727905, fake loss 0.08919796347618103\tGenerator: loss 10.283514022827148\n","Epoch 82, batch 180/240:\tDiscriminator: real loss 0.09351816773414612, fake loss 0.1442185342311859\tGenerator: loss 9.192427635192871\n","Epoch 82, batch 181/240:\tDiscriminator: real loss 0.11573328077793121, fake loss 0.26682141423225403\tGenerator: loss 8.423938751220703\n","Epoch 82, batch 182/240:\tDiscriminator: real loss 0.1193995475769043, fake loss 0.19504041969776154\tGenerator: loss 8.788844108581543\n","Epoch 82, batch 183/240:\tDiscriminator: real loss 0.21384881436824799, fake loss 0.2114904820919037\tGenerator: loss 10.109310150146484\n","Epoch 82, batch 184/240:\tDiscriminator: real loss 0.21931029856204987, fake loss 0.15015628933906555\tGenerator: loss 9.704571723937988\n","Epoch 82, batch 185/240:\tDiscriminator: real loss 0.06639805436134338, fake loss 0.23095566034317017\tGenerator: loss 9.529838562011719\n","Epoch 82, batch 186/240:\tDiscriminator: real loss 0.17174190282821655, fake loss 0.08146504312753677\tGenerator: loss 10.514004707336426\n","Epoch 82, batch 187/240:\tDiscriminator: real loss 0.18857692182064056, fake loss 0.2236379235982895\tGenerator: loss 8.250615119934082\n","Epoch 82, batch 188/240:\tDiscriminator: real loss 0.12210669368505478, fake loss 0.27600032091140747\tGenerator: loss 9.1616792678833\n","Epoch 82, batch 189/240:\tDiscriminator: real loss 0.10280797630548477, fake loss 0.16454358398914337\tGenerator: loss 9.558490753173828\n","Epoch 82, batch 190/240:\tDiscriminator: real loss 0.10274927318096161, fake loss 0.19519193470478058\tGenerator: loss 10.634940147399902\n","Epoch 82, batch 191/240:\tDiscriminator: real loss 0.13529984652996063, fake loss 0.2530478537082672\tGenerator: loss 11.927988052368164\n","Epoch 82, batch 192/240:\tDiscriminator: real loss 0.09262973815202713, fake loss 0.19006410241127014\tGenerator: loss 13.736381530761719\n","Epoch 82, batch 193/240:\tDiscriminator: real loss 0.16241329908370972, fake loss 0.08866769820451736\tGenerator: loss 11.489640235900879\n","Epoch 82, batch 194/240:\tDiscriminator: real loss 0.12107671052217484, fake loss 0.22511404752731323\tGenerator: loss 11.401871681213379\n","Epoch 82, batch 195/240:\tDiscriminator: real loss 0.11080627143383026, fake loss 0.13753065466880798\tGenerator: loss 11.262565612792969\n","Epoch 82, batch 196/240:\tDiscriminator: real loss 0.1003335639834404, fake loss 0.27513039112091064\tGenerator: loss 11.077495574951172\n","Epoch 82, batch 197/240:\tDiscriminator: real loss 0.1800629049539566, fake loss 0.12271244823932648\tGenerator: loss 7.824293613433838\n","Epoch 82, batch 198/240:\tDiscriminator: real loss 0.12243610620498657, fake loss 0.11184524744749069\tGenerator: loss 6.846771717071533\n","Epoch 82, batch 199/240:\tDiscriminator: real loss 0.14801691472530365, fake loss 0.32675400376319885\tGenerator: loss 8.712050437927246\n","Epoch 82, batch 200/240:\tDiscriminator: real loss 0.07988831400871277, fake loss 0.3410201370716095\tGenerator: loss 9.794346809387207\n","Epoch 82, batch 201/240:\tDiscriminator: real loss 0.1308802217245102, fake loss 0.13773874938488007\tGenerator: loss 10.716714859008789\n","Epoch 82, batch 202/240:\tDiscriminator: real loss 0.1537264585494995, fake loss 0.12501360476016998\tGenerator: loss 8.904972076416016\n","Epoch 82, batch 203/240:\tDiscriminator: real loss 0.21340343356132507, fake loss 0.1257908195257187\tGenerator: loss 9.818114280700684\n","Epoch 82, batch 204/240:\tDiscriminator: real loss 0.09707708656787872, fake loss 0.15388423204421997\tGenerator: loss 8.737703323364258\n","Epoch 82, batch 205/240:\tDiscriminator: real loss 0.09364053606987, fake loss 0.22871702909469604\tGenerator: loss 9.117191314697266\n","Epoch 82, batch 206/240:\tDiscriminator: real loss 0.08963563293218613, fake loss 0.26603060960769653\tGenerator: loss 8.762029647827148\n","Epoch 82, batch 207/240:\tDiscriminator: real loss 0.28611519932746887, fake loss 0.15249770879745483\tGenerator: loss 11.554354667663574\n","Epoch 82, batch 208/240:\tDiscriminator: real loss 0.11278748512268066, fake loss 0.18548047542572021\tGenerator: loss 11.835624694824219\n","Epoch 82, batch 209/240:\tDiscriminator: real loss 0.14128351211547852, fake loss 0.17624618113040924\tGenerator: loss 9.947891235351562\n","Epoch 82, batch 210/240:\tDiscriminator: real loss 0.0978911966085434, fake loss 0.2643633782863617\tGenerator: loss 10.9373140335083\n","Epoch 82, batch 211/240:\tDiscriminator: real loss 0.20510292053222656, fake loss 0.1363772302865982\tGenerator: loss 10.924246788024902\n","Epoch 82, batch 212/240:\tDiscriminator: real loss 0.13965150713920593, fake loss 0.1540476381778717\tGenerator: loss 10.126670837402344\n","Epoch 82, batch 213/240:\tDiscriminator: real loss 0.11182031780481339, fake loss 0.2862010896205902\tGenerator: loss 11.640644073486328\n","Epoch 82, batch 214/240:\tDiscriminator: real loss 0.09523381292819977, fake loss 0.10380774736404419\tGenerator: loss 12.164966583251953\n","Epoch 82, batch 215/240:\tDiscriminator: real loss 0.09987258911132812, fake loss 0.1221352219581604\tGenerator: loss 12.456914901733398\n","Epoch 82, batch 216/240:\tDiscriminator: real loss 0.1319412738084793, fake loss 0.2546604871749878\tGenerator: loss 11.138513565063477\n","Epoch 82, batch 217/240:\tDiscriminator: real loss 0.12102282792329788, fake loss 0.2490813136100769\tGenerator: loss 10.602944374084473\n","Epoch 82, batch 218/240:\tDiscriminator: real loss 0.24931307137012482, fake loss 0.15237240493297577\tGenerator: loss 9.42152214050293\n","Epoch 82, batch 219/240:\tDiscriminator: real loss 0.1012832373380661, fake loss 0.1618150770664215\tGenerator: loss 10.049309730529785\n","Epoch 82, batch 220/240:\tDiscriminator: real loss 0.1219102293252945, fake loss 0.14573320746421814\tGenerator: loss 9.821842193603516\n","Epoch 82, batch 221/240:\tDiscriminator: real loss 0.07680058479309082, fake loss 0.2529671788215637\tGenerator: loss 11.629377365112305\n","Epoch 82, batch 222/240:\tDiscriminator: real loss 0.1391162872314453, fake loss 0.0484812967479229\tGenerator: loss 11.763072967529297\n","Epoch 82, batch 223/240:\tDiscriminator: real loss 0.1599258929491043, fake loss 0.33199259638786316\tGenerator: loss 10.814845085144043\n","Epoch 82, batch 224/240:\tDiscriminator: real loss 0.151089608669281, fake loss 0.1291559338569641\tGenerator: loss 9.96058177947998\n","Epoch 82, batch 225/240:\tDiscriminator: real loss 0.12044618278741837, fake loss 0.2594623863697052\tGenerator: loss 9.894737243652344\n","Epoch 82, batch 226/240:\tDiscriminator: real loss 0.2309095710515976, fake loss 0.09664063155651093\tGenerator: loss 9.71894645690918\n","Epoch 82, batch 227/240:\tDiscriminator: real loss 0.08185789734125137, fake loss 0.2321815937757492\tGenerator: loss 10.389639854431152\n","Epoch 82, batch 228/240:\tDiscriminator: real loss 0.1310051679611206, fake loss 0.22682823240756989\tGenerator: loss 11.383009910583496\n","Epoch 82, batch 229/240:\tDiscriminator: real loss 0.14072027802467346, fake loss 0.2837843596935272\tGenerator: loss 11.671893119812012\n","Epoch 82, batch 230/240:\tDiscriminator: real loss 0.08533212542533875, fake loss 0.142639622092247\tGenerator: loss 12.307291030883789\n","Epoch 82, batch 231/240:\tDiscriminator: real loss 0.22594913840293884, fake loss 0.12333738058805466\tGenerator: loss 10.852347373962402\n","Epoch 82, batch 232/240:\tDiscriminator: real loss 0.09046033769845963, fake loss 0.16436070203781128\tGenerator: loss 11.623625755310059\n","Epoch 82, batch 233/240:\tDiscriminator: real loss 0.09706088900566101, fake loss 0.22723427414894104\tGenerator: loss 13.05946159362793\n","Epoch 82, batch 234/240:\tDiscriminator: real loss 0.14769957959651947, fake loss 0.19032169878482819\tGenerator: loss 13.360352516174316\n","Epoch 82, batch 235/240:\tDiscriminator: real loss 0.19142986834049225, fake loss 0.15853795409202576\tGenerator: loss 10.145004272460938\n","Epoch 82, batch 236/240:\tDiscriminator: real loss 0.13798068463802338, fake loss 0.20853473246097565\tGenerator: loss 7.805657863616943\n","Epoch 82, batch 237/240:\tDiscriminator: real loss 0.18907764554023743, fake loss 0.1032167598605156\tGenerator: loss 8.876069068908691\n","Epoch 82, batch 238/240:\tDiscriminator: real loss 0.09255801886320114, fake loss 0.25304675102233887\tGenerator: loss 11.059017181396484\n","Epoch 82, batch 239/240:\tDiscriminator: real loss 0.05224592238664627, fake loss 0.15010924637317657\tGenerator: loss 13.981776237487793\n","Epoch 82, batch 240/240:\tDiscriminator: real loss 0.0886075496673584, fake loss 0.2770784795284271\tGenerator: loss 13.938713073730469\n","Epoch 83, batch 1/240:\tDiscriminator: real loss 0.15028290450572968, fake loss 0.2188299298286438\tGenerator: loss 11.958233833312988\n","Epoch 83, batch 2/240:\tDiscriminator: real loss 0.11231932044029236, fake loss 0.16410282254219055\tGenerator: loss 10.8123197555542\n","Epoch 83, batch 3/240:\tDiscriminator: real loss 0.16481029987335205, fake loss 0.18613994121551514\tGenerator: loss 11.146707534790039\n","Epoch 83, batch 4/240:\tDiscriminator: real loss 0.17694391310214996, fake loss 0.20541206002235413\tGenerator: loss 11.736546516418457\n","Epoch 83, batch 5/240:\tDiscriminator: real loss 0.12434324622154236, fake loss 0.31924667954444885\tGenerator: loss 11.461773872375488\n","Epoch 83, batch 6/240:\tDiscriminator: real loss 0.1909998655319214, fake loss 0.17133332788944244\tGenerator: loss 13.802495002746582\n","Epoch 83, batch 7/240:\tDiscriminator: real loss 0.21354854106903076, fake loss 0.2728080749511719\tGenerator: loss 11.221363067626953\n","Epoch 83, batch 8/240:\tDiscriminator: real loss 0.1282159984111786, fake loss 0.17296737432479858\tGenerator: loss 9.993556022644043\n","Epoch 83, batch 9/240:\tDiscriminator: real loss 0.11520539224147797, fake loss 0.23840929567813873\tGenerator: loss 10.651224136352539\n","Epoch 83, batch 10/240:\tDiscriminator: real loss 0.17595987021923065, fake loss 0.05756112560629845\tGenerator: loss 9.761645317077637\n","Epoch 83, batch 11/240:\tDiscriminator: real loss 0.11295151710510254, fake loss 0.3352991044521332\tGenerator: loss 10.254345893859863\n","Epoch 83, batch 12/240:\tDiscriminator: real loss 0.1464298963546753, fake loss 0.13706916570663452\tGenerator: loss 9.582613945007324\n","Epoch 83, batch 13/240:\tDiscriminator: real loss 0.20413480699062347, fake loss 0.20495566725730896\tGenerator: loss 8.224501609802246\n","Epoch 83, batch 14/240:\tDiscriminator: real loss 0.09994879364967346, fake loss 0.3507141172885895\tGenerator: loss 11.028729438781738\n","Epoch 83, batch 15/240:\tDiscriminator: real loss 0.13084295392036438, fake loss 0.13837724924087524\tGenerator: loss 11.83938980102539\n","Epoch 83, batch 16/240:\tDiscriminator: real loss 0.13264872133731842, fake loss 0.16033600270748138\tGenerator: loss 10.900912284851074\n","Epoch 83, batch 17/240:\tDiscriminator: real loss 0.1337870955467224, fake loss 0.18534648418426514\tGenerator: loss 10.668346405029297\n","Epoch 83, batch 18/240:\tDiscriminator: real loss 0.16290836036205292, fake loss 0.24330256879329681\tGenerator: loss 9.660665512084961\n","Epoch 83, batch 19/240:\tDiscriminator: real loss 0.18083056807518005, fake loss 0.2588939964771271\tGenerator: loss 9.750669479370117\n","Epoch 83, batch 20/240:\tDiscriminator: real loss 0.1303052306175232, fake loss 0.22423122823238373\tGenerator: loss 10.67752456665039\n","Epoch 83, batch 21/240:\tDiscriminator: real loss 0.17024433612823486, fake loss 0.11456196010112762\tGenerator: loss 9.017304420471191\n","Epoch 83, batch 22/240:\tDiscriminator: real loss 0.13458377122879028, fake loss 0.06534431874752045\tGenerator: loss 6.527127742767334\n","Epoch 83, batch 23/240:\tDiscriminator: real loss 0.0970500260591507, fake loss 0.37015461921691895\tGenerator: loss 7.857687950134277\n","Epoch 83, batch 24/240:\tDiscriminator: real loss 0.06896629929542542, fake loss 0.2096201330423355\tGenerator: loss 9.959847450256348\n","Epoch 83, batch 25/240:\tDiscriminator: real loss 0.31590861082077026, fake loss 0.1664973497390747\tGenerator: loss 10.369604110717773\n","Epoch 83, batch 26/240:\tDiscriminator: real loss 0.11230042576789856, fake loss 0.2520422339439392\tGenerator: loss 9.73049545288086\n","Epoch 83, batch 27/240:\tDiscriminator: real loss 0.10777326673269272, fake loss 0.1251230388879776\tGenerator: loss 10.30581283569336\n","Epoch 83, batch 28/240:\tDiscriminator: real loss 0.13372674584388733, fake loss 0.14271557331085205\tGenerator: loss 9.680412292480469\n","Epoch 83, batch 29/240:\tDiscriminator: real loss 0.0691574364900589, fake loss 0.1060636043548584\tGenerator: loss 11.467225074768066\n","Epoch 83, batch 30/240:\tDiscriminator: real loss 0.11948545277118683, fake loss 0.24899674952030182\tGenerator: loss 12.462848663330078\n","Epoch 83, batch 31/240:\tDiscriminator: real loss 0.17974719405174255, fake loss 0.18901470303535461\tGenerator: loss 13.359475135803223\n","Epoch 83, batch 32/240:\tDiscriminator: real loss 0.10561834275722504, fake loss 0.32440894842147827\tGenerator: loss 14.235583305358887\n","Epoch 83, batch 33/240:\tDiscriminator: real loss 0.25021564960479736, fake loss 0.12293538451194763\tGenerator: loss 10.991250038146973\n","Epoch 83, batch 34/240:\tDiscriminator: real loss 0.10308711975812912, fake loss 0.1627790778875351\tGenerator: loss 9.001565933227539\n","Epoch 83, batch 35/240:\tDiscriminator: real loss 0.07963220030069351, fake loss 0.2548617124557495\tGenerator: loss 8.225622177124023\n","Epoch 83, batch 36/240:\tDiscriminator: real loss 0.18863917887210846, fake loss 0.07727208733558655\tGenerator: loss 7.836259841918945\n","Epoch 83, batch 37/240:\tDiscriminator: real loss 0.11801134049892426, fake loss 0.2728528678417206\tGenerator: loss 9.035573959350586\n","Epoch 83, batch 38/240:\tDiscriminator: real loss 0.10099571198225021, fake loss 0.27208295464515686\tGenerator: loss 10.175568580627441\n","Epoch 83, batch 39/240:\tDiscriminator: real loss 0.23242805898189545, fake loss 0.15190887451171875\tGenerator: loss 9.150047302246094\n","Epoch 83, batch 40/240:\tDiscriminator: real loss 0.19221127033233643, fake loss 0.22797563672065735\tGenerator: loss 11.838412284851074\n","Epoch 83, batch 41/240:\tDiscriminator: real loss 0.07996673882007599, fake loss 0.1371038556098938\tGenerator: loss 11.501246452331543\n","Epoch 83, batch 42/240:\tDiscriminator: real loss 0.18960626423358917, fake loss 0.37163394689559937\tGenerator: loss 13.6211576461792\n","Epoch 83, batch 43/240:\tDiscriminator: real loss 0.1811160147190094, fake loss 0.1855793595314026\tGenerator: loss 12.976139068603516\n","Epoch 83, batch 44/240:\tDiscriminator: real loss 0.10134811699390411, fake loss 0.29471534490585327\tGenerator: loss 11.822134971618652\n","Epoch 83, batch 45/240:\tDiscriminator: real loss 0.20534957945346832, fake loss 0.18382789194583893\tGenerator: loss 11.884607315063477\n","Epoch 83, batch 46/240:\tDiscriminator: real loss 0.13999275863170624, fake loss 0.16255159676074982\tGenerator: loss 9.851468086242676\n","Epoch 83, batch 47/240:\tDiscriminator: real loss 0.06855570524930954, fake loss 0.26342809200286865\tGenerator: loss 9.394452095031738\n","Epoch 83, batch 48/240:\tDiscriminator: real loss 0.14311657845973969, fake loss 0.15226733684539795\tGenerator: loss 8.310471534729004\n","Epoch 83, batch 49/240:\tDiscriminator: real loss 0.16122132539749146, fake loss 0.12429270148277283\tGenerator: loss 7.895626068115234\n","Epoch 83, batch 50/240:\tDiscriminator: real loss 0.12187856435775757, fake loss 0.2860645055770874\tGenerator: loss 10.750815391540527\n","Epoch 83, batch 51/240:\tDiscriminator: real loss 0.08323515951633453, fake loss 0.10348818451166153\tGenerator: loss 12.556451797485352\n","Epoch 83, batch 52/240:\tDiscriminator: real loss 0.05913080275058746, fake loss 0.14690454304218292\tGenerator: loss 13.573835372924805\n","Epoch 83, batch 53/240:\tDiscriminator: real loss 0.1484876275062561, fake loss 0.10608972609043121\tGenerator: loss 11.492757797241211\n","Epoch 83, batch 54/240:\tDiscriminator: real loss 0.09918952733278275, fake loss 0.11166814714670181\tGenerator: loss 12.045432090759277\n","Epoch 83, batch 55/240:\tDiscriminator: real loss 0.08408045768737793, fake loss 0.39576172828674316\tGenerator: loss 12.004605293273926\n","Epoch 83, batch 56/240:\tDiscriminator: real loss 0.12265056371688843, fake loss 0.1572786271572113\tGenerator: loss 9.794829368591309\n","Epoch 83, batch 57/240:\tDiscriminator: real loss 0.161855086684227, fake loss 0.10621663182973862\tGenerator: loss 9.131784439086914\n","Epoch 83, batch 58/240:\tDiscriminator: real loss 0.1539667695760727, fake loss 0.30305373668670654\tGenerator: loss 8.959222793579102\n","Epoch 83, batch 59/240:\tDiscriminator: real loss 0.12875036895275116, fake loss 0.16994249820709229\tGenerator: loss 9.533836364746094\n","Epoch 83, batch 60/240:\tDiscriminator: real loss 0.15510155260562897, fake loss 0.0640144869685173\tGenerator: loss 9.906851768493652\n","Epoch 83, batch 61/240:\tDiscriminator: real loss 0.08155853301286697, fake loss 0.15947550535202026\tGenerator: loss 8.950394630432129\n","Epoch 83, batch 62/240:\tDiscriminator: real loss 0.07246225327253342, fake loss 0.16828125715255737\tGenerator: loss 12.7520170211792\n","Epoch 83, batch 63/240:\tDiscriminator: real loss 0.1442103236913681, fake loss 0.15181498229503632\tGenerator: loss 13.620118141174316\n","Epoch 83, batch 64/240:\tDiscriminator: real loss 0.10658905655145645, fake loss 0.2882331907749176\tGenerator: loss 13.823555946350098\n","Epoch 83, batch 65/240:\tDiscriminator: real loss 0.1221734806895256, fake loss 0.167449489235878\tGenerator: loss 12.33700180053711\n","Epoch 83, batch 66/240:\tDiscriminator: real loss 0.18318310379981995, fake loss 0.13470567762851715\tGenerator: loss 8.826342582702637\n","Epoch 83, batch 67/240:\tDiscriminator: real loss 0.11265817284584045, fake loss 0.1270381510257721\tGenerator: loss 8.958072662353516\n","Epoch 83, batch 68/240:\tDiscriminator: real loss 0.1263892948627472, fake loss 0.2546740472316742\tGenerator: loss 8.158594131469727\n","Epoch 83, batch 69/240:\tDiscriminator: real loss 0.1661071926355362, fake loss 0.11245428025722504\tGenerator: loss 9.488718032836914\n","Epoch 83, batch 70/240:\tDiscriminator: real loss 0.10941271483898163, fake loss 0.3031303286552429\tGenerator: loss 9.039011001586914\n","Epoch 83, batch 71/240:\tDiscriminator: real loss 0.05979020148515701, fake loss 0.18167054653167725\tGenerator: loss 9.661111831665039\n","Epoch 83, batch 72/240:\tDiscriminator: real loss 0.198154017329216, fake loss 0.2266753613948822\tGenerator: loss 10.513657569885254\n","Epoch 83, batch 73/240:\tDiscriminator: real loss 0.11765960603952408, fake loss 0.13081549108028412\tGenerator: loss 10.029814720153809\n","Epoch 83, batch 74/240:\tDiscriminator: real loss 0.14384526014328003, fake loss 0.11917290091514587\tGenerator: loss 10.303502082824707\n","Epoch 83, batch 75/240:\tDiscriminator: real loss 0.10994008183479309, fake loss 0.10281307250261307\tGenerator: loss 8.701725006103516\n","Epoch 83, batch 76/240:\tDiscriminator: real loss 0.11307545006275177, fake loss 0.21674633026123047\tGenerator: loss 9.123125076293945\n","Epoch 83, batch 77/240:\tDiscriminator: real loss 0.07537048310041428, fake loss 0.42708584666252136\tGenerator: loss 12.220978736877441\n","Epoch 83, batch 78/240:\tDiscriminator: real loss 0.19807006418704987, fake loss 0.12776273488998413\tGenerator: loss 14.59890365600586\n","Epoch 83, batch 79/240:\tDiscriminator: real loss 0.2151459902524948, fake loss 0.2159237116575241\tGenerator: loss 10.714381217956543\n","Epoch 83, batch 80/240:\tDiscriminator: real loss 0.13381507992744446, fake loss 0.2813861072063446\tGenerator: loss 12.316425323486328\n","Epoch 83, batch 81/240:\tDiscriminator: real loss 0.17811991274356842, fake loss 0.013196498155593872\tGenerator: loss 11.799457550048828\n","Epoch 83, batch 82/240:\tDiscriminator: real loss 0.08811376243829727, fake loss 0.5797332525253296\tGenerator: loss 14.624059677124023\n","Epoch 83, batch 83/240:\tDiscriminator: real loss 0.11195137351751328, fake loss 0.07519810646772385\tGenerator: loss 13.692591667175293\n","Epoch 83, batch 84/240:\tDiscriminator: real loss 0.24180588126182556, fake loss 0.12088003009557724\tGenerator: loss 10.558531761169434\n","Epoch 83, batch 85/240:\tDiscriminator: real loss 0.15010567009449005, fake loss 0.11344726383686066\tGenerator: loss 10.44291877746582\n","Epoch 83, batch 86/240:\tDiscriminator: real loss 0.047337986528873444, fake loss 0.22928205132484436\tGenerator: loss 11.052038192749023\n","Epoch 83, batch 87/240:\tDiscriminator: real loss 0.06129219010472298, fake loss 0.3890495300292969\tGenerator: loss 11.200865745544434\n","Epoch 83, batch 88/240:\tDiscriminator: real loss 0.24742446839809418, fake loss 0.31757327914237976\tGenerator: loss 10.958745956420898\n","Epoch 83, batch 89/240:\tDiscriminator: real loss 0.3011244237422943, fake loss 0.2928423285484314\tGenerator: loss 6.502227306365967\n","Epoch 83, batch 90/240:\tDiscriminator: real loss 0.1940114051103592, fake loss 0.1741935908794403\tGenerator: loss 6.733997821807861\n","Epoch 83, batch 91/240:\tDiscriminator: real loss 0.14012275636196136, fake loss 0.22184795141220093\tGenerator: loss 9.924036979675293\n","Epoch 83, batch 92/240:\tDiscriminator: real loss 0.202198326587677, fake loss 0.2720906734466553\tGenerator: loss 13.000842094421387\n","Epoch 83, batch 93/240:\tDiscriminator: real loss 0.12062101066112518, fake loss 0.13216274976730347\tGenerator: loss 12.312359809875488\n","Epoch 83, batch 94/240:\tDiscriminator: real loss 0.1411927491426468, fake loss 0.17818115651607513\tGenerator: loss 11.734382629394531\n","Epoch 83, batch 95/240:\tDiscriminator: real loss 0.10164882987737656, fake loss 0.23159655928611755\tGenerator: loss 11.528639793395996\n","Epoch 83, batch 96/240:\tDiscriminator: real loss 0.15308219194412231, fake loss 0.12010200321674347\tGenerator: loss 11.617956161499023\n","Epoch 83, batch 97/240:\tDiscriminator: real loss 0.13996922969818115, fake loss 0.3691376745700836\tGenerator: loss 11.427552223205566\n","Epoch 83, batch 98/240:\tDiscriminator: real loss 0.11966971307992935, fake loss 0.2508845627307892\tGenerator: loss 12.298430442810059\n","Epoch 83, batch 99/240:\tDiscriminator: real loss 0.20074871182441711, fake loss 0.04432399198412895\tGenerator: loss 11.796897888183594\n","Epoch 83, batch 100/240:\tDiscriminator: real loss 0.107892245054245, fake loss 0.27364975214004517\tGenerator: loss 11.719535827636719\n","Epoch 83, batch 101/240:\tDiscriminator: real loss 0.10265758633613586, fake loss 0.22218869626522064\tGenerator: loss 12.4540376663208\n","Epoch 83, batch 102/240:\tDiscriminator: real loss 0.17899982631206512, fake loss 0.22536033391952515\tGenerator: loss 12.155279159545898\n","Epoch 83, batch 103/240:\tDiscriminator: real loss 0.257011741399765, fake loss 0.1406935453414917\tGenerator: loss 12.833880424499512\n","Epoch 83, batch 104/240:\tDiscriminator: real loss 0.1570068746805191, fake loss 0.2654514014720917\tGenerator: loss 11.972648620605469\n","Epoch 83, batch 105/240:\tDiscriminator: real loss 0.052454933524131775, fake loss 0.11067914962768555\tGenerator: loss 12.186083793640137\n","Epoch 83, batch 106/240:\tDiscriminator: real loss 0.11209546774625778, fake loss 0.19897040724754333\tGenerator: loss 11.119589805603027\n","Epoch 83, batch 107/240:\tDiscriminator: real loss 0.06985906511545181, fake loss 0.1727128028869629\tGenerator: loss 10.532792091369629\n","Epoch 83, batch 108/240:\tDiscriminator: real loss 0.12742215394973755, fake loss 0.16382938623428345\tGenerator: loss 11.947741508483887\n","Epoch 83, batch 109/240:\tDiscriminator: real loss 0.0827891156077385, fake loss 0.08280692249536514\tGenerator: loss 11.239572525024414\n","Epoch 83, batch 110/240:\tDiscriminator: real loss 0.13065342605113983, fake loss 0.2555781304836273\tGenerator: loss 12.54121208190918\n","Epoch 83, batch 111/240:\tDiscriminator: real loss 0.14239466190338135, fake loss 0.29086410999298096\tGenerator: loss 10.782299041748047\n","Epoch 83, batch 112/240:\tDiscriminator: real loss 0.22750568389892578, fake loss 0.1502007693052292\tGenerator: loss 9.720465660095215\n","Epoch 83, batch 113/240:\tDiscriminator: real loss 0.1883097141981125, fake loss 0.21666310727596283\tGenerator: loss 8.588970184326172\n","Epoch 83, batch 114/240:\tDiscriminator: real loss 0.1319093555212021, fake loss 0.20281295478343964\tGenerator: loss 8.975098609924316\n","Epoch 83, batch 115/240:\tDiscriminator: real loss 0.0940939411520958, fake loss 0.1174425333738327\tGenerator: loss 8.640356063842773\n","Epoch 83, batch 116/240:\tDiscriminator: real loss 0.13555949926376343, fake loss 0.17684988677501678\tGenerator: loss 8.500580787658691\n","Epoch 83, batch 117/240:\tDiscriminator: real loss 0.11593417823314667, fake loss 0.34176596999168396\tGenerator: loss 9.91482162475586\n","Epoch 83, batch 118/240:\tDiscriminator: real loss 0.1591503918170929, fake loss 0.18048061430454254\tGenerator: loss 9.458115577697754\n","Epoch 83, batch 119/240:\tDiscriminator: real loss 0.18317237496376038, fake loss 0.15192630887031555\tGenerator: loss 11.231258392333984\n","Epoch 83, batch 120/240:\tDiscriminator: real loss 0.16115351021289825, fake loss 0.16568847000598907\tGenerator: loss 9.458709716796875\n","Epoch 83, batch 121/240:\tDiscriminator: real loss 0.10248842090368271, fake loss 0.2019326537847519\tGenerator: loss 8.596779823303223\n","Epoch 83, batch 122/240:\tDiscriminator: real loss 0.17751069366931915, fake loss 0.15544307231903076\tGenerator: loss 10.519765853881836\n","Epoch 83, batch 123/240:\tDiscriminator: real loss 0.07284398376941681, fake loss 0.36591818928718567\tGenerator: loss 11.015036582946777\n","Epoch 83, batch 124/240:\tDiscriminator: real loss 0.20762044191360474, fake loss 0.13119328022003174\tGenerator: loss 9.58299446105957\n","Epoch 83, batch 125/240:\tDiscriminator: real loss 0.1990489810705185, fake loss 0.17761144042015076\tGenerator: loss 10.0668363571167\n","Epoch 83, batch 126/240:\tDiscriminator: real loss 0.1219138354063034, fake loss 0.38799574971199036\tGenerator: loss 10.310267448425293\n","Epoch 83, batch 127/240:\tDiscriminator: real loss 0.19877620041370392, fake loss 0.12095813453197479\tGenerator: loss 12.073519706726074\n","Epoch 83, batch 128/240:\tDiscriminator: real loss 0.1275690793991089, fake loss 0.1607908457517624\tGenerator: loss 11.250622749328613\n","Epoch 83, batch 129/240:\tDiscriminator: real loss 0.1429067999124527, fake loss 0.2581832706928253\tGenerator: loss 10.809758186340332\n","Epoch 83, batch 130/240:\tDiscriminator: real loss 0.10057986527681351, fake loss 0.05957545340061188\tGenerator: loss 10.411002159118652\n","Epoch 83, batch 131/240:\tDiscriminator: real loss 0.14233501255512238, fake loss 0.14094670116901398\tGenerator: loss 10.10757827758789\n","Epoch 83, batch 132/240:\tDiscriminator: real loss 0.1289401352405548, fake loss 0.36084675788879395\tGenerator: loss 10.119965553283691\n","Epoch 83, batch 133/240:\tDiscriminator: real loss 0.11099228262901306, fake loss 0.13004615902900696\tGenerator: loss 11.560154914855957\n","Epoch 83, batch 134/240:\tDiscriminator: real loss 0.14933624863624573, fake loss 0.07563541829586029\tGenerator: loss 10.161860466003418\n","Epoch 83, batch 135/240:\tDiscriminator: real loss 0.13064739108085632, fake loss 0.10546696931123734\tGenerator: loss 9.80947208404541\n","Epoch 83, batch 136/240:\tDiscriminator: real loss 0.09533289819955826, fake loss 0.3494834899902344\tGenerator: loss 10.831230163574219\n","Epoch 83, batch 137/240:\tDiscriminator: real loss 0.07321077585220337, fake loss 0.2517138421535492\tGenerator: loss 13.154840469360352\n","Epoch 83, batch 138/240:\tDiscriminator: real loss 0.17633327841758728, fake loss 0.1658504456281662\tGenerator: loss 12.034663200378418\n","Epoch 83, batch 139/240:\tDiscriminator: real loss 0.19542087614536285, fake loss 0.09700341522693634\tGenerator: loss 9.581316947937012\n","Epoch 83, batch 140/240:\tDiscriminator: real loss 0.06999781727790833, fake loss 0.3425352871417999\tGenerator: loss 11.284955024719238\n","Epoch 83, batch 141/240:\tDiscriminator: real loss 0.14707837998867035, fake loss 0.12134524434804916\tGenerator: loss 10.305414199829102\n","Epoch 83, batch 142/240:\tDiscriminator: real loss 0.17771762609481812, fake loss 0.185613214969635\tGenerator: loss 8.747928619384766\n","Epoch 83, batch 143/240:\tDiscriminator: real loss 0.17013680934906006, fake loss 0.13596989214420319\tGenerator: loss 10.0655517578125\n","Epoch 83, batch 144/240:\tDiscriminator: real loss 0.1643945574760437, fake loss 0.24374070763587952\tGenerator: loss 9.607547760009766\n","Epoch 83, batch 145/240:\tDiscriminator: real loss 0.12582562863826752, fake loss 0.15222284197807312\tGenerator: loss 11.569775581359863\n","Epoch 83, batch 146/240:\tDiscriminator: real loss 0.15362662076950073, fake loss 0.33143821358680725\tGenerator: loss 12.85576057434082\n","Epoch 83, batch 147/240:\tDiscriminator: real loss 0.09048938006162643, fake loss 0.19567900896072388\tGenerator: loss 13.496245384216309\n","Epoch 83, batch 148/240:\tDiscriminator: real loss 0.1839858591556549, fake loss 0.18305955827236176\tGenerator: loss 12.650328636169434\n","Epoch 83, batch 149/240:\tDiscriminator: real loss 0.16660171747207642, fake loss 0.19949327409267426\tGenerator: loss 10.976566314697266\n","Epoch 83, batch 150/240:\tDiscriminator: real loss 0.1079820916056633, fake loss 0.17270129919052124\tGenerator: loss 9.410161972045898\n","Epoch 83, batch 151/240:\tDiscriminator: real loss 0.08757835626602173, fake loss 0.19691616296768188\tGenerator: loss 10.248757362365723\n","Epoch 83, batch 152/240:\tDiscriminator: real loss 0.24841606616973877, fake loss 0.05432571843266487\tGenerator: loss 7.221987247467041\n","Epoch 83, batch 153/240:\tDiscriminator: real loss 0.15421171486377716, fake loss 0.17767468094825745\tGenerator: loss 7.3974199295043945\n","Epoch 83, batch 154/240:\tDiscriminator: real loss 0.0506710559129715, fake loss 0.3585742712020874\tGenerator: loss 7.084736347198486\n","Epoch 83, batch 155/240:\tDiscriminator: real loss 0.07334038615226746, fake loss 0.10568328946828842\tGenerator: loss 7.417735576629639\n","Epoch 83, batch 156/240:\tDiscriminator: real loss 0.2718498408794403, fake loss 0.15632747113704681\tGenerator: loss 9.231839179992676\n","Epoch 83, batch 157/240:\tDiscriminator: real loss 0.11721836030483246, fake loss 0.1404314488172531\tGenerator: loss 9.211030006408691\n","Epoch 83, batch 158/240:\tDiscriminator: real loss 0.10339031368494034, fake loss 0.23587889969348907\tGenerator: loss 11.254890441894531\n","Epoch 83, batch 159/240:\tDiscriminator: real loss 0.05823444947600365, fake loss 0.17907088994979858\tGenerator: loss 12.105177879333496\n","Epoch 83, batch 160/240:\tDiscriminator: real loss 0.11747097223997116, fake loss 0.1896190643310547\tGenerator: loss 12.698647499084473\n","Epoch 83, batch 161/240:\tDiscriminator: real loss 0.12624132633209229, fake loss 0.08482073992490768\tGenerator: loss 12.200133323669434\n","Epoch 83, batch 162/240:\tDiscriminator: real loss 0.14368274807929993, fake loss 0.19907456636428833\tGenerator: loss 10.546891212463379\n","Epoch 83, batch 163/240:\tDiscriminator: real loss 0.08409704267978668, fake loss 0.2336874008178711\tGenerator: loss 11.005420684814453\n","Epoch 83, batch 164/240:\tDiscriminator: real loss 0.10515924543142319, fake loss 0.1715671569108963\tGenerator: loss 10.637757301330566\n","Epoch 83, batch 165/240:\tDiscriminator: real loss 0.11654840409755707, fake loss 0.13724128901958466\tGenerator: loss 9.48830795288086\n","Epoch 83, batch 166/240:\tDiscriminator: real loss 0.13804572820663452, fake loss 0.2312793731689453\tGenerator: loss 8.817625999450684\n","Epoch 83, batch 167/240:\tDiscriminator: real loss 0.1333744376897812, fake loss 0.11009328812360764\tGenerator: loss 10.067194938659668\n","Epoch 83, batch 168/240:\tDiscriminator: real loss 0.10346490889787674, fake loss 0.2640204429626465\tGenerator: loss 9.978614807128906\n","Epoch 83, batch 169/240:\tDiscriminator: real loss 0.13327576220035553, fake loss 0.160904198884964\tGenerator: loss 10.001326560974121\n","Epoch 83, batch 170/240:\tDiscriminator: real loss 0.15761251747608185, fake loss 0.11818317323923111\tGenerator: loss 8.878765106201172\n","Epoch 83, batch 171/240:\tDiscriminator: real loss 0.10976023972034454, fake loss 0.13829630613327026\tGenerator: loss 7.673293590545654\n","Epoch 83, batch 172/240:\tDiscriminator: real loss 0.1024189367890358, fake loss 0.3789539635181427\tGenerator: loss 10.684637069702148\n","Epoch 83, batch 173/240:\tDiscriminator: real loss 0.14539818465709686, fake loss 0.07322072237730026\tGenerator: loss 12.621929168701172\n","Epoch 83, batch 174/240:\tDiscriminator: real loss 0.11584052443504333, fake loss 0.20336027443408966\tGenerator: loss 14.010440826416016\n","Epoch 83, batch 175/240:\tDiscriminator: real loss 0.07685500383377075, fake loss 0.3942157030105591\tGenerator: loss 14.018143653869629\n","Epoch 83, batch 176/240:\tDiscriminator: real loss 0.2711015045642853, fake loss 0.11110972613096237\tGenerator: loss 11.290501594543457\n","Epoch 83, batch 177/240:\tDiscriminator: real loss 0.21132732927799225, fake loss 0.130458801984787\tGenerator: loss 10.370748519897461\n","Epoch 83, batch 178/240:\tDiscriminator: real loss 0.07808184623718262, fake loss 0.10505979508161545\tGenerator: loss 11.126229286193848\n","Epoch 83, batch 179/240:\tDiscriminator: real loss 0.11318609863519669, fake loss 0.5527644157409668\tGenerator: loss 13.330466270446777\n","Epoch 83, batch 180/240:\tDiscriminator: real loss 0.19137020409107208, fake loss 0.1553393006324768\tGenerator: loss 13.163481712341309\n","Epoch 83, batch 181/240:\tDiscriminator: real loss 0.14463689923286438, fake loss 0.1630406230688095\tGenerator: loss 14.055242538452148\n","Epoch 83, batch 182/240:\tDiscriminator: real loss 0.16890251636505127, fake loss 0.11619587987661362\tGenerator: loss 10.173986434936523\n","Epoch 83, batch 183/240:\tDiscriminator: real loss 0.13238951563835144, fake loss 0.07065477222204208\tGenerator: loss 10.787006378173828\n","Epoch 83, batch 184/240:\tDiscriminator: real loss 0.08012010902166367, fake loss 0.2988763153553009\tGenerator: loss 11.171568870544434\n","Epoch 83, batch 185/240:\tDiscriminator: real loss 0.07364117354154587, fake loss 0.15022815763950348\tGenerator: loss 13.58332633972168\n","Epoch 83, batch 186/240:\tDiscriminator: real loss 0.1218765452504158, fake loss 0.25684046745300293\tGenerator: loss 14.066218376159668\n","Epoch 83, batch 187/240:\tDiscriminator: real loss 0.20376361906528473, fake loss 0.1437714546918869\tGenerator: loss 13.86807632446289\n","Epoch 83, batch 188/240:\tDiscriminator: real loss 0.14236120879650116, fake loss 0.26459285616874695\tGenerator: loss 12.977643013000488\n","Epoch 83, batch 189/240:\tDiscriminator: real loss 0.1383771002292633, fake loss 0.17222177982330322\tGenerator: loss 9.830862045288086\n","Epoch 83, batch 190/240:\tDiscriminator: real loss 0.14541733264923096, fake loss 0.09082639962434769\tGenerator: loss 8.906465530395508\n","Epoch 83, batch 191/240:\tDiscriminator: real loss 0.12815140187740326, fake loss 0.2947852611541748\tGenerator: loss 7.414874076843262\n","Epoch 83, batch 192/240:\tDiscriminator: real loss 0.1831127107143402, fake loss 0.19861696660518646\tGenerator: loss 10.968749046325684\n","Epoch 83, batch 193/240:\tDiscriminator: real loss 0.14713694155216217, fake loss 0.11882754415273666\tGenerator: loss 10.525848388671875\n","Epoch 83, batch 194/240:\tDiscriminator: real loss 0.04448383301496506, fake loss 0.1022341176867485\tGenerator: loss 11.974835395812988\n","Epoch 83, batch 195/240:\tDiscriminator: real loss 0.1018352136015892, fake loss 0.19164888560771942\tGenerator: loss 10.24221420288086\n","Epoch 83, batch 196/240:\tDiscriminator: real loss 0.11045476049184799, fake loss 0.16984058916568756\tGenerator: loss 9.696161270141602\n","Epoch 83, batch 197/240:\tDiscriminator: real loss 0.10055763274431229, fake loss 0.14849314093589783\tGenerator: loss 8.821781158447266\n","Epoch 83, batch 198/240:\tDiscriminator: real loss 0.2089676707983017, fake loss 0.24596630036830902\tGenerator: loss 8.124347686767578\n","Epoch 83, batch 199/240:\tDiscriminator: real loss 0.09037099778652191, fake loss 0.07662642747163773\tGenerator: loss 7.54934549331665\n","Epoch 83, batch 200/240:\tDiscriminator: real loss 0.10342574864625931, fake loss 0.19737909734249115\tGenerator: loss 8.195586204528809\n","Epoch 83, batch 201/240:\tDiscriminator: real loss 0.1738535314798355, fake loss 0.26938971877098083\tGenerator: loss 7.342060089111328\n","Epoch 83, batch 202/240:\tDiscriminator: real loss 0.1216135025024414, fake loss 0.09106811881065369\tGenerator: loss 7.564475059509277\n","Epoch 83, batch 203/240:\tDiscriminator: real loss 0.10997757315635681, fake loss 0.297811895608902\tGenerator: loss 10.757341384887695\n","Epoch 83, batch 204/240:\tDiscriminator: real loss 0.08203686028718948, fake loss 0.12383552640676498\tGenerator: loss 12.229762077331543\n","Epoch 83, batch 205/240:\tDiscriminator: real loss 0.15156978368759155, fake loss 0.1314706951379776\tGenerator: loss 12.59552001953125\n","Epoch 83, batch 206/240:\tDiscriminator: real loss 0.12557081878185272, fake loss 0.2275782823562622\tGenerator: loss 13.956755638122559\n","Epoch 83, batch 207/240:\tDiscriminator: real loss 0.10670241713523865, fake loss 0.15628771483898163\tGenerator: loss 14.48398208618164\n","Epoch 83, batch 208/240:\tDiscriminator: real loss 0.16273464262485504, fake loss 0.2838749587535858\tGenerator: loss 14.200061798095703\n","Epoch 83, batch 209/240:\tDiscriminator: real loss 0.11528003960847855, fake loss 0.21261844038963318\tGenerator: loss 12.947750091552734\n","Epoch 83, batch 210/240:\tDiscriminator: real loss 0.23361903429031372, fake loss 0.10482084006071091\tGenerator: loss 11.650367736816406\n","Epoch 83, batch 211/240:\tDiscriminator: real loss 0.10319842398166656, fake loss 0.3050720989704132\tGenerator: loss 12.198286056518555\n","Epoch 83, batch 212/240:\tDiscriminator: real loss 0.114905446767807, fake loss 0.1485678106546402\tGenerator: loss 12.708361625671387\n","Epoch 83, batch 213/240:\tDiscriminator: real loss 0.16083453595638275, fake loss 0.1808725744485855\tGenerator: loss 11.749922752380371\n","Epoch 83, batch 214/240:\tDiscriminator: real loss 0.10798676311969757, fake loss 0.10985145717859268\tGenerator: loss 10.54869270324707\n","Epoch 83, batch 215/240:\tDiscriminator: real loss 0.09848670661449432, fake loss 0.17211128771305084\tGenerator: loss 11.467371940612793\n","Epoch 83, batch 216/240:\tDiscriminator: real loss 0.12441134452819824, fake loss 0.25337690114974976\tGenerator: loss 12.217495918273926\n","Epoch 83, batch 217/240:\tDiscriminator: real loss 0.14248424768447876, fake loss 0.3040754795074463\tGenerator: loss 11.261109352111816\n","Epoch 83, batch 218/240:\tDiscriminator: real loss 0.20790065824985504, fake loss 0.13392171263694763\tGenerator: loss 9.614023208618164\n","Epoch 83, batch 219/240:\tDiscriminator: real loss 0.1777464747428894, fake loss 0.23229572176933289\tGenerator: loss 11.214252471923828\n","Epoch 83, batch 220/240:\tDiscriminator: real loss 0.1045062243938446, fake loss 0.2108282893896103\tGenerator: loss 11.913407325744629\n","Epoch 83, batch 221/240:\tDiscriminator: real loss 0.11582084745168686, fake loss 0.3330375552177429\tGenerator: loss 11.229137420654297\n","Epoch 83, batch 222/240:\tDiscriminator: real loss 0.23092541098594666, fake loss 0.09194118529558182\tGenerator: loss 12.20656967163086\n","Epoch 83, batch 223/240:\tDiscriminator: real loss 0.10947933048009872, fake loss 0.22505523264408112\tGenerator: loss 12.808320045471191\n","Epoch 83, batch 224/240:\tDiscriminator: real loss 0.12653346359729767, fake loss 0.25102293491363525\tGenerator: loss 13.747025489807129\n","Epoch 83, batch 225/240:\tDiscriminator: real loss 0.14477701485157013, fake loss 0.1291969269514084\tGenerator: loss 12.392370223999023\n","Epoch 83, batch 226/240:\tDiscriminator: real loss 0.11704206466674805, fake loss 0.17371056973934174\tGenerator: loss 12.266382217407227\n","Epoch 83, batch 227/240:\tDiscriminator: real loss 0.17157720029354095, fake loss 0.10123837739229202\tGenerator: loss 11.568070411682129\n","Epoch 83, batch 228/240:\tDiscriminator: real loss 0.07501220703125, fake loss 0.23111018538475037\tGenerator: loss 11.075368881225586\n","Epoch 83, batch 229/240:\tDiscriminator: real loss 0.1033765971660614, fake loss 0.12379676848649979\tGenerator: loss 10.895524978637695\n","Epoch 83, batch 230/240:\tDiscriminator: real loss 0.1101551353931427, fake loss 0.17416198551654816\tGenerator: loss 11.167880058288574\n","Epoch 83, batch 231/240:\tDiscriminator: real loss 0.1163090169429779, fake loss 0.33114197850227356\tGenerator: loss 12.080984115600586\n","Epoch 83, batch 232/240:\tDiscriminator: real loss 0.11457905173301697, fake loss 0.08523422479629517\tGenerator: loss 12.889142990112305\n","Epoch 83, batch 233/240:\tDiscriminator: real loss 0.14906542003154755, fake loss 0.16984784603118896\tGenerator: loss 12.199563026428223\n","Epoch 83, batch 234/240:\tDiscriminator: real loss 0.13091416656970978, fake loss 0.2431841492652893\tGenerator: loss 11.895108222961426\n","Epoch 83, batch 235/240:\tDiscriminator: real loss 0.13358740508556366, fake loss 0.26788341999053955\tGenerator: loss 11.602107048034668\n","Epoch 83, batch 236/240:\tDiscriminator: real loss 0.2836071848869324, fake loss 0.14483724534511566\tGenerator: loss 10.130654335021973\n","Epoch 83, batch 237/240:\tDiscriminator: real loss 0.09007617086172104, fake loss 0.1740991622209549\tGenerator: loss 8.942206382751465\n","Epoch 83, batch 238/240:\tDiscriminator: real loss 0.07594151794910431, fake loss 0.20919941365718842\tGenerator: loss 8.897692680358887\n","Epoch 83, batch 239/240:\tDiscriminator: real loss 0.20393848419189453, fake loss 0.34330618381500244\tGenerator: loss 9.713617324829102\n","Epoch 83, batch 240/240:\tDiscriminator: real loss 0.1679619401693344, fake loss 0.21911664307117462\tGenerator: loss 12.055461883544922\n","Epoch 84, batch 1/240:\tDiscriminator: real loss 0.24634622037410736, fake loss 0.1748548001050949\tGenerator: loss 7.719676494598389\n","Epoch 84, batch 2/240:\tDiscriminator: real loss 0.08457190543413162, fake loss 0.153399258852005\tGenerator: loss 7.07755184173584\n","Epoch 84, batch 3/240:\tDiscriminator: real loss 0.1767956018447876, fake loss 0.2932441234588623\tGenerator: loss 8.375543594360352\n","Epoch 84, batch 4/240:\tDiscriminator: real loss 0.17243888974189758, fake loss 0.2643924057483673\tGenerator: loss 7.221230983734131\n","Epoch 84, batch 5/240:\tDiscriminator: real loss 0.1296108216047287, fake loss 0.17409680783748627\tGenerator: loss 8.593860626220703\n","Epoch 84, batch 6/240:\tDiscriminator: real loss 0.1707596778869629, fake loss 0.14594295620918274\tGenerator: loss 8.236454963684082\n","Epoch 84, batch 7/240:\tDiscriminator: real loss 0.16353771090507507, fake loss 0.16581735014915466\tGenerator: loss 8.842665672302246\n","Epoch 84, batch 8/240:\tDiscriminator: real loss 0.0833585262298584, fake loss 0.2671564221382141\tGenerator: loss 9.65304946899414\n","Epoch 84, batch 9/240:\tDiscriminator: real loss 0.12046293169260025, fake loss 0.15729375183582306\tGenerator: loss 9.096309661865234\n","Epoch 84, batch 10/240:\tDiscriminator: real loss 0.20948980748653412, fake loss 0.197494775056839\tGenerator: loss 7.772726058959961\n","Epoch 84, batch 11/240:\tDiscriminator: real loss 0.07792529463768005, fake loss 0.14969727396965027\tGenerator: loss 6.291337966918945\n","Epoch 84, batch 12/240:\tDiscriminator: real loss 0.16783258318901062, fake loss 0.13134032487869263\tGenerator: loss 7.157974720001221\n","Epoch 84, batch 13/240:\tDiscriminator: real loss 0.08894798904657364, fake loss 0.19256709516048431\tGenerator: loss 7.8187479972839355\n","Epoch 84, batch 14/240:\tDiscriminator: real loss 0.13478480279445648, fake loss 0.2089356929063797\tGenerator: loss 9.387210845947266\n","Epoch 84, batch 15/240:\tDiscriminator: real loss 0.14968091249465942, fake loss 0.07164106518030167\tGenerator: loss 9.185393333435059\n","Epoch 84, batch 16/240:\tDiscriminator: real loss 0.16906043887138367, fake loss 0.18909583985805511\tGenerator: loss 10.78648567199707\n","Epoch 84, batch 17/240:\tDiscriminator: real loss 0.07696084678173065, fake loss 0.3551575839519501\tGenerator: loss 13.381869316101074\n","Epoch 84, batch 18/240:\tDiscriminator: real loss 0.1494535654783249, fake loss 0.2240419238805771\tGenerator: loss 10.567983627319336\n","Epoch 84, batch 19/240:\tDiscriminator: real loss 0.2070726603269577, fake loss 0.12493614107370377\tGenerator: loss 9.218551635742188\n","Epoch 84, batch 20/240:\tDiscriminator: real loss 0.1540299355983734, fake loss 0.18157432973384857\tGenerator: loss 9.031820297241211\n","Epoch 84, batch 21/240:\tDiscriminator: real loss 0.10868746787309647, fake loss 0.282823383808136\tGenerator: loss 9.830065727233887\n","Epoch 84, batch 22/240:\tDiscriminator: real loss 0.1588633507490158, fake loss 0.17224952578544617\tGenerator: loss 8.544670104980469\n","Epoch 84, batch 23/240:\tDiscriminator: real loss 0.167120099067688, fake loss 0.16595160961151123\tGenerator: loss 9.233870506286621\n","Epoch 84, batch 24/240:\tDiscriminator: real loss 0.11935142427682877, fake loss 0.24635639786720276\tGenerator: loss 10.803915023803711\n","Epoch 84, batch 25/240:\tDiscriminator: real loss 0.2058192491531372, fake loss 0.07371442764997482\tGenerator: loss 10.62308120727539\n","Epoch 84, batch 26/240:\tDiscriminator: real loss 0.0981215164065361, fake loss 0.158832848072052\tGenerator: loss 9.673885345458984\n","Epoch 84, batch 27/240:\tDiscriminator: real loss 0.06107538193464279, fake loss 0.17418216168880463\tGenerator: loss 10.15035343170166\n","Epoch 84, batch 28/240:\tDiscriminator: real loss 0.11730724573135376, fake loss 0.2526981234550476\tGenerator: loss 9.987113952636719\n","Epoch 84, batch 29/240:\tDiscriminator: real loss 0.12946541607379913, fake loss 0.07797938585281372\tGenerator: loss 9.850278854370117\n","Epoch 84, batch 30/240:\tDiscriminator: real loss 0.17719177901744843, fake loss 0.12362377345561981\tGenerator: loss 9.878334045410156\n","Epoch 84, batch 31/240:\tDiscriminator: real loss 0.09519441425800323, fake loss 0.1087886169552803\tGenerator: loss 8.592489242553711\n","Epoch 84, batch 32/240:\tDiscriminator: real loss 0.04896136745810509, fake loss 0.17128081619739532\tGenerator: loss 8.7782621383667\n","Epoch 84, batch 33/240:\tDiscriminator: real loss 0.09162619709968567, fake loss 0.24654895067214966\tGenerator: loss 8.659640312194824\n","Epoch 84, batch 34/240:\tDiscriminator: real loss 0.1510785073041916, fake loss 0.10454908013343811\tGenerator: loss 9.438028335571289\n","Epoch 84, batch 35/240:\tDiscriminator: real loss 0.07414866238832474, fake loss 0.22251763939857483\tGenerator: loss 10.350475311279297\n","Epoch 84, batch 36/240:\tDiscriminator: real loss 0.13521482050418854, fake loss 0.21125923097133636\tGenerator: loss 11.454742431640625\n","Epoch 84, batch 37/240:\tDiscriminator: real loss 0.1625303328037262, fake loss 0.10135006159543991\tGenerator: loss 12.311837196350098\n","Epoch 84, batch 38/240:\tDiscriminator: real loss 0.08994340151548386, fake loss 0.09043166786432266\tGenerator: loss 10.644556999206543\n","Epoch 84, batch 39/240:\tDiscriminator: real loss 0.10517015308141708, fake loss 0.16752155125141144\tGenerator: loss 10.038479804992676\n","Epoch 84, batch 40/240:\tDiscriminator: real loss 0.12946940958499908, fake loss 0.1399504393339157\tGenerator: loss 9.786931037902832\n","Epoch 84, batch 41/240:\tDiscriminator: real loss 0.069460429251194, fake loss 0.2156742513179779\tGenerator: loss 9.850757598876953\n","Epoch 84, batch 42/240:\tDiscriminator: real loss 0.1248435378074646, fake loss 0.19468170404434204\tGenerator: loss 11.718072891235352\n","Epoch 84, batch 43/240:\tDiscriminator: real loss 0.12598633766174316, fake loss 0.20288901031017303\tGenerator: loss 11.993002891540527\n","Epoch 84, batch 44/240:\tDiscriminator: real loss 0.17892594635486603, fake loss 0.11416957527399063\tGenerator: loss 10.683053970336914\n","Epoch 84, batch 45/240:\tDiscriminator: real loss 0.1348574459552765, fake loss 0.12760435044765472\tGenerator: loss 9.055853843688965\n","Epoch 84, batch 46/240:\tDiscriminator: real loss 0.1323678195476532, fake loss 0.24942134320735931\tGenerator: loss 8.44128704071045\n","Epoch 84, batch 47/240:\tDiscriminator: real loss 0.13113562762737274, fake loss 0.047686867415905\tGenerator: loss 7.496577739715576\n","Epoch 84, batch 48/240:\tDiscriminator: real loss 0.07153501361608505, fake loss 0.2403598427772522\tGenerator: loss 7.653308868408203\n","Epoch 84, batch 49/240:\tDiscriminator: real loss 0.10979151725769043, fake loss 0.24481768906116486\tGenerator: loss 10.082585334777832\n","Epoch 84, batch 50/240:\tDiscriminator: real loss 0.08634132146835327, fake loss 0.12787054479122162\tGenerator: loss 11.632848739624023\n","Epoch 84, batch 51/240:\tDiscriminator: real loss 0.1617000550031662, fake loss 0.11883136630058289\tGenerator: loss 11.286070823669434\n","Epoch 84, batch 52/240:\tDiscriminator: real loss 0.20501673221588135, fake loss 0.11367206275463104\tGenerator: loss 9.247952461242676\n","Epoch 84, batch 53/240:\tDiscriminator: real loss 0.0844825953245163, fake loss 0.13451093435287476\tGenerator: loss 8.518434524536133\n","Epoch 84, batch 54/240:\tDiscriminator: real loss 0.08437317609786987, fake loss 0.23900291323661804\tGenerator: loss 8.239851951599121\n","Epoch 84, batch 55/240:\tDiscriminator: real loss 0.08120357245206833, fake loss 0.2532505989074707\tGenerator: loss 10.689257621765137\n","Epoch 84, batch 56/240:\tDiscriminator: real loss 0.13607007265090942, fake loss 0.12278975546360016\tGenerator: loss 12.198873519897461\n","Epoch 84, batch 57/240:\tDiscriminator: real loss 0.15033172070980072, fake loss 0.2407952845096588\tGenerator: loss 11.893426895141602\n","Epoch 84, batch 58/240:\tDiscriminator: real loss 0.20352385938167572, fake loss 0.17498405277729034\tGenerator: loss 11.54580307006836\n","Epoch 84, batch 59/240:\tDiscriminator: real loss 0.0594283826649189, fake loss 0.19761870801448822\tGenerator: loss 11.025174140930176\n","Epoch 84, batch 60/240:\tDiscriminator: real loss 0.136263906955719, fake loss 0.24934490025043488\tGenerator: loss 10.386368751525879\n","Epoch 84, batch 61/240:\tDiscriminator: real loss 0.19574013352394104, fake loss 0.1809428185224533\tGenerator: loss 8.398965835571289\n","Epoch 84, batch 62/240:\tDiscriminator: real loss 0.11451254040002823, fake loss 0.17450116574764252\tGenerator: loss 8.475227355957031\n","Epoch 84, batch 63/240:\tDiscriminator: real loss 0.11230700463056564, fake loss 0.2145581692457199\tGenerator: loss 9.93146800994873\n","Epoch 84, batch 64/240:\tDiscriminator: real loss 0.13470105826854706, fake loss 0.12120894342660904\tGenerator: loss 12.242032051086426\n","Epoch 84, batch 65/240:\tDiscriminator: real loss 0.15098071098327637, fake loss 0.31262731552124023\tGenerator: loss 13.604883193969727\n","Epoch 84, batch 66/240:\tDiscriminator: real loss 0.153034970164299, fake loss 0.13641542196273804\tGenerator: loss 12.7149019241333\n","Epoch 84, batch 67/240:\tDiscriminator: real loss 0.1602625697851181, fake loss 0.16026052832603455\tGenerator: loss 10.067846298217773\n","Epoch 84, batch 68/240:\tDiscriminator: real loss 0.08853220194578171, fake loss 0.14798849821090698\tGenerator: loss 8.575130462646484\n","Epoch 84, batch 69/240:\tDiscriminator: real loss 0.114586241543293, fake loss 0.15646354854106903\tGenerator: loss 7.179199695587158\n","Epoch 84, batch 70/240:\tDiscriminator: real loss 0.07539250701665878, fake loss 0.41130581498146057\tGenerator: loss 8.722055435180664\n","Epoch 84, batch 71/240:\tDiscriminator: real loss 0.12019068002700806, fake loss 0.1348000466823578\tGenerator: loss 9.425704002380371\n","Epoch 84, batch 72/240:\tDiscriminator: real loss 0.23781311511993408, fake loss 0.11977019906044006\tGenerator: loss 10.925975799560547\n","Epoch 84, batch 73/240:\tDiscriminator: real loss 0.08955775946378708, fake loss 0.09159853309392929\tGenerator: loss 11.256269454956055\n","Epoch 84, batch 74/240:\tDiscriminator: real loss 0.06593062728643417, fake loss 0.2200937718153\tGenerator: loss 12.334131240844727\n","Epoch 84, batch 75/240:\tDiscriminator: real loss 0.09188106656074524, fake loss 0.19682052731513977\tGenerator: loss 12.764448165893555\n","Epoch 84, batch 76/240:\tDiscriminator: real loss 0.15193010866641998, fake loss 0.15982837975025177\tGenerator: loss 10.601312637329102\n","Epoch 84, batch 77/240:\tDiscriminator: real loss 0.16738095879554749, fake loss 0.22768104076385498\tGenerator: loss 10.916149139404297\n","Epoch 84, batch 78/240:\tDiscriminator: real loss 0.21495895087718964, fake loss 0.22751854360103607\tGenerator: loss 8.87257194519043\n","Epoch 84, batch 79/240:\tDiscriminator: real loss 0.105074442923069, fake loss 0.13843980431556702\tGenerator: loss 7.9637651443481445\n","Epoch 84, batch 80/240:\tDiscriminator: real loss 0.22853761911392212, fake loss 0.1686590164899826\tGenerator: loss 8.933780670166016\n","Epoch 84, batch 81/240:\tDiscriminator: real loss 0.0785708799958229, fake loss 0.27401939034461975\tGenerator: loss 11.730663299560547\n","Epoch 84, batch 82/240:\tDiscriminator: real loss 0.12626564502716064, fake loss 0.3377510905265808\tGenerator: loss 13.837982177734375\n","Epoch 84, batch 83/240:\tDiscriminator: real loss 0.1695239245891571, fake loss 0.07744767516851425\tGenerator: loss 13.480345726013184\n","Epoch 84, batch 84/240:\tDiscriminator: real loss 0.15643061697483063, fake loss 0.10051168501377106\tGenerator: loss 13.444782257080078\n","Epoch 84, batch 85/240:\tDiscriminator: real loss 0.10441823303699493, fake loss 0.2668617367744446\tGenerator: loss 12.879486083984375\n","Epoch 84, batch 86/240:\tDiscriminator: real loss 0.11341613531112671, fake loss 0.2073906660079956\tGenerator: loss 11.573797225952148\n","Epoch 84, batch 87/240:\tDiscriminator: real loss 0.12718965113162994, fake loss 0.2708413302898407\tGenerator: loss 11.605067253112793\n","Epoch 84, batch 88/240:\tDiscriminator: real loss 0.17662343382835388, fake loss 0.2776396572589874\tGenerator: loss 13.095977783203125\n","Epoch 84, batch 89/240:\tDiscriminator: real loss 0.12363900989294052, fake loss 0.08524247258901596\tGenerator: loss 11.496160507202148\n","Epoch 84, batch 90/240:\tDiscriminator: real loss 0.08830219507217407, fake loss 0.1387474238872528\tGenerator: loss 12.29911994934082\n","Epoch 84, batch 91/240:\tDiscriminator: real loss 0.15849468111991882, fake loss 0.19822946190834045\tGenerator: loss 11.811237335205078\n","Epoch 84, batch 92/240:\tDiscriminator: real loss 0.13234998285770416, fake loss 0.0581260584294796\tGenerator: loss 10.649113655090332\n","Epoch 84, batch 93/240:\tDiscriminator: real loss 0.11018133908510208, fake loss 0.23545530438423157\tGenerator: loss 11.882884979248047\n","Epoch 84, batch 94/240:\tDiscriminator: real loss 0.12641949951648712, fake loss 0.2630452811717987\tGenerator: loss 12.341774940490723\n","Epoch 84, batch 95/240:\tDiscriminator: real loss 0.11865455657243729, fake loss 0.26925671100616455\tGenerator: loss 13.489336013793945\n","Epoch 84, batch 96/240:\tDiscriminator: real loss 0.30673208832740784, fake loss 0.07380170375108719\tGenerator: loss 9.219817161560059\n","Epoch 84, batch 97/240:\tDiscriminator: real loss 0.10420233011245728, fake loss 0.1845211535692215\tGenerator: loss 7.970766544342041\n","Epoch 84, batch 98/240:\tDiscriminator: real loss 0.06274416297674179, fake loss 0.3617439270019531\tGenerator: loss 8.603279113769531\n","Epoch 84, batch 99/240:\tDiscriminator: real loss 0.1718553900718689, fake loss 0.16863155364990234\tGenerator: loss 9.645740509033203\n","Epoch 84, batch 100/240:\tDiscriminator: real loss 0.18619126081466675, fake loss 0.094034343957901\tGenerator: loss 9.215385437011719\n","Epoch 84, batch 101/240:\tDiscriminator: real loss 0.14262239634990692, fake loss 0.3049144744873047\tGenerator: loss 6.548492908477783\n","Epoch 84, batch 102/240:\tDiscriminator: real loss 0.11800911277532578, fake loss 0.19337350130081177\tGenerator: loss 6.394742965698242\n","Epoch 84, batch 103/240:\tDiscriminator: real loss 0.15479415655136108, fake loss 0.16154736280441284\tGenerator: loss 7.817623138427734\n","Epoch 84, batch 104/240:\tDiscriminator: real loss 0.11676538735628128, fake loss 0.21306024491786957\tGenerator: loss 9.610250473022461\n","Epoch 84, batch 105/240:\tDiscriminator: real loss 0.13481391966342926, fake loss 0.14561647176742554\tGenerator: loss 11.000576972961426\n","Epoch 84, batch 106/240:\tDiscriminator: real loss 0.12425289303064346, fake loss 0.17629621922969818\tGenerator: loss 10.526105880737305\n","Epoch 84, batch 107/240:\tDiscriminator: real loss 0.11538223177194595, fake loss 0.18856585025787354\tGenerator: loss 10.743322372436523\n","Epoch 84, batch 108/240:\tDiscriminator: real loss 0.13013853132724762, fake loss 0.2542557418346405\tGenerator: loss 14.534418106079102\n","Epoch 84, batch 109/240:\tDiscriminator: real loss 0.1334185004234314, fake loss 0.16600508987903595\tGenerator: loss 14.7141695022583\n","Epoch 84, batch 110/240:\tDiscriminator: real loss 0.1644187569618225, fake loss 0.19951175153255463\tGenerator: loss 11.197490692138672\n","Epoch 84, batch 111/240:\tDiscriminator: real loss 0.13894838094711304, fake loss 0.18016202747821808\tGenerator: loss 11.894186973571777\n","Epoch 84, batch 112/240:\tDiscriminator: real loss 0.1835087239742279, fake loss 0.29509440064430237\tGenerator: loss 9.180913925170898\n","Epoch 84, batch 113/240:\tDiscriminator: real loss 0.14509791135787964, fake loss 0.23089897632598877\tGenerator: loss 11.9214506149292\n","Epoch 84, batch 114/240:\tDiscriminator: real loss 0.10144475847482681, fake loss 0.12443897128105164\tGenerator: loss 13.348976135253906\n","Epoch 84, batch 115/240:\tDiscriminator: real loss 0.1329207420349121, fake loss 0.14667238295078278\tGenerator: loss 12.281108856201172\n","Epoch 84, batch 116/240:\tDiscriminator: real loss 0.17670613527297974, fake loss 0.3756987452507019\tGenerator: loss 10.604101181030273\n","Epoch 84, batch 117/240:\tDiscriminator: real loss 0.2218809276819229, fake loss 0.06465413421392441\tGenerator: loss 9.252480506896973\n","Epoch 84, batch 118/240:\tDiscriminator: real loss 0.1878722608089447, fake loss 0.207235187292099\tGenerator: loss 8.896248817443848\n","Epoch 84, batch 119/240:\tDiscriminator: real loss 0.1133594736456871, fake loss 0.25340893864631653\tGenerator: loss 9.780770301818848\n","Epoch 84, batch 120/240:\tDiscriminator: real loss 0.102876216173172, fake loss 0.13052400946617126\tGenerator: loss 11.659768104553223\n","Epoch 84, batch 121/240:\tDiscriminator: real loss 0.17845483124256134, fake loss 0.09535709023475647\tGenerator: loss 11.814652442932129\n","Epoch 84, batch 122/240:\tDiscriminator: real loss 0.08231577277183533, fake loss 0.1769220530986786\tGenerator: loss 11.725717544555664\n","Epoch 84, batch 123/240:\tDiscriminator: real loss 0.07076959311962128, fake loss 0.26127079129219055\tGenerator: loss 14.414789199829102\n","Epoch 84, batch 124/240:\tDiscriminator: real loss 0.16328415274620056, fake loss 0.14001844823360443\tGenerator: loss 12.313895225524902\n","Epoch 84, batch 125/240:\tDiscriminator: real loss 0.1385740339756012, fake loss 0.34445658326148987\tGenerator: loss 10.63094711303711\n","Epoch 84, batch 126/240:\tDiscriminator: real loss 0.21882252395153046, fake loss 0.20183320343494415\tGenerator: loss 9.288106918334961\n","Epoch 84, batch 127/240:\tDiscriminator: real loss 0.24710586667060852, fake loss 0.13283762335777283\tGenerator: loss 9.620889663696289\n","Epoch 84, batch 128/240:\tDiscriminator: real loss 0.10463087260723114, fake loss 0.20413082838058472\tGenerator: loss 12.865584373474121\n","Epoch 84, batch 129/240:\tDiscriminator: real loss 0.09318964183330536, fake loss 0.2193799614906311\tGenerator: loss 12.251652717590332\n","Epoch 84, batch 130/240:\tDiscriminator: real loss 0.15633513033390045, fake loss 0.2111847996711731\tGenerator: loss 11.696560859680176\n","Epoch 84, batch 131/240:\tDiscriminator: real loss 0.11068306863307953, fake loss 0.13952335715293884\tGenerator: loss 9.62657642364502\n","Epoch 84, batch 132/240:\tDiscriminator: real loss 0.15156863629817963, fake loss 0.12675602734088898\tGenerator: loss 10.837608337402344\n","Epoch 84, batch 133/240:\tDiscriminator: real loss 0.1120244488120079, fake loss 0.2334529161453247\tGenerator: loss 11.021571159362793\n","Epoch 84, batch 134/240:\tDiscriminator: real loss 0.1034824401140213, fake loss 0.11008773744106293\tGenerator: loss 14.126140594482422\n","Epoch 84, batch 135/240:\tDiscriminator: real loss 0.16044174134731293, fake loss 0.27497437596321106\tGenerator: loss 13.940878868103027\n","Epoch 84, batch 136/240:\tDiscriminator: real loss 0.14666473865509033, fake loss 0.10457732528448105\tGenerator: loss 13.136836051940918\n","Epoch 84, batch 137/240:\tDiscriminator: real loss 0.13211855292320251, fake loss 0.21920068562030792\tGenerator: loss 11.8784761428833\n","Epoch 84, batch 138/240:\tDiscriminator: real loss 0.18462733924388885, fake loss 0.39749211072921753\tGenerator: loss 12.62502670288086\n","Epoch 84, batch 139/240:\tDiscriminator: real loss 0.17410439252853394, fake loss 0.17964355647563934\tGenerator: loss 11.886374473571777\n","Epoch 84, batch 140/240:\tDiscriminator: real loss 0.11538027971982956, fake loss 0.16471479833126068\tGenerator: loss 13.442865371704102\n","Epoch 84, batch 141/240:\tDiscriminator: real loss 0.14179842174053192, fake loss 0.23869365453720093\tGenerator: loss 12.114431381225586\n","Epoch 84, batch 142/240:\tDiscriminator: real loss 0.1839260458946228, fake loss 0.12613371014595032\tGenerator: loss 12.327749252319336\n","Epoch 84, batch 143/240:\tDiscriminator: real loss 0.10425171256065369, fake loss 0.18502922356128693\tGenerator: loss 13.81734848022461\n","Epoch 84, batch 144/240:\tDiscriminator: real loss 0.07908663153648376, fake loss 0.4408586621284485\tGenerator: loss 12.219608306884766\n","Epoch 84, batch 145/240:\tDiscriminator: real loss 0.22104217112064362, fake loss 0.03716331347823143\tGenerator: loss 10.362340927124023\n","Epoch 84, batch 146/240:\tDiscriminator: real loss 0.1888408660888672, fake loss 0.07810135185718536\tGenerator: loss 7.07794189453125\n","Epoch 84, batch 147/240:\tDiscriminator: real loss 0.0646122470498085, fake loss 0.2291651964187622\tGenerator: loss 8.133955001831055\n","Epoch 84, batch 148/240:\tDiscriminator: real loss 0.05462481081485748, fake loss 0.12709510326385498\tGenerator: loss 9.292189598083496\n","Epoch 84, batch 149/240:\tDiscriminator: real loss 0.10478752851486206, fake loss 0.2257765531539917\tGenerator: loss 12.318866729736328\n","Epoch 84, batch 150/240:\tDiscriminator: real loss 0.10541606694459915, fake loss 0.1970481127500534\tGenerator: loss 13.203895568847656\n","Epoch 84, batch 151/240:\tDiscriminator: real loss 0.13288438320159912, fake loss 0.05964869633316994\tGenerator: loss 11.941524505615234\n","Epoch 84, batch 152/240:\tDiscriminator: real loss 0.10093992203474045, fake loss 0.29754307866096497\tGenerator: loss 11.90991497039795\n","Epoch 84, batch 153/240:\tDiscriminator: real loss 0.10199638456106186, fake loss 0.22236113250255585\tGenerator: loss 12.797211647033691\n","Epoch 84, batch 154/240:\tDiscriminator: real loss 0.20641784369945526, fake loss 0.19798196852207184\tGenerator: loss 13.513230323791504\n","Epoch 84, batch 155/240:\tDiscriminator: real loss 0.09773137420415878, fake loss 0.13336899876594543\tGenerator: loss 12.503525733947754\n","Epoch 84, batch 156/240:\tDiscriminator: real loss 0.16077838838100433, fake loss 0.16065680980682373\tGenerator: loss 11.996862411499023\n","Epoch 84, batch 157/240:\tDiscriminator: real loss 0.17702102661132812, fake loss 0.15711867809295654\tGenerator: loss 10.548192024230957\n","Epoch 84, batch 158/240:\tDiscriminator: real loss 0.10295656323432922, fake loss 0.15784931182861328\tGenerator: loss 9.635309219360352\n","Epoch 84, batch 159/240:\tDiscriminator: real loss 0.08655496686697006, fake loss 0.22982925176620483\tGenerator: loss 10.947033882141113\n","Epoch 84, batch 160/240:\tDiscriminator: real loss 0.15147817134857178, fake loss 0.1518530249595642\tGenerator: loss 12.035656929016113\n","Epoch 84, batch 161/240:\tDiscriminator: real loss 0.12012382596731186, fake loss 0.23083144426345825\tGenerator: loss 10.918146133422852\n","Epoch 84, batch 162/240:\tDiscriminator: real loss 0.15712866187095642, fake loss 0.1954049915075302\tGenerator: loss 10.306357383728027\n","Epoch 84, batch 163/240:\tDiscriminator: real loss 0.2357850968837738, fake loss 0.12739752233028412\tGenerator: loss 9.598952293395996\n","Epoch 84, batch 164/240:\tDiscriminator: real loss 0.12502402067184448, fake loss 0.32508090138435364\tGenerator: loss 8.871720314025879\n","Epoch 84, batch 165/240:\tDiscriminator: real loss 0.057833269238471985, fake loss 0.26310569047927856\tGenerator: loss 10.702369689941406\n","Epoch 84, batch 166/240:\tDiscriminator: real loss 0.15734891593456268, fake loss 0.0902281254529953\tGenerator: loss 10.868066787719727\n","Epoch 84, batch 167/240:\tDiscriminator: real loss 0.16524285078048706, fake loss 0.2128978669643402\tGenerator: loss 15.663654327392578\n","Epoch 84, batch 168/240:\tDiscriminator: real loss 0.1359323263168335, fake loss 0.10486622154712677\tGenerator: loss 14.602704048156738\n","Epoch 84, batch 169/240:\tDiscriminator: real loss 0.17567482590675354, fake loss 0.14868898689746857\tGenerator: loss 10.05164909362793\n","Epoch 84, batch 170/240:\tDiscriminator: real loss 0.07501991838216782, fake loss 0.39879631996154785\tGenerator: loss 10.539207458496094\n","Epoch 84, batch 171/240:\tDiscriminator: real loss 0.08669092506170273, fake loss 0.17208604514598846\tGenerator: loss 11.432611465454102\n","Epoch 84, batch 172/240:\tDiscriminator: real loss 0.21663372218608856, fake loss 0.2066827267408371\tGenerator: loss 8.20348834991455\n","Epoch 84, batch 173/240:\tDiscriminator: real loss 0.1557348519563675, fake loss 0.22947543859481812\tGenerator: loss 9.47803020477295\n","Epoch 84, batch 174/240:\tDiscriminator: real loss 0.2181217074394226, fake loss 0.15879438817501068\tGenerator: loss 11.923205375671387\n","Epoch 84, batch 175/240:\tDiscriminator: real loss 0.10520804673433304, fake loss 0.26960253715515137\tGenerator: loss 10.643712043762207\n","Epoch 84, batch 176/240:\tDiscriminator: real loss 0.09483133256435394, fake loss 0.1954789012670517\tGenerator: loss 12.51586627960205\n","Epoch 84, batch 177/240:\tDiscriminator: real loss 0.15606801211833954, fake loss 0.19264644384384155\tGenerator: loss 8.093228340148926\n","Epoch 84, batch 178/240:\tDiscriminator: real loss 0.16585351526737213, fake loss 0.1917833834886551\tGenerator: loss 7.587242603302002\n","Epoch 84, batch 179/240:\tDiscriminator: real loss 0.13711053133010864, fake loss 0.09918605536222458\tGenerator: loss 8.172643661499023\n","Epoch 84, batch 180/240:\tDiscriminator: real loss 0.17434436082839966, fake loss 0.3281385898590088\tGenerator: loss 10.968552589416504\n","Epoch 84, batch 181/240:\tDiscriminator: real loss 0.09469208121299744, fake loss 0.22789119184017181\tGenerator: loss 11.426460266113281\n","Epoch 84, batch 182/240:\tDiscriminator: real loss 0.13306939601898193, fake loss 0.14497646689414978\tGenerator: loss 11.704198837280273\n","Epoch 84, batch 183/240:\tDiscriminator: real loss 0.27914947271347046, fake loss 0.22411149740219116\tGenerator: loss 7.257944107055664\n","Epoch 84, batch 184/240:\tDiscriminator: real loss 0.17395839095115662, fake loss 0.15148597955703735\tGenerator: loss 6.36893367767334\n","Epoch 84, batch 185/240:\tDiscriminator: real loss 0.0852125734090805, fake loss 0.10435802489519119\tGenerator: loss 8.003952026367188\n","Epoch 84, batch 186/240:\tDiscriminator: real loss 0.06118854507803917, fake loss 0.2890048325061798\tGenerator: loss 10.628811836242676\n","Epoch 84, batch 187/240:\tDiscriminator: real loss 0.10799364000558853, fake loss 0.05293307825922966\tGenerator: loss 9.290478706359863\n","Epoch 84, batch 188/240:\tDiscriminator: real loss 0.14996479451656342, fake loss 0.15431007742881775\tGenerator: loss 8.657272338867188\n","Epoch 84, batch 189/240:\tDiscriminator: real loss 0.06597955524921417, fake loss 0.133931502699852\tGenerator: loss 8.103044509887695\n","Epoch 84, batch 190/240:\tDiscriminator: real loss 0.17767122387886047, fake loss 0.19232632219791412\tGenerator: loss 9.007895469665527\n","Epoch 84, batch 191/240:\tDiscriminator: real loss 0.0783652663230896, fake loss 0.12931542098522186\tGenerator: loss 9.05735969543457\n","Epoch 84, batch 192/240:\tDiscriminator: real loss 0.1284714639186859, fake loss 0.24083565175533295\tGenerator: loss 7.043432712554932\n","Epoch 84, batch 193/240:\tDiscriminator: real loss 0.0927884504199028, fake loss 0.11894736438989639\tGenerator: loss 6.63564920425415\n","Epoch 84, batch 194/240:\tDiscriminator: real loss 0.16485050320625305, fake loss 0.18261398375034332\tGenerator: loss 8.7730131149292\n","Epoch 84, batch 195/240:\tDiscriminator: real loss 0.16550560295581818, fake loss 0.1520807147026062\tGenerator: loss 8.12075424194336\n","Epoch 84, batch 196/240:\tDiscriminator: real loss 0.06393816322088242, fake loss 0.17069855332374573\tGenerator: loss 7.4299845695495605\n","Epoch 84, batch 197/240:\tDiscriminator: real loss 0.0866822600364685, fake loss 0.14500963687896729\tGenerator: loss 8.014098167419434\n","Epoch 84, batch 198/240:\tDiscriminator: real loss 0.10370500385761261, fake loss 0.07737453281879425\tGenerator: loss 7.0760321617126465\n","Epoch 84, batch 199/240:\tDiscriminator: real loss 0.16091816127300262, fake loss 0.1343359798192978\tGenerator: loss 6.434603691101074\n","Epoch 84, batch 200/240:\tDiscriminator: real loss 0.060618650168180466, fake loss 0.14859451353549957\tGenerator: loss 7.297116756439209\n","Epoch 84, batch 201/240:\tDiscriminator: real loss 0.05852704867720604, fake loss 0.21272338926792145\tGenerator: loss 8.577749252319336\n","Epoch 84, batch 202/240:\tDiscriminator: real loss 0.12780606746673584, fake loss 0.21527038514614105\tGenerator: loss 12.233407974243164\n","Epoch 84, batch 203/240:\tDiscriminator: real loss 0.18700608611106873, fake loss 0.056444354355335236\tGenerator: loss 12.368289947509766\n","Epoch 84, batch 204/240:\tDiscriminator: real loss 0.1074715256690979, fake loss 0.17054948210716248\tGenerator: loss 10.857832908630371\n","Epoch 84, batch 205/240:\tDiscriminator: real loss 0.08892853558063507, fake loss 0.1634138524532318\tGenerator: loss 11.329151153564453\n","Epoch 84, batch 206/240:\tDiscriminator: real loss 0.07156311720609665, fake loss 0.10933071374893188\tGenerator: loss 11.267724990844727\n","Epoch 84, batch 207/240:\tDiscriminator: real loss 0.13617347180843353, fake loss 0.11757003515958786\tGenerator: loss 10.943706512451172\n","Epoch 84, batch 208/240:\tDiscriminator: real loss 0.08228986710309982, fake loss 0.1148524060845375\tGenerator: loss 11.87977409362793\n","Epoch 84, batch 209/240:\tDiscriminator: real loss 0.0987749844789505, fake loss 0.24776248633861542\tGenerator: loss 11.362300872802734\n","Epoch 84, batch 210/240:\tDiscriminator: real loss 0.08443107455968857, fake loss 0.09682576358318329\tGenerator: loss 10.05290412902832\n","Epoch 84, batch 211/240:\tDiscriminator: real loss 0.20687133073806763, fake loss 0.10847078263759613\tGenerator: loss 11.605725288391113\n","Epoch 84, batch 212/240:\tDiscriminator: real loss 0.13275663554668427, fake loss 0.1777847707271576\tGenerator: loss 10.534767150878906\n","Epoch 84, batch 213/240:\tDiscriminator: real loss 0.05872981622815132, fake loss 0.4040912389755249\tGenerator: loss 12.44598388671875\n","Epoch 84, batch 214/240:\tDiscriminator: real loss 0.11948240548372269, fake loss 0.11298026889562607\tGenerator: loss 11.79313850402832\n","Epoch 84, batch 215/240:\tDiscriminator: real loss 0.3067220449447632, fake loss 0.29755425453186035\tGenerator: loss 12.984766960144043\n","Epoch 84, batch 216/240:\tDiscriminator: real loss 0.09572767466306686, fake loss 0.18371061980724335\tGenerator: loss 11.848592758178711\n","Epoch 84, batch 217/240:\tDiscriminator: real loss 0.10771067440509796, fake loss 0.13604483008384705\tGenerator: loss 13.005226135253906\n","Epoch 84, batch 218/240:\tDiscriminator: real loss 0.10548590868711472, fake loss 0.17309704422950745\tGenerator: loss 11.168514251708984\n","Epoch 84, batch 219/240:\tDiscriminator: real loss 0.09759647399187088, fake loss 0.2236207127571106\tGenerator: loss 10.356067657470703\n","Epoch 84, batch 220/240:\tDiscriminator: real loss 0.21502727270126343, fake loss 0.15538537502288818\tGenerator: loss 10.931800842285156\n","Epoch 84, batch 221/240:\tDiscriminator: real loss 0.09759965538978577, fake loss 0.20942267775535583\tGenerator: loss 10.853859901428223\n","Epoch 84, batch 222/240:\tDiscriminator: real loss 0.07273384928703308, fake loss 0.25162434577941895\tGenerator: loss 12.609004020690918\n","Epoch 84, batch 223/240:\tDiscriminator: real loss 0.10978027433156967, fake loss 0.21494558453559875\tGenerator: loss 13.165914535522461\n","Epoch 84, batch 224/240:\tDiscriminator: real loss 0.2019118070602417, fake loss 0.09349335730075836\tGenerator: loss 12.197566032409668\n","Epoch 84, batch 225/240:\tDiscriminator: real loss 0.17215433716773987, fake loss 0.15348096191883087\tGenerator: loss 10.650594711303711\n","Epoch 84, batch 226/240:\tDiscriminator: real loss 0.08670687675476074, fake loss 0.19189678132534027\tGenerator: loss 12.1439208984375\n","Epoch 84, batch 227/240:\tDiscriminator: real loss 0.11326809227466583, fake loss 0.24424561858177185\tGenerator: loss 12.965127944946289\n","Epoch 84, batch 228/240:\tDiscriminator: real loss 0.11119529604911804, fake loss 0.14416950941085815\tGenerator: loss 13.146306991577148\n","Epoch 84, batch 229/240:\tDiscriminator: real loss 0.1591394990682602, fake loss 0.1835237741470337\tGenerator: loss 10.616721153259277\n","Epoch 84, batch 230/240:\tDiscriminator: real loss 0.1724085956811905, fake loss 0.12573440372943878\tGenerator: loss 8.271885871887207\n","Epoch 84, batch 231/240:\tDiscriminator: real loss 0.13920825719833374, fake loss 0.19082368910312653\tGenerator: loss 8.490827560424805\n","Epoch 84, batch 232/240:\tDiscriminator: real loss 0.07080014050006866, fake loss 0.21505680680274963\tGenerator: loss 10.04378890991211\n","Epoch 84, batch 233/240:\tDiscriminator: real loss 0.1082988753914833, fake loss 0.21826621890068054\tGenerator: loss 15.4253511428833\n","Epoch 84, batch 234/240:\tDiscriminator: real loss 0.12346597760915756, fake loss 0.1337023824453354\tGenerator: loss 16.266193389892578\n","Epoch 84, batch 235/240:\tDiscriminator: real loss 0.16915598511695862, fake loss 0.2140921950340271\tGenerator: loss 14.793201446533203\n","Epoch 84, batch 236/240:\tDiscriminator: real loss 0.1760750412940979, fake loss 0.3272732198238373\tGenerator: loss 13.926212310791016\n","Epoch 84, batch 237/240:\tDiscriminator: real loss 0.11001907289028168, fake loss 0.13908664882183075\tGenerator: loss 12.273268699645996\n","Epoch 84, batch 238/240:\tDiscriminator: real loss 0.1983504295349121, fake loss 0.13362428545951843\tGenerator: loss 13.66457748413086\n","Epoch 84, batch 239/240:\tDiscriminator: real loss 0.0893123596906662, fake loss 0.135783389210701\tGenerator: loss 11.983745574951172\n","Epoch 84, batch 240/240:\tDiscriminator: real loss 0.07377108931541443, fake loss 0.2160988599061966\tGenerator: loss 12.038108825683594\n","Epoch 85, batch 1/240:\tDiscriminator: real loss 0.10631778836250305, fake loss 0.1419009566307068\tGenerator: loss 14.301353454589844\n","Epoch 85, batch 2/240:\tDiscriminator: real loss 0.24796897172927856, fake loss 0.23414455354213715\tGenerator: loss 12.953234672546387\n","Epoch 85, batch 3/240:\tDiscriminator: real loss 0.12277644872665405, fake loss 0.3045518398284912\tGenerator: loss 11.873932838439941\n","Epoch 85, batch 4/240:\tDiscriminator: real loss 0.1330994963645935, fake loss 0.11156949400901794\tGenerator: loss 12.936125755310059\n","Epoch 85, batch 5/240:\tDiscriminator: real loss 0.13687019050121307, fake loss 0.23604807257652283\tGenerator: loss 12.324193954467773\n","Epoch 85, batch 6/240:\tDiscriminator: real loss 0.15461549162864685, fake loss 0.19868306815624237\tGenerator: loss 13.150407791137695\n","Epoch 85, batch 7/240:\tDiscriminator: real loss 0.10481064021587372, fake loss 0.14301088452339172\tGenerator: loss 11.211709022521973\n","Epoch 85, batch 8/240:\tDiscriminator: real loss 0.13835225999355316, fake loss 0.2050803005695343\tGenerator: loss 10.196843147277832\n","Epoch 85, batch 9/240:\tDiscriminator: real loss 0.08467219024896622, fake loss 0.14819353818893433\tGenerator: loss 9.437682151794434\n","Epoch 85, batch 10/240:\tDiscriminator: real loss 0.13140250742435455, fake loss 0.1992819905281067\tGenerator: loss 9.815145492553711\n","Epoch 85, batch 11/240:\tDiscriminator: real loss 0.19212135672569275, fake loss 0.23110000789165497\tGenerator: loss 11.369582176208496\n","Epoch 85, batch 12/240:\tDiscriminator: real loss 0.10876516997814178, fake loss 0.17416484653949738\tGenerator: loss 12.202235221862793\n","Epoch 85, batch 13/240:\tDiscriminator: real loss 0.07622253894805908, fake loss 0.10570903867483139\tGenerator: loss 11.20431137084961\n","Epoch 85, batch 14/240:\tDiscriminator: real loss 0.10688713192939758, fake loss 0.143856942653656\tGenerator: loss 11.845502853393555\n","Epoch 85, batch 15/240:\tDiscriminator: real loss 0.06962505728006363, fake loss 0.07852472364902496\tGenerator: loss 11.253305435180664\n","Epoch 85, batch 16/240:\tDiscriminator: real loss 0.08343604952096939, fake loss 0.11432337015867233\tGenerator: loss 9.410699844360352\n","Epoch 85, batch 17/240:\tDiscriminator: real loss 0.05916561186313629, fake loss 0.10174667090177536\tGenerator: loss 8.25328254699707\n","Epoch 85, batch 18/240:\tDiscriminator: real loss 0.0982217863202095, fake loss 0.23832695186138153\tGenerator: loss 7.851846218109131\n","Epoch 85, batch 19/240:\tDiscriminator: real loss 0.12628404796123505, fake loss 0.09123111516237259\tGenerator: loss 8.87258529663086\n","Epoch 85, batch 20/240:\tDiscriminator: real loss 0.11211336404085159, fake loss 0.20746122300624847\tGenerator: loss 9.77256965637207\n","Epoch 85, batch 21/240:\tDiscriminator: real loss 0.098440982401371, fake loss 0.13200359046459198\tGenerator: loss 10.097443580627441\n","Epoch 85, batch 22/240:\tDiscriminator: real loss 0.16717761754989624, fake loss 0.10653716325759888\tGenerator: loss 8.771502494812012\n","Epoch 85, batch 23/240:\tDiscriminator: real loss 0.1402645707130432, fake loss 0.17431272566318512\tGenerator: loss 8.552072525024414\n","Epoch 85, batch 24/240:\tDiscriminator: real loss 0.07801911979913712, fake loss 0.1710202991962433\tGenerator: loss 8.07138442993164\n","Epoch 85, batch 25/240:\tDiscriminator: real loss 0.10422708839178085, fake loss 0.22195711731910706\tGenerator: loss 8.871870994567871\n","Epoch 85, batch 26/240:\tDiscriminator: real loss 0.1463068425655365, fake loss 0.09401838481426239\tGenerator: loss 9.376197814941406\n","Epoch 85, batch 27/240:\tDiscriminator: real loss 0.14540287852287292, fake loss 0.16023670136928558\tGenerator: loss 7.549122333526611\n","Epoch 85, batch 28/240:\tDiscriminator: real loss 0.09726864099502563, fake loss 0.27188342809677124\tGenerator: loss 9.074261665344238\n","Epoch 85, batch 29/240:\tDiscriminator: real loss 0.08834167569875717, fake loss 0.08978837728500366\tGenerator: loss 9.377605438232422\n","Epoch 85, batch 30/240:\tDiscriminator: real loss 0.1699577271938324, fake loss 0.07728744298219681\tGenerator: loss 9.329338073730469\n","Epoch 85, batch 31/240:\tDiscriminator: real loss 0.13523538410663605, fake loss 0.1708211749792099\tGenerator: loss 8.34048080444336\n","Epoch 85, batch 32/240:\tDiscriminator: real loss 0.07083283364772797, fake loss 0.23874996602535248\tGenerator: loss 11.518774032592773\n","Epoch 85, batch 33/240:\tDiscriminator: real loss 0.08773891627788544, fake loss 0.1330968737602234\tGenerator: loss 12.3427095413208\n","Epoch 85, batch 34/240:\tDiscriminator: real loss 0.15753187239170074, fake loss 0.09822157770395279\tGenerator: loss 10.362714767456055\n","Epoch 85, batch 35/240:\tDiscriminator: real loss 0.1474592089653015, fake loss 0.0855422094464302\tGenerator: loss 8.119903564453125\n","Epoch 85, batch 36/240:\tDiscriminator: real loss 0.07981708645820618, fake loss 0.017516978085041046\tGenerator: loss 12.574494361877441\n","Epoch 85, batch 37/240:\tDiscriminator: real loss 0.05248720943927765, fake loss 0.0030958461575210094\tGenerator: loss 12.119250297546387\n","Epoch 85, batch 38/240:\tDiscriminator: real loss 0.026423677802085876, fake loss 0.5431508421897888\tGenerator: loss 28.291397094726562\n","Epoch 85, batch 39/240:\tDiscriminator: real loss 0.08092791587114334, fake loss 2.6365705707576126e-05\tGenerator: loss 40.743377685546875\n","Epoch 85, batch 40/240:\tDiscriminator: real loss 0.30250340700149536, fake loss 1.7843832438302343e-06\tGenerator: loss 33.667755126953125\n","Epoch 85, batch 41/240:\tDiscriminator: real loss 0.05585732311010361, fake loss 0.0007375622517429292\tGenerator: loss 28.792238235473633\n","Epoch 85, batch 42/240:\tDiscriminator: real loss 0.03655772656202316, fake loss 0.04833291843533516\tGenerator: loss 24.918167114257812\n","Epoch 85, batch 43/240:\tDiscriminator: real loss 0.006561512127518654, fake loss 0.10454937070608139\tGenerator: loss 24.27871322631836\n","Epoch 85, batch 44/240:\tDiscriminator: real loss 0.018908163532614708, fake loss 0.037779565900564194\tGenerator: loss 21.304340362548828\n","Epoch 85, batch 45/240:\tDiscriminator: real loss 0.035043708980083466, fake loss 0.23547206819057465\tGenerator: loss 22.720294952392578\n","Epoch 85, batch 46/240:\tDiscriminator: real loss 0.06541003286838531, fake loss 0.30037370324134827\tGenerator: loss 22.629728317260742\n","Epoch 85, batch 47/240:\tDiscriminator: real loss 0.11271379142999649, fake loss 0.16500058770179749\tGenerator: loss 23.414531707763672\n","Epoch 85, batch 48/240:\tDiscriminator: real loss 0.13325104117393494, fake loss 0.3321009576320648\tGenerator: loss 27.72072982788086\n","Epoch 85, batch 49/240:\tDiscriminator: real loss 0.125660240650177, fake loss 0.3727494478225708\tGenerator: loss 32.33101272583008\n","Epoch 85, batch 50/240:\tDiscriminator: real loss 0.1313479095697403, fake loss 0.03603226691484451\tGenerator: loss 36.690093994140625\n","Epoch 85, batch 51/240:\tDiscriminator: real loss 0.19239220023155212, fake loss 0.22228392958641052\tGenerator: loss 32.72323989868164\n","Epoch 85, batch 52/240:\tDiscriminator: real loss 0.10470487922430038, fake loss 0.04394001141190529\tGenerator: loss 30.118494033813477\n","Epoch 85, batch 53/240:\tDiscriminator: real loss 0.07331094890832901, fake loss 0.20224742591381073\tGenerator: loss 28.820636749267578\n","Epoch 85, batch 54/240:\tDiscriminator: real loss 0.08266472071409225, fake loss 0.13171900808811188\tGenerator: loss 26.3646183013916\n","Epoch 85, batch 55/240:\tDiscriminator: real loss 0.07591040432453156, fake loss 0.06030157953500748\tGenerator: loss 26.640403747558594\n","Epoch 85, batch 56/240:\tDiscriminator: real loss 0.1829046756029129, fake loss 0.1302473247051239\tGenerator: loss 26.90399169921875\n","Epoch 85, batch 57/240:\tDiscriminator: real loss 0.04589208588004112, fake loss 0.2415003627538681\tGenerator: loss 27.17529296875\n","Epoch 85, batch 58/240:\tDiscriminator: real loss 0.08645688742399216, fake loss 0.10297398269176483\tGenerator: loss 27.76000213623047\n","Epoch 85, batch 59/240:\tDiscriminator: real loss 0.10497870296239853, fake loss 0.10716632008552551\tGenerator: loss 25.373397827148438\n","Epoch 85, batch 60/240:\tDiscriminator: real loss 0.07540121674537659, fake loss 0.06076221913099289\tGenerator: loss 26.992074966430664\n","Epoch 85, batch 61/240:\tDiscriminator: real loss 0.08431895077228546, fake loss 0.14949196577072144\tGenerator: loss 24.20168685913086\n","Epoch 85, batch 62/240:\tDiscriminator: real loss 0.09122982621192932, fake loss 0.14751020073890686\tGenerator: loss 25.029069900512695\n","Epoch 85, batch 63/240:\tDiscriminator: real loss 0.13163059949874878, fake loss 0.08108697831630707\tGenerator: loss 23.430540084838867\n","Epoch 85, batch 64/240:\tDiscriminator: real loss 0.07606162130832672, fake loss 0.06404542177915573\tGenerator: loss 23.278440475463867\n","Epoch 85, batch 65/240:\tDiscriminator: real loss 0.06585761904716492, fake loss 0.16290496289730072\tGenerator: loss 23.061464309692383\n","Epoch 85, batch 66/240:\tDiscriminator: real loss 0.06065203621983528, fake loss 0.07277911901473999\tGenerator: loss 22.991748809814453\n","Epoch 85, batch 67/240:\tDiscriminator: real loss 0.07403688132762909, fake loss 0.16797548532485962\tGenerator: loss 22.83438491821289\n","Epoch 85, batch 68/240:\tDiscriminator: real loss 0.1381014585494995, fake loss 0.0697101280093193\tGenerator: loss 25.910093307495117\n","Epoch 85, batch 69/240:\tDiscriminator: real loss 0.05910253897309303, fake loss 0.18853867053985596\tGenerator: loss 28.22014808654785\n","Epoch 85, batch 70/240:\tDiscriminator: real loss 0.10857400298118591, fake loss 0.10318296402692795\tGenerator: loss 30.314594268798828\n","Epoch 85, batch 71/240:\tDiscriminator: real loss 0.068425253033638, fake loss 0.16692276298999786\tGenerator: loss 31.813486099243164\n","Epoch 85, batch 72/240:\tDiscriminator: real loss 0.15850166976451874, fake loss 0.17520646750926971\tGenerator: loss 26.723892211914062\n","Epoch 85, batch 73/240:\tDiscriminator: real loss 0.16067974269390106, fake loss 0.16530144214630127\tGenerator: loss 25.190889358520508\n","Epoch 85, batch 74/240:\tDiscriminator: real loss 0.10171952843666077, fake loss 0.13416942954063416\tGenerator: loss 23.63282012939453\n","Epoch 85, batch 75/240:\tDiscriminator: real loss 0.11495161056518555, fake loss 0.22512508928775787\tGenerator: loss 22.192005157470703\n","Epoch 85, batch 76/240:\tDiscriminator: real loss 0.09016187489032745, fake loss 0.10102034360170364\tGenerator: loss 24.140344619750977\n","Epoch 85, batch 77/240:\tDiscriminator: real loss 0.14163047075271606, fake loss 0.1448155641555786\tGenerator: loss 24.586923599243164\n","Epoch 85, batch 78/240:\tDiscriminator: real loss 0.10817108303308487, fake loss 0.08165059983730316\tGenerator: loss 23.579748153686523\n","Epoch 85, batch 79/240:\tDiscriminator: real loss 0.09456975758075714, fake loss 0.04663128778338432\tGenerator: loss 23.449918746948242\n","Epoch 85, batch 80/240:\tDiscriminator: real loss 0.08303966373205185, fake loss 0.22437815368175507\tGenerator: loss 25.716440200805664\n","Epoch 85, batch 81/240:\tDiscriminator: real loss 0.04722067341208458, fake loss 0.21178553998470306\tGenerator: loss 27.688390731811523\n","Epoch 85, batch 82/240:\tDiscriminator: real loss 0.07607367634773254, fake loss 0.08056486397981644\tGenerator: loss 26.875783920288086\n","Epoch 85, batch 83/240:\tDiscriminator: real loss 0.06766822189092636, fake loss 0.048786260187625885\tGenerator: loss 24.683265686035156\n","Epoch 85, batch 84/240:\tDiscriminator: real loss 0.1583680957555771, fake loss 0.18582920730113983\tGenerator: loss 25.01744842529297\n","Epoch 85, batch 85/240:\tDiscriminator: real loss 0.07924768328666687, fake loss 0.2650527358055115\tGenerator: loss 24.414562225341797\n","Epoch 85, batch 86/240:\tDiscriminator: real loss 0.09958657622337341, fake loss 0.14330773055553436\tGenerator: loss 22.823659896850586\n","Epoch 85, batch 87/240:\tDiscriminator: real loss 0.19822315871715546, fake loss 0.06409445405006409\tGenerator: loss 22.778562545776367\n","Epoch 85, batch 88/240:\tDiscriminator: real loss 0.0876619815826416, fake loss 0.06868230551481247\tGenerator: loss 25.162147521972656\n","Epoch 85, batch 89/240:\tDiscriminator: real loss 0.07363705337047577, fake loss 0.26561611890792847\tGenerator: loss 23.17560386657715\n","Epoch 85, batch 90/240:\tDiscriminator: real loss 0.17346550524234772, fake loss 0.16985489428043365\tGenerator: loss 21.434890747070312\n","Epoch 85, batch 91/240:\tDiscriminator: real loss 0.056193165481090546, fake loss 0.10143737494945526\tGenerator: loss 22.003456115722656\n","Epoch 85, batch 92/240:\tDiscriminator: real loss 0.2023385614156723, fake loss 0.1513592004776001\tGenerator: loss 20.893016815185547\n","Epoch 85, batch 93/240:\tDiscriminator: real loss 0.09769269078969955, fake loss 0.21840831637382507\tGenerator: loss 23.883407592773438\n","Epoch 85, batch 94/240:\tDiscriminator: real loss 0.06392047554254532, fake loss 0.04954728111624718\tGenerator: loss 27.39032745361328\n","Epoch 85, batch 95/240:\tDiscriminator: real loss 0.1063857302069664, fake loss 0.11581958085298538\tGenerator: loss 24.467897415161133\n","Epoch 85, batch 96/240:\tDiscriminator: real loss 0.08685000240802765, fake loss 0.19765301048755646\tGenerator: loss 23.897411346435547\n","Epoch 85, batch 97/240:\tDiscriminator: real loss 0.11940817534923553, fake loss 0.19525651633739471\tGenerator: loss 27.5640926361084\n","Epoch 85, batch 98/240:\tDiscriminator: real loss 0.0939600020647049, fake loss 0.10427763313055038\tGenerator: loss 26.39794921875\n","Epoch 85, batch 99/240:\tDiscriminator: real loss 0.17899705469608307, fake loss 0.17585720121860504\tGenerator: loss 23.50381851196289\n","Epoch 85, batch 100/240:\tDiscriminator: real loss 0.08323840796947479, fake loss 0.12008064240217209\tGenerator: loss 23.912294387817383\n","Epoch 85, batch 101/240:\tDiscriminator: real loss 0.07793163508176804, fake loss 0.13505426049232483\tGenerator: loss 24.388347625732422\n","Epoch 85, batch 102/240:\tDiscriminator: real loss 0.11554115265607834, fake loss 0.17044837772846222\tGenerator: loss 22.758455276489258\n","Epoch 85, batch 103/240:\tDiscriminator: real loss 0.09559788554906845, fake loss 0.13762587308883667\tGenerator: loss 21.913955688476562\n","Epoch 85, batch 104/240:\tDiscriminator: real loss 0.1794111430644989, fake loss 0.12760856747627258\tGenerator: loss 24.937646865844727\n","Epoch 85, batch 105/240:\tDiscriminator: real loss 0.05188295990228653, fake loss 0.22767360508441925\tGenerator: loss 24.672731399536133\n","Epoch 85, batch 106/240:\tDiscriminator: real loss 0.11058738082647324, fake loss 0.24339412152767181\tGenerator: loss 25.530611038208008\n","Epoch 85, batch 107/240:\tDiscriminator: real loss 0.11576267331838608, fake loss 0.09238410741090775\tGenerator: loss 24.702688217163086\n","Epoch 85, batch 108/240:\tDiscriminator: real loss 0.1701982319355011, fake loss 0.13741454482078552\tGenerator: loss 23.223234176635742\n","Epoch 85, batch 109/240:\tDiscriminator: real loss 0.07560951262712479, fake loss 0.21526385843753815\tGenerator: loss 26.728063583374023\n","Epoch 85, batch 110/240:\tDiscriminator: real loss 0.11415069550275803, fake loss 0.07380285114049911\tGenerator: loss 24.43927001953125\n","Epoch 85, batch 111/240:\tDiscriminator: real loss 0.09076783806085587, fake loss 0.1267477422952652\tGenerator: loss 24.826387405395508\n","Epoch 85, batch 112/240:\tDiscriminator: real loss 0.13435372710227966, fake loss 0.10968129336833954\tGenerator: loss 26.25072479248047\n","Epoch 85, batch 113/240:\tDiscriminator: real loss 0.08233019709587097, fake loss 0.08651192486286163\tGenerator: loss 24.255840301513672\n","Epoch 85, batch 114/240:\tDiscriminator: real loss 0.11697712540626526, fake loss 0.17323671281337738\tGenerator: loss 24.750652313232422\n","Epoch 85, batch 115/240:\tDiscriminator: real loss 0.08068446815013885, fake loss 0.06717365235090256\tGenerator: loss 21.1329288482666\n","Epoch 85, batch 116/240:\tDiscriminator: real loss 0.09120447188615799, fake loss 0.20241117477416992\tGenerator: loss 23.102025985717773\n","Epoch 85, batch 117/240:\tDiscriminator: real loss 0.06387127935886383, fake loss 0.17841143906116486\tGenerator: loss 23.371442794799805\n","Epoch 85, batch 118/240:\tDiscriminator: real loss 0.09016624093055725, fake loss 0.11126681417226791\tGenerator: loss 21.770174026489258\n","Epoch 85, batch 119/240:\tDiscriminator: real loss 0.19104057550430298, fake loss 0.11539459973573685\tGenerator: loss 23.84662437438965\n","Epoch 85, batch 120/240:\tDiscriminator: real loss 0.06710601598024368, fake loss 0.25554701685905457\tGenerator: loss 25.852319717407227\n","Epoch 85, batch 121/240:\tDiscriminator: real loss 0.09639587998390198, fake loss 0.041969168931245804\tGenerator: loss 25.553579330444336\n","Epoch 85, batch 122/240:\tDiscriminator: real loss 0.13994187116622925, fake loss 0.09576922655105591\tGenerator: loss 23.78557777404785\n","Epoch 85, batch 123/240:\tDiscriminator: real loss 0.08268792927265167, fake loss 0.1368311643600464\tGenerator: loss 22.797056198120117\n","Epoch 85, batch 124/240:\tDiscriminator: real loss 0.056280530989170074, fake loss 0.16001804172992706\tGenerator: loss 22.362140655517578\n","Epoch 85, batch 125/240:\tDiscriminator: real loss 0.10665883868932724, fake loss 0.1802992820739746\tGenerator: loss 24.331769943237305\n","Epoch 85, batch 126/240:\tDiscriminator: real loss 0.06877186894416809, fake loss 0.11345260590314865\tGenerator: loss 21.266956329345703\n","Epoch 85, batch 127/240:\tDiscriminator: real loss 0.1128586009144783, fake loss 0.10095365345478058\tGenerator: loss 21.900653839111328\n","Epoch 85, batch 128/240:\tDiscriminator: real loss 0.10507883131504059, fake loss 0.17555302381515503\tGenerator: loss 23.239185333251953\n","Epoch 85, batch 129/240:\tDiscriminator: real loss 0.1063108742237091, fake loss 0.14362967014312744\tGenerator: loss 23.7514705657959\n","Epoch 85, batch 130/240:\tDiscriminator: real loss 0.12045043706893921, fake loss 0.09767749160528183\tGenerator: loss 24.614702224731445\n","Epoch 85, batch 131/240:\tDiscriminator: real loss 0.11653397232294083, fake loss 0.08811889588832855\tGenerator: loss 24.29779815673828\n","Epoch 85, batch 132/240:\tDiscriminator: real loss 0.04729602858424187, fake loss 0.1544281244277954\tGenerator: loss 23.9947452545166\n","Epoch 85, batch 133/240:\tDiscriminator: real loss 0.08985546231269836, fake loss 0.20493216812610626\tGenerator: loss 24.228477478027344\n","Epoch 85, batch 134/240:\tDiscriminator: real loss 0.10044755786657333, fake loss 0.06161563843488693\tGenerator: loss 24.209688186645508\n","Epoch 85, batch 135/240:\tDiscriminator: real loss 0.08513569086790085, fake loss 0.038349736481904984\tGenerator: loss 24.346233367919922\n","Epoch 85, batch 136/240:\tDiscriminator: real loss 0.04686186835169792, fake loss 0.12008339166641235\tGenerator: loss 23.879915237426758\n","Epoch 85, batch 137/240:\tDiscriminator: real loss 0.08486080169677734, fake loss 0.07016541063785553\tGenerator: loss 23.591970443725586\n","Epoch 85, batch 138/240:\tDiscriminator: real loss 0.11456684023141861, fake loss 0.1950344443321228\tGenerator: loss 23.086566925048828\n","Epoch 85, batch 139/240:\tDiscriminator: real loss 0.07412619888782501, fake loss 0.1888633370399475\tGenerator: loss 23.193193435668945\n","Epoch 85, batch 140/240:\tDiscriminator: real loss 0.11019515991210938, fake loss 0.12056531757116318\tGenerator: loss 22.187301635742188\n","Epoch 85, batch 141/240:\tDiscriminator: real loss 0.14027279615402222, fake loss 0.12471719086170197\tGenerator: loss 22.274192810058594\n","Epoch 85, batch 142/240:\tDiscriminator: real loss 0.11440989375114441, fake loss 0.09094647318124771\tGenerator: loss 22.30254554748535\n","Epoch 85, batch 143/240:\tDiscriminator: real loss 0.07432367652654648, fake loss 0.2014562487602234\tGenerator: loss 25.106481552124023\n","Epoch 85, batch 144/240:\tDiscriminator: real loss 0.09929721057415009, fake loss 0.0980229601264\tGenerator: loss 22.290058135986328\n","Epoch 85, batch 145/240:\tDiscriminator: real loss 0.09514553099870682, fake loss 0.10678479820489883\tGenerator: loss 22.7827205657959\n","Epoch 85, batch 146/240:\tDiscriminator: real loss 0.1199379712343216, fake loss 0.11824113875627518\tGenerator: loss 24.66796875\n","Epoch 85, batch 147/240:\tDiscriminator: real loss 0.07810311019420624, fake loss 0.16451624035835266\tGenerator: loss 22.905771255493164\n","Epoch 85, batch 148/240:\tDiscriminator: real loss 0.09730053693056107, fake loss 0.2209826111793518\tGenerator: loss 19.632984161376953\n","Epoch 85, batch 149/240:\tDiscriminator: real loss 0.0698247179389, fake loss 0.15128383040428162\tGenerator: loss 21.006793975830078\n","Epoch 85, batch 150/240:\tDiscriminator: real loss 0.08755117654800415, fake loss 0.10272692888975143\tGenerator: loss 21.712060928344727\n","Epoch 85, batch 151/240:\tDiscriminator: real loss 0.10712643712759018, fake loss 0.11725763231515884\tGenerator: loss 19.10369300842285\n","Epoch 85, batch 152/240:\tDiscriminator: real loss 0.10623595863580704, fake loss 0.2430528849363327\tGenerator: loss 20.984947204589844\n","Epoch 85, batch 153/240:\tDiscriminator: real loss 0.14929208159446716, fake loss 0.04350373148918152\tGenerator: loss 22.028139114379883\n","Epoch 85, batch 154/240:\tDiscriminator: real loss 0.150161013007164, fake loss 0.1273370236158371\tGenerator: loss 21.64169692993164\n","Epoch 85, batch 155/240:\tDiscriminator: real loss 0.06286145001649857, fake loss 0.1272253543138504\tGenerator: loss 20.395950317382812\n","Epoch 85, batch 156/240:\tDiscriminator: real loss 0.08546866476535797, fake loss 0.158309668302536\tGenerator: loss 20.513904571533203\n","Epoch 85, batch 157/240:\tDiscriminator: real loss 0.0830293595790863, fake loss 0.08056327700614929\tGenerator: loss 20.757186889648438\n","Epoch 85, batch 158/240:\tDiscriminator: real loss 0.0783977136015892, fake loss 0.13602803647518158\tGenerator: loss 19.46306037902832\n","Epoch 85, batch 159/240:\tDiscriminator: real loss 0.0862061083316803, fake loss 0.2367178350687027\tGenerator: loss 19.146757125854492\n","Epoch 85, batch 160/240:\tDiscriminator: real loss 0.13538965582847595, fake loss 0.08664503693580627\tGenerator: loss 17.05150604248047\n","Epoch 85, batch 161/240:\tDiscriminator: real loss 0.0564299114048481, fake loss 0.15762507915496826\tGenerator: loss 20.188034057617188\n","Epoch 85, batch 162/240:\tDiscriminator: real loss 0.11376813799142838, fake loss 0.07669852674007416\tGenerator: loss 20.46688461303711\n","Epoch 85, batch 163/240:\tDiscriminator: real loss 0.09911180287599564, fake loss 0.15176521241664886\tGenerator: loss 20.592140197753906\n","Epoch 85, batch 164/240:\tDiscriminator: real loss 0.12905578315258026, fake loss 0.24658961594104767\tGenerator: loss 19.896486282348633\n","Epoch 85, batch 165/240:\tDiscriminator: real loss 0.06874345988035202, fake loss 0.10185053944587708\tGenerator: loss 22.096330642700195\n","Epoch 85, batch 166/240:\tDiscriminator: real loss 0.10386171191930771, fake loss 0.16645382344722748\tGenerator: loss 20.743118286132812\n","Epoch 85, batch 167/240:\tDiscriminator: real loss 0.08666025847196579, fake loss 0.14393968880176544\tGenerator: loss 22.84429931640625\n","Epoch 85, batch 168/240:\tDiscriminator: real loss 0.11750156432390213, fake loss 0.04907727241516113\tGenerator: loss 20.544675827026367\n","Epoch 85, batch 169/240:\tDiscriminator: real loss 0.08129207789897919, fake loss 0.09099084883928299\tGenerator: loss 17.725934982299805\n","Epoch 85, batch 170/240:\tDiscriminator: real loss 0.07672525197267532, fake loss 0.2266780138015747\tGenerator: loss 18.873451232910156\n","Epoch 85, batch 171/240:\tDiscriminator: real loss 0.09242536872625351, fake loss 0.06626677513122559\tGenerator: loss 18.995065689086914\n","Epoch 85, batch 172/240:\tDiscriminator: real loss 0.11110243946313858, fake loss 0.2605467438697815\tGenerator: loss 18.72336769104004\n","Epoch 85, batch 173/240:\tDiscriminator: real loss 0.11916553229093552, fake loss 0.04942636936903\tGenerator: loss 21.09015655517578\n","Epoch 85, batch 174/240:\tDiscriminator: real loss 0.12937229871749878, fake loss 0.06537991762161255\tGenerator: loss 21.185436248779297\n","Epoch 85, batch 175/240:\tDiscriminator: real loss 0.07710911333560944, fake loss 0.22822196781635284\tGenerator: loss 21.926939010620117\n","Epoch 85, batch 176/240:\tDiscriminator: real loss 0.06553400307893753, fake loss 0.070220448076725\tGenerator: loss 21.361501693725586\n","Epoch 85, batch 177/240:\tDiscriminator: real loss 0.10818672180175781, fake loss 0.12440963834524155\tGenerator: loss 20.232114791870117\n","Epoch 85, batch 178/240:\tDiscriminator: real loss 0.10842759907245636, fake loss 0.15353374183177948\tGenerator: loss 20.734094619750977\n","Epoch 85, batch 179/240:\tDiscriminator: real loss 0.04693586379289627, fake loss 0.08526784926652908\tGenerator: loss 19.802488327026367\n","Epoch 85, batch 180/240:\tDiscriminator: real loss 0.07705171406269073, fake loss 0.06922274827957153\tGenerator: loss 18.244569778442383\n","Epoch 85, batch 181/240:\tDiscriminator: real loss 0.08070173114538193, fake loss 0.13925886154174805\tGenerator: loss 18.864368438720703\n","Epoch 85, batch 182/240:\tDiscriminator: real loss 0.16167375445365906, fake loss 0.18282005190849304\tGenerator: loss 18.20543670654297\n","Epoch 85, batch 183/240:\tDiscriminator: real loss 0.06272897869348526, fake loss 0.1110515296459198\tGenerator: loss 19.928300857543945\n","Epoch 85, batch 184/240:\tDiscriminator: real loss 0.1062183678150177, fake loss 0.306468665599823\tGenerator: loss 19.631193161010742\n","Epoch 85, batch 185/240:\tDiscriminator: real loss 0.16729915142059326, fake loss 0.14330340921878815\tGenerator: loss 20.415634155273438\n","Epoch 85, batch 186/240:\tDiscriminator: real loss 0.1644795536994934, fake loss 0.08251040428876877\tGenerator: loss 20.465696334838867\n","Epoch 85, batch 187/240:\tDiscriminator: real loss 0.10487385094165802, fake loss 0.13970977067947388\tGenerator: loss 21.508926391601562\n","Epoch 85, batch 188/240:\tDiscriminator: real loss 0.06842974573373795, fake loss 0.13861368596553802\tGenerator: loss 20.060401916503906\n","Epoch 85, batch 189/240:\tDiscriminator: real loss 0.10183966904878616, fake loss 0.1655855029821396\tGenerator: loss 20.40235137939453\n","Epoch 85, batch 190/240:\tDiscriminator: real loss 0.12322088330984116, fake loss 0.16601493954658508\tGenerator: loss 19.724050521850586\n","Epoch 85, batch 191/240:\tDiscriminator: real loss 0.15212252736091614, fake loss 0.1065780445933342\tGenerator: loss 18.74382781982422\n","Epoch 85, batch 192/240:\tDiscriminator: real loss 0.17289027571678162, fake loss 0.07591725140810013\tGenerator: loss 18.322154998779297\n","Epoch 85, batch 193/240:\tDiscriminator: real loss 0.10701745003461838, fake loss 0.18632099032402039\tGenerator: loss 16.948871612548828\n","Epoch 85, batch 194/240:\tDiscriminator: real loss 0.11034577339887619, fake loss 0.20936565101146698\tGenerator: loss 20.246952056884766\n","Epoch 85, batch 195/240:\tDiscriminator: real loss 0.09469128400087357, fake loss 0.15679676830768585\tGenerator: loss 21.749134063720703\n","Epoch 85, batch 196/240:\tDiscriminator: real loss 0.08821810036897659, fake loss 0.12014152854681015\tGenerator: loss 22.91437530517578\n","Epoch 85, batch 197/240:\tDiscriminator: real loss 0.26193171739578247, fake loss 0.10669136792421341\tGenerator: loss 19.557281494140625\n","Epoch 85, batch 198/240:\tDiscriminator: real loss 0.08365484327077866, fake loss 0.2385607212781906\tGenerator: loss 19.810544967651367\n","Epoch 85, batch 199/240:\tDiscriminator: real loss 0.10621175169944763, fake loss 0.17585760354995728\tGenerator: loss 20.62997055053711\n","Epoch 85, batch 200/240:\tDiscriminator: real loss 0.14020678400993347, fake loss 0.10610877722501755\tGenerator: loss 21.22916030883789\n","Epoch 85, batch 201/240:\tDiscriminator: real loss 0.06590254604816437, fake loss 0.1872284710407257\tGenerator: loss 19.71222496032715\n","Epoch 85, batch 202/240:\tDiscriminator: real loss 0.10727960616350174, fake loss 0.07851964235305786\tGenerator: loss 22.586536407470703\n","Epoch 85, batch 203/240:\tDiscriminator: real loss 0.09032909572124481, fake loss 0.11950791627168655\tGenerator: loss 19.85820198059082\n","Epoch 85, batch 204/240:\tDiscriminator: real loss 0.1741265058517456, fake loss 0.16321316361427307\tGenerator: loss 17.952835083007812\n","Epoch 85, batch 205/240:\tDiscriminator: real loss 0.06677553057670593, fake loss 0.14406494796276093\tGenerator: loss 18.51641273498535\n","Epoch 85, batch 206/240:\tDiscriminator: real loss 0.08189204335212708, fake loss 0.135019913315773\tGenerator: loss 18.351163864135742\n","Epoch 85, batch 207/240:\tDiscriminator: real loss 0.15676812827587128, fake loss 0.09627025574445724\tGenerator: loss 19.454635620117188\n","Epoch 85, batch 208/240:\tDiscriminator: real loss 0.06170956790447235, fake loss 0.18502461910247803\tGenerator: loss 18.526870727539062\n","Epoch 85, batch 209/240:\tDiscriminator: real loss 0.14429441094398499, fake loss 0.09926536679267883\tGenerator: loss 19.438016891479492\n","Epoch 85, batch 210/240:\tDiscriminator: real loss 0.07202447205781937, fake loss 0.10975007712841034\tGenerator: loss 19.129667282104492\n","Epoch 85, batch 211/240:\tDiscriminator: real loss 0.09119022637605667, fake loss 0.21105727553367615\tGenerator: loss 18.719465255737305\n","Epoch 85, batch 212/240:\tDiscriminator: real loss 0.17647510766983032, fake loss 0.04649282619357109\tGenerator: loss 16.99014663696289\n","Epoch 85, batch 213/240:\tDiscriminator: real loss 0.059269580990076065, fake loss 0.045034244656562805\tGenerator: loss 16.965316772460938\n","Epoch 85, batch 214/240:\tDiscriminator: real loss 0.039149001240730286, fake loss 0.13193149864673615\tGenerator: loss 15.315887451171875\n","Epoch 85, batch 215/240:\tDiscriminator: real loss 0.07744952291250229, fake loss 0.15689711272716522\tGenerator: loss 16.46103858947754\n","Epoch 85, batch 216/240:\tDiscriminator: real loss 0.12535662949085236, fake loss 0.18034662306308746\tGenerator: loss 18.777320861816406\n","Epoch 85, batch 217/240:\tDiscriminator: real loss 0.08800558000802994, fake loss 0.1419583261013031\tGenerator: loss 18.87371253967285\n","Epoch 85, batch 218/240:\tDiscriminator: real loss 0.1314924955368042, fake loss 0.12267697602510452\tGenerator: loss 19.51276969909668\n","Epoch 85, batch 219/240:\tDiscriminator: real loss 0.10905494540929794, fake loss 0.09377841651439667\tGenerator: loss 16.87777328491211\n","Epoch 85, batch 220/240:\tDiscriminator: real loss 0.08649617433547974, fake loss 0.05178896337747574\tGenerator: loss 18.304481506347656\n","Epoch 85, batch 221/240:\tDiscriminator: real loss 0.09684796631336212, fake loss 0.11243991553783417\tGenerator: loss 19.039180755615234\n","Epoch 85, batch 222/240:\tDiscriminator: real loss 0.09436860680580139, fake loss 0.08924972265958786\tGenerator: loss 18.668292999267578\n","Epoch 85, batch 223/240:\tDiscriminator: real loss 0.0893506407737732, fake loss 0.0743219256401062\tGenerator: loss 20.023155212402344\n","Epoch 85, batch 224/240:\tDiscriminator: real loss 0.035779453814029694, fake loss 0.2582376301288605\tGenerator: loss 19.358840942382812\n","Epoch 85, batch 225/240:\tDiscriminator: real loss 0.1126757264137268, fake loss 0.14275047183036804\tGenerator: loss 20.351707458496094\n","Epoch 85, batch 226/240:\tDiscriminator: real loss 0.17578533291816711, fake loss 0.19740420579910278\tGenerator: loss 18.752748489379883\n","Epoch 85, batch 227/240:\tDiscriminator: real loss 0.09371362626552582, fake loss 0.18021823465824127\tGenerator: loss 15.592044830322266\n","Epoch 85, batch 228/240:\tDiscriminator: real loss 0.10150155425071716, fake loss 0.30639714002609253\tGenerator: loss 20.217857360839844\n","Epoch 85, batch 229/240:\tDiscriminator: real loss 0.16767223179340363, fake loss 0.08502736687660217\tGenerator: loss 18.7685604095459\n","Epoch 85, batch 230/240:\tDiscriminator: real loss 0.12096475809812546, fake loss 0.15313412249088287\tGenerator: loss 16.368364334106445\n","Epoch 85, batch 231/240:\tDiscriminator: real loss 0.12835422158241272, fake loss 0.13699424266815186\tGenerator: loss 15.031669616699219\n","Epoch 85, batch 232/240:\tDiscriminator: real loss 0.20325422286987305, fake loss 0.23537610471248627\tGenerator: loss 17.59105110168457\n","Epoch 85, batch 233/240:\tDiscriminator: real loss 0.06032758578658104, fake loss 0.1461399495601654\tGenerator: loss 18.658077239990234\n","Epoch 85, batch 234/240:\tDiscriminator: real loss 0.059602878987789154, fake loss 0.09816295653581619\tGenerator: loss 17.082542419433594\n","Epoch 85, batch 235/240:\tDiscriminator: real loss 0.1761564463376999, fake loss 0.09156492352485657\tGenerator: loss 16.859317779541016\n","Epoch 85, batch 236/240:\tDiscriminator: real loss 0.08139368891716003, fake loss 0.10334352403879166\tGenerator: loss 15.298425674438477\n","Epoch 85, batch 237/240:\tDiscriminator: real loss 0.053410448133945465, fake loss 0.16172900795936584\tGenerator: loss 15.896419525146484\n","Epoch 85, batch 238/240:\tDiscriminator: real loss 0.0583958625793457, fake loss 0.22902624309062958\tGenerator: loss 18.516254425048828\n","Epoch 85, batch 239/240:\tDiscriminator: real loss 0.06755492836236954, fake loss 0.07513696700334549\tGenerator: loss 18.851577758789062\n","Epoch 85, batch 240/240:\tDiscriminator: real loss 0.2615876793861389, fake loss 0.10647695511579514\tGenerator: loss 15.225878715515137\n","Epoch 86, batch 1/240:\tDiscriminator: real loss 0.10651468485593796, fake loss 0.1908654421567917\tGenerator: loss 15.953449249267578\n","Epoch 86, batch 2/240:\tDiscriminator: real loss 0.045137885957956314, fake loss 0.14562702178955078\tGenerator: loss 15.798786163330078\n","Epoch 86, batch 3/240:\tDiscriminator: real loss 0.0898682177066803, fake loss 0.11818234622478485\tGenerator: loss 16.734024047851562\n","Epoch 86, batch 4/240:\tDiscriminator: real loss 0.10976093262434006, fake loss 0.13458152115345\tGenerator: loss 16.176546096801758\n","Epoch 86, batch 5/240:\tDiscriminator: real loss 0.08393530547618866, fake loss 0.15878549218177795\tGenerator: loss 16.212244033813477\n","Epoch 86, batch 6/240:\tDiscriminator: real loss 0.20782674849033356, fake loss 0.12079420685768127\tGenerator: loss 15.871908187866211\n","Epoch 86, batch 7/240:\tDiscriminator: real loss 0.1134779080748558, fake loss 0.13968390226364136\tGenerator: loss 16.143566131591797\n","Epoch 86, batch 8/240:\tDiscriminator: real loss 0.05849340558052063, fake loss 0.2577095925807953\tGenerator: loss 17.34451675415039\n","Epoch 86, batch 9/240:\tDiscriminator: real loss 0.10510574281215668, fake loss 0.20853714644908905\tGenerator: loss 18.13745880126953\n","Epoch 86, batch 10/240:\tDiscriminator: real loss 0.20097656548023224, fake loss 0.1304350197315216\tGenerator: loss 15.629983901977539\n","Epoch 86, batch 11/240:\tDiscriminator: real loss 0.0813167542219162, fake loss 0.1808375120162964\tGenerator: loss 14.568530082702637\n","Epoch 86, batch 12/240:\tDiscriminator: real loss 0.07666812092065811, fake loss 0.17290033400058746\tGenerator: loss 13.430058479309082\n","Epoch 86, batch 13/240:\tDiscriminator: real loss 0.12012234330177307, fake loss 0.08183303475379944\tGenerator: loss 16.692724227905273\n","Epoch 86, batch 14/240:\tDiscriminator: real loss 0.11171085387468338, fake loss 0.07096509635448456\tGenerator: loss 14.39494514465332\n","Epoch 86, batch 15/240:\tDiscriminator: real loss 0.13307853043079376, fake loss 0.24357345700263977\tGenerator: loss 15.333279609680176\n","Epoch 86, batch 16/240:\tDiscriminator: real loss 0.13465647399425507, fake loss 0.1226382851600647\tGenerator: loss 16.702882766723633\n","Epoch 86, batch 17/240:\tDiscriminator: real loss 0.10984516888856888, fake loss 0.24116218090057373\tGenerator: loss 16.789140701293945\n","Epoch 86, batch 18/240:\tDiscriminator: real loss 0.17997592687606812, fake loss 0.16901178658008575\tGenerator: loss 14.400542259216309\n","Epoch 86, batch 19/240:\tDiscriminator: real loss 0.15060275793075562, fake loss 0.19678863883018494\tGenerator: loss 16.974599838256836\n","Epoch 86, batch 20/240:\tDiscriminator: real loss 0.17278139293193817, fake loss 0.16432170569896698\tGenerator: loss 16.412988662719727\n","Epoch 86, batch 21/240:\tDiscriminator: real loss 0.11345290392637253, fake loss 0.15537726879119873\tGenerator: loss 16.074684143066406\n","Epoch 86, batch 22/240:\tDiscriminator: real loss 0.11314567923545837, fake loss 0.24560214579105377\tGenerator: loss 16.579626083374023\n","Epoch 86, batch 23/240:\tDiscriminator: real loss 0.1555219143629074, fake loss 0.126888245344162\tGenerator: loss 16.964448928833008\n","Epoch 86, batch 24/240:\tDiscriminator: real loss 0.13113370537757874, fake loss 0.12308969348669052\tGenerator: loss 16.044918060302734\n","Epoch 86, batch 25/240:\tDiscriminator: real loss 0.12285875529050827, fake loss 0.24458052217960358\tGenerator: loss 17.51392936706543\n","Epoch 86, batch 26/240:\tDiscriminator: real loss 0.12205705791711807, fake loss 0.15385642647743225\tGenerator: loss 16.076271057128906\n","Epoch 86, batch 27/240:\tDiscriminator: real loss 0.13867835700511932, fake loss 0.057200003415346146\tGenerator: loss 15.537991523742676\n","Epoch 86, batch 28/240:\tDiscriminator: real loss 0.12519963085651398, fake loss 0.23636920750141144\tGenerator: loss 16.576377868652344\n","Epoch 86, batch 29/240:\tDiscriminator: real loss 0.11377269774675369, fake loss 0.1443394273519516\tGenerator: loss 18.57694435119629\n","Epoch 86, batch 30/240:\tDiscriminator: real loss 0.16258233785629272, fake loss 0.1330794095993042\tGenerator: loss 17.21466636657715\n","Epoch 86, batch 31/240:\tDiscriminator: real loss 0.08133655786514282, fake loss 0.10162659734487534\tGenerator: loss 16.6032772064209\n","Epoch 86, batch 32/240:\tDiscriminator: real loss 0.06361829489469528, fake loss 0.1795998215675354\tGenerator: loss 17.792282104492188\n","Epoch 86, batch 33/240:\tDiscriminator: real loss 0.13206766545772552, fake loss 0.19050055742263794\tGenerator: loss 15.359424591064453\n","Epoch 86, batch 34/240:\tDiscriminator: real loss 0.15631040930747986, fake loss 0.08981852233409882\tGenerator: loss 17.033531188964844\n","Epoch 86, batch 35/240:\tDiscriminator: real loss 0.08291453123092651, fake loss 0.18544723093509674\tGenerator: loss 16.299901962280273\n","Epoch 86, batch 36/240:\tDiscriminator: real loss 0.07852112501859665, fake loss 0.10479970276355743\tGenerator: loss 16.478574752807617\n","Epoch 86, batch 37/240:\tDiscriminator: real loss 0.11150529235601425, fake loss 0.19231979548931122\tGenerator: loss 16.449548721313477\n","Epoch 86, batch 38/240:\tDiscriminator: real loss 0.20477314293384552, fake loss 0.14353428781032562\tGenerator: loss 17.150318145751953\n","Epoch 86, batch 39/240:\tDiscriminator: real loss 0.08559343218803406, fake loss 0.19951273500919342\tGenerator: loss 18.230186462402344\n","Epoch 86, batch 40/240:\tDiscriminator: real loss 0.09436453878879547, fake loss 0.20043060183525085\tGenerator: loss 16.535873413085938\n","Epoch 86, batch 41/240:\tDiscriminator: real loss 0.20927971601486206, fake loss 0.10799790173768997\tGenerator: loss 16.702045440673828\n","Epoch 86, batch 42/240:\tDiscriminator: real loss 0.08544200658798218, fake loss 0.13775840401649475\tGenerator: loss 15.07516098022461\n","Epoch 86, batch 43/240:\tDiscriminator: real loss 0.11923146992921829, fake loss 0.19401447474956512\tGenerator: loss 15.77136516571045\n","Epoch 86, batch 44/240:\tDiscriminator: real loss 0.08281709998846054, fake loss 0.10624244809150696\tGenerator: loss 14.822371482849121\n","Epoch 86, batch 45/240:\tDiscriminator: real loss 0.1835501492023468, fake loss 0.2254021316766739\tGenerator: loss 17.080289840698242\n","Epoch 86, batch 46/240:\tDiscriminator: real loss 0.1655236780643463, fake loss 0.14093972742557526\tGenerator: loss 16.495967864990234\n","Epoch 86, batch 47/240:\tDiscriminator: real loss 0.06523962318897247, fake loss 0.09307806193828583\tGenerator: loss 14.370682716369629\n","Epoch 86, batch 48/240:\tDiscriminator: real loss 0.10102260857820511, fake loss 0.17160503566265106\tGenerator: loss 16.25877571105957\n","Epoch 86, batch 49/240:\tDiscriminator: real loss 0.07008735835552216, fake loss 0.22807548940181732\tGenerator: loss 18.242326736450195\n","Epoch 86, batch 50/240:\tDiscriminator: real loss 0.1613365113735199, fake loss 0.07958390563726425\tGenerator: loss 17.323617935180664\n","Epoch 86, batch 51/240:\tDiscriminator: real loss 0.12282539159059525, fake loss 0.08732626587152481\tGenerator: loss 14.587983131408691\n","Epoch 86, batch 52/240:\tDiscriminator: real loss 0.08134321123361588, fake loss 0.1725456267595291\tGenerator: loss 14.318146705627441\n","Epoch 86, batch 53/240:\tDiscriminator: real loss 0.09378166496753693, fake loss 0.2663038671016693\tGenerator: loss 16.333621978759766\n","Epoch 86, batch 54/240:\tDiscriminator: real loss 0.1411983072757721, fake loss 0.04497348889708519\tGenerator: loss 18.335346221923828\n","Epoch 86, batch 55/240:\tDiscriminator: real loss 0.1500702053308487, fake loss 0.2564810514450073\tGenerator: loss 16.713300704956055\n","Epoch 86, batch 56/240:\tDiscriminator: real loss 0.06627275794744492, fake loss 0.11711782217025757\tGenerator: loss 17.84962272644043\n","Epoch 86, batch 57/240:\tDiscriminator: real loss 0.14963814616203308, fake loss 0.12198593467473984\tGenerator: loss 16.601037979125977\n","Epoch 86, batch 58/240:\tDiscriminator: real loss 0.0789736732840538, fake loss 0.10793249309062958\tGenerator: loss 18.199359893798828\n","Epoch 86, batch 59/240:\tDiscriminator: real loss 0.13257557153701782, fake loss 0.37979498505592346\tGenerator: loss 17.474084854125977\n","Epoch 86, batch 60/240:\tDiscriminator: real loss 0.1226077526807785, fake loss 0.10297885537147522\tGenerator: loss 18.161237716674805\n","Epoch 86, batch 61/240:\tDiscriminator: real loss 0.24644389748573303, fake loss 0.10590348392724991\tGenerator: loss 15.579215049743652\n","Epoch 86, batch 62/240:\tDiscriminator: real loss 0.052760325372219086, fake loss 0.2001061588525772\tGenerator: loss 16.75743293762207\n","Epoch 86, batch 63/240:\tDiscriminator: real loss 0.1942606419324875, fake loss 0.1804991513490677\tGenerator: loss 15.137128829956055\n","Epoch 86, batch 64/240:\tDiscriminator: real loss 0.11489642411470413, fake loss 0.226324200630188\tGenerator: loss 16.137022018432617\n","Epoch 86, batch 65/240:\tDiscriminator: real loss 0.1494360864162445, fake loss 0.16289854049682617\tGenerator: loss 17.678747177124023\n","Epoch 86, batch 66/240:\tDiscriminator: real loss 0.16577231884002686, fake loss 0.17953361570835114\tGenerator: loss 14.129596710205078\n","Epoch 86, batch 67/240:\tDiscriminator: real loss 0.15702223777770996, fake loss 0.1693604290485382\tGenerator: loss 16.163530349731445\n","Epoch 86, batch 68/240:\tDiscriminator: real loss 0.12474049627780914, fake loss 0.20134752988815308\tGenerator: loss 14.977753639221191\n","Epoch 86, batch 69/240:\tDiscriminator: real loss 0.12087959051132202, fake loss 0.1535724699497223\tGenerator: loss 14.415843963623047\n","Epoch 86, batch 70/240:\tDiscriminator: real loss 0.1202423945069313, fake loss 0.17195899784564972\tGenerator: loss 14.385767936706543\n","Epoch 86, batch 71/240:\tDiscriminator: real loss 0.14985838532447815, fake loss 0.15293589234352112\tGenerator: loss 14.72793960571289\n","Epoch 86, batch 72/240:\tDiscriminator: real loss 0.149063840508461, fake loss 0.24757134914398193\tGenerator: loss 14.434826850891113\n","Epoch 86, batch 73/240:\tDiscriminator: real loss 0.15071693062782288, fake loss 0.13395358622074127\tGenerator: loss 12.566904067993164\n","Epoch 86, batch 74/240:\tDiscriminator: real loss 0.08882655948400497, fake loss 0.10565857589244843\tGenerator: loss 11.871973991394043\n","Epoch 86, batch 75/240:\tDiscriminator: real loss 0.09174507856369019, fake loss 0.061117008328437805\tGenerator: loss 12.425393104553223\n","Epoch 86, batch 76/240:\tDiscriminator: real loss 0.10970404744148254, fake loss 0.1346704363822937\tGenerator: loss 13.944750785827637\n","Epoch 86, batch 77/240:\tDiscriminator: real loss 0.06602451950311661, fake loss 0.1631391942501068\tGenerator: loss 15.961291313171387\n","Epoch 86, batch 78/240:\tDiscriminator: real loss 0.07232192158699036, fake loss 0.18744218349456787\tGenerator: loss 16.264312744140625\n","Epoch 86, batch 79/240:\tDiscriminator: real loss 0.163725808262825, fake loss 0.2232026308774948\tGenerator: loss 12.885601043701172\n","Epoch 86, batch 80/240:\tDiscriminator: real loss 0.12183347344398499, fake loss 0.2492520958185196\tGenerator: loss 14.901257514953613\n","Epoch 86, batch 81/240:\tDiscriminator: real loss 0.10953987389802933, fake loss 0.058466557413339615\tGenerator: loss 14.52363395690918\n","Epoch 86, batch 82/240:\tDiscriminator: real loss 0.14284612238407135, fake loss 0.0649728998541832\tGenerator: loss 13.342296600341797\n","Epoch 86, batch 83/240:\tDiscriminator: real loss 0.08830389380455017, fake loss 0.19240693747997284\tGenerator: loss 13.6964693069458\n","Epoch 86, batch 84/240:\tDiscriminator: real loss 0.07863375544548035, fake loss 0.18825560808181763\tGenerator: loss 16.234453201293945\n","Epoch 86, batch 85/240:\tDiscriminator: real loss 0.07143291085958481, fake loss 0.1849707067012787\tGenerator: loss 16.197423934936523\n","Epoch 86, batch 86/240:\tDiscriminator: real loss 0.08485081791877747, fake loss 0.18210574984550476\tGenerator: loss 17.732898712158203\n","Epoch 86, batch 87/240:\tDiscriminator: real loss 0.20544472336769104, fake loss 0.06421548128128052\tGenerator: loss 15.775399208068848\n","Epoch 86, batch 88/240:\tDiscriminator: real loss 0.20307785272598267, fake loss 0.21882124245166779\tGenerator: loss 15.375511169433594\n","Epoch 86, batch 89/240:\tDiscriminator: real loss 0.10009390115737915, fake loss 0.09708405286073685\tGenerator: loss 15.672306060791016\n","Epoch 86, batch 90/240:\tDiscriminator: real loss 0.06607673317193985, fake loss 0.23016361892223358\tGenerator: loss 15.072893142700195\n","Epoch 86, batch 91/240:\tDiscriminator: real loss 0.03823523968458176, fake loss 0.08120179921388626\tGenerator: loss 17.125595092773438\n","Epoch 86, batch 92/240:\tDiscriminator: real loss 0.12747448682785034, fake loss 0.12364984303712845\tGenerator: loss 17.437177658081055\n","Epoch 86, batch 93/240:\tDiscriminator: real loss 0.07061596214771271, fake loss 0.10284141451120377\tGenerator: loss 15.768525123596191\n","Epoch 86, batch 94/240:\tDiscriminator: real loss 0.15890081226825714, fake loss 0.0803317055106163\tGenerator: loss 13.831193923950195\n","Epoch 86, batch 95/240:\tDiscriminator: real loss 0.11423081159591675, fake loss 0.17841243743896484\tGenerator: loss 13.164156913757324\n","Epoch 86, batch 96/240:\tDiscriminator: real loss 0.07566571980714798, fake loss 0.23168490827083588\tGenerator: loss 14.727078437805176\n","Epoch 86, batch 97/240:\tDiscriminator: real loss 0.12692596018314362, fake loss 0.11604142189025879\tGenerator: loss 15.002957344055176\n","Epoch 86, batch 98/240:\tDiscriminator: real loss 0.13508853316307068, fake loss 0.1370869278907776\tGenerator: loss 14.013419151306152\n","Epoch 86, batch 99/240:\tDiscriminator: real loss 0.09607226401567459, fake loss 0.08183171600103378\tGenerator: loss 14.956744194030762\n","Epoch 86, batch 100/240:\tDiscriminator: real loss 0.08217561990022659, fake loss 0.17678599059581757\tGenerator: loss 16.370975494384766\n","Epoch 86, batch 101/240:\tDiscriminator: real loss 0.07132059335708618, fake loss 0.29152974486351013\tGenerator: loss 17.671606063842773\n","Epoch 86, batch 102/240:\tDiscriminator: real loss 0.1291603147983551, fake loss 0.16430668532848358\tGenerator: loss 18.249208450317383\n","Epoch 86, batch 103/240:\tDiscriminator: real loss 0.16994933784008026, fake loss 0.13613338768482208\tGenerator: loss 14.833592414855957\n","Epoch 86, batch 104/240:\tDiscriminator: real loss 0.09156271815299988, fake loss 0.17999416589736938\tGenerator: loss 16.41228485107422\n","Epoch 86, batch 105/240:\tDiscriminator: real loss 0.11373879760503769, fake loss 0.15043899416923523\tGenerator: loss 16.94701385498047\n","Epoch 86, batch 106/240:\tDiscriminator: real loss 0.14858874678611755, fake loss 0.18991905450820923\tGenerator: loss 16.439895629882812\n","Epoch 86, batch 107/240:\tDiscriminator: real loss 0.10480163246393204, fake loss 0.1949312537908554\tGenerator: loss 16.430095672607422\n","Epoch 86, batch 108/240:\tDiscriminator: real loss 0.2187010645866394, fake loss 0.14014528691768646\tGenerator: loss 17.451868057250977\n","Epoch 86, batch 109/240:\tDiscriminator: real loss 0.10911522805690765, fake loss 0.24801895022392273\tGenerator: loss 14.458324432373047\n","Epoch 86, batch 110/240:\tDiscriminator: real loss 0.10154891759157181, fake loss 0.10689322650432587\tGenerator: loss 13.905488014221191\n","Epoch 86, batch 111/240:\tDiscriminator: real loss 0.11726325750350952, fake loss 0.19249717891216278\tGenerator: loss 13.736584663391113\n","Epoch 86, batch 112/240:\tDiscriminator: real loss 0.09566034376621246, fake loss 0.12133386731147766\tGenerator: loss 15.127067565917969\n","Epoch 86, batch 113/240:\tDiscriminator: real loss 0.14348948001861572, fake loss 0.21020527184009552\tGenerator: loss 15.411188125610352\n","Epoch 86, batch 114/240:\tDiscriminator: real loss 0.1380576491355896, fake loss 0.27957621216773987\tGenerator: loss 18.03658676147461\n","Epoch 86, batch 115/240:\tDiscriminator: real loss 0.17152079939842224, fake loss 0.16799043118953705\tGenerator: loss 18.064098358154297\n","Epoch 86, batch 116/240:\tDiscriminator: real loss 0.08725649118423462, fake loss 0.15255311131477356\tGenerator: loss 16.71825408935547\n","Epoch 86, batch 117/240:\tDiscriminator: real loss 0.18425388634204865, fake loss 0.14856940507888794\tGenerator: loss 16.415098190307617\n","Epoch 86, batch 118/240:\tDiscriminator: real loss 0.10189118981361389, fake loss 0.10107128322124481\tGenerator: loss 14.531852722167969\n","Epoch 86, batch 119/240:\tDiscriminator: real loss 0.08860618621110916, fake loss 0.16524574160575867\tGenerator: loss 16.960124969482422\n","Epoch 86, batch 120/240:\tDiscriminator: real loss 0.1595335304737091, fake loss 0.22869586944580078\tGenerator: loss 15.862892150878906\n","Epoch 86, batch 121/240:\tDiscriminator: real loss 0.1541232019662857, fake loss 0.06752779334783554\tGenerator: loss 15.43488883972168\n","Epoch 86, batch 122/240:\tDiscriminator: real loss 0.07007032632827759, fake loss 0.1775762438774109\tGenerator: loss 13.932221412658691\n","Epoch 86, batch 123/240:\tDiscriminator: real loss 0.05765155702829361, fake loss 0.20746338367462158\tGenerator: loss 16.71018409729004\n","Epoch 86, batch 124/240:\tDiscriminator: real loss 0.1525801122188568, fake loss 0.23880432546138763\tGenerator: loss 16.655921936035156\n","Epoch 86, batch 125/240:\tDiscriminator: real loss 0.13627485930919647, fake loss 0.19984756410121918\tGenerator: loss 16.64593505859375\n","Epoch 86, batch 126/240:\tDiscriminator: real loss 0.09379987418651581, fake loss 0.18443311750888824\tGenerator: loss 15.803173065185547\n","Epoch 86, batch 127/240:\tDiscriminator: real loss 0.16530171036720276, fake loss 0.16512589156627655\tGenerator: loss 15.519030570983887\n","Epoch 86, batch 128/240:\tDiscriminator: real loss 0.08649960160255432, fake loss 0.11899695545434952\tGenerator: loss 16.100933074951172\n","Epoch 86, batch 129/240:\tDiscriminator: real loss 0.09531870484352112, fake loss 0.10928358882665634\tGenerator: loss 14.4772367477417\n","Epoch 86, batch 130/240:\tDiscriminator: real loss 0.09533069282770157, fake loss 0.21797478199005127\tGenerator: loss 13.977558135986328\n","Epoch 86, batch 131/240:\tDiscriminator: real loss 0.2248026728630066, fake loss 0.11402174085378647\tGenerator: loss 14.631892204284668\n","Epoch 86, batch 132/240:\tDiscriminator: real loss 0.22836264967918396, fake loss 0.18243825435638428\tGenerator: loss 14.198443412780762\n","Epoch 86, batch 133/240:\tDiscriminator: real loss 0.0931258574128151, fake loss 0.25804194808006287\tGenerator: loss 14.129607200622559\n","Epoch 86, batch 134/240:\tDiscriminator: real loss 0.0810968205332756, fake loss 0.20117466151714325\tGenerator: loss 13.972237586975098\n","Epoch 86, batch 135/240:\tDiscriminator: real loss 0.12396550178527832, fake loss 0.1655183732509613\tGenerator: loss 14.785103797912598\n","Epoch 86, batch 136/240:\tDiscriminator: real loss 0.14526565372943878, fake loss 0.15816043317317963\tGenerator: loss 14.512674331665039\n","Epoch 86, batch 137/240:\tDiscriminator: real loss 0.2138969451189041, fake loss 0.15750758349895477\tGenerator: loss 12.548816680908203\n","Epoch 86, batch 138/240:\tDiscriminator: real loss 0.059230703860521317, fake loss 0.08736330270767212\tGenerator: loss 13.197025299072266\n","Epoch 86, batch 139/240:\tDiscriminator: real loss 0.1151583194732666, fake loss 0.16767114400863647\tGenerator: loss 14.0691556930542\n","Epoch 86, batch 140/240:\tDiscriminator: real loss 0.1388048231601715, fake loss 0.1621994972229004\tGenerator: loss 15.885641098022461\n","Epoch 86, batch 141/240:\tDiscriminator: real loss 0.07858654856681824, fake loss 0.14632904529571533\tGenerator: loss 15.548608779907227\n","Epoch 86, batch 142/240:\tDiscriminator: real loss 0.07812785357236862, fake loss 0.23340871930122375\tGenerator: loss 14.86989974975586\n","Epoch 86, batch 143/240:\tDiscriminator: real loss 0.1533695012331009, fake loss 0.12597043812274933\tGenerator: loss 14.0203218460083\n","Epoch 86, batch 144/240:\tDiscriminator: real loss 0.07088896632194519, fake loss 0.13197700679302216\tGenerator: loss 14.896079063415527\n","Epoch 86, batch 145/240:\tDiscriminator: real loss 0.12646080553531647, fake loss 0.3241884708404541\tGenerator: loss 15.340306282043457\n","Epoch 86, batch 146/240:\tDiscriminator: real loss 0.197176992893219, fake loss 0.08224625885486603\tGenerator: loss 12.456229209899902\n","Epoch 86, batch 147/240:\tDiscriminator: real loss 0.08763288706541061, fake loss 0.18401801586151123\tGenerator: loss 10.749713897705078\n","Epoch 86, batch 148/240:\tDiscriminator: real loss 0.1952085644006729, fake loss 0.14702127873897552\tGenerator: loss 11.343881607055664\n","Epoch 86, batch 149/240:\tDiscriminator: real loss 0.12905336916446686, fake loss 0.10824472457170486\tGenerator: loss 10.857458114624023\n","Epoch 86, batch 150/240:\tDiscriminator: real loss 0.10835376381874084, fake loss 0.20260602235794067\tGenerator: loss 13.360871315002441\n","Epoch 86, batch 151/240:\tDiscriminator: real loss 0.07483179122209549, fake loss 0.299075722694397\tGenerator: loss 13.001338958740234\n","Epoch 86, batch 152/240:\tDiscriminator: real loss 0.16323694586753845, fake loss 0.09879889339208603\tGenerator: loss 13.509102821350098\n","Epoch 86, batch 153/240:\tDiscriminator: real loss 0.10885896533727646, fake loss 0.057678721845149994\tGenerator: loss 13.462986946105957\n","Epoch 86, batch 154/240:\tDiscriminator: real loss 0.09420711547136307, fake loss 0.3676801025867462\tGenerator: loss 12.593060493469238\n","Epoch 86, batch 155/240:\tDiscriminator: real loss 0.13302017748355865, fake loss 0.11378098279237747\tGenerator: loss 12.608333587646484\n","Epoch 86, batch 156/240:\tDiscriminator: real loss 0.15994492173194885, fake loss 0.10674092918634415\tGenerator: loss 12.021392822265625\n","Epoch 86, batch 157/240:\tDiscriminator: real loss 0.05336274206638336, fake loss 0.12325889617204666\tGenerator: loss 11.885340690612793\n","Epoch 86, batch 158/240:\tDiscriminator: real loss 0.08580166846513748, fake loss 0.22022545337677002\tGenerator: loss 13.220544815063477\n","Epoch 86, batch 159/240:\tDiscriminator: real loss 0.14414986968040466, fake loss 0.04755328223109245\tGenerator: loss 13.561967849731445\n","Epoch 86, batch 160/240:\tDiscriminator: real loss 0.14677231013774872, fake loss 0.10085571557283401\tGenerator: loss 9.40898609161377\n","Epoch 86, batch 161/240:\tDiscriminator: real loss 0.04730736091732979, fake loss 0.29605889320373535\tGenerator: loss 11.220702171325684\n","Epoch 86, batch 162/240:\tDiscriminator: real loss 0.12163995951414108, fake loss 0.022521190345287323\tGenerator: loss 10.58610725402832\n","Epoch 86, batch 163/240:\tDiscriminator: real loss 0.18973371386528015, fake loss 0.2294968217611313\tGenerator: loss 9.871075630187988\n","Epoch 86, batch 164/240:\tDiscriminator: real loss 0.07305160909891129, fake loss 0.1328837275505066\tGenerator: loss 11.867635726928711\n","Epoch 86, batch 165/240:\tDiscriminator: real loss 0.09710966795682907, fake loss 0.141340434551239\tGenerator: loss 11.339325904846191\n","Epoch 86, batch 166/240:\tDiscriminator: real loss 0.05676133558154106, fake loss 0.23914842307567596\tGenerator: loss 13.662625312805176\n","Epoch 86, batch 167/240:\tDiscriminator: real loss 0.09902004152536392, fake loss 0.1229974776506424\tGenerator: loss 12.604636192321777\n","Epoch 86, batch 168/240:\tDiscriminator: real loss 0.10688234120607376, fake loss 0.23401905596256256\tGenerator: loss 14.988636016845703\n","Epoch 86, batch 169/240:\tDiscriminator: real loss 0.11664165556430817, fake loss 0.1593194603919983\tGenerator: loss 15.174874305725098\n","Epoch 86, batch 170/240:\tDiscriminator: real loss 0.27193406224250793, fake loss 0.19195665419101715\tGenerator: loss 12.36699104309082\n","Epoch 86, batch 171/240:\tDiscriminator: real loss 0.12212936580181122, fake loss 0.1645260751247406\tGenerator: loss 13.165153503417969\n","Epoch 86, batch 172/240:\tDiscriminator: real loss 0.07458329945802689, fake loss 0.25054511427879333\tGenerator: loss 13.594786643981934\n","Epoch 86, batch 173/240:\tDiscriminator: real loss 0.14134366810321808, fake loss 0.13858014345169067\tGenerator: loss 13.444549560546875\n","Epoch 86, batch 174/240:\tDiscriminator: real loss 0.0698702409863472, fake loss 0.0969385877251625\tGenerator: loss 13.021020889282227\n","Epoch 86, batch 175/240:\tDiscriminator: real loss 0.06473810970783234, fake loss 0.16815851628780365\tGenerator: loss 13.447602272033691\n","Epoch 86, batch 176/240:\tDiscriminator: real loss 0.21548280119895935, fake loss 0.1441718488931656\tGenerator: loss 13.624587059020996\n","Epoch 86, batch 177/240:\tDiscriminator: real loss 0.06710135191679001, fake loss 0.14588060975074768\tGenerator: loss 12.408289909362793\n","Epoch 86, batch 178/240:\tDiscriminator: real loss 0.1316710114479065, fake loss 0.11211571842432022\tGenerator: loss 13.907445907592773\n","Epoch 86, batch 179/240:\tDiscriminator: real loss 0.07954791933298111, fake loss 0.13708287477493286\tGenerator: loss 13.766510963439941\n","Epoch 86, batch 180/240:\tDiscriminator: real loss 0.10579123347997665, fake loss 0.2671131193637848\tGenerator: loss 12.385886192321777\n","Epoch 86, batch 181/240:\tDiscriminator: real loss 0.10774786025285721, fake loss 0.12991535663604736\tGenerator: loss 13.676732063293457\n","Epoch 86, batch 182/240:\tDiscriminator: real loss 0.09970363974571228, fake loss 0.1847081333398819\tGenerator: loss 15.057599067687988\n","Epoch 86, batch 183/240:\tDiscriminator: real loss 0.1644413024187088, fake loss 0.09818189591169357\tGenerator: loss 14.396406173706055\n","Epoch 86, batch 184/240:\tDiscriminator: real loss 0.0604674331843853, fake loss 0.19032274186611176\tGenerator: loss 14.640071868896484\n","Epoch 86, batch 185/240:\tDiscriminator: real loss 0.1043553352355957, fake loss 0.1534556746482849\tGenerator: loss 14.40976333618164\n","Epoch 86, batch 186/240:\tDiscriminator: real loss 0.13112756609916687, fake loss 0.07522358000278473\tGenerator: loss 13.073758125305176\n","Epoch 86, batch 187/240:\tDiscriminator: real loss 0.05492101237177849, fake loss 0.10785873234272003\tGenerator: loss 12.338827133178711\n","Epoch 86, batch 188/240:\tDiscriminator: real loss 0.14120666682720184, fake loss 0.21331359446048737\tGenerator: loss 12.695825576782227\n","Epoch 86, batch 189/240:\tDiscriminator: real loss 0.09510500729084015, fake loss 0.12986750900745392\tGenerator: loss 14.101629257202148\n","Epoch 86, batch 190/240:\tDiscriminator: real loss 0.1296604871749878, fake loss 0.14756625890731812\tGenerator: loss 11.829660415649414\n","Epoch 86, batch 191/240:\tDiscriminator: real loss 0.09687504917383194, fake loss 0.19200283288955688\tGenerator: loss 11.211182594299316\n","Epoch 86, batch 192/240:\tDiscriminator: real loss 0.13522885739803314, fake loss 0.1271355003118515\tGenerator: loss 9.912686347961426\n","Epoch 86, batch 193/240:\tDiscriminator: real loss 0.12452343106269836, fake loss 0.160703644156456\tGenerator: loss 9.715409278869629\n","Epoch 86, batch 194/240:\tDiscriminator: real loss 0.1273626983165741, fake loss 0.08327390998601913\tGenerator: loss 9.748218536376953\n","Epoch 86, batch 195/240:\tDiscriminator: real loss 0.12589429318904877, fake loss 0.20692123472690582\tGenerator: loss 12.566415786743164\n","Epoch 86, batch 196/240:\tDiscriminator: real loss 0.054521940648555756, fake loss 0.14267946779727936\tGenerator: loss 12.95880126953125\n","Epoch 86, batch 197/240:\tDiscriminator: real loss 0.13907046616077423, fake loss 0.09830604493618011\tGenerator: loss 12.705238342285156\n","Epoch 86, batch 198/240:\tDiscriminator: real loss 0.13929232954978943, fake loss 0.12427118420600891\tGenerator: loss 11.134699821472168\n","Epoch 86, batch 199/240:\tDiscriminator: real loss 0.06302054226398468, fake loss 0.1310628056526184\tGenerator: loss 12.127335548400879\n","Epoch 86, batch 200/240:\tDiscriminator: real loss 0.05690668895840645, fake loss 0.15992607176303864\tGenerator: loss 13.564977645874023\n","Epoch 86, batch 201/240:\tDiscriminator: real loss 0.11388655006885529, fake loss 0.19638292491436005\tGenerator: loss 12.86735725402832\n","Epoch 86, batch 202/240:\tDiscriminator: real loss 0.1066332459449768, fake loss 0.2609403729438782\tGenerator: loss 12.467630386352539\n","Epoch 86, batch 203/240:\tDiscriminator: real loss 0.1427840292453766, fake loss 0.22328180074691772\tGenerator: loss 13.430794715881348\n","Epoch 86, batch 204/240:\tDiscriminator: real loss 0.10949847847223282, fake loss 0.09369559586048126\tGenerator: loss 14.076716423034668\n","Epoch 86, batch 205/240:\tDiscriminator: real loss 0.19899216294288635, fake loss 0.18634352087974548\tGenerator: loss 13.502645492553711\n","Epoch 86, batch 206/240:\tDiscriminator: real loss 0.15457600355148315, fake loss 0.08338937908411026\tGenerator: loss 12.681445121765137\n","Epoch 86, batch 207/240:\tDiscriminator: real loss 0.0731453076004982, fake loss 0.31923773884773254\tGenerator: loss 14.012704849243164\n","Epoch 86, batch 208/240:\tDiscriminator: real loss 0.12172054499387741, fake loss 0.17520646750926971\tGenerator: loss 14.653212547302246\n","Epoch 86, batch 209/240:\tDiscriminator: real loss 0.21120448410511017, fake loss 0.09105853736400604\tGenerator: loss 13.76517105102539\n","Epoch 86, batch 210/240:\tDiscriminator: real loss 0.09429990500211716, fake loss 0.3396482467651367\tGenerator: loss 11.320420265197754\n","Epoch 86, batch 211/240:\tDiscriminator: real loss 0.11833242326974869, fake loss 0.14043940603733063\tGenerator: loss 11.962210655212402\n","Epoch 86, batch 212/240:\tDiscriminator: real loss 0.17185825109481812, fake loss 0.06676139682531357\tGenerator: loss 12.658825874328613\n","Epoch 86, batch 213/240:\tDiscriminator: real loss 0.06605970114469528, fake loss 0.28910720348358154\tGenerator: loss 13.432616233825684\n","Epoch 86, batch 214/240:\tDiscriminator: real loss 0.09340794384479523, fake loss 0.061466388404369354\tGenerator: loss 10.95844841003418\n","Epoch 86, batch 215/240:\tDiscriminator: real loss 0.16850757598876953, fake loss 0.15289340913295746\tGenerator: loss 9.888266563415527\n","Epoch 86, batch 216/240:\tDiscriminator: real loss 0.12314046919345856, fake loss 0.05942608788609505\tGenerator: loss 9.2352933883667\n","Epoch 86, batch 217/240:\tDiscriminator: real loss 0.11464926600456238, fake loss 0.29737919569015503\tGenerator: loss 10.239662170410156\n","Epoch 86, batch 218/240:\tDiscriminator: real loss 0.06709558516740799, fake loss 0.21122586727142334\tGenerator: loss 9.607958793640137\n","Epoch 86, batch 219/240:\tDiscriminator: real loss 0.21445538103580475, fake loss 0.09303684532642365\tGenerator: loss 10.09096908569336\n","Epoch 86, batch 220/240:\tDiscriminator: real loss 0.16142593324184418, fake loss 0.19636745750904083\tGenerator: loss 10.621726036071777\n","Epoch 86, batch 221/240:\tDiscriminator: real loss 0.170380637049675, fake loss 0.14101380109786987\tGenerator: loss 11.437108039855957\n","Epoch 86, batch 222/240:\tDiscriminator: real loss 0.10013669729232788, fake loss 0.17893432080745697\tGenerator: loss 13.13735580444336\n","Epoch 86, batch 223/240:\tDiscriminator: real loss 0.14274926483631134, fake loss 0.15049153566360474\tGenerator: loss 12.657975196838379\n","Epoch 86, batch 224/240:\tDiscriminator: real loss 0.0634320005774498, fake loss 0.08442926406860352\tGenerator: loss 14.871423721313477\n","Epoch 86, batch 225/240:\tDiscriminator: real loss 0.19392386078834534, fake loss 0.1494242548942566\tGenerator: loss 11.976426124572754\n","Epoch 86, batch 226/240:\tDiscriminator: real loss 0.05419911444187164, fake loss 0.19442978501319885\tGenerator: loss 10.729820251464844\n","Epoch 86, batch 227/240:\tDiscriminator: real loss 0.048648204654455185, fake loss 0.09746930003166199\tGenerator: loss 12.326162338256836\n","Epoch 86, batch 228/240:\tDiscriminator: real loss 0.1339975744485855, fake loss 0.2135501652956009\tGenerator: loss 11.96285629272461\n","Epoch 86, batch 229/240:\tDiscriminator: real loss 0.0939784124493599, fake loss 0.21307523548603058\tGenerator: loss 13.328418731689453\n","Epoch 86, batch 230/240:\tDiscriminator: real loss 0.15355245769023895, fake loss 0.08110544830560684\tGenerator: loss 10.624180793762207\n","Epoch 86, batch 231/240:\tDiscriminator: real loss 0.15612883865833282, fake loss 0.025304803624749184\tGenerator: loss 9.491016387939453\n","Epoch 86, batch 232/240:\tDiscriminator: real loss 0.07113627344369888, fake loss 0.31715866923332214\tGenerator: loss 8.947699546813965\n","Epoch 86, batch 233/240:\tDiscriminator: real loss 0.12908416986465454, fake loss 0.27066004276275635\tGenerator: loss 12.154375076293945\n","Epoch 86, batch 234/240:\tDiscriminator: real loss 0.10200401395559311, fake loss 0.15666884183883667\tGenerator: loss 13.1198091506958\n","Epoch 86, batch 235/240:\tDiscriminator: real loss 0.1628720462322235, fake loss 0.08093848824501038\tGenerator: loss 14.011290550231934\n","Epoch 86, batch 236/240:\tDiscriminator: real loss 0.14671528339385986, fake loss 0.24555648863315582\tGenerator: loss 12.5590181350708\n","Epoch 86, batch 237/240:\tDiscriminator: real loss 0.06954281777143478, fake loss 0.1207953542470932\tGenerator: loss 13.731164932250977\n","Epoch 86, batch 238/240:\tDiscriminator: real loss 0.080468088388443, fake loss 0.12504041194915771\tGenerator: loss 13.952435493469238\n","Epoch 86, batch 239/240:\tDiscriminator: real loss 0.16036231815814972, fake loss 0.1274215579032898\tGenerator: loss 12.149578094482422\n","Epoch 86, batch 240/240:\tDiscriminator: real loss 0.1386634111404419, fake loss 0.17836470901966095\tGenerator: loss 13.113432884216309\n","Epoch 87, batch 1/240:\tDiscriminator: real loss 0.06513384729623795, fake loss 0.06342827528715134\tGenerator: loss 13.27651596069336\n","Epoch 87, batch 2/240:\tDiscriminator: real loss 0.13890449702739716, fake loss 0.25171351432800293\tGenerator: loss 14.033727645874023\n","Epoch 87, batch 3/240:\tDiscriminator: real loss 0.07641925662755966, fake loss 0.11011873185634613\tGenerator: loss 14.649478912353516\n","Epoch 87, batch 4/240:\tDiscriminator: real loss 0.16849669814109802, fake loss 0.11118045449256897\tGenerator: loss 13.084877967834473\n","Epoch 87, batch 5/240:\tDiscriminator: real loss 0.15536950528621674, fake loss 0.24644729495048523\tGenerator: loss 13.036443710327148\n","Epoch 87, batch 6/240:\tDiscriminator: real loss 0.16050690412521362, fake loss 0.03522086888551712\tGenerator: loss 13.586045265197754\n","Epoch 87, batch 7/240:\tDiscriminator: real loss 0.06238695979118347, fake loss 0.29373249411582947\tGenerator: loss 14.899639129638672\n","Epoch 87, batch 8/240:\tDiscriminator: real loss 0.0916534885764122, fake loss 0.04747279733419418\tGenerator: loss 15.3505277633667\n","Epoch 87, batch 9/240:\tDiscriminator: real loss 0.15462681651115417, fake loss 0.14613480865955353\tGenerator: loss 12.934837341308594\n","Epoch 87, batch 10/240:\tDiscriminator: real loss 0.07357887923717499, fake loss 0.20005176961421967\tGenerator: loss 12.74694538116455\n","Epoch 87, batch 11/240:\tDiscriminator: real loss 0.12047149986028671, fake loss 0.09938400983810425\tGenerator: loss 10.783855438232422\n","Epoch 87, batch 12/240:\tDiscriminator: real loss 0.20317775011062622, fake loss 0.13175299763679504\tGenerator: loss 10.352034568786621\n","Epoch 87, batch 13/240:\tDiscriminator: real loss 0.09286714345216751, fake loss 0.1723150759935379\tGenerator: loss 10.639656066894531\n","Epoch 87, batch 14/240:\tDiscriminator: real loss 0.07425781339406967, fake loss 0.1345888376235962\tGenerator: loss 11.373091697692871\n","Epoch 87, batch 15/240:\tDiscriminator: real loss 0.09121837466955185, fake loss 0.18164360523223877\tGenerator: loss 11.836999893188477\n","Epoch 87, batch 16/240:\tDiscriminator: real loss 0.17663852870464325, fake loss 0.27121588587760925\tGenerator: loss 13.492332458496094\n","Epoch 87, batch 17/240:\tDiscriminator: real loss 0.16158412396907806, fake loss 0.05401553213596344\tGenerator: loss 12.84060287475586\n","Epoch 87, batch 18/240:\tDiscriminator: real loss 0.058425359427928925, fake loss 0.19162577390670776\tGenerator: loss 12.322010040283203\n","Epoch 87, batch 19/240:\tDiscriminator: real loss 0.1443842053413391, fake loss 0.12143850326538086\tGenerator: loss 13.463118553161621\n","Epoch 87, batch 20/240:\tDiscriminator: real loss 0.08320324867963791, fake loss 0.20598968863487244\tGenerator: loss 15.274824142456055\n","Epoch 87, batch 21/240:\tDiscriminator: real loss 0.16479969024658203, fake loss 0.2587973475456238\tGenerator: loss 14.179089546203613\n","Epoch 87, batch 22/240:\tDiscriminator: real loss 0.09046725183725357, fake loss 0.14094550907611847\tGenerator: loss 12.140750885009766\n","Epoch 87, batch 23/240:\tDiscriminator: real loss 0.18702831864356995, fake loss 0.05647195875644684\tGenerator: loss 13.216329574584961\n","Epoch 87, batch 24/240:\tDiscriminator: real loss 0.10330379754304886, fake loss 0.1499100923538208\tGenerator: loss 12.391467094421387\n","Epoch 87, batch 25/240:\tDiscriminator: real loss 0.07934851944446564, fake loss 0.17084339261054993\tGenerator: loss 12.79637336730957\n","Epoch 87, batch 26/240:\tDiscriminator: real loss 0.096315898001194, fake loss 0.16092723608016968\tGenerator: loss 13.348255157470703\n","Epoch 87, batch 27/240:\tDiscriminator: real loss 0.06620976328849792, fake loss 0.05126295983791351\tGenerator: loss 13.85387897491455\n","Epoch 87, batch 28/240:\tDiscriminator: real loss 0.14421938359737396, fake loss 0.10225275158882141\tGenerator: loss 12.034172058105469\n","Epoch 87, batch 29/240:\tDiscriminator: real loss 0.1337706595659256, fake loss 0.13520991802215576\tGenerator: loss 12.856197357177734\n","Epoch 87, batch 30/240:\tDiscriminator: real loss 0.1065564751625061, fake loss 0.10646350681781769\tGenerator: loss 10.819896697998047\n","Epoch 87, batch 31/240:\tDiscriminator: real loss 0.05257631465792656, fake loss 0.15470226109027863\tGenerator: loss 10.453102111816406\n","Epoch 87, batch 32/240:\tDiscriminator: real loss 0.07928133010864258, fake loss 0.14908096194267273\tGenerator: loss 13.206439018249512\n","Epoch 87, batch 33/240:\tDiscriminator: real loss 0.14355634152889252, fake loss 0.2389325499534607\tGenerator: loss 11.259142875671387\n","Epoch 87, batch 34/240:\tDiscriminator: real loss 0.16841819882392883, fake loss 0.17252974212169647\tGenerator: loss 11.026383399963379\n","Epoch 87, batch 35/240:\tDiscriminator: real loss 0.08042435348033905, fake loss 0.0934167131781578\tGenerator: loss 11.409834861755371\n","Epoch 87, batch 36/240:\tDiscriminator: real loss 0.14117923378944397, fake loss 0.19501039385795593\tGenerator: loss 13.195995330810547\n","Epoch 87, batch 37/240:\tDiscriminator: real loss 0.12826265394687653, fake loss 0.09192924201488495\tGenerator: loss 13.103793144226074\n","Epoch 87, batch 38/240:\tDiscriminator: real loss 0.08767808973789215, fake loss 0.19362498819828033\tGenerator: loss 11.726614952087402\n","Epoch 87, batch 39/240:\tDiscriminator: real loss 0.05243026837706566, fake loss 0.1306345909833908\tGenerator: loss 10.507573127746582\n","Epoch 87, batch 40/240:\tDiscriminator: real loss 0.10252789407968521, fake loss 0.10392998903989792\tGenerator: loss 10.544211387634277\n","Epoch 87, batch 41/240:\tDiscriminator: real loss 0.14102855324745178, fake loss 0.19130271673202515\tGenerator: loss 12.72391128540039\n","Epoch 87, batch 42/240:\tDiscriminator: real loss 0.10116109997034073, fake loss 0.23201513290405273\tGenerator: loss 15.920541763305664\n","Epoch 87, batch 43/240:\tDiscriminator: real loss 0.11876573413610458, fake loss 0.06711078435182571\tGenerator: loss 15.34493637084961\n","Epoch 87, batch 44/240:\tDiscriminator: real loss 0.12107803672552109, fake loss 0.15473897755146027\tGenerator: loss 11.24180793762207\n","Epoch 87, batch 45/240:\tDiscriminator: real loss 0.054842252284288406, fake loss 0.19349956512451172\tGenerator: loss 11.659558296203613\n","Epoch 87, batch 46/240:\tDiscriminator: real loss 0.19385480880737305, fake loss 0.24664045870304108\tGenerator: loss 10.77135944366455\n","Epoch 87, batch 47/240:\tDiscriminator: real loss 0.11191053688526154, fake loss 0.18008063733577728\tGenerator: loss 10.734151840209961\n","Epoch 87, batch 48/240:\tDiscriminator: real loss 0.11079532653093338, fake loss 0.04686147719621658\tGenerator: loss 11.800106048583984\n","Epoch 87, batch 49/240:\tDiscriminator: real loss 0.08948614448308945, fake loss 0.17303887009620667\tGenerator: loss 11.183122634887695\n","Epoch 87, batch 50/240:\tDiscriminator: real loss 0.09445396065711975, fake loss 0.15432226657867432\tGenerator: loss 12.374669075012207\n","Epoch 87, batch 51/240:\tDiscriminator: real loss 0.15306569635868073, fake loss 0.17369624972343445\tGenerator: loss 12.213043212890625\n","Epoch 87, batch 52/240:\tDiscriminator: real loss 0.10641015321016312, fake loss 0.11764591932296753\tGenerator: loss 14.308627128601074\n","Epoch 87, batch 53/240:\tDiscriminator: real loss 0.08667445182800293, fake loss 0.17543406784534454\tGenerator: loss 13.712449073791504\n","Epoch 87, batch 54/240:\tDiscriminator: real loss 0.14051316678524017, fake loss 0.17160141468048096\tGenerator: loss 12.20828628540039\n","Epoch 87, batch 55/240:\tDiscriminator: real loss 0.09329117089509964, fake loss 0.1304442584514618\tGenerator: loss 10.098745346069336\n","Epoch 87, batch 56/240:\tDiscriminator: real loss 0.11481647193431854, fake loss 0.16179583966732025\tGenerator: loss 9.17768669128418\n","Epoch 87, batch 57/240:\tDiscriminator: real loss 0.12980854511260986, fake loss 0.05460856482386589\tGenerator: loss 9.593502044677734\n","Epoch 87, batch 58/240:\tDiscriminator: real loss 0.05014472454786301, fake loss 0.15530206263065338\tGenerator: loss 10.467135429382324\n","Epoch 87, batch 59/240:\tDiscriminator: real loss 0.08078799396753311, fake loss 0.12466451525688171\tGenerator: loss 12.003042221069336\n","Epoch 87, batch 60/240:\tDiscriminator: real loss 0.11850786209106445, fake loss 0.1582976132631302\tGenerator: loss 11.424102783203125\n","Epoch 87, batch 61/240:\tDiscriminator: real loss 0.1448354572057724, fake loss 0.15765854716300964\tGenerator: loss 11.63555908203125\n","Epoch 87, batch 62/240:\tDiscriminator: real loss 0.13694551587104797, fake loss 0.18297043442726135\tGenerator: loss 13.478143692016602\n","Epoch 87, batch 63/240:\tDiscriminator: real loss 0.06368604302406311, fake loss 0.14779916405677795\tGenerator: loss 14.715058326721191\n","Epoch 87, batch 64/240:\tDiscriminator: real loss 0.09991738945245743, fake loss 0.11716420203447342\tGenerator: loss 13.891646385192871\n","Epoch 87, batch 65/240:\tDiscriminator: real loss 0.16043519973754883, fake loss 0.23520340025424957\tGenerator: loss 14.03722858428955\n","Epoch 87, batch 66/240:\tDiscriminator: real loss 0.11891279369592667, fake loss 0.1514669507741928\tGenerator: loss 14.829319953918457\n","Epoch 87, batch 67/240:\tDiscriminator: real loss 0.12345729768276215, fake loss 0.06694655865430832\tGenerator: loss 14.796757698059082\n","Epoch 87, batch 68/240:\tDiscriminator: real loss 0.0777888149023056, fake loss 0.18831142783164978\tGenerator: loss 14.21203327178955\n","Epoch 87, batch 69/240:\tDiscriminator: real loss 0.06285316497087479, fake loss 0.10234709084033966\tGenerator: loss 13.805864334106445\n","Epoch 87, batch 70/240:\tDiscriminator: real loss 0.07298494875431061, fake loss 0.14882171154022217\tGenerator: loss 13.95922565460205\n","Epoch 87, batch 71/240:\tDiscriminator: real loss 0.08074786514043808, fake loss 0.22722716629505157\tGenerator: loss 14.666245460510254\n","Epoch 87, batch 72/240:\tDiscriminator: real loss 0.23426128923892975, fake loss 0.1273762583732605\tGenerator: loss 11.794593811035156\n","Epoch 87, batch 73/240:\tDiscriminator: real loss 0.1285235732793808, fake loss 0.21077170968055725\tGenerator: loss 10.857839584350586\n","Epoch 87, batch 74/240:\tDiscriminator: real loss 0.10092688351869583, fake loss 0.14793714880943298\tGenerator: loss 12.229511260986328\n","Epoch 87, batch 75/240:\tDiscriminator: real loss 0.0966181829571724, fake loss 0.27729520201683044\tGenerator: loss 13.338201522827148\n","Epoch 87, batch 76/240:\tDiscriminator: real loss 0.2156396508216858, fake loss 0.22211109101772308\tGenerator: loss 12.505876541137695\n","Epoch 87, batch 77/240:\tDiscriminator: real loss 0.1598777174949646, fake loss 0.15732960402965546\tGenerator: loss 11.345541954040527\n","Epoch 87, batch 78/240:\tDiscriminator: real loss 0.22044840455055237, fake loss 0.0688004121184349\tGenerator: loss 10.559739112854004\n","Epoch 87, batch 79/240:\tDiscriminator: real loss 0.056127481162548065, fake loss 0.1414303183555603\tGenerator: loss 11.140506744384766\n","Epoch 87, batch 80/240:\tDiscriminator: real loss 0.03709018602967262, fake loss 0.26841625571250916\tGenerator: loss 10.795504570007324\n","Epoch 87, batch 81/240:\tDiscriminator: real loss 0.10925470292568207, fake loss 0.09895746409893036\tGenerator: loss 9.56017780303955\n","Epoch 87, batch 82/240:\tDiscriminator: real loss 0.12993375957012177, fake loss 0.09184084087610245\tGenerator: loss 9.544654846191406\n","Epoch 87, batch 83/240:\tDiscriminator: real loss 0.1369529664516449, fake loss 0.20298342406749725\tGenerator: loss 10.76495361328125\n","Epoch 87, batch 84/240:\tDiscriminator: real loss 0.044333186000585556, fake loss 0.10346513986587524\tGenerator: loss 10.932068824768066\n","Epoch 87, batch 85/240:\tDiscriminator: real loss 0.13687433302402496, fake loss 0.15916475653648376\tGenerator: loss 11.130134582519531\n","Epoch 87, batch 86/240:\tDiscriminator: real loss 0.06520857661962509, fake loss 0.19591809809207916\tGenerator: loss 12.715171813964844\n","Epoch 87, batch 87/240:\tDiscriminator: real loss 0.13542409241199493, fake loss 0.11707764863967896\tGenerator: loss 11.261635780334473\n","Epoch 87, batch 88/240:\tDiscriminator: real loss 0.16500043869018555, fake loss 0.23274169862270355\tGenerator: loss 8.823244094848633\n","Epoch 87, batch 89/240:\tDiscriminator: real loss 0.0997292548418045, fake loss 0.25622859597206116\tGenerator: loss 9.20219612121582\n","Epoch 87, batch 90/240:\tDiscriminator: real loss 0.0931476578116417, fake loss 0.19799990952014923\tGenerator: loss 11.672829627990723\n","Epoch 87, batch 91/240:\tDiscriminator: real loss 0.1125369444489479, fake loss 0.09827396273612976\tGenerator: loss 12.57803726196289\n","Epoch 87, batch 92/240:\tDiscriminator: real loss 0.16766424477100372, fake loss 0.14757724106311798\tGenerator: loss 11.41703987121582\n","Epoch 87, batch 93/240:\tDiscriminator: real loss 0.12051732838153839, fake loss 0.1902104914188385\tGenerator: loss 9.903850555419922\n","Epoch 87, batch 94/240:\tDiscriminator: real loss 0.11001859605312347, fake loss 0.08469243347644806\tGenerator: loss 8.910222053527832\n","Epoch 87, batch 95/240:\tDiscriminator: real loss 0.11342419683933258, fake loss 0.1525428146123886\tGenerator: loss 9.71643352508545\n","Epoch 87, batch 96/240:\tDiscriminator: real loss 0.09569341689348221, fake loss 0.2404676228761673\tGenerator: loss 11.16693115234375\n","Epoch 87, batch 97/240:\tDiscriminator: real loss 0.17668817937374115, fake loss 0.11455430835485458\tGenerator: loss 12.945930480957031\n","Epoch 87, batch 98/240:\tDiscriminator: real loss 0.08416542410850525, fake loss 0.1066528856754303\tGenerator: loss 12.162991523742676\n","Epoch 87, batch 99/240:\tDiscriminator: real loss 0.10759510099887848, fake loss 0.12381485104560852\tGenerator: loss 11.26879596710205\n","Epoch 87, batch 100/240:\tDiscriminator: real loss 0.05482333153486252, fake loss 0.24711528420448303\tGenerator: loss 11.727888107299805\n","Epoch 87, batch 101/240:\tDiscriminator: real loss 0.14818404614925385, fake loss 0.053954072296619415\tGenerator: loss 11.71160888671875\n","Epoch 87, batch 102/240:\tDiscriminator: real loss 0.12740740180015564, fake loss 0.16152667999267578\tGenerator: loss 11.307653427124023\n","Epoch 87, batch 103/240:\tDiscriminator: real loss 0.12555749714374542, fake loss 0.1612038016319275\tGenerator: loss 10.789512634277344\n","Epoch 87, batch 104/240:\tDiscriminator: real loss 0.0999937653541565, fake loss 0.1870659589767456\tGenerator: loss 10.52424430847168\n","Epoch 87, batch 105/240:\tDiscriminator: real loss 0.09404931962490082, fake loss 0.2582769989967346\tGenerator: loss 11.826728820800781\n","Epoch 87, batch 106/240:\tDiscriminator: real loss 0.21814437210559845, fake loss 0.12174174934625626\tGenerator: loss 11.037569999694824\n","Epoch 87, batch 107/240:\tDiscriminator: real loss 0.07981608808040619, fake loss 0.14092198014259338\tGenerator: loss 11.41235065460205\n","Epoch 87, batch 108/240:\tDiscriminator: real loss 0.11453336477279663, fake loss 0.18759089708328247\tGenerator: loss 10.724961280822754\n","Epoch 87, batch 109/240:\tDiscriminator: real loss 0.1587802916765213, fake loss 0.12055608630180359\tGenerator: loss 10.500205039978027\n","Epoch 87, batch 110/240:\tDiscriminator: real loss 0.1478443592786789, fake loss 0.10961870849132538\tGenerator: loss 9.143265724182129\n","Epoch 87, batch 111/240:\tDiscriminator: real loss 0.10991304367780685, fake loss 0.13872979581356049\tGenerator: loss 8.26730728149414\n","Epoch 87, batch 112/240:\tDiscriminator: real loss 0.12075719982385635, fake loss 0.1394832283258438\tGenerator: loss 8.878501892089844\n","Epoch 87, batch 113/240:\tDiscriminator: real loss 0.04407758638262749, fake loss 0.21867766976356506\tGenerator: loss 10.786951065063477\n","Epoch 87, batch 114/240:\tDiscriminator: real loss 0.08526778966188431, fake loss 0.1933666467666626\tGenerator: loss 11.002752304077148\n","Epoch 87, batch 115/240:\tDiscriminator: real loss 0.21971683204174042, fake loss 0.16717569530010223\tGenerator: loss 11.267963409423828\n","Epoch 87, batch 116/240:\tDiscriminator: real loss 0.07953868061304092, fake loss 0.22189873456954956\tGenerator: loss 10.847417831420898\n","Epoch 87, batch 117/240:\tDiscriminator: real loss 0.16485334932804108, fake loss 0.11771975457668304\tGenerator: loss 10.932953834533691\n","Epoch 87, batch 118/240:\tDiscriminator: real loss 0.10852063447237015, fake loss 0.15642604231834412\tGenerator: loss 10.089539527893066\n","Epoch 87, batch 119/240:\tDiscriminator: real loss 0.1146080419421196, fake loss 0.18463750183582306\tGenerator: loss 10.606781959533691\n","Epoch 87, batch 120/240:\tDiscriminator: real loss 0.17299999296665192, fake loss 0.12602709233760834\tGenerator: loss 10.740617752075195\n","Epoch 87, batch 121/240:\tDiscriminator: real loss 0.11131270229816437, fake loss 0.23467443883419037\tGenerator: loss 13.954751968383789\n","Epoch 87, batch 122/240:\tDiscriminator: real loss 0.1436251997947693, fake loss 0.11410795152187347\tGenerator: loss 12.613664627075195\n","Epoch 87, batch 123/240:\tDiscriminator: real loss 0.10133960843086243, fake loss 0.11504743248224258\tGenerator: loss 13.64510726928711\n","Epoch 87, batch 124/240:\tDiscriminator: real loss 0.1659013032913208, fake loss 0.119926817715168\tGenerator: loss 10.476612091064453\n","Epoch 87, batch 125/240:\tDiscriminator: real loss 0.050708819180727005, fake loss 0.25261932611465454\tGenerator: loss 11.191471099853516\n","Epoch 87, batch 126/240:\tDiscriminator: real loss 0.16749049723148346, fake loss 0.23435978591442108\tGenerator: loss 12.380271911621094\n","Epoch 87, batch 127/240:\tDiscriminator: real loss 0.13394346833229065, fake loss 0.117188461124897\tGenerator: loss 11.401066780090332\n","Epoch 87, batch 128/240:\tDiscriminator: real loss 0.12337072193622589, fake loss 0.20489837229251862\tGenerator: loss 12.174160957336426\n","Epoch 87, batch 129/240:\tDiscriminator: real loss 0.11302900314331055, fake loss 0.2227003425359726\tGenerator: loss 12.4735107421875\n","Epoch 87, batch 130/240:\tDiscriminator: real loss 0.1244441419839859, fake loss 0.05302058532834053\tGenerator: loss 12.028430938720703\n","Epoch 87, batch 131/240:\tDiscriminator: real loss 0.13695038855075836, fake loss 0.25975361466407776\tGenerator: loss 11.768729209899902\n","Epoch 87, batch 132/240:\tDiscriminator: real loss 0.11924763023853302, fake loss 0.16148735582828522\tGenerator: loss 11.601304054260254\n","Epoch 87, batch 133/240:\tDiscriminator: real loss 0.15858304500579834, fake loss 0.13232742249965668\tGenerator: loss 10.758893013000488\n","Epoch 87, batch 134/240:\tDiscriminator: real loss 0.076614148914814, fake loss 0.21407224237918854\tGenerator: loss 13.226740837097168\n","Epoch 87, batch 135/240:\tDiscriminator: real loss 0.11201272904872894, fake loss 0.12861944735050201\tGenerator: loss 12.106854438781738\n","Epoch 87, batch 136/240:\tDiscriminator: real loss 0.1538710594177246, fake loss 0.20610103011131287\tGenerator: loss 10.852221488952637\n","Epoch 87, batch 137/240:\tDiscriminator: real loss 0.15364426374435425, fake loss 0.17952926456928253\tGenerator: loss 12.005366325378418\n","Epoch 87, batch 138/240:\tDiscriminator: real loss 0.18559446930885315, fake loss 0.11296996474266052\tGenerator: loss 10.615662574768066\n","Epoch 87, batch 139/240:\tDiscriminator: real loss 0.08929528295993805, fake loss 0.10297734290361404\tGenerator: loss 11.527207374572754\n","Epoch 87, batch 140/240:\tDiscriminator: real loss 0.1055518314242363, fake loss 0.12188319861888885\tGenerator: loss 11.846810340881348\n","Epoch 87, batch 141/240:\tDiscriminator: real loss 0.06510312110185623, fake loss 0.15853852033615112\tGenerator: loss 11.999366760253906\n","Epoch 87, batch 142/240:\tDiscriminator: real loss 0.08636540174484253, fake loss 0.2709200978279114\tGenerator: loss 12.698068618774414\n","Epoch 87, batch 143/240:\tDiscriminator: real loss 0.14149685204029083, fake loss 0.13277453184127808\tGenerator: loss 11.346592903137207\n","Epoch 87, batch 144/240:\tDiscriminator: real loss 0.14823538064956665, fake loss 0.1274559646844864\tGenerator: loss 11.20393180847168\n","Epoch 87, batch 145/240:\tDiscriminator: real loss 0.23418502509593964, fake loss 0.1457190215587616\tGenerator: loss 11.065267562866211\n","Epoch 87, batch 146/240:\tDiscriminator: real loss 0.0880771055817604, fake loss 0.23201261460781097\tGenerator: loss 12.51644515991211\n","Epoch 87, batch 147/240:\tDiscriminator: real loss 0.08894731849431992, fake loss 0.14971110224723816\tGenerator: loss 13.05385971069336\n","Epoch 87, batch 148/240:\tDiscriminator: real loss 0.10161531716585159, fake loss 0.1184653788805008\tGenerator: loss 12.889334678649902\n","Epoch 87, batch 149/240:\tDiscriminator: real loss 0.10973106324672699, fake loss 0.13160693645477295\tGenerator: loss 11.510231971740723\n","Epoch 87, batch 150/240:\tDiscriminator: real loss 0.13374492526054382, fake loss 0.09428095817565918\tGenerator: loss 10.77981185913086\n","Epoch 87, batch 151/240:\tDiscriminator: real loss 0.0565430112183094, fake loss 0.10915552079677582\tGenerator: loss 12.1657075881958\n","Epoch 87, batch 152/240:\tDiscriminator: real loss 0.06608282774686813, fake loss 0.14789672195911407\tGenerator: loss 9.584314346313477\n","Epoch 87, batch 153/240:\tDiscriminator: real loss 0.08530835807323456, fake loss 0.2814617455005646\tGenerator: loss 9.019291877746582\n","Epoch 87, batch 154/240:\tDiscriminator: real loss 0.22129373252391815, fake loss 0.10398710519075394\tGenerator: loss 9.597701072692871\n","Epoch 87, batch 155/240:\tDiscriminator: real loss 0.1352122724056244, fake loss 0.14293351769447327\tGenerator: loss 9.733678817749023\n","Epoch 87, batch 156/240:\tDiscriminator: real loss 0.13484185934066772, fake loss 0.11097846925258636\tGenerator: loss 9.985368728637695\n","Epoch 87, batch 157/240:\tDiscriminator: real loss 0.09513629227876663, fake loss 0.08797114342451096\tGenerator: loss 8.764534950256348\n","Epoch 87, batch 158/240:\tDiscriminator: real loss 0.05756311118602753, fake loss 0.1576250195503235\tGenerator: loss 8.666707038879395\n","Epoch 87, batch 159/240:\tDiscriminator: real loss 0.06434641033411026, fake loss 0.17773431539535522\tGenerator: loss 11.106410026550293\n","Epoch 87, batch 160/240:\tDiscriminator: real loss 0.1359313726425171, fake loss 0.19275258481502533\tGenerator: loss 11.122674942016602\n","Epoch 87, batch 161/240:\tDiscriminator: real loss 0.08756839483976364, fake loss 0.08535661548376083\tGenerator: loss 11.097127914428711\n","Epoch 87, batch 162/240:\tDiscriminator: real loss 0.07807265967130661, fake loss 0.1992081254720688\tGenerator: loss 10.698490142822266\n","Epoch 87, batch 163/240:\tDiscriminator: real loss 0.16681091487407684, fake loss 0.14448267221450806\tGenerator: loss 8.474847793579102\n","Epoch 87, batch 164/240:\tDiscriminator: real loss 0.10308949649333954, fake loss 0.16560007631778717\tGenerator: loss 9.007769584655762\n","Epoch 87, batch 165/240:\tDiscriminator: real loss 0.07159020751714706, fake loss 0.1687338948249817\tGenerator: loss 9.752535820007324\n","Epoch 87, batch 166/240:\tDiscriminator: real loss 0.1369856894016266, fake loss 0.031412795186042786\tGenerator: loss 10.053772926330566\n","Epoch 87, batch 167/240:\tDiscriminator: real loss 0.10024654120206833, fake loss 0.09824854135513306\tGenerator: loss 9.965927124023438\n","Epoch 87, batch 168/240:\tDiscriminator: real loss 0.08947791904211044, fake loss 0.31670257449150085\tGenerator: loss 10.621768951416016\n","Epoch 87, batch 169/240:\tDiscriminator: real loss 0.10478522628545761, fake loss 0.20719493925571442\tGenerator: loss 9.163507461547852\n","Epoch 87, batch 170/240:\tDiscriminator: real loss 0.18194572627544403, fake loss 0.16886615753173828\tGenerator: loss 7.345651626586914\n","Epoch 87, batch 171/240:\tDiscriminator: real loss 0.1137683317065239, fake loss 0.11795296519994736\tGenerator: loss 7.511683940887451\n","Epoch 87, batch 172/240:\tDiscriminator: real loss 0.1227962076663971, fake loss 0.13360857963562012\tGenerator: loss 9.563824653625488\n","Epoch 87, batch 173/240:\tDiscriminator: real loss 0.1796165108680725, fake loss 0.14198654890060425\tGenerator: loss 11.977066993713379\n","Epoch 87, batch 174/240:\tDiscriminator: real loss 0.09112325310707092, fake loss 0.1411077082157135\tGenerator: loss 14.031841278076172\n","Epoch 87, batch 175/240:\tDiscriminator: real loss 0.1293296366930008, fake loss 0.027355652302503586\tGenerator: loss 12.194441795349121\n","Epoch 87, batch 176/240:\tDiscriminator: real loss 0.044647205621004105, fake loss 0.16252845525741577\tGenerator: loss 12.71582317352295\n","Epoch 87, batch 177/240:\tDiscriminator: real loss 0.07083461433649063, fake loss 0.04635680094361305\tGenerator: loss 12.444709777832031\n","Epoch 87, batch 178/240:\tDiscriminator: real loss 0.06796734780073166, fake loss 0.2509728670120239\tGenerator: loss 12.42595100402832\n","Epoch 87, batch 179/240:\tDiscriminator: real loss 0.05888297036290169, fake loss 0.15013162791728973\tGenerator: loss 11.560449600219727\n","Epoch 87, batch 180/240:\tDiscriminator: real loss 0.08813025802373886, fake loss 0.1398337036371231\tGenerator: loss 11.37454605102539\n","Epoch 87, batch 181/240:\tDiscriminator: real loss 0.12707605957984924, fake loss 0.05720724165439606\tGenerator: loss 8.788987159729004\n","Epoch 87, batch 182/240:\tDiscriminator: real loss 0.06544949114322662, fake loss 0.15398895740509033\tGenerator: loss 8.014810562133789\n","Epoch 87, batch 183/240:\tDiscriminator: real loss 0.14735302329063416, fake loss 0.18511369824409485\tGenerator: loss 9.761713027954102\n","Epoch 87, batch 184/240:\tDiscriminator: real loss 0.14609917998313904, fake loss 0.3403882086277008\tGenerator: loss 11.074929237365723\n","Epoch 87, batch 185/240:\tDiscriminator: real loss 0.243011474609375, fake loss 0.06575045734643936\tGenerator: loss 12.51138687133789\n","Epoch 87, batch 186/240:\tDiscriminator: real loss 0.08516651391983032, fake loss 0.0653814896941185\tGenerator: loss 13.108128547668457\n","Epoch 87, batch 187/240:\tDiscriminator: real loss 0.04109371080994606, fake loss 0.3400766849517822\tGenerator: loss 13.64642333984375\n","Epoch 87, batch 188/240:\tDiscriminator: real loss 0.10481909662485123, fake loss 0.354564905166626\tGenerator: loss 14.349457740783691\n","Epoch 87, batch 189/240:\tDiscriminator: real loss 0.21428842842578888, fake loss 0.034357450902462006\tGenerator: loss 12.060857772827148\n","Epoch 87, batch 190/240:\tDiscriminator: real loss 0.1699294149875641, fake loss 0.1875196397304535\tGenerator: loss 11.543980598449707\n","Epoch 87, batch 191/240:\tDiscriminator: real loss 0.06180741637945175, fake loss 0.17980216443538666\tGenerator: loss 13.58226203918457\n","Epoch 87, batch 192/240:\tDiscriminator: real loss 0.10340837389230728, fake loss 0.14070643484592438\tGenerator: loss 14.168356895446777\n","Epoch 87, batch 193/240:\tDiscriminator: real loss 0.17117588222026825, fake loss 0.054719313979148865\tGenerator: loss 13.52074909210205\n","Epoch 87, batch 194/240:\tDiscriminator: real loss 0.11373379826545715, fake loss 0.15074285864830017\tGenerator: loss 10.958313941955566\n","Epoch 87, batch 195/240:\tDiscriminator: real loss 0.07850348204374313, fake loss 0.2052842378616333\tGenerator: loss 9.378711700439453\n","Epoch 87, batch 196/240:\tDiscriminator: real loss 0.1370590627193451, fake loss 0.18688537180423737\tGenerator: loss 10.199762344360352\n","Epoch 87, batch 197/240:\tDiscriminator: real loss 0.09832621365785599, fake loss 0.09140828251838684\tGenerator: loss 10.678572654724121\n","Epoch 87, batch 198/240:\tDiscriminator: real loss 0.17762579023838043, fake loss 0.07754115760326385\tGenerator: loss 10.058209419250488\n","Epoch 87, batch 199/240:\tDiscriminator: real loss 0.07811129093170166, fake loss 0.219079852104187\tGenerator: loss 10.034353256225586\n","Epoch 87, batch 200/240:\tDiscriminator: real loss 0.14214551448822021, fake loss 0.2534693777561188\tGenerator: loss 10.819514274597168\n","Epoch 87, batch 201/240:\tDiscriminator: real loss 0.08642550557851791, fake loss 0.046317145228385925\tGenerator: loss 11.263263702392578\n","Epoch 87, batch 202/240:\tDiscriminator: real loss 0.14332464337348938, fake loss 0.20892465114593506\tGenerator: loss 11.100847244262695\n","Epoch 87, batch 203/240:\tDiscriminator: real loss 0.14145031571388245, fake loss 0.14188732206821442\tGenerator: loss 12.219099998474121\n","Epoch 87, batch 204/240:\tDiscriminator: real loss 0.1398739069700241, fake loss 0.20491714775562286\tGenerator: loss 12.291755676269531\n","Epoch 87, batch 205/240:\tDiscriminator: real loss 0.13196179270744324, fake loss 0.35164299607276917\tGenerator: loss 12.292060852050781\n","Epoch 87, batch 206/240:\tDiscriminator: real loss 0.09727848321199417, fake loss 0.16280637681484222\tGenerator: loss 13.888134002685547\n","Epoch 87, batch 207/240:\tDiscriminator: real loss 0.18317075073719025, fake loss 0.18889327347278595\tGenerator: loss 12.877701759338379\n","Epoch 87, batch 208/240:\tDiscriminator: real loss 0.16298753023147583, fake loss 0.15348732471466064\tGenerator: loss 12.663017272949219\n","Epoch 87, batch 209/240:\tDiscriminator: real loss 0.08426514267921448, fake loss 0.17286747694015503\tGenerator: loss 12.241979598999023\n","Epoch 87, batch 210/240:\tDiscriminator: real loss 0.17370140552520752, fake loss 0.05725313350558281\tGenerator: loss 11.102330207824707\n","Epoch 87, batch 211/240:\tDiscriminator: real loss 0.10457003861665726, fake loss 0.1970939040184021\tGenerator: loss 11.529166221618652\n","Epoch 87, batch 212/240:\tDiscriminator: real loss 0.08230390399694443, fake loss 0.07415865361690521\tGenerator: loss 11.49085807800293\n","Epoch 87, batch 213/240:\tDiscriminator: real loss 0.05493907630443573, fake loss 0.07002848386764526\tGenerator: loss 13.043046951293945\n","Epoch 87, batch 214/240:\tDiscriminator: real loss 0.07117272168397903, fake loss 0.16777290403842926\tGenerator: loss 15.009860038757324\n","Epoch 87, batch 215/240:\tDiscriminator: real loss 0.08576580882072449, fake loss 0.13974514603614807\tGenerator: loss 13.907278060913086\n","Epoch 87, batch 216/240:\tDiscriminator: real loss 0.14671257138252258, fake loss 0.12245132774114609\tGenerator: loss 12.920554161071777\n","Epoch 87, batch 217/240:\tDiscriminator: real loss 0.11672725528478622, fake loss 0.2056775689125061\tGenerator: loss 11.597938537597656\n","Epoch 87, batch 218/240:\tDiscriminator: real loss 0.1292715072631836, fake loss 0.20368614792823792\tGenerator: loss 10.945274353027344\n","Epoch 87, batch 219/240:\tDiscriminator: real loss 0.2814091742038727, fake loss 0.35114288330078125\tGenerator: loss 12.173563003540039\n","Epoch 87, batch 220/240:\tDiscriminator: real loss 0.14563524723052979, fake loss 0.26481086015701294\tGenerator: loss 13.27134895324707\n","Epoch 87, batch 221/240:\tDiscriminator: real loss 0.15736165642738342, fake loss 0.0799608826637268\tGenerator: loss 11.530035018920898\n","Epoch 87, batch 222/240:\tDiscriminator: real loss 0.13398315012454987, fake loss 0.20874173939228058\tGenerator: loss 11.874903678894043\n","Epoch 87, batch 223/240:\tDiscriminator: real loss 0.06528177112340927, fake loss 0.11036214977502823\tGenerator: loss 12.076120376586914\n","Epoch 87, batch 224/240:\tDiscriminator: real loss 0.19147752225399017, fake loss 0.16901493072509766\tGenerator: loss 15.155434608459473\n","Epoch 87, batch 225/240:\tDiscriminator: real loss 0.15162540972232819, fake loss 0.12346035242080688\tGenerator: loss 15.100286483764648\n","Epoch 87, batch 226/240:\tDiscriminator: real loss 0.08399493247270584, fake loss 0.16788768768310547\tGenerator: loss 13.273506164550781\n","Epoch 87, batch 227/240:\tDiscriminator: real loss 0.12338689714670181, fake loss 0.1837049424648285\tGenerator: loss 13.71130657196045\n","Epoch 87, batch 228/240:\tDiscriminator: real loss 0.10822346061468124, fake loss 0.15183474123477936\tGenerator: loss 12.914505958557129\n","Epoch 87, batch 229/240:\tDiscriminator: real loss 0.17626219987869263, fake loss 0.08519014716148376\tGenerator: loss 12.253589630126953\n","Epoch 87, batch 230/240:\tDiscriminator: real loss 0.05198410525918007, fake loss 0.11502943187952042\tGenerator: loss 11.120942115783691\n","Epoch 87, batch 231/240:\tDiscriminator: real loss 0.0952373668551445, fake loss 0.17672881484031677\tGenerator: loss 12.275891304016113\n","Epoch 87, batch 232/240:\tDiscriminator: real loss 0.08225195109844208, fake loss 0.0843968391418457\tGenerator: loss 11.337392807006836\n","Epoch 87, batch 233/240:\tDiscriminator: real loss 0.19094179570674896, fake loss 0.15869422256946564\tGenerator: loss 10.776025772094727\n","Epoch 87, batch 234/240:\tDiscriminator: real loss 0.052396755665540695, fake loss 0.12862591445446014\tGenerator: loss 10.971826553344727\n","Epoch 87, batch 235/240:\tDiscriminator: real loss 0.14530760049819946, fake loss 0.09658023715019226\tGenerator: loss 11.4480562210083\n","Epoch 87, batch 236/240:\tDiscriminator: real loss 0.06072559952735901, fake loss 0.19406700134277344\tGenerator: loss 8.794183731079102\n","Epoch 87, batch 237/240:\tDiscriminator: real loss 0.07653442025184631, fake loss 0.13757050037384033\tGenerator: loss 8.965113639831543\n","Epoch 87, batch 238/240:\tDiscriminator: real loss 0.08487752825021744, fake loss 0.11431611329317093\tGenerator: loss 9.272101402282715\n","Epoch 87, batch 239/240:\tDiscriminator: real loss 0.19577854871749878, fake loss 0.16919226944446564\tGenerator: loss 11.141105651855469\n","Epoch 87, batch 240/240:\tDiscriminator: real loss 0.05125458166003227, fake loss 0.12277568876743317\tGenerator: loss 13.394364356994629\n","Epoch 88, batch 1/240:\tDiscriminator: real loss 0.1454838365316391, fake loss 0.23247939348220825\tGenerator: loss 11.727203369140625\n","Epoch 88, batch 2/240:\tDiscriminator: real loss 0.08825740963220596, fake loss 0.1490452140569687\tGenerator: loss 11.031462669372559\n","Epoch 88, batch 3/240:\tDiscriminator: real loss 0.13187849521636963, fake loss 0.024016642943024635\tGenerator: loss 9.139043807983398\n","Epoch 88, batch 4/240:\tDiscriminator: real loss 0.07396779954433441, fake loss 0.10986234992742538\tGenerator: loss 8.060924530029297\n","Epoch 88, batch 5/240:\tDiscriminator: real loss 0.09939399361610413, fake loss 0.20698282122612\tGenerator: loss 9.669983863830566\n","Epoch 88, batch 6/240:\tDiscriminator: real loss 0.07562045007944107, fake loss 0.11512582749128342\tGenerator: loss 10.065038681030273\n","Epoch 88, batch 7/240:\tDiscriminator: real loss 0.0736105740070343, fake loss 0.19065852463245392\tGenerator: loss 11.971290588378906\n","Epoch 88, batch 8/240:\tDiscriminator: real loss 0.08513610810041428, fake loss 0.07145756483078003\tGenerator: loss 11.781050682067871\n","Epoch 88, batch 9/240:\tDiscriminator: real loss 0.19202114641666412, fake loss 0.22620075941085815\tGenerator: loss 10.041923522949219\n","Epoch 88, batch 10/240:\tDiscriminator: real loss 0.05448068678379059, fake loss 0.1701100766658783\tGenerator: loss 9.885416030883789\n","Epoch 88, batch 11/240:\tDiscriminator: real loss 0.078431636095047, fake loss 0.20572704076766968\tGenerator: loss 11.785037994384766\n","Epoch 88, batch 12/240:\tDiscriminator: real loss 0.11368966847658157, fake loss 0.05389237403869629\tGenerator: loss 11.021773338317871\n","Epoch 88, batch 13/240:\tDiscriminator: real loss 0.18832214176654816, fake loss 0.08317695558071136\tGenerator: loss 9.975242614746094\n","Epoch 88, batch 14/240:\tDiscriminator: real loss 0.07989434897899628, fake loss 0.2125909924507141\tGenerator: loss 8.882357597351074\n","Epoch 88, batch 15/240:\tDiscriminator: real loss 0.046706389635801315, fake loss 0.22100910544395447\tGenerator: loss 9.934460639953613\n","Epoch 88, batch 16/240:\tDiscriminator: real loss 0.12884487211704254, fake loss 0.23964467644691467\tGenerator: loss 10.44771957397461\n","Epoch 88, batch 17/240:\tDiscriminator: real loss 0.1301315873861313, fake loss 0.06859838217496872\tGenerator: loss 10.72427749633789\n","Epoch 88, batch 18/240:\tDiscriminator: real loss 0.16960129141807556, fake loss 0.19442987442016602\tGenerator: loss 10.278162002563477\n","Epoch 88, batch 19/240:\tDiscriminator: real loss 0.16010922193527222, fake loss 0.15449906885623932\tGenerator: loss 12.641021728515625\n","Epoch 88, batch 20/240:\tDiscriminator: real loss 0.1281268149614334, fake loss 0.2732965052127838\tGenerator: loss 13.541852951049805\n","Epoch 88, batch 21/240:\tDiscriminator: real loss 0.12708234786987305, fake loss 0.12368669360876083\tGenerator: loss 14.330488204956055\n","Epoch 88, batch 22/240:\tDiscriminator: real loss 0.13753221929073334, fake loss 0.09807150065898895\tGenerator: loss 13.748321533203125\n","Epoch 88, batch 23/240:\tDiscriminator: real loss 0.17152446508407593, fake loss 0.2829817831516266\tGenerator: loss 12.451984405517578\n","Epoch 88, batch 24/240:\tDiscriminator: real loss 0.06601250916719437, fake loss 0.08108943700790405\tGenerator: loss 11.07600212097168\n","Epoch 88, batch 25/240:\tDiscriminator: real loss 0.0746103972196579, fake loss 0.16580037772655487\tGenerator: loss 10.922882080078125\n","Epoch 88, batch 26/240:\tDiscriminator: real loss 0.21015426516532898, fake loss 0.21459075808525085\tGenerator: loss 12.849055290222168\n","Epoch 88, batch 27/240:\tDiscriminator: real loss 0.08804168552160263, fake loss 0.09955576807260513\tGenerator: loss 12.13425064086914\n","Epoch 88, batch 28/240:\tDiscriminator: real loss 0.10299277305603027, fake loss 0.11909773200750351\tGenerator: loss 12.338951110839844\n","Epoch 88, batch 29/240:\tDiscriminator: real loss 0.10489082336425781, fake loss 0.1522931456565857\tGenerator: loss 11.627233505249023\n","Epoch 88, batch 30/240:\tDiscriminator: real loss 0.12486451119184494, fake loss 0.2329276204109192\tGenerator: loss 12.958666801452637\n","Epoch 88, batch 31/240:\tDiscriminator: real loss 0.06150253117084503, fake loss 0.1721612811088562\tGenerator: loss 12.285163879394531\n","Epoch 88, batch 32/240:\tDiscriminator: real loss 0.0809340700507164, fake loss 0.182583749294281\tGenerator: loss 12.222180366516113\n","Epoch 88, batch 33/240:\tDiscriminator: real loss 0.17501415312290192, fake loss 0.16899347305297852\tGenerator: loss 11.910120010375977\n","Epoch 88, batch 34/240:\tDiscriminator: real loss 0.1153477281332016, fake loss 0.12519703805446625\tGenerator: loss 11.601893424987793\n","Epoch 88, batch 35/240:\tDiscriminator: real loss 0.14914755523204803, fake loss 0.23817922174930573\tGenerator: loss 10.77708625793457\n","Epoch 88, batch 36/240:\tDiscriminator: real loss 0.11874363571405411, fake loss 0.41061440110206604\tGenerator: loss 11.516934394836426\n","Epoch 88, batch 37/240:\tDiscriminator: real loss 0.25521793961524963, fake loss 0.18172992765903473\tGenerator: loss 12.172685623168945\n","Epoch 88, batch 38/240:\tDiscriminator: real loss 0.1760958433151245, fake loss 0.10136184841394424\tGenerator: loss 10.567008018493652\n","Epoch 88, batch 39/240:\tDiscriminator: real loss 0.10508764535188675, fake loss 0.1310862898826599\tGenerator: loss 11.255666732788086\n","Epoch 88, batch 40/240:\tDiscriminator: real loss 0.0781392827630043, fake loss 0.10652583092451096\tGenerator: loss 12.853825569152832\n","Epoch 88, batch 41/240:\tDiscriminator: real loss 0.09191938489675522, fake loss 0.28651800751686096\tGenerator: loss 12.683843612670898\n","Epoch 88, batch 42/240:\tDiscriminator: real loss 0.10915765911340714, fake loss 0.24236033856868744\tGenerator: loss 12.420361518859863\n","Epoch 88, batch 43/240:\tDiscriminator: real loss 0.11729677021503448, fake loss 0.06946080923080444\tGenerator: loss 10.865861892700195\n","Epoch 88, batch 44/240:\tDiscriminator: real loss 0.15030422806739807, fake loss 0.12584680318832397\tGenerator: loss 10.926762580871582\n","Epoch 88, batch 45/240:\tDiscriminator: real loss 0.18901735544204712, fake loss 0.22076022624969482\tGenerator: loss 11.234858512878418\n","Epoch 88, batch 46/240:\tDiscriminator: real loss 0.0804738998413086, fake loss 0.18524764478206635\tGenerator: loss 12.93289566040039\n","Epoch 88, batch 47/240:\tDiscriminator: real loss 0.10794005542993546, fake loss 0.16125299036502838\tGenerator: loss 12.368461608886719\n","Epoch 88, batch 48/240:\tDiscriminator: real loss 0.13589835166931152, fake loss 0.17448821663856506\tGenerator: loss 8.954596519470215\n","Epoch 88, batch 49/240:\tDiscriminator: real loss 0.0715215653181076, fake loss 0.1333828866481781\tGenerator: loss 9.603992462158203\n","Epoch 88, batch 50/240:\tDiscriminator: real loss 0.10437113791704178, fake loss 0.1500278115272522\tGenerator: loss 10.810975074768066\n","Epoch 88, batch 51/240:\tDiscriminator: real loss 0.1968528777360916, fake loss 0.24496787786483765\tGenerator: loss 9.407739639282227\n","Epoch 88, batch 52/240:\tDiscriminator: real loss 0.13402418792247772, fake loss 0.14798814058303833\tGenerator: loss 8.444855690002441\n","Epoch 88, batch 53/240:\tDiscriminator: real loss 0.121024951338768, fake loss 0.24472501873970032\tGenerator: loss 10.660527229309082\n","Epoch 88, batch 54/240:\tDiscriminator: real loss 0.14355051517486572, fake loss 0.14059190452098846\tGenerator: loss 12.352463722229004\n","Epoch 88, batch 55/240:\tDiscriminator: real loss 0.12473044544458389, fake loss 0.15650096535682678\tGenerator: loss 12.118642807006836\n","Epoch 88, batch 56/240:\tDiscriminator: real loss 0.1109820082783699, fake loss 0.2784090042114258\tGenerator: loss 12.119863510131836\n","Epoch 88, batch 57/240:\tDiscriminator: real loss 0.20331649482250214, fake loss 0.12094776332378387\tGenerator: loss 10.9443998336792\n","Epoch 88, batch 58/240:\tDiscriminator: real loss 0.16049128770828247, fake loss 0.12824806571006775\tGenerator: loss 12.309038162231445\n","Epoch 88, batch 59/240:\tDiscriminator: real loss 0.05728478729724884, fake loss 0.0887853130698204\tGenerator: loss 11.718613624572754\n","Epoch 88, batch 60/240:\tDiscriminator: real loss 0.03715314716100693, fake loss 0.08213724195957184\tGenerator: loss 12.01636028289795\n","Epoch 88, batch 61/240:\tDiscriminator: real loss 0.07057573646306992, fake loss 0.2188756912946701\tGenerator: loss 14.479055404663086\n","Epoch 88, batch 62/240:\tDiscriminator: real loss 0.12662063539028168, fake loss 0.16968020796775818\tGenerator: loss 13.684754371643066\n","Epoch 88, batch 63/240:\tDiscriminator: real loss 0.10201532393693924, fake loss 0.16282451152801514\tGenerator: loss 14.527922630310059\n","Epoch 88, batch 64/240:\tDiscriminator: real loss 0.21065664291381836, fake loss 0.1144416406750679\tGenerator: loss 13.610107421875\n","Epoch 88, batch 65/240:\tDiscriminator: real loss 0.11478233337402344, fake loss 0.1355714350938797\tGenerator: loss 14.741828918457031\n","Epoch 88, batch 66/240:\tDiscriminator: real loss 0.11326194554567337, fake loss 0.05419384315609932\tGenerator: loss 12.39175033569336\n","Epoch 88, batch 67/240:\tDiscriminator: real loss 0.054126814007759094, fake loss 0.3959185481071472\tGenerator: loss 14.2670259475708\n","Epoch 88, batch 68/240:\tDiscriminator: real loss 0.1670408695936203, fake loss 0.26039302349090576\tGenerator: loss 14.688859939575195\n","Epoch 88, batch 69/240:\tDiscriminator: real loss 0.1292291283607483, fake loss 0.07709086686372757\tGenerator: loss 15.688567161560059\n","Epoch 88, batch 70/240:\tDiscriminator: real loss 0.10754355788230896, fake loss 0.129336878657341\tGenerator: loss 13.851959228515625\n","Epoch 88, batch 71/240:\tDiscriminator: real loss 0.1597076803445816, fake loss 0.18726517260074615\tGenerator: loss 13.880380630493164\n","Epoch 88, batch 72/240:\tDiscriminator: real loss 0.07921408861875534, fake loss 0.16892097890377045\tGenerator: loss 14.561180114746094\n","Epoch 88, batch 73/240:\tDiscriminator: real loss 0.1574123054742813, fake loss 0.1654144823551178\tGenerator: loss 13.722127914428711\n","Epoch 88, batch 74/240:\tDiscriminator: real loss 0.1461511254310608, fake loss 0.1124948188662529\tGenerator: loss 14.658300399780273\n","Epoch 88, batch 75/240:\tDiscriminator: real loss 0.06526228040456772, fake loss 0.31024453043937683\tGenerator: loss 14.151285171508789\n","Epoch 88, batch 76/240:\tDiscriminator: real loss 0.13060015439987183, fake loss 0.15523642301559448\tGenerator: loss 15.339634895324707\n","Epoch 88, batch 77/240:\tDiscriminator: real loss 0.18587416410446167, fake loss 0.11554209887981415\tGenerator: loss 11.313990592956543\n","Epoch 88, batch 78/240:\tDiscriminator: real loss 0.12726107239723206, fake loss 0.1667519211769104\tGenerator: loss 10.534693717956543\n","Epoch 88, batch 79/240:\tDiscriminator: real loss 0.13442544639110565, fake loss 0.3267330825328827\tGenerator: loss 11.951665878295898\n","Epoch 88, batch 80/240:\tDiscriminator: real loss 0.09528005868196487, fake loss 0.14280007779598236\tGenerator: loss 14.531950950622559\n","Epoch 88, batch 81/240:\tDiscriminator: real loss 0.16458913683891296, fake loss 0.21180972456932068\tGenerator: loss 13.66977310180664\n","Epoch 88, batch 82/240:\tDiscriminator: real loss 0.10218483209609985, fake loss 0.1371069699525833\tGenerator: loss 12.648611068725586\n","Epoch 88, batch 83/240:\tDiscriminator: real loss 0.12027489393949509, fake loss 0.2508799433708191\tGenerator: loss 12.1455717086792\n","Epoch 88, batch 84/240:\tDiscriminator: real loss 0.08977044373750687, fake loss 0.1372508853673935\tGenerator: loss 12.287086486816406\n","Epoch 88, batch 85/240:\tDiscriminator: real loss 0.1391248106956482, fake loss 0.1026717945933342\tGenerator: loss 12.837074279785156\n","Epoch 88, batch 86/240:\tDiscriminator: real loss 0.142771378159523, fake loss 0.14753179252147675\tGenerator: loss 11.832430839538574\n","Epoch 88, batch 87/240:\tDiscriminator: real loss 0.10012500733137131, fake loss 0.23020920157432556\tGenerator: loss 13.73239517211914\n","Epoch 88, batch 88/240:\tDiscriminator: real loss 0.10350623726844788, fake loss 0.10867884010076523\tGenerator: loss 12.544763565063477\n","Epoch 88, batch 89/240:\tDiscriminator: real loss 0.06706616282463074, fake loss 0.08272407203912735\tGenerator: loss 13.564820289611816\n","Epoch 88, batch 90/240:\tDiscriminator: real loss 0.09981223940849304, fake loss 0.1595073938369751\tGenerator: loss 14.501304626464844\n","Epoch 88, batch 91/240:\tDiscriminator: real loss 0.1504918932914734, fake loss 0.20662498474121094\tGenerator: loss 11.960302352905273\n","Epoch 88, batch 92/240:\tDiscriminator: real loss 0.09049376845359802, fake loss 0.08047010749578476\tGenerator: loss 11.1732759475708\n","Epoch 88, batch 93/240:\tDiscriminator: real loss 0.16379356384277344, fake loss 0.2431863397359848\tGenerator: loss 12.40434455871582\n","Epoch 88, batch 94/240:\tDiscriminator: real loss 0.1811865270137787, fake loss 0.06547491252422333\tGenerator: loss 11.815643310546875\n","Epoch 88, batch 95/240:\tDiscriminator: real loss 0.06629946827888489, fake loss 0.21067100763320923\tGenerator: loss 11.087284088134766\n","Epoch 88, batch 96/240:\tDiscriminator: real loss 0.07298444956541061, fake loss 0.2942061424255371\tGenerator: loss 12.766061782836914\n","Epoch 88, batch 97/240:\tDiscriminator: real loss 0.09844919294118881, fake loss 0.04245088994503021\tGenerator: loss 13.045998573303223\n","Epoch 88, batch 98/240:\tDiscriminator: real loss 0.0996181070804596, fake loss 0.15285034477710724\tGenerator: loss 13.42636489868164\n","Epoch 88, batch 99/240:\tDiscriminator: real loss 0.18593360483646393, fake loss 0.1230861246585846\tGenerator: loss 11.216922760009766\n","Epoch 88, batch 100/240:\tDiscriminator: real loss 0.13455775380134583, fake loss 0.15654347836971283\tGenerator: loss 9.88015365600586\n","Epoch 88, batch 101/240:\tDiscriminator: real loss 0.12133315205574036, fake loss 0.14818282425403595\tGenerator: loss 8.394972801208496\n","Epoch 88, batch 102/240:\tDiscriminator: real loss 0.10279805213212967, fake loss 0.36346790194511414\tGenerator: loss 9.138568878173828\n","Epoch 88, batch 103/240:\tDiscriminator: real loss 0.19625093042850494, fake loss 0.11480710655450821\tGenerator: loss 11.452698707580566\n","Epoch 88, batch 104/240:\tDiscriminator: real loss 0.1899397075176239, fake loss 0.16267594695091248\tGenerator: loss 10.302759170532227\n","Epoch 88, batch 105/240:\tDiscriminator: real loss 0.0594710074365139, fake loss 0.2959092855453491\tGenerator: loss 11.65380573272705\n","Epoch 88, batch 106/240:\tDiscriminator: real loss 0.16692066192626953, fake loss 0.15211765468120575\tGenerator: loss 11.141593933105469\n","Epoch 88, batch 107/240:\tDiscriminator: real loss 0.11994640529155731, fake loss 0.12572357058525085\tGenerator: loss 11.293622016906738\n","Epoch 88, batch 108/240:\tDiscriminator: real loss 0.11256258934736252, fake loss 0.2562064230442047\tGenerator: loss 9.944005966186523\n","Epoch 88, batch 109/240:\tDiscriminator: real loss 0.1570126712322235, fake loss 0.3287007212638855\tGenerator: loss 8.981575965881348\n","Epoch 88, batch 110/240:\tDiscriminator: real loss 0.16083763539791107, fake loss 0.1993688941001892\tGenerator: loss 10.274340629577637\n","Epoch 88, batch 111/240:\tDiscriminator: real loss 0.14426864683628082, fake loss 0.16408437490463257\tGenerator: loss 9.591793060302734\n","Epoch 88, batch 112/240:\tDiscriminator: real loss 0.10856649279594421, fake loss 0.10840297490358353\tGenerator: loss 10.562215805053711\n","Epoch 88, batch 113/240:\tDiscriminator: real loss 0.08962827920913696, fake loss 0.14812281727790833\tGenerator: loss 11.803053855895996\n","Epoch 88, batch 114/240:\tDiscriminator: real loss 0.12699578702449799, fake loss 0.14552940428256989\tGenerator: loss 10.830948829650879\n","Epoch 88, batch 115/240:\tDiscriminator: real loss 0.13758155703544617, fake loss 0.16470658779144287\tGenerator: loss 10.342347145080566\n","Epoch 88, batch 116/240:\tDiscriminator: real loss 0.10027366876602173, fake loss 0.18484215438365936\tGenerator: loss 12.282480239868164\n","Epoch 88, batch 117/240:\tDiscriminator: real loss 0.10648513585329056, fake loss 0.112403504550457\tGenerator: loss 11.132646560668945\n","Epoch 88, batch 118/240:\tDiscriminator: real loss 0.1588205248117447, fake loss 0.195887953042984\tGenerator: loss 10.823707580566406\n","Epoch 88, batch 119/240:\tDiscriminator: real loss 0.08862689882516861, fake loss 0.21020030975341797\tGenerator: loss 10.368167877197266\n","Epoch 88, batch 120/240:\tDiscriminator: real loss 0.09013697504997253, fake loss 0.1589074730873108\tGenerator: loss 9.282713890075684\n","Epoch 88, batch 121/240:\tDiscriminator: real loss 0.15863636136054993, fake loss 0.15752865374088287\tGenerator: loss 10.562543869018555\n","Epoch 88, batch 122/240:\tDiscriminator: real loss 0.11771276593208313, fake loss 0.1128295361995697\tGenerator: loss 10.017629623413086\n","Epoch 88, batch 123/240:\tDiscriminator: real loss 0.09810283035039902, fake loss 0.1264425814151764\tGenerator: loss 8.985394477844238\n","Epoch 88, batch 124/240:\tDiscriminator: real loss 0.13158714771270752, fake loss 0.14193983376026154\tGenerator: loss 9.09242057800293\n","Epoch 88, batch 125/240:\tDiscriminator: real loss 0.10028474032878876, fake loss 0.11471016705036163\tGenerator: loss 10.971014022827148\n","Epoch 88, batch 126/240:\tDiscriminator: real loss 0.11285435408353806, fake loss 0.07984531670808792\tGenerator: loss 10.431421279907227\n","Epoch 88, batch 127/240:\tDiscriminator: real loss 0.11428432166576385, fake loss 0.24562068283557892\tGenerator: loss 8.9775390625\n","Epoch 88, batch 128/240:\tDiscriminator: real loss 0.060446225106716156, fake loss 0.09560749679803848\tGenerator: loss 9.245441436767578\n","Epoch 88, batch 129/240:\tDiscriminator: real loss 0.06764497607946396, fake loss 0.11666959524154663\tGenerator: loss 9.931821823120117\n","Epoch 88, batch 130/240:\tDiscriminator: real loss 0.14684811234474182, fake loss 0.20656707882881165\tGenerator: loss 8.674370765686035\n","Epoch 88, batch 131/240:\tDiscriminator: real loss 0.0831649973988533, fake loss 0.11067996174097061\tGenerator: loss 9.076703071594238\n","Epoch 88, batch 132/240:\tDiscriminator: real loss 0.13047534227371216, fake loss 0.1870034635066986\tGenerator: loss 9.840402603149414\n","Epoch 88, batch 133/240:\tDiscriminator: real loss 0.12669788300991058, fake loss 0.1939554065465927\tGenerator: loss 9.916655540466309\n","Epoch 88, batch 134/240:\tDiscriminator: real loss 0.14187684655189514, fake loss 0.10685481876134872\tGenerator: loss 10.344372749328613\n","Epoch 88, batch 135/240:\tDiscriminator: real loss 0.11268008500337601, fake loss 0.2813035845756531\tGenerator: loss 9.363669395446777\n","Epoch 88, batch 136/240:\tDiscriminator: real loss 0.07374350726604462, fake loss 0.1358463168144226\tGenerator: loss 8.829480171203613\n","Epoch 88, batch 137/240:\tDiscriminator: real loss 0.1318681389093399, fake loss 0.0394350029528141\tGenerator: loss 8.826227188110352\n","Epoch 88, batch 138/240:\tDiscriminator: real loss 0.04407094046473503, fake loss 0.2474617063999176\tGenerator: loss 9.614574432373047\n","Epoch 88, batch 139/240:\tDiscriminator: real loss 0.24136672914028168, fake loss 0.15295232832431793\tGenerator: loss 8.256516456604004\n","Epoch 88, batch 140/240:\tDiscriminator: real loss 0.09561805427074432, fake loss 0.1880606859922409\tGenerator: loss 9.65131664276123\n","Epoch 88, batch 141/240:\tDiscriminator: real loss 0.12307918816804886, fake loss 0.126538947224617\tGenerator: loss 10.983085632324219\n","Epoch 88, batch 142/240:\tDiscriminator: real loss 0.056024953722953796, fake loss 0.15003901720046997\tGenerator: loss 11.432544708251953\n","Epoch 88, batch 143/240:\tDiscriminator: real loss 0.09508348256349564, fake loss 0.08145669102668762\tGenerator: loss 10.599817276000977\n","Epoch 88, batch 144/240:\tDiscriminator: real loss 0.08199780434370041, fake loss 0.38807886838912964\tGenerator: loss 10.343894004821777\n","Epoch 88, batch 145/240:\tDiscriminator: real loss 0.2346450835466385, fake loss 0.13303138315677643\tGenerator: loss 10.474047660827637\n","Epoch 88, batch 146/240:\tDiscriminator: real loss 0.08116385340690613, fake loss 0.11975286155939102\tGenerator: loss 10.757038116455078\n","Epoch 88, batch 147/240:\tDiscriminator: real loss 0.158050999045372, fake loss 0.21965812146663666\tGenerator: loss 10.472320556640625\n","Epoch 88, batch 148/240:\tDiscriminator: real loss 0.07254808396100998, fake loss 0.057564422488212585\tGenerator: loss 11.599443435668945\n","Epoch 88, batch 149/240:\tDiscriminator: real loss 0.08159680664539337, fake loss 0.09070362895727158\tGenerator: loss 11.707344055175781\n","Epoch 88, batch 150/240:\tDiscriminator: real loss 0.10638024657964706, fake loss 0.14129877090454102\tGenerator: loss 12.083420753479004\n","Epoch 88, batch 151/240:\tDiscriminator: real loss 0.08981789648532867, fake loss 0.16563229262828827\tGenerator: loss 12.325817108154297\n","Epoch 88, batch 152/240:\tDiscriminator: real loss 0.04419742524623871, fake loss 0.10990043729543686\tGenerator: loss 11.751293182373047\n","Epoch 88, batch 153/240:\tDiscriminator: real loss 0.07983829826116562, fake loss 0.2696312367916107\tGenerator: loss 15.478205680847168\n","Epoch 88, batch 154/240:\tDiscriminator: real loss 0.10390279442071915, fake loss 0.12456531822681427\tGenerator: loss 15.221368789672852\n","Epoch 88, batch 155/240:\tDiscriminator: real loss 0.16873575747013092, fake loss 0.10990054905414581\tGenerator: loss 12.989374160766602\n","Epoch 88, batch 156/240:\tDiscriminator: real loss 0.11355271935462952, fake loss 0.13200567662715912\tGenerator: loss 13.810386657714844\n","Epoch 88, batch 157/240:\tDiscriminator: real loss 0.08373531699180603, fake loss 0.21129344403743744\tGenerator: loss 12.31201457977295\n","Epoch 88, batch 158/240:\tDiscriminator: real loss 0.14480191469192505, fake loss 0.1643301546573639\tGenerator: loss 11.74310302734375\n","Epoch 88, batch 159/240:\tDiscriminator: real loss 0.12332790344953537, fake loss 0.16644367575645447\tGenerator: loss 11.445379257202148\n","Epoch 88, batch 160/240:\tDiscriminator: real loss 0.16113299131393433, fake loss 0.24274159967899323\tGenerator: loss 11.316951751708984\n","Epoch 88, batch 161/240:\tDiscriminator: real loss 0.13769280910491943, fake loss 0.1190565973520279\tGenerator: loss 10.857580184936523\n","Epoch 88, batch 162/240:\tDiscriminator: real loss 0.046488579362630844, fake loss 0.12816567718982697\tGenerator: loss 12.608210563659668\n","Epoch 88, batch 163/240:\tDiscriminator: real loss 0.13091960549354553, fake loss 0.15685777366161346\tGenerator: loss 12.948469161987305\n","Epoch 88, batch 164/240:\tDiscriminator: real loss 0.08951377123594284, fake loss 0.07539413124322891\tGenerator: loss 11.385275840759277\n","Epoch 88, batch 165/240:\tDiscriminator: real loss 0.09486328065395355, fake loss 0.22860977053642273\tGenerator: loss 11.104031562805176\n","Epoch 88, batch 166/240:\tDiscriminator: real loss 0.08067724108695984, fake loss 0.10977006703615189\tGenerator: loss 11.902168273925781\n","Epoch 88, batch 167/240:\tDiscriminator: real loss 0.12988439202308655, fake loss 0.21975737810134888\tGenerator: loss 13.02452278137207\n","Epoch 88, batch 168/240:\tDiscriminator: real loss 0.12073774635791779, fake loss 0.11338081955909729\tGenerator: loss 14.054427146911621\n","Epoch 88, batch 169/240:\tDiscriminator: real loss 0.15212082862854004, fake loss 0.08729963004589081\tGenerator: loss 9.815071105957031\n","Epoch 88, batch 170/240:\tDiscriminator: real loss 0.049819301813840866, fake loss 0.1473338007926941\tGenerator: loss 9.88855266571045\n","Epoch 88, batch 171/240:\tDiscriminator: real loss 0.084691621363163, fake loss 0.2125476896762848\tGenerator: loss 10.960407257080078\n","Epoch 88, batch 172/240:\tDiscriminator: real loss 0.12699443101882935, fake loss 0.14510418474674225\tGenerator: loss 10.170817375183105\n","Epoch 88, batch 173/240:\tDiscriminator: real loss 0.11815071105957031, fake loss 0.3524446487426758\tGenerator: loss 11.772605895996094\n","Epoch 88, batch 174/240:\tDiscriminator: real loss 0.08723373711109161, fake loss 0.05641292408108711\tGenerator: loss 12.274392127990723\n","Epoch 88, batch 175/240:\tDiscriminator: real loss 0.13496506214141846, fake loss 0.16809192299842834\tGenerator: loss 12.505356788635254\n","Epoch 88, batch 176/240:\tDiscriminator: real loss 0.10326661169528961, fake loss 0.18907593190670013\tGenerator: loss 14.826791763305664\n","Epoch 88, batch 177/240:\tDiscriminator: real loss 0.1502673327922821, fake loss 0.33836039900779724\tGenerator: loss 12.446308135986328\n","Epoch 88, batch 178/240:\tDiscriminator: real loss 0.18958209455013275, fake loss 0.10721507668495178\tGenerator: loss 11.237685203552246\n","Epoch 88, batch 179/240:\tDiscriminator: real loss 0.12484611570835114, fake loss 0.12671251595020294\tGenerator: loss 11.580291748046875\n","Epoch 88, batch 180/240:\tDiscriminator: real loss 0.09760290384292603, fake loss 0.2666051983833313\tGenerator: loss 13.385302543640137\n","Epoch 88, batch 181/240:\tDiscriminator: real loss 0.0951317697763443, fake loss 0.11270593851804733\tGenerator: loss 13.920248985290527\n","Epoch 88, batch 182/240:\tDiscriminator: real loss 0.22393806278705597, fake loss 0.14110726118087769\tGenerator: loss 8.934165954589844\n","Epoch 88, batch 183/240:\tDiscriminator: real loss 0.10577771067619324, fake loss 0.13250073790550232\tGenerator: loss 8.919187545776367\n","Epoch 88, batch 184/240:\tDiscriminator: real loss 0.07373451441526413, fake loss 0.3013225495815277\tGenerator: loss 10.561524391174316\n","Epoch 88, batch 185/240:\tDiscriminator: real loss 0.06703419983386993, fake loss 0.16670159995555878\tGenerator: loss 11.789817810058594\n","Epoch 88, batch 186/240:\tDiscriminator: real loss 0.1505489945411682, fake loss 0.13336114585399628\tGenerator: loss 13.790477752685547\n","Epoch 88, batch 187/240:\tDiscriminator: real loss 0.14589941501617432, fake loss 0.16433681547641754\tGenerator: loss 13.264094352722168\n","Epoch 88, batch 188/240:\tDiscriminator: real loss 0.1800343543291092, fake loss 0.07306846976280212\tGenerator: loss 9.933533668518066\n","Epoch 88, batch 189/240:\tDiscriminator: real loss 0.09259538352489471, fake loss 0.19400645792484283\tGenerator: loss 12.728346824645996\n","Epoch 88, batch 190/240:\tDiscriminator: real loss 0.09473612159490585, fake loss 0.15424256026744843\tGenerator: loss 13.773508071899414\n","Epoch 88, batch 191/240:\tDiscriminator: real loss 0.05203661322593689, fake loss 0.13785381615161896\tGenerator: loss 15.731768608093262\n","Epoch 88, batch 192/240:\tDiscriminator: real loss 0.13777953386306763, fake loss 0.1178811639547348\tGenerator: loss 14.940155029296875\n","Epoch 88, batch 193/240:\tDiscriminator: real loss 0.20271648466587067, fake loss 0.22501549124717712\tGenerator: loss 12.61636734008789\n","Epoch 88, batch 194/240:\tDiscriminator: real loss 0.09299179911613464, fake loss 0.21416473388671875\tGenerator: loss 13.495246887207031\n","Epoch 88, batch 195/240:\tDiscriminator: real loss 0.09283655136823654, fake loss 0.17819508910179138\tGenerator: loss 12.652806282043457\n","Epoch 88, batch 196/240:\tDiscriminator: real loss 0.19416388869285583, fake loss 0.10862919688224792\tGenerator: loss 12.095484733581543\n","Epoch 88, batch 197/240:\tDiscriminator: real loss 0.09097660332918167, fake loss 0.22156845033168793\tGenerator: loss 10.814740180969238\n","Epoch 88, batch 198/240:\tDiscriminator: real loss 0.08102065324783325, fake loss 0.10496896505355835\tGenerator: loss 12.208889961242676\n","Epoch 88, batch 199/240:\tDiscriminator: real loss 0.2658623456954956, fake loss 0.18876150250434875\tGenerator: loss 12.653883934020996\n","Epoch 88, batch 200/240:\tDiscriminator: real loss 0.17343725264072418, fake loss 0.14406763017177582\tGenerator: loss 13.419149398803711\n","Epoch 88, batch 201/240:\tDiscriminator: real loss 0.08861446380615234, fake loss 0.2270776629447937\tGenerator: loss 14.105508804321289\n","Epoch 88, batch 202/240:\tDiscriminator: real loss 0.09454108029603958, fake loss 0.11903102695941925\tGenerator: loss 16.016834259033203\n","Epoch 88, batch 203/240:\tDiscriminator: real loss 0.18058300018310547, fake loss 0.22999785840511322\tGenerator: loss 14.876818656921387\n","Epoch 88, batch 204/240:\tDiscriminator: real loss 0.0965157225728035, fake loss 0.027584418654441833\tGenerator: loss 14.036163330078125\n","Epoch 88, batch 205/240:\tDiscriminator: real loss 0.09257612377405167, fake loss 0.25853490829467773\tGenerator: loss 13.986898422241211\n","Epoch 88, batch 206/240:\tDiscriminator: real loss 0.09257091581821442, fake loss 0.14509160816669464\tGenerator: loss 13.463369369506836\n","Epoch 88, batch 207/240:\tDiscriminator: real loss 0.15077108144760132, fake loss 0.20637620985507965\tGenerator: loss 14.619695663452148\n","Epoch 88, batch 208/240:\tDiscriminator: real loss 0.1345723420381546, fake loss 0.1648550182580948\tGenerator: loss 16.070720672607422\n","Epoch 88, batch 209/240:\tDiscriminator: real loss 0.14997096359729767, fake loss 0.17755237221717834\tGenerator: loss 13.327637672424316\n","Epoch 88, batch 210/240:\tDiscriminator: real loss 0.11364418268203735, fake loss 0.25294554233551025\tGenerator: loss 12.872466087341309\n","Epoch 88, batch 211/240:\tDiscriminator: real loss 0.09467973560094833, fake loss 0.16357269883155823\tGenerator: loss 13.206673622131348\n","Epoch 88, batch 212/240:\tDiscriminator: real loss 0.09036005288362503, fake loss 0.1284250020980835\tGenerator: loss 13.607809066772461\n","Epoch 88, batch 213/240:\tDiscriminator: real loss 0.1993226557970047, fake loss 0.09347397089004517\tGenerator: loss 12.765664100646973\n","Epoch 88, batch 214/240:\tDiscriminator: real loss 0.13234394788742065, fake loss 0.3020439147949219\tGenerator: loss 13.921634674072266\n","Epoch 88, batch 215/240:\tDiscriminator: real loss 0.1316622942686081, fake loss 0.17397013306617737\tGenerator: loss 11.479410171508789\n","Epoch 88, batch 216/240:\tDiscriminator: real loss 0.1409371942281723, fake loss 0.07805777341127396\tGenerator: loss 11.592620849609375\n","Epoch 88, batch 217/240:\tDiscriminator: real loss 0.2534623444080353, fake loss 0.2768069803714752\tGenerator: loss 10.8458890914917\n","Epoch 88, batch 218/240:\tDiscriminator: real loss 0.10982955992221832, fake loss 0.23298747837543488\tGenerator: loss 11.152270317077637\n","Epoch 88, batch 219/240:\tDiscriminator: real loss 0.14260821044445038, fake loss 0.22678960859775543\tGenerator: loss 11.402754783630371\n","Epoch 88, batch 220/240:\tDiscriminator: real loss 0.1696629673242569, fake loss 0.10146627575159073\tGenerator: loss 10.887145042419434\n","Epoch 88, batch 221/240:\tDiscriminator: real loss 0.1178017407655716, fake loss 0.1536865085363388\tGenerator: loss 11.020617485046387\n","Epoch 88, batch 222/240:\tDiscriminator: real loss 0.06509621441364288, fake loss 0.16852322220802307\tGenerator: loss 12.37746810913086\n","Epoch 88, batch 223/240:\tDiscriminator: real loss 0.11863214522600174, fake loss 0.09885790199041367\tGenerator: loss 12.268750190734863\n","Epoch 88, batch 224/240:\tDiscriminator: real loss 0.08151329308748245, fake loss 0.09489775449037552\tGenerator: loss 10.751045227050781\n","Epoch 88, batch 225/240:\tDiscriminator: real loss 0.08574159443378448, fake loss 0.24918346107006073\tGenerator: loss 10.804657936096191\n","Epoch 88, batch 226/240:\tDiscriminator: real loss 0.10610561072826385, fake loss 0.13227182626724243\tGenerator: loss 13.283111572265625\n","Epoch 88, batch 227/240:\tDiscriminator: real loss 0.2502480745315552, fake loss 0.23532043397426605\tGenerator: loss 11.617149353027344\n","Epoch 88, batch 228/240:\tDiscriminator: real loss 0.10323043912649155, fake loss 0.12471035122871399\tGenerator: loss 11.237042427062988\n","Epoch 88, batch 229/240:\tDiscriminator: real loss 0.18860618770122528, fake loss 0.1698257327079773\tGenerator: loss 12.347258567810059\n","Epoch 88, batch 230/240:\tDiscriminator: real loss 0.09444181621074677, fake loss 0.3001613914966583\tGenerator: loss 15.559958457946777\n","Epoch 88, batch 231/240:\tDiscriminator: real loss 0.09490812569856644, fake loss 0.11895768344402313\tGenerator: loss 13.906180381774902\n","Epoch 88, batch 232/240:\tDiscriminator: real loss 0.1743529736995697, fake loss 0.23586362600326538\tGenerator: loss 13.248543739318848\n","Epoch 88, batch 233/240:\tDiscriminator: real loss 0.10156846791505814, fake loss 0.06490815430879593\tGenerator: loss 12.39593505859375\n","Epoch 88, batch 234/240:\tDiscriminator: real loss 0.17042481899261475, fake loss 0.06078576669096947\tGenerator: loss 10.70425796508789\n","Epoch 88, batch 235/240:\tDiscriminator: real loss 0.055181678384542465, fake loss 0.15634730458259583\tGenerator: loss 10.539127349853516\n","Epoch 88, batch 236/240:\tDiscriminator: real loss 0.10143893957138062, fake loss 0.18120406568050385\tGenerator: loss 11.623449325561523\n","Epoch 88, batch 237/240:\tDiscriminator: real loss 0.03895208239555359, fake loss 0.15861819684505463\tGenerator: loss 11.240017890930176\n","Epoch 88, batch 238/240:\tDiscriminator: real loss 0.11136528104543686, fake loss 0.13862168788909912\tGenerator: loss 14.8034029006958\n","Epoch 88, batch 239/240:\tDiscriminator: real loss 0.167043536901474, fake loss 0.15700025856494904\tGenerator: loss 12.732037544250488\n","Epoch 88, batch 240/240:\tDiscriminator: real loss 0.14581485092639923, fake loss 0.13502898812294006\tGenerator: loss 13.553248405456543\n","Epoch 89, batch 1/240:\tDiscriminator: real loss 0.08742575347423553, fake loss 0.12467224150896072\tGenerator: loss 12.154522895812988\n","Epoch 89, batch 2/240:\tDiscriminator: real loss 0.11266589164733887, fake loss 0.11020998656749725\tGenerator: loss 11.734443664550781\n","Epoch 89, batch 3/240:\tDiscriminator: real loss 0.07741373777389526, fake loss 0.1698564738035202\tGenerator: loss 11.185115814208984\n","Epoch 89, batch 4/240:\tDiscriminator: real loss 0.08576218783855438, fake loss 0.20260176062583923\tGenerator: loss 13.123173713684082\n","Epoch 89, batch 5/240:\tDiscriminator: real loss 0.06920327246189117, fake loss 0.17366951704025269\tGenerator: loss 14.438096046447754\n","Epoch 89, batch 6/240:\tDiscriminator: real loss 0.24868372082710266, fake loss 0.1925903707742691\tGenerator: loss 10.383615493774414\n","Epoch 89, batch 7/240:\tDiscriminator: real loss 0.13599815964698792, fake loss 0.10166379064321518\tGenerator: loss 10.454411506652832\n","Epoch 89, batch 8/240:\tDiscriminator: real loss 0.09300684183835983, fake loss 0.23652055859565735\tGenerator: loss 11.430773735046387\n","Epoch 89, batch 9/240:\tDiscriminator: real loss 0.1505843698978424, fake loss 0.1788865476846695\tGenerator: loss 10.749035835266113\n","Epoch 89, batch 10/240:\tDiscriminator: real loss 0.08458603918552399, fake loss 0.1324135959148407\tGenerator: loss 11.294519424438477\n","Epoch 89, batch 11/240:\tDiscriminator: real loss 0.11848436295986176, fake loss 0.07744031399488449\tGenerator: loss 11.460527420043945\n","Epoch 89, batch 12/240:\tDiscriminator: real loss 0.13589520752429962, fake loss 0.17763710021972656\tGenerator: loss 12.475481986999512\n","Epoch 89, batch 13/240:\tDiscriminator: real loss 0.12595167756080627, fake loss 0.060748253017663956\tGenerator: loss 12.85378646850586\n","Epoch 89, batch 14/240:\tDiscriminator: real loss 0.10759598761796951, fake loss 0.21041280031204224\tGenerator: loss 10.697822570800781\n","Epoch 89, batch 15/240:\tDiscriminator: real loss 0.09254977107048035, fake loss 0.24391812086105347\tGenerator: loss 12.59986686706543\n","Epoch 89, batch 16/240:\tDiscriminator: real loss 0.09103261679410934, fake loss 0.13233043253421783\tGenerator: loss 15.09411334991455\n","Epoch 89, batch 17/240:\tDiscriminator: real loss 0.1440245360136032, fake loss 0.19891467690467834\tGenerator: loss 12.651069641113281\n","Epoch 89, batch 18/240:\tDiscriminator: real loss 0.07041266560554504, fake loss 0.05669204890727997\tGenerator: loss 11.275006294250488\n","Epoch 89, batch 19/240:\tDiscriminator: real loss 0.15286022424697876, fake loss 0.16818641126155853\tGenerator: loss 11.023645401000977\n","Epoch 89, batch 20/240:\tDiscriminator: real loss 0.056355878710746765, fake loss 0.2805252969264984\tGenerator: loss 12.062626838684082\n","Epoch 89, batch 21/240:\tDiscriminator: real loss 0.07771503180265427, fake loss 0.05879206582903862\tGenerator: loss 11.819474220275879\n","Epoch 89, batch 22/240:\tDiscriminator: real loss 0.10018184036016464, fake loss 0.21976032853126526\tGenerator: loss 11.8602933883667\n","Epoch 89, batch 23/240:\tDiscriminator: real loss 0.09371253103017807, fake loss 0.12568633258342743\tGenerator: loss 12.877041816711426\n","Epoch 89, batch 24/240:\tDiscriminator: real loss 0.08800306916236877, fake loss 0.0917958989739418\tGenerator: loss 14.324847221374512\n","Epoch 89, batch 25/240:\tDiscriminator: real loss 0.08824186027050018, fake loss 0.13144995272159576\tGenerator: loss 12.101862907409668\n","Epoch 89, batch 26/240:\tDiscriminator: real loss 0.10920374095439911, fake loss 0.22654467821121216\tGenerator: loss 10.71484375\n","Epoch 89, batch 27/240:\tDiscriminator: real loss 0.14862863719463348, fake loss 0.10533591359853745\tGenerator: loss 11.326578140258789\n","Epoch 89, batch 28/240:\tDiscriminator: real loss 0.11158571392297745, fake loss 0.10683046281337738\tGenerator: loss 10.71384048461914\n","Epoch 89, batch 29/240:\tDiscriminator: real loss 0.08441013097763062, fake loss 0.30857279896736145\tGenerator: loss 11.25662612915039\n","Epoch 89, batch 30/240:\tDiscriminator: real loss 0.1324908286333084, fake loss 0.03411945700645447\tGenerator: loss 10.765568733215332\n","Epoch 89, batch 31/240:\tDiscriminator: real loss 0.1307976096868515, fake loss 0.14141570031642914\tGenerator: loss 10.301409721374512\n","Epoch 89, batch 32/240:\tDiscriminator: real loss 0.10930804908275604, fake loss 0.183914452791214\tGenerator: loss 11.078250885009766\n","Epoch 89, batch 33/240:\tDiscriminator: real loss 0.13526904582977295, fake loss 0.1546560525894165\tGenerator: loss 10.403878211975098\n","Epoch 89, batch 34/240:\tDiscriminator: real loss 0.09254483878612518, fake loss 0.19674479961395264\tGenerator: loss 12.303630828857422\n","Epoch 89, batch 35/240:\tDiscriminator: real loss 0.21136043965816498, fake loss 0.05377763882279396\tGenerator: loss 10.044332504272461\n","Epoch 89, batch 36/240:\tDiscriminator: real loss 0.1342628449201584, fake loss 0.13615672290325165\tGenerator: loss 7.985137939453125\n","Epoch 89, batch 37/240:\tDiscriminator: real loss 0.09593271464109421, fake loss 0.19047756493091583\tGenerator: loss 10.462532997131348\n","Epoch 89, batch 38/240:\tDiscriminator: real loss 0.15780191123485565, fake loss 0.21649104356765747\tGenerator: loss 11.95465087890625\n","Epoch 89, batch 39/240:\tDiscriminator: real loss 0.1318548321723938, fake loss 0.11128930002450943\tGenerator: loss 10.671886444091797\n","Epoch 89, batch 40/240:\tDiscriminator: real loss 0.09422795474529266, fake loss 0.2042716145515442\tGenerator: loss 11.995615005493164\n","Epoch 89, batch 41/240:\tDiscriminator: real loss 0.09169599413871765, fake loss 0.10754530876874924\tGenerator: loss 12.959641456604004\n","Epoch 89, batch 42/240:\tDiscriminator: real loss 0.11392408609390259, fake loss 0.1800062358379364\tGenerator: loss 12.373126029968262\n","Epoch 89, batch 43/240:\tDiscriminator: real loss 0.14334701001644135, fake loss 0.16526269912719727\tGenerator: loss 12.058571815490723\n","Epoch 89, batch 44/240:\tDiscriminator: real loss 0.1360548436641693, fake loss 0.17902058362960815\tGenerator: loss 11.495155334472656\n","Epoch 89, batch 45/240:\tDiscriminator: real loss 0.1521412581205368, fake loss 0.05764613673090935\tGenerator: loss 10.439262390136719\n","Epoch 89, batch 46/240:\tDiscriminator: real loss 0.10288481414318085, fake loss 0.3645455539226532\tGenerator: loss 12.076690673828125\n","Epoch 89, batch 47/240:\tDiscriminator: real loss 0.23324421048164368, fake loss 0.17308734357357025\tGenerator: loss 8.951847076416016\n","Epoch 89, batch 48/240:\tDiscriminator: real loss 0.09863583743572235, fake loss 0.16202011704444885\tGenerator: loss 9.803642272949219\n","Epoch 89, batch 49/240:\tDiscriminator: real loss 0.10585830360651016, fake loss 0.11616253852844238\tGenerator: loss 9.712021827697754\n","Epoch 89, batch 50/240:\tDiscriminator: real loss 0.19160139560699463, fake loss 0.16660241782665253\tGenerator: loss 9.320721626281738\n","Epoch 89, batch 51/240:\tDiscriminator: real loss 0.1639845222234726, fake loss 0.11167314648628235\tGenerator: loss 10.095344543457031\n","Epoch 89, batch 52/240:\tDiscriminator: real loss 0.08034906536340714, fake loss 0.12344768643379211\tGenerator: loss 8.040775299072266\n","Epoch 89, batch 53/240:\tDiscriminator: real loss 0.0851668268442154, fake loss 0.17148274183273315\tGenerator: loss 10.622437477111816\n","Epoch 89, batch 54/240:\tDiscriminator: real loss 0.1022527813911438, fake loss 0.18297213315963745\tGenerator: loss 9.927507400512695\n","Epoch 89, batch 55/240:\tDiscriminator: real loss 0.22400455176830292, fake loss 0.16287599503993988\tGenerator: loss 9.765129089355469\n","Epoch 89, batch 56/240:\tDiscriminator: real loss 0.1195438951253891, fake loss 0.15365244448184967\tGenerator: loss 9.214240074157715\n","Epoch 89, batch 57/240:\tDiscriminator: real loss 0.0695810616016388, fake loss 0.06799487769603729\tGenerator: loss 10.949536323547363\n","Epoch 89, batch 58/240:\tDiscriminator: real loss 0.14521172642707825, fake loss 0.18830066919326782\tGenerator: loss 9.894328117370605\n","Epoch 89, batch 59/240:\tDiscriminator: real loss 0.1155811995267868, fake loss 0.2072804570198059\tGenerator: loss 11.464712142944336\n","Epoch 89, batch 60/240:\tDiscriminator: real loss 0.1278836876153946, fake loss 0.1535765826702118\tGenerator: loss 9.791799545288086\n","Epoch 89, batch 61/240:\tDiscriminator: real loss 0.08013483881950378, fake loss 0.11592359840869904\tGenerator: loss 9.315940856933594\n","Epoch 89, batch 62/240:\tDiscriminator: real loss 0.07875248044729233, fake loss 0.2242884784936905\tGenerator: loss 8.932280540466309\n","Epoch 89, batch 63/240:\tDiscriminator: real loss 0.15027980506420135, fake loss 0.12888355553150177\tGenerator: loss 11.276537895202637\n","Epoch 89, batch 64/240:\tDiscriminator: real loss 0.12272636592388153, fake loss 0.030533285811543465\tGenerator: loss 9.827532768249512\n","Epoch 89, batch 65/240:\tDiscriminator: real loss 0.07920584082603455, fake loss 0.04980405420064926\tGenerator: loss 8.892794609069824\n","Epoch 89, batch 66/240:\tDiscriminator: real loss 0.05875128135085106, fake loss 0.3498731851577759\tGenerator: loss 11.618999481201172\n","Epoch 89, batch 67/240:\tDiscriminator: real loss 0.11773350834846497, fake loss 0.16497178375720978\tGenerator: loss 11.197277069091797\n","Epoch 89, batch 68/240:\tDiscriminator: real loss 0.13579268753528595, fake loss 0.03811263665556908\tGenerator: loss 9.84193229675293\n","Epoch 89, batch 69/240:\tDiscriminator: real loss 0.08694160729646683, fake loss 0.1645343154668808\tGenerator: loss 11.245351791381836\n","Epoch 89, batch 70/240:\tDiscriminator: real loss 0.10896649956703186, fake loss 0.10193341225385666\tGenerator: loss 11.087264060974121\n","Epoch 89, batch 71/240:\tDiscriminator: real loss 0.0645076110959053, fake loss 0.19252607226371765\tGenerator: loss 10.92043685913086\n","Epoch 89, batch 72/240:\tDiscriminator: real loss 0.09370557963848114, fake loss 0.20408397912979126\tGenerator: loss 13.265458106994629\n","Epoch 89, batch 73/240:\tDiscriminator: real loss 0.15246866643428802, fake loss 0.07716827094554901\tGenerator: loss 13.82025146484375\n","Epoch 89, batch 74/240:\tDiscriminator: real loss 0.10541370511054993, fake loss 0.0405099056661129\tGenerator: loss 11.198554992675781\n","Epoch 89, batch 75/240:\tDiscriminator: real loss 0.09017547965049744, fake loss 0.3295387029647827\tGenerator: loss 9.11511516571045\n","Epoch 89, batch 76/240:\tDiscriminator: real loss 0.1245802789926529, fake loss 0.23278258740901947\tGenerator: loss 10.892243385314941\n","Epoch 89, batch 77/240:\tDiscriminator: real loss 0.1345626711845398, fake loss 0.11599472165107727\tGenerator: loss 9.631516456604004\n","Epoch 89, batch 78/240:\tDiscriminator: real loss 0.18755768239498138, fake loss 0.1284329742193222\tGenerator: loss 9.5241117477417\n","Epoch 89, batch 79/240:\tDiscriminator: real loss 0.09908854216337204, fake loss 0.309149831533432\tGenerator: loss 12.040704727172852\n","Epoch 89, batch 80/240:\tDiscriminator: real loss 0.11311094462871552, fake loss 0.13347643613815308\tGenerator: loss 13.024001121520996\n","Epoch 89, batch 81/240:\tDiscriminator: real loss 0.10949379205703735, fake loss 0.15544982254505157\tGenerator: loss 14.598947525024414\n","Epoch 89, batch 82/240:\tDiscriminator: real loss 0.11939463019371033, fake loss 0.10189399868249893\tGenerator: loss 14.404003143310547\n","Epoch 89, batch 83/240:\tDiscriminator: real loss 0.10583393275737762, fake loss 0.31974586844444275\tGenerator: loss 14.066201210021973\n","Epoch 89, batch 84/240:\tDiscriminator: real loss 0.15844596922397614, fake loss 0.07763770967721939\tGenerator: loss 14.604291915893555\n","Epoch 89, batch 85/240:\tDiscriminator: real loss 0.18763485550880432, fake loss 0.21157650649547577\tGenerator: loss 12.437230110168457\n","Epoch 89, batch 86/240:\tDiscriminator: real loss 0.12400903552770615, fake loss 0.2605394124984741\tGenerator: loss 10.77127456665039\n","Epoch 89, batch 87/240:\tDiscriminator: real loss 0.10844068229198456, fake loss 0.12064532935619354\tGenerator: loss 12.161760330200195\n","Epoch 89, batch 88/240:\tDiscriminator: real loss 0.08154252916574478, fake loss 0.10140007734298706\tGenerator: loss 13.443495750427246\n","Epoch 89, batch 89/240:\tDiscriminator: real loss 0.1064920648932457, fake loss 0.17093005776405334\tGenerator: loss 12.269028663635254\n","Epoch 89, batch 90/240:\tDiscriminator: real loss 0.0840301588177681, fake loss 0.20533017814159393\tGenerator: loss 11.961395263671875\n","Epoch 89, batch 91/240:\tDiscriminator: real loss 0.1417759656906128, fake loss 0.09829355031251907\tGenerator: loss 11.173752784729004\n","Epoch 89, batch 92/240:\tDiscriminator: real loss 0.23832054436206818, fake loss 0.13476669788360596\tGenerator: loss 9.021617889404297\n","Epoch 89, batch 93/240:\tDiscriminator: real loss 0.06252189725637436, fake loss 0.09079128503799438\tGenerator: loss 9.612074851989746\n","Epoch 89, batch 94/240:\tDiscriminator: real loss 0.0663466826081276, fake loss 0.08782213181257248\tGenerator: loss 9.738726615905762\n","Epoch 89, batch 95/240:\tDiscriminator: real loss 0.0741778165102005, fake loss 0.12223601341247559\tGenerator: loss 10.320008277893066\n","Epoch 89, batch 96/240:\tDiscriminator: real loss 0.04511523246765137, fake loss 0.06242702528834343\tGenerator: loss 10.012931823730469\n","Epoch 89, batch 97/240:\tDiscriminator: real loss 0.05824732780456543, fake loss 0.21964329481124878\tGenerator: loss 11.936662673950195\n","Epoch 89, batch 98/240:\tDiscriminator: real loss 0.10545753687620163, fake loss 0.09733191132545471\tGenerator: loss 13.609029769897461\n","Epoch 89, batch 99/240:\tDiscriminator: real loss 0.1525697559118271, fake loss 0.1098751574754715\tGenerator: loss 13.3464994430542\n","Epoch 89, batch 100/240:\tDiscriminator: real loss 0.05625663697719574, fake loss 0.24430322647094727\tGenerator: loss 14.915600776672363\n","Epoch 89, batch 101/240:\tDiscriminator: real loss 0.1682102382183075, fake loss 0.13217201828956604\tGenerator: loss 12.731318473815918\n","Epoch 89, batch 102/240:\tDiscriminator: real loss 0.14703041315078735, fake loss 0.2082783579826355\tGenerator: loss 11.035679817199707\n","Epoch 89, batch 103/240:\tDiscriminator: real loss 0.079262875020504, fake loss 0.11554425954818726\tGenerator: loss 11.883334159851074\n","Epoch 89, batch 104/240:\tDiscriminator: real loss 0.0734863206744194, fake loss 0.08196312189102173\tGenerator: loss 12.451959609985352\n","Epoch 89, batch 105/240:\tDiscriminator: real loss 0.09446875751018524, fake loss 0.11050765961408615\tGenerator: loss 12.385711669921875\n","Epoch 89, batch 106/240:\tDiscriminator: real loss 0.08389421552419662, fake loss 0.1499531865119934\tGenerator: loss 10.9763765335083\n","Epoch 89, batch 107/240:\tDiscriminator: real loss 0.07664133608341217, fake loss 0.16707099974155426\tGenerator: loss 11.925108909606934\n","Epoch 89, batch 108/240:\tDiscriminator: real loss 0.2019863724708557, fake loss 0.19246551394462585\tGenerator: loss 13.59335708618164\n","Epoch 89, batch 109/240:\tDiscriminator: real loss 0.10132398456335068, fake loss 0.1597464382648468\tGenerator: loss 15.119117736816406\n","Epoch 89, batch 110/240:\tDiscriminator: real loss 0.15636105835437775, fake loss 0.2355160266160965\tGenerator: loss 13.77490520477295\n","Epoch 89, batch 111/240:\tDiscriminator: real loss 0.1223142221570015, fake loss 0.10941879451274872\tGenerator: loss 11.7378568649292\n","Epoch 89, batch 112/240:\tDiscriminator: real loss 0.15492862462997437, fake loss 0.2359527200460434\tGenerator: loss 10.716205596923828\n","Epoch 89, batch 113/240:\tDiscriminator: real loss 0.07215934246778488, fake loss 0.244636669754982\tGenerator: loss 11.527948379516602\n","Epoch 89, batch 114/240:\tDiscriminator: real loss 0.2399580329656601, fake loss 0.20532937347888947\tGenerator: loss 12.576419830322266\n","Epoch 89, batch 115/240:\tDiscriminator: real loss 0.13298965990543365, fake loss 0.11044710874557495\tGenerator: loss 12.250788688659668\n","Epoch 89, batch 116/240:\tDiscriminator: real loss 0.09573909640312195, fake loss 0.10076625645160675\tGenerator: loss 11.924276351928711\n","Epoch 89, batch 117/240:\tDiscriminator: real loss 0.09472227096557617, fake loss 0.15503087639808655\tGenerator: loss 11.133674621582031\n","Epoch 89, batch 118/240:\tDiscriminator: real loss 0.09015467017889023, fake loss 0.06167075037956238\tGenerator: loss 10.531057357788086\n","Epoch 89, batch 119/240:\tDiscriminator: real loss 0.0868833139538765, fake loss 0.1924385279417038\tGenerator: loss 10.836187362670898\n","Epoch 89, batch 120/240:\tDiscriminator: real loss 0.0550549142062664, fake loss 0.13032284379005432\tGenerator: loss 12.233824729919434\n","Epoch 89, batch 121/240:\tDiscriminator: real loss 0.09772913157939911, fake loss 0.16021454334259033\tGenerator: loss 11.576274871826172\n","Epoch 89, batch 122/240:\tDiscriminator: real loss 0.18381310999393463, fake loss 0.13430996239185333\tGenerator: loss 10.180429458618164\n","Epoch 89, batch 123/240:\tDiscriminator: real loss 0.17021450400352478, fake loss 0.1547817885875702\tGenerator: loss 8.223102569580078\n","Epoch 89, batch 124/240:\tDiscriminator: real loss 0.09576134383678436, fake loss 0.1541585773229599\tGenerator: loss 9.298445701599121\n","Epoch 89, batch 125/240:\tDiscriminator: real loss 0.188462033867836, fake loss 0.2943623661994934\tGenerator: loss 9.403809547424316\n","Epoch 89, batch 126/240:\tDiscriminator: real loss 0.07592746615409851, fake loss 0.12041124701499939\tGenerator: loss 10.392040252685547\n","Epoch 89, batch 127/240:\tDiscriminator: real loss 0.12372535467147827, fake loss 0.2285553216934204\tGenerator: loss 11.315079689025879\n","Epoch 89, batch 128/240:\tDiscriminator: real loss 0.17970113456249237, fake loss 0.17672185599803925\tGenerator: loss 13.956499099731445\n","Epoch 89, batch 129/240:\tDiscriminator: real loss 0.0991346538066864, fake loss 0.2645641565322876\tGenerator: loss 12.522988319396973\n","Epoch 89, batch 130/240:\tDiscriminator: real loss 0.2401392161846161, fake loss 0.2351633906364441\tGenerator: loss 11.233715057373047\n","Epoch 89, batch 131/240:\tDiscriminator: real loss 0.09507482498884201, fake loss 0.17403165996074677\tGenerator: loss 11.37704849243164\n","Epoch 89, batch 132/240:\tDiscriminator: real loss 0.2957829535007477, fake loss 0.05960366129875183\tGenerator: loss 10.482470512390137\n","Epoch 89, batch 133/240:\tDiscriminator: real loss 0.1127333864569664, fake loss 0.18422703444957733\tGenerator: loss 9.571810722351074\n","Epoch 89, batch 134/240:\tDiscriminator: real loss 0.05786306411027908, fake loss 0.08595278114080429\tGenerator: loss 10.201645851135254\n","Epoch 89, batch 135/240:\tDiscriminator: real loss 0.04342815279960632, fake loss 0.26581549644470215\tGenerator: loss 13.042160987854004\n","Epoch 89, batch 136/240:\tDiscriminator: real loss 0.1010078638792038, fake loss 0.23358291387557983\tGenerator: loss 16.316246032714844\n","Epoch 89, batch 137/240:\tDiscriminator: real loss 0.2448756992816925, fake loss 0.17812775075435638\tGenerator: loss 12.961060523986816\n","Epoch 89, batch 138/240:\tDiscriminator: real loss 0.07351365685462952, fake loss 0.12980829179286957\tGenerator: loss 12.079837799072266\n","Epoch 89, batch 139/240:\tDiscriminator: real loss 0.20331881940364838, fake loss 0.1177050992846489\tGenerator: loss 11.44660758972168\n","Epoch 89, batch 140/240:\tDiscriminator: real loss 0.04845583066344261, fake loss 0.17109011113643646\tGenerator: loss 11.657693862915039\n","Epoch 89, batch 141/240:\tDiscriminator: real loss 0.09814238548278809, fake loss 0.208740696310997\tGenerator: loss 13.262513160705566\n","Epoch 89, batch 142/240:\tDiscriminator: real loss 0.0921812430024147, fake loss 0.048145998269319534\tGenerator: loss 12.950519561767578\n","Epoch 89, batch 143/240:\tDiscriminator: real loss 0.0778159648180008, fake loss 0.04831487312912941\tGenerator: loss 12.258746147155762\n","Epoch 89, batch 144/240:\tDiscriminator: real loss 0.06953825801610947, fake loss 0.1576697826385498\tGenerator: loss 12.927153587341309\n","Epoch 89, batch 145/240:\tDiscriminator: real loss 0.08192405849695206, fake loss 0.06226736679673195\tGenerator: loss 14.673270225524902\n","Epoch 89, batch 146/240:\tDiscriminator: real loss 0.11680316925048828, fake loss 0.16364437341690063\tGenerator: loss 13.36782455444336\n","Epoch 89, batch 147/240:\tDiscriminator: real loss 0.08005435019731522, fake loss 0.26082855463027954\tGenerator: loss 16.102602005004883\n","Epoch 89, batch 148/240:\tDiscriminator: real loss 0.16747726500034332, fake loss 0.0698525607585907\tGenerator: loss 13.968311309814453\n","Epoch 89, batch 149/240:\tDiscriminator: real loss 0.1212189644575119, fake loss 0.051834460347890854\tGenerator: loss 12.656472206115723\n","Epoch 89, batch 150/240:\tDiscriminator: real loss 0.048195838928222656, fake loss 0.20215654373168945\tGenerator: loss 11.524439811706543\n","Epoch 89, batch 151/240:\tDiscriminator: real loss 0.048476967960596085, fake loss 0.24034374952316284\tGenerator: loss 13.67448616027832\n","Epoch 89, batch 152/240:\tDiscriminator: real loss 0.1127268597483635, fake loss 0.1368095427751541\tGenerator: loss 14.239501953125\n","Epoch 89, batch 153/240:\tDiscriminator: real loss 0.1775956153869629, fake loss 0.10059822350740433\tGenerator: loss 14.340825080871582\n","Epoch 89, batch 154/240:\tDiscriminator: real loss 0.08790725469589233, fake loss 0.28446048498153687\tGenerator: loss 12.892865180969238\n","Epoch 89, batch 155/240:\tDiscriminator: real loss 0.11728426069021225, fake loss 0.1374608278274536\tGenerator: loss 11.817854881286621\n","Epoch 89, batch 156/240:\tDiscriminator: real loss 0.17825989425182343, fake loss 0.12437999993562698\tGenerator: loss 10.281685829162598\n","Epoch 89, batch 157/240:\tDiscriminator: real loss 0.09530498832464218, fake loss 0.10884840786457062\tGenerator: loss 10.129263877868652\n","Epoch 89, batch 158/240:\tDiscriminator: real loss 0.06652076542377472, fake loss 0.1351187825202942\tGenerator: loss 11.224266052246094\n","Epoch 89, batch 159/240:\tDiscriminator: real loss 0.11556417495012283, fake loss 0.09298589825630188\tGenerator: loss 10.049222946166992\n","Epoch 89, batch 160/240:\tDiscriminator: real loss 0.08413103222846985, fake loss 0.22589200735092163\tGenerator: loss 10.635790824890137\n","Epoch 89, batch 161/240:\tDiscriminator: real loss 0.0832110121846199, fake loss 0.2705497741699219\tGenerator: loss 11.599798202514648\n","Epoch 89, batch 162/240:\tDiscriminator: real loss 0.15288294851779938, fake loss 0.09650983661413193\tGenerator: loss 12.762407302856445\n","Epoch 89, batch 163/240:\tDiscriminator: real loss 0.16266971826553345, fake loss 0.1530088186264038\tGenerator: loss 10.896723747253418\n","Epoch 89, batch 164/240:\tDiscriminator: real loss 0.10390058159828186, fake loss 0.3202851116657257\tGenerator: loss 11.644672393798828\n","Epoch 89, batch 165/240:\tDiscriminator: real loss 0.1881272941827774, fake loss 0.14907608926296234\tGenerator: loss 14.647002220153809\n","Epoch 89, batch 166/240:\tDiscriminator: real loss 0.20067329704761505, fake loss 0.15234310925006866\tGenerator: loss 10.85275650024414\n","Epoch 89, batch 167/240:\tDiscriminator: real loss 0.08882822096347809, fake loss 0.1982867270708084\tGenerator: loss 11.910235404968262\n","Epoch 89, batch 168/240:\tDiscriminator: real loss 0.1489233672618866, fake loss 0.16971167922019958\tGenerator: loss 13.591424942016602\n","Epoch 89, batch 169/240:\tDiscriminator: real loss 0.11600007861852646, fake loss 0.14346420764923096\tGenerator: loss 15.72818374633789\n","Epoch 89, batch 170/240:\tDiscriminator: real loss 0.08391778916120529, fake loss 0.13893701136112213\tGenerator: loss 14.497674942016602\n","Epoch 89, batch 171/240:\tDiscriminator: real loss 0.1245710551738739, fake loss 0.24187621474266052\tGenerator: loss 15.285543441772461\n","Epoch 89, batch 172/240:\tDiscriminator: real loss 0.22739002108573914, fake loss 0.17178486287593842\tGenerator: loss 13.977195739746094\n","Epoch 89, batch 173/240:\tDiscriminator: real loss 0.10465454310178757, fake loss 0.1178453341126442\tGenerator: loss 15.095824241638184\n","Epoch 89, batch 174/240:\tDiscriminator: real loss 0.14234523475170135, fake loss 0.25616317987442017\tGenerator: loss 14.748149871826172\n","Epoch 89, batch 175/240:\tDiscriminator: real loss 0.13629615306854248, fake loss 0.16784992814064026\tGenerator: loss 14.126557350158691\n","Epoch 89, batch 176/240:\tDiscriminator: real loss 0.11615745723247528, fake loss 0.1343051642179489\tGenerator: loss 12.728228569030762\n","Epoch 89, batch 177/240:\tDiscriminator: real loss 0.1033942773938179, fake loss 0.15100763738155365\tGenerator: loss 11.870246887207031\n","Epoch 89, batch 178/240:\tDiscriminator: real loss 0.1475265920162201, fake loss 0.26193174719810486\tGenerator: loss 12.235753059387207\n","Epoch 89, batch 179/240:\tDiscriminator: real loss 0.10499348491430283, fake loss 0.05635249614715576\tGenerator: loss 11.925287246704102\n","Epoch 89, batch 180/240:\tDiscriminator: real loss 0.14423471689224243, fake loss 0.27875491976737976\tGenerator: loss 11.07852554321289\n","Epoch 89, batch 181/240:\tDiscriminator: real loss 0.13083483278751373, fake loss 0.13172245025634766\tGenerator: loss 10.85525131225586\n","Epoch 89, batch 182/240:\tDiscriminator: real loss 0.11566439270973206, fake loss 0.16315755248069763\tGenerator: loss 9.861669540405273\n","Epoch 89, batch 183/240:\tDiscriminator: real loss 0.08513477444648743, fake loss 0.1826159656047821\tGenerator: loss 10.535486221313477\n","Epoch 89, batch 184/240:\tDiscriminator: real loss 0.09290191531181335, fake loss 0.12114418298006058\tGenerator: loss 9.809407234191895\n","Epoch 89, batch 185/240:\tDiscriminator: real loss 0.2097281664609909, fake loss 0.17506557703018188\tGenerator: loss 9.315104484558105\n","Epoch 89, batch 186/240:\tDiscriminator: real loss 0.2105281800031662, fake loss 0.2881315052509308\tGenerator: loss 9.645486831665039\n","Epoch 89, batch 187/240:\tDiscriminator: real loss 0.08754140883684158, fake loss 0.2149895429611206\tGenerator: loss 12.491344451904297\n","Epoch 89, batch 188/240:\tDiscriminator: real loss 0.1863226294517517, fake loss 0.2932155430316925\tGenerator: loss 14.95987319946289\n","Epoch 89, batch 189/240:\tDiscriminator: real loss 0.2412245124578476, fake loss 0.10523326694965363\tGenerator: loss 14.455613136291504\n","Epoch 89, batch 190/240:\tDiscriminator: real loss 0.09903562813997269, fake loss 0.1805422157049179\tGenerator: loss 14.199048042297363\n","Epoch 89, batch 191/240:\tDiscriminator: real loss 0.14621590077877045, fake loss 0.21356534957885742\tGenerator: loss 14.531536102294922\n","Epoch 89, batch 192/240:\tDiscriminator: real loss 0.1450400948524475, fake loss 0.13164259493350983\tGenerator: loss 14.510454177856445\n","Epoch 89, batch 193/240:\tDiscriminator: real loss 0.08620074391365051, fake loss 0.19676350057125092\tGenerator: loss 12.800057411193848\n","Epoch 89, batch 194/240:\tDiscriminator: real loss 0.16205129027366638, fake loss 0.20443883538246155\tGenerator: loss 11.431475639343262\n","Epoch 89, batch 195/240:\tDiscriminator: real loss 0.1911029815673828, fake loss 0.06434277445077896\tGenerator: loss 12.69762897491455\n","Epoch 89, batch 196/240:\tDiscriminator: real loss 0.09371063113212585, fake loss 0.1018730103969574\tGenerator: loss 11.194300651550293\n","Epoch 89, batch 197/240:\tDiscriminator: real loss 0.07739929854869843, fake loss 0.16654902696609497\tGenerator: loss 10.550301551818848\n","Epoch 89, batch 198/240:\tDiscriminator: real loss 0.07268411666154861, fake loss 0.1479841023683548\tGenerator: loss 10.640633583068848\n","Epoch 89, batch 199/240:\tDiscriminator: real loss 0.11763730645179749, fake loss 0.21591684222221375\tGenerator: loss 10.9802827835083\n","Epoch 89, batch 200/240:\tDiscriminator: real loss 0.13494347035884857, fake loss 0.026526575908064842\tGenerator: loss 8.672502517700195\n","Epoch 89, batch 201/240:\tDiscriminator: real loss 0.17607606947422028, fake loss 0.25984638929367065\tGenerator: loss 10.954231262207031\n","Epoch 89, batch 202/240:\tDiscriminator: real loss 0.08019337058067322, fake loss 0.20766884088516235\tGenerator: loss 12.536905288696289\n","Epoch 89, batch 203/240:\tDiscriminator: real loss 0.09640676528215408, fake loss 0.21469134092330933\tGenerator: loss 13.127053260803223\n","Epoch 89, batch 204/240:\tDiscriminator: real loss 0.17146989703178406, fake loss 0.13887371122837067\tGenerator: loss 11.574723243713379\n","Epoch 89, batch 205/240:\tDiscriminator: real loss 0.07128552347421646, fake loss 0.15835031867027283\tGenerator: loss 10.636584281921387\n","Epoch 89, batch 206/240:\tDiscriminator: real loss 0.13790008425712585, fake loss 0.19357025623321533\tGenerator: loss 11.6365385055542\n","Epoch 89, batch 207/240:\tDiscriminator: real loss 0.13852928578853607, fake loss 0.1945076435804367\tGenerator: loss 13.571523666381836\n","Epoch 89, batch 208/240:\tDiscriminator: real loss 0.19734138250350952, fake loss 0.12842878699302673\tGenerator: loss 13.519523620605469\n","Epoch 89, batch 209/240:\tDiscriminator: real loss 0.17489022016525269, fake loss 0.32544997334480286\tGenerator: loss 14.011130332946777\n","Epoch 89, batch 210/240:\tDiscriminator: real loss 0.15675733983516693, fake loss 0.12743118405342102\tGenerator: loss 13.016437530517578\n","Epoch 89, batch 211/240:\tDiscriminator: real loss 0.20840691030025482, fake loss 0.17479656636714935\tGenerator: loss 11.586691856384277\n","Epoch 89, batch 212/240:\tDiscriminator: real loss 0.15358564257621765, fake loss 0.15505824983119965\tGenerator: loss 10.4404878616333\n","Epoch 89, batch 213/240:\tDiscriminator: real loss 0.06756233423948288, fake loss 0.16499949991703033\tGenerator: loss 12.43498420715332\n","Epoch 89, batch 214/240:\tDiscriminator: real loss 0.07321859151124954, fake loss 0.19020164012908936\tGenerator: loss 11.824749946594238\n","Epoch 89, batch 215/240:\tDiscriminator: real loss 0.14949549734592438, fake loss 0.1826222836971283\tGenerator: loss 12.365638732910156\n","Epoch 89, batch 216/240:\tDiscriminator: real loss 0.07284774631261826, fake loss 0.10564934462308884\tGenerator: loss 10.92184066772461\n","Epoch 89, batch 217/240:\tDiscriminator: real loss 0.2241194099187851, fake loss 0.24803929030895233\tGenerator: loss 10.33114242553711\n","Epoch 89, batch 218/240:\tDiscriminator: real loss 0.16858898103237152, fake loss 0.16133660078048706\tGenerator: loss 10.904777526855469\n","Epoch 89, batch 219/240:\tDiscriminator: real loss 0.06342164427042007, fake loss 0.2252623438835144\tGenerator: loss 9.734477996826172\n","Epoch 89, batch 220/240:\tDiscriminator: real loss 0.15118087828159332, fake loss 0.145716592669487\tGenerator: loss 10.202108383178711\n","Epoch 89, batch 221/240:\tDiscriminator: real loss 0.09779105335474014, fake loss 0.13876454532146454\tGenerator: loss 9.653125762939453\n","Epoch 89, batch 222/240:\tDiscriminator: real loss 0.18183346092700958, fake loss 0.15201827883720398\tGenerator: loss 11.596663475036621\n","Epoch 89, batch 223/240:\tDiscriminator: real loss 0.11737391352653503, fake loss 0.13710317015647888\tGenerator: loss 10.001919746398926\n","Epoch 89, batch 224/240:\tDiscriminator: real loss 0.07912670820951462, fake loss 0.21384285390377045\tGenerator: loss 10.372941017150879\n","Epoch 89, batch 225/240:\tDiscriminator: real loss 0.09235267341136932, fake loss 0.14118751883506775\tGenerator: loss 8.894323348999023\n","Epoch 89, batch 226/240:\tDiscriminator: real loss 0.2134653925895691, fake loss 0.0626344084739685\tGenerator: loss 9.262945175170898\n","Epoch 89, batch 227/240:\tDiscriminator: real loss 0.0859285369515419, fake loss 0.22991375625133514\tGenerator: loss 11.482255935668945\n","Epoch 89, batch 228/240:\tDiscriminator: real loss 0.07767670601606369, fake loss 0.14679576456546783\tGenerator: loss 11.725166320800781\n","Epoch 89, batch 229/240:\tDiscriminator: real loss 0.08393290638923645, fake loss 0.11026769876480103\tGenerator: loss 10.679108619689941\n","Epoch 89, batch 230/240:\tDiscriminator: real loss 0.07435130327939987, fake loss 0.14030402898788452\tGenerator: loss 10.384676933288574\n","Epoch 89, batch 231/240:\tDiscriminator: real loss 0.10300026088953018, fake loss 0.16358350217342377\tGenerator: loss 10.303838729858398\n","Epoch 89, batch 232/240:\tDiscriminator: real loss 0.12625764310359955, fake loss 0.21723400056362152\tGenerator: loss 11.351727485656738\n","Epoch 89, batch 233/240:\tDiscriminator: real loss 0.17157185077667236, fake loss 0.26459407806396484\tGenerator: loss 10.714424133300781\n","Epoch 89, batch 234/240:\tDiscriminator: real loss 0.09342347830533981, fake loss 0.13009849190711975\tGenerator: loss 8.664180755615234\n","Epoch 89, batch 235/240:\tDiscriminator: real loss 0.2316550314426422, fake loss 0.13826072216033936\tGenerator: loss 7.78809928894043\n","Epoch 89, batch 236/240:\tDiscriminator: real loss 0.08580731600522995, fake loss 0.32364869117736816\tGenerator: loss 8.426087379455566\n","Epoch 89, batch 237/240:\tDiscriminator: real loss 0.14598417282104492, fake loss 0.18316516280174255\tGenerator: loss 11.113879203796387\n","Epoch 89, batch 238/240:\tDiscriminator: real loss 0.06428997218608856, fake loss 0.11897781491279602\tGenerator: loss 11.500799179077148\n","Epoch 89, batch 239/240:\tDiscriminator: real loss 0.1015138030052185, fake loss 0.21373987197875977\tGenerator: loss 12.258731842041016\n","Epoch 89, batch 240/240:\tDiscriminator: real loss 0.15420788526535034, fake loss 0.16682754456996918\tGenerator: loss 13.127918243408203\n","Epoch 90, batch 1/240:\tDiscriminator: real loss 0.14924868941307068, fake loss 0.1369415819644928\tGenerator: loss 11.322656631469727\n","Epoch 90, batch 2/240:\tDiscriminator: real loss 0.08621665835380554, fake loss 0.1417275071144104\tGenerator: loss 12.57359504699707\n","Epoch 90, batch 3/240:\tDiscriminator: real loss 0.09207858145236969, fake loss 0.056777987629175186\tGenerator: loss 11.034789085388184\n","Epoch 90, batch 4/240:\tDiscriminator: real loss 0.10712597519159317, fake loss 0.31757718324661255\tGenerator: loss 10.579950332641602\n","Epoch 90, batch 5/240:\tDiscriminator: real loss 0.10028089582920074, fake loss 0.1878139078617096\tGenerator: loss 9.882827758789062\n","Epoch 90, batch 6/240:\tDiscriminator: real loss 0.18328332901000977, fake loss 0.22438888251781464\tGenerator: loss 11.215933799743652\n","Epoch 90, batch 7/240:\tDiscriminator: real loss 0.20453453063964844, fake loss 0.1693619191646576\tGenerator: loss 8.39449691772461\n","Epoch 90, batch 8/240:\tDiscriminator: real loss 0.08045458048582077, fake loss 0.2715457081794739\tGenerator: loss 9.17846393585205\n","Epoch 90, batch 9/240:\tDiscriminator: real loss 0.09171205759048462, fake loss 0.08182401955127716\tGenerator: loss 8.81710433959961\n","Epoch 90, batch 10/240:\tDiscriminator: real loss 0.10113899409770966, fake loss 0.3306530714035034\tGenerator: loss 9.967562675476074\n","Epoch 90, batch 11/240:\tDiscriminator: real loss 0.15249550342559814, fake loss 0.12493600696325302\tGenerator: loss 9.5050048828125\n","Epoch 90, batch 12/240:\tDiscriminator: real loss 0.1377139687538147, fake loss 0.3113711178302765\tGenerator: loss 12.617822647094727\n","Epoch 90, batch 13/240:\tDiscriminator: real loss 0.19904062151908875, fake loss 0.2559376060962677\tGenerator: loss 11.317425727844238\n","Epoch 90, batch 14/240:\tDiscriminator: real loss 0.1228794977068901, fake loss 0.11089523136615753\tGenerator: loss 12.805569648742676\n","Epoch 90, batch 15/240:\tDiscriminator: real loss 0.1999855786561966, fake loss 0.38177257776260376\tGenerator: loss 12.194151878356934\n","Epoch 90, batch 16/240:\tDiscriminator: real loss 0.19592861831188202, fake loss 0.04908100143074989\tGenerator: loss 11.363293647766113\n","Epoch 90, batch 17/240:\tDiscriminator: real loss 0.15231317281723022, fake loss 0.18994903564453125\tGenerator: loss 8.716148376464844\n","Epoch 90, batch 18/240:\tDiscriminator: real loss 0.04341581463813782, fake loss 0.1783192753791809\tGenerator: loss 8.837166786193848\n","Epoch 90, batch 19/240:\tDiscriminator: real loss 0.0991399958729744, fake loss 0.07753102481365204\tGenerator: loss 8.76025390625\n","Epoch 90, batch 20/240:\tDiscriminator: real loss 0.11654429137706757, fake loss 0.2867542505264282\tGenerator: loss 10.538609504699707\n","Epoch 90, batch 21/240:\tDiscriminator: real loss 0.17675966024398804, fake loss 0.024923481047153473\tGenerator: loss 9.220484733581543\n","Epoch 90, batch 22/240:\tDiscriminator: real loss 0.1265716701745987, fake loss 0.20240716636180878\tGenerator: loss 10.399674415588379\n","Epoch 90, batch 23/240:\tDiscriminator: real loss 0.078885018825531, fake loss 0.18510475754737854\tGenerator: loss 10.418839454650879\n","Epoch 90, batch 24/240:\tDiscriminator: real loss 0.15881095826625824, fake loss 0.07190331816673279\tGenerator: loss 7.5229973793029785\n","Epoch 90, batch 25/240:\tDiscriminator: real loss 0.08730020374059677, fake loss 0.2771761417388916\tGenerator: loss 12.422436714172363\n","Epoch 90, batch 26/240:\tDiscriminator: real loss 0.09770840406417847, fake loss 0.13297739624977112\tGenerator: loss 16.19158363342285\n","Epoch 90, batch 27/240:\tDiscriminator: real loss 0.192522794008255, fake loss 0.1926388144493103\tGenerator: loss 16.761354446411133\n","Epoch 90, batch 28/240:\tDiscriminator: real loss 0.12849044799804688, fake loss 0.0958927571773529\tGenerator: loss 15.593555450439453\n","Epoch 90, batch 29/240:\tDiscriminator: real loss 0.07551097124814987, fake loss 0.19268664717674255\tGenerator: loss 16.87509536743164\n","Epoch 90, batch 30/240:\tDiscriminator: real loss 0.1159006804227829, fake loss 0.13689318299293518\tGenerator: loss 17.603418350219727\n","Epoch 90, batch 31/240:\tDiscriminator: real loss 0.15175645053386688, fake loss 0.0649254247546196\tGenerator: loss 14.785578727722168\n","Epoch 90, batch 32/240:\tDiscriminator: real loss 0.1073371097445488, fake loss 0.1549231857061386\tGenerator: loss 15.081313133239746\n","Epoch 90, batch 33/240:\tDiscriminator: real loss 0.06595565378665924, fake loss 0.2726460099220276\tGenerator: loss 15.058415412902832\n","Epoch 90, batch 34/240:\tDiscriminator: real loss 0.13277782499790192, fake loss 0.03343064337968826\tGenerator: loss 14.359241485595703\n","Epoch 90, batch 35/240:\tDiscriminator: real loss 0.13481470942497253, fake loss 0.17731864750385284\tGenerator: loss 12.225329399108887\n","Epoch 90, batch 36/240:\tDiscriminator: real loss 0.06807460635900497, fake loss 0.12877561151981354\tGenerator: loss 14.177724838256836\n","Epoch 90, batch 37/240:\tDiscriminator: real loss 0.14098209142684937, fake loss 0.15960881114006042\tGenerator: loss 15.020285606384277\n","Epoch 90, batch 38/240:\tDiscriminator: real loss 0.14861391484737396, fake loss 0.18817013502120972\tGenerator: loss 13.787946701049805\n","Epoch 90, batch 39/240:\tDiscriminator: real loss 0.11758793890476227, fake loss 0.20865929126739502\tGenerator: loss 15.805830955505371\n","Epoch 90, batch 40/240:\tDiscriminator: real loss 0.22930742800235748, fake loss 0.12036354839801788\tGenerator: loss 13.77173137664795\n","Epoch 90, batch 41/240:\tDiscriminator: real loss 0.09187687188386917, fake loss 0.20488464832305908\tGenerator: loss 11.970794677734375\n","Epoch 90, batch 42/240:\tDiscriminator: real loss 0.10465511679649353, fake loss 0.15867692232131958\tGenerator: loss 13.273720741271973\n","Epoch 90, batch 43/240:\tDiscriminator: real loss 0.1571248173713684, fake loss 0.13860897719860077\tGenerator: loss 13.394579887390137\n","Epoch 90, batch 44/240:\tDiscriminator: real loss 0.17249304056167603, fake loss 0.157215416431427\tGenerator: loss 12.208059310913086\n","Epoch 90, batch 45/240:\tDiscriminator: real loss 0.16071708500385284, fake loss 0.16828592121601105\tGenerator: loss 13.038970947265625\n","Epoch 90, batch 46/240:\tDiscriminator: real loss 0.07594481110572815, fake loss 0.2415054440498352\tGenerator: loss 13.849803924560547\n","Epoch 90, batch 47/240:\tDiscriminator: real loss 0.07921993732452393, fake loss 0.09464816004037857\tGenerator: loss 14.876644134521484\n","Epoch 90, batch 48/240:\tDiscriminator: real loss 0.1775253415107727, fake loss 0.1914842575788498\tGenerator: loss 13.077951431274414\n","Epoch 90, batch 49/240:\tDiscriminator: real loss 0.07775460183620453, fake loss 0.18428480625152588\tGenerator: loss 13.318414688110352\n","Epoch 90, batch 50/240:\tDiscriminator: real loss 0.07058415561914444, fake loss 0.1508275270462036\tGenerator: loss 14.902029037475586\n","Epoch 90, batch 51/240:\tDiscriminator: real loss 0.16483445465564728, fake loss 0.09872544556856155\tGenerator: loss 15.531603813171387\n","Epoch 90, batch 52/240:\tDiscriminator: real loss 0.0962047278881073, fake loss 0.12071196734905243\tGenerator: loss 12.667075157165527\n","Epoch 90, batch 53/240:\tDiscriminator: real loss 0.08642332255840302, fake loss 0.3454432785511017\tGenerator: loss 14.308000564575195\n","Epoch 90, batch 54/240:\tDiscriminator: real loss 0.1480410099029541, fake loss 0.31100669503211975\tGenerator: loss 14.057082176208496\n","Epoch 90, batch 55/240:\tDiscriminator: real loss 0.21194007992744446, fake loss 0.12490013241767883\tGenerator: loss 13.501433372497559\n","Epoch 90, batch 56/240:\tDiscriminator: real loss 0.17792564630508423, fake loss 0.12156534194946289\tGenerator: loss 11.381621360778809\n","Epoch 90, batch 57/240:\tDiscriminator: real loss 0.07699604332447052, fake loss 0.10522828251123428\tGenerator: loss 10.955750465393066\n","Epoch 90, batch 58/240:\tDiscriminator: real loss 0.17788831889629364, fake loss 0.2654460072517395\tGenerator: loss 11.931382179260254\n","Epoch 90, batch 59/240:\tDiscriminator: real loss 0.0764777660369873, fake loss 0.12936046719551086\tGenerator: loss 12.269857406616211\n","Epoch 90, batch 60/240:\tDiscriminator: real loss 0.1437218338251114, fake loss 0.24692481756210327\tGenerator: loss 11.031076431274414\n","Epoch 90, batch 61/240:\tDiscriminator: real loss 0.15295261144638062, fake loss 0.09610956907272339\tGenerator: loss 11.121803283691406\n","Epoch 90, batch 62/240:\tDiscriminator: real loss 0.05825817957520485, fake loss 0.1056770384311676\tGenerator: loss 10.654767036437988\n","Epoch 90, batch 63/240:\tDiscriminator: real loss 0.0931379497051239, fake loss 0.11177186667919159\tGenerator: loss 11.269622802734375\n","Epoch 90, batch 64/240:\tDiscriminator: real loss 0.0501694492995739, fake loss 0.15007875859737396\tGenerator: loss 11.644927024841309\n","Epoch 90, batch 65/240:\tDiscriminator: real loss 0.12459151446819305, fake loss 0.17606818675994873\tGenerator: loss 12.379798889160156\n","Epoch 90, batch 66/240:\tDiscriminator: real loss 0.15738236904144287, fake loss 0.179819718003273\tGenerator: loss 13.632085800170898\n","Epoch 90, batch 67/240:\tDiscriminator: real loss 0.19052329659461975, fake loss 0.074802927672863\tGenerator: loss 12.42159652709961\n","Epoch 90, batch 68/240:\tDiscriminator: real loss 0.05029021203517914, fake loss 0.32650282979011536\tGenerator: loss 14.503351211547852\n","Epoch 90, batch 69/240:\tDiscriminator: real loss 0.10730058699846268, fake loss 0.15198026597499847\tGenerator: loss 14.156347274780273\n","Epoch 90, batch 70/240:\tDiscriminator: real loss 0.09050389379262924, fake loss 0.05104391649365425\tGenerator: loss 12.95107650756836\n","Epoch 90, batch 71/240:\tDiscriminator: real loss 0.09720778465270996, fake loss 0.15201939642429352\tGenerator: loss 10.808382987976074\n","Epoch 90, batch 72/240:\tDiscriminator: real loss 0.11835090816020966, fake loss 0.22775378823280334\tGenerator: loss 12.980530738830566\n","Epoch 90, batch 73/240:\tDiscriminator: real loss 0.08435255289077759, fake loss 0.2593732178211212\tGenerator: loss 13.226954460144043\n","Epoch 90, batch 74/240:\tDiscriminator: real loss 0.161274716258049, fake loss 0.11290699243545532\tGenerator: loss 15.123950958251953\n","Epoch 90, batch 75/240:\tDiscriminator: real loss 0.22586902976036072, fake loss 0.17237728834152222\tGenerator: loss 13.877045631408691\n","Epoch 90, batch 76/240:\tDiscriminator: real loss 0.11375812441110611, fake loss 0.3017643392086029\tGenerator: loss 13.517093658447266\n","Epoch 90, batch 77/240:\tDiscriminator: real loss 0.07877599447965622, fake loss 0.20287609100341797\tGenerator: loss 14.475546836853027\n","Epoch 90, batch 78/240:\tDiscriminator: real loss 0.15321248769760132, fake loss 0.13881008327007294\tGenerator: loss 12.558258056640625\n","Epoch 90, batch 79/240:\tDiscriminator: real loss 0.11837729811668396, fake loss 0.26510733366012573\tGenerator: loss 11.578902244567871\n","Epoch 90, batch 80/240:\tDiscriminator: real loss 0.1530826985836029, fake loss 0.15147657692432404\tGenerator: loss 12.311598777770996\n","Epoch 90, batch 81/240:\tDiscriminator: real loss 0.1153232678771019, fake loss 0.12228637933731079\tGenerator: loss 13.390454292297363\n","Epoch 90, batch 82/240:\tDiscriminator: real loss 0.11268553882837296, fake loss 0.10143668949604034\tGenerator: loss 11.048967361450195\n","Epoch 90, batch 83/240:\tDiscriminator: real loss 0.09729456156492233, fake loss 0.14248648285865784\tGenerator: loss 12.063562393188477\n","Epoch 90, batch 84/240:\tDiscriminator: real loss 0.1369549036026001, fake loss 0.15278920531272888\tGenerator: loss 13.4833345413208\n","Epoch 90, batch 85/240:\tDiscriminator: real loss 0.08668670058250427, fake loss 0.19452133774757385\tGenerator: loss 16.1079044342041\n","Epoch 90, batch 86/240:\tDiscriminator: real loss 0.14663033187389374, fake loss 0.3457798361778259\tGenerator: loss 14.370987892150879\n","Epoch 90, batch 87/240:\tDiscriminator: real loss 0.11359088122844696, fake loss 0.07265863567590714\tGenerator: loss 15.065028190612793\n","Epoch 90, batch 88/240:\tDiscriminator: real loss 0.09879998117685318, fake loss 0.13093793392181396\tGenerator: loss 14.282231330871582\n","Epoch 90, batch 89/240:\tDiscriminator: real loss 0.09688255935907364, fake loss 0.09974448382854462\tGenerator: loss 13.64018440246582\n","Epoch 90, batch 90/240:\tDiscriminator: real loss 0.05502881854772568, fake loss 0.06319213658571243\tGenerator: loss 13.496341705322266\n","Epoch 90, batch 91/240:\tDiscriminator: real loss 0.06983020156621933, fake loss 0.28387290239334106\tGenerator: loss 13.119200706481934\n","Epoch 90, batch 92/240:\tDiscriminator: real loss 0.1937679648399353, fake loss 0.27303609251976013\tGenerator: loss 16.18756675720215\n","Epoch 90, batch 93/240:\tDiscriminator: real loss 0.2390689253807068, fake loss 0.03709709271788597\tGenerator: loss 13.093811988830566\n","Epoch 90, batch 94/240:\tDiscriminator: real loss 0.0745016485452652, fake loss 0.23231510818004608\tGenerator: loss 14.247954368591309\n","Epoch 90, batch 95/240:\tDiscriminator: real loss 0.06299983710050583, fake loss 0.14477239549160004\tGenerator: loss 14.411654472351074\n","Epoch 90, batch 96/240:\tDiscriminator: real loss 0.10595421493053436, fake loss 0.26795679330825806\tGenerator: loss 13.577254295349121\n","Epoch 90, batch 97/240:\tDiscriminator: real loss 0.17145754396915436, fake loss 0.08551336079835892\tGenerator: loss 13.916923522949219\n","Epoch 90, batch 98/240:\tDiscriminator: real loss 0.16870982944965363, fake loss 0.06619330495595932\tGenerator: loss 10.72883415222168\n","Epoch 90, batch 99/240:\tDiscriminator: real loss 0.048083022236824036, fake loss 0.29219716787338257\tGenerator: loss 13.257684707641602\n","Epoch 90, batch 100/240:\tDiscriminator: real loss 0.12398605048656464, fake loss 0.2279234379529953\tGenerator: loss 13.855669975280762\n","Epoch 90, batch 101/240:\tDiscriminator: real loss 0.19529685378074646, fake loss 0.057540163397789\tGenerator: loss 14.276432037353516\n","Epoch 90, batch 102/240:\tDiscriminator: real loss 0.09020441025495529, fake loss 0.15534991025924683\tGenerator: loss 12.285761833190918\n","Epoch 90, batch 103/240:\tDiscriminator: real loss 0.09406501799821854, fake loss 0.35510265827178955\tGenerator: loss 11.601269721984863\n","Epoch 90, batch 104/240:\tDiscriminator: real loss 0.138580784201622, fake loss 0.09586548060178757\tGenerator: loss 12.784917831420898\n","Epoch 90, batch 105/240:\tDiscriminator: real loss 0.12729261815547943, fake loss 0.17281922698020935\tGenerator: loss 12.68109130859375\n","Epoch 90, batch 106/240:\tDiscriminator: real loss 0.07223831117153168, fake loss 0.33726704120635986\tGenerator: loss 12.893871307373047\n","Epoch 90, batch 107/240:\tDiscriminator: real loss 0.13382472097873688, fake loss 0.1758192479610443\tGenerator: loss 12.206047058105469\n","Epoch 90, batch 108/240:\tDiscriminator: real loss 0.23020480573177338, fake loss 0.10710454732179642\tGenerator: loss 13.294804573059082\n","Epoch 90, batch 109/240:\tDiscriminator: real loss 0.21311067044734955, fake loss 0.1285284459590912\tGenerator: loss 11.773720741271973\n","Epoch 90, batch 110/240:\tDiscriminator: real loss 0.1030927449464798, fake loss 0.3406864106655121\tGenerator: loss 12.326147079467773\n","Epoch 90, batch 111/240:\tDiscriminator: real loss 0.13790005445480347, fake loss 0.28160542249679565\tGenerator: loss 13.443634033203125\n","Epoch 90, batch 112/240:\tDiscriminator: real loss 0.1083894744515419, fake loss 0.05742815136909485\tGenerator: loss 13.907876014709473\n","Epoch 90, batch 113/240:\tDiscriminator: real loss 0.12875637412071228, fake loss 0.14048302173614502\tGenerator: loss 11.056750297546387\n","Epoch 90, batch 114/240:\tDiscriminator: real loss 0.14597667753696442, fake loss 0.17170128226280212\tGenerator: loss 10.857146263122559\n","Epoch 90, batch 115/240:\tDiscriminator: real loss 0.09706075489521027, fake loss 0.34913018345832825\tGenerator: loss 9.870458602905273\n","Epoch 90, batch 116/240:\tDiscriminator: real loss 0.19436052441596985, fake loss 0.16072791814804077\tGenerator: loss 11.835376739501953\n","Epoch 90, batch 117/240:\tDiscriminator: real loss 0.22846584022045135, fake loss 0.16769206523895264\tGenerator: loss 12.067902565002441\n","Epoch 90, batch 118/240:\tDiscriminator: real loss 0.12187761068344116, fake loss 0.07918830960988998\tGenerator: loss 10.384344100952148\n","Epoch 90, batch 119/240:\tDiscriminator: real loss 0.0893411934375763, fake loss 0.2120581418275833\tGenerator: loss 10.352608680725098\n","Epoch 90, batch 120/240:\tDiscriminator: real loss 0.09347110986709595, fake loss 0.27065902948379517\tGenerator: loss 11.03747844696045\n","Epoch 90, batch 121/240:\tDiscriminator: real loss 0.14370498061180115, fake loss 0.19561630487442017\tGenerator: loss 11.193450927734375\n","Epoch 90, batch 122/240:\tDiscriminator: real loss 0.19511421024799347, fake loss 0.14441055059432983\tGenerator: loss 11.428864479064941\n","Epoch 90, batch 123/240:\tDiscriminator: real loss 0.25051429867744446, fake loss 0.37146034836769104\tGenerator: loss 10.982831954956055\n","Epoch 90, batch 124/240:\tDiscriminator: real loss 0.23591382801532745, fake loss 0.14550115168094635\tGenerator: loss 10.939043045043945\n","Epoch 90, batch 125/240:\tDiscriminator: real loss 0.08854213356971741, fake loss 0.15288369357585907\tGenerator: loss 9.949566841125488\n","Epoch 90, batch 126/240:\tDiscriminator: real loss 0.10723987221717834, fake loss 0.15121445059776306\tGenerator: loss 9.042353630065918\n","Epoch 90, batch 127/240:\tDiscriminator: real loss 0.05959684029221535, fake loss 0.12056303024291992\tGenerator: loss 10.851655006408691\n","Epoch 90, batch 128/240:\tDiscriminator: real loss 0.2051229476928711, fake loss 0.09855824708938599\tGenerator: loss 9.939156532287598\n","Epoch 90, batch 129/240:\tDiscriminator: real loss 0.17478950321674347, fake loss 0.28329601883888245\tGenerator: loss 10.156201362609863\n","Epoch 90, batch 130/240:\tDiscriminator: real loss 0.11365518718957901, fake loss 0.135729119181633\tGenerator: loss 8.538751602172852\n","Epoch 90, batch 131/240:\tDiscriminator: real loss 0.1251315474510193, fake loss 0.129463329911232\tGenerator: loss 10.440668106079102\n","Epoch 90, batch 132/240:\tDiscriminator: real loss 0.1905294805765152, fake loss 0.16361182928085327\tGenerator: loss 11.574119567871094\n","Epoch 90, batch 133/240:\tDiscriminator: real loss 0.1108870729804039, fake loss 0.14029507339000702\tGenerator: loss 10.993758201599121\n","Epoch 90, batch 134/240:\tDiscriminator: real loss 0.13355323672294617, fake loss 0.0764445960521698\tGenerator: loss 11.632328987121582\n","Epoch 90, batch 135/240:\tDiscriminator: real loss 0.047546789050102234, fake loss 0.22151169180870056\tGenerator: loss 11.906149864196777\n","Epoch 90, batch 136/240:\tDiscriminator: real loss 0.12173400819301605, fake loss 0.1912238895893097\tGenerator: loss 11.402387619018555\n","Epoch 90, batch 137/240:\tDiscriminator: real loss 0.08400238305330276, fake loss 0.17087064683437347\tGenerator: loss 11.798694610595703\n","Epoch 90, batch 138/240:\tDiscriminator: real loss 0.1322004646062851, fake loss 0.075700543820858\tGenerator: loss 10.715814590454102\n","Epoch 90, batch 139/240:\tDiscriminator: real loss 0.07606101036071777, fake loss 0.2503023147583008\tGenerator: loss 12.87805461883545\n","Epoch 90, batch 140/240:\tDiscriminator: real loss 0.16265155375003815, fake loss 0.1377788484096527\tGenerator: loss 11.499887466430664\n","Epoch 90, batch 141/240:\tDiscriminator: real loss 0.09925395995378494, fake loss 0.1491146981716156\tGenerator: loss 11.313665390014648\n","Epoch 90, batch 142/240:\tDiscriminator: real loss 0.1472625434398651, fake loss 0.06581825762987137\tGenerator: loss 10.8782377243042\n","Epoch 90, batch 143/240:\tDiscriminator: real loss 0.0833478569984436, fake loss 0.3112766742706299\tGenerator: loss 11.315532684326172\n","Epoch 90, batch 144/240:\tDiscriminator: real loss 0.08231561630964279, fake loss 0.14909875392913818\tGenerator: loss 12.291243553161621\n","Epoch 90, batch 145/240:\tDiscriminator: real loss 0.12594309449195862, fake loss 0.062251634895801544\tGenerator: loss 13.532448768615723\n","Epoch 90, batch 146/240:\tDiscriminator: real loss 0.17012350261211395, fake loss 0.35956132411956787\tGenerator: loss 12.464672088623047\n","Epoch 90, batch 147/240:\tDiscriminator: real loss 0.09657818078994751, fake loss 0.10018239915370941\tGenerator: loss 12.108631134033203\n","Epoch 90, batch 148/240:\tDiscriminator: real loss 0.12726646661758423, fake loss 0.20588475465774536\tGenerator: loss 10.309548377990723\n","Epoch 90, batch 149/240:\tDiscriminator: real loss 0.1911054253578186, fake loss 0.11987654864788055\tGenerator: loss 10.011013984680176\n","Epoch 90, batch 150/240:\tDiscriminator: real loss 0.08845219761133194, fake loss 0.20784921944141388\tGenerator: loss 10.13547134399414\n","Epoch 90, batch 151/240:\tDiscriminator: real loss 0.08499190956354141, fake loss 0.1394125372171402\tGenerator: loss 11.881775856018066\n","Epoch 90, batch 152/240:\tDiscriminator: real loss 0.07147347182035446, fake loss 0.08227423578500748\tGenerator: loss 12.626229286193848\n","Epoch 90, batch 153/240:\tDiscriminator: real loss 0.09913801401853561, fake loss 0.05402817577123642\tGenerator: loss 12.266236305236816\n","Epoch 90, batch 154/240:\tDiscriminator: real loss 0.09406587481498718, fake loss 0.2665506899356842\tGenerator: loss 12.943655967712402\n","Epoch 90, batch 155/240:\tDiscriminator: real loss 0.18789535760879517, fake loss 0.14225827157497406\tGenerator: loss 11.931916236877441\n","Epoch 90, batch 156/240:\tDiscriminator: real loss 0.08256407082080841, fake loss 0.1772339940071106\tGenerator: loss 13.423095703125\n","Epoch 90, batch 157/240:\tDiscriminator: real loss 0.11213792860507965, fake loss 0.14790500700473785\tGenerator: loss 14.036913871765137\n","Epoch 90, batch 158/240:\tDiscriminator: real loss 0.12400149554014206, fake loss 0.30061501264572144\tGenerator: loss 12.01333999633789\n","Epoch 90, batch 159/240:\tDiscriminator: real loss 0.2930775284767151, fake loss 0.23605668544769287\tGenerator: loss 11.263084411621094\n","Epoch 90, batch 160/240:\tDiscriminator: real loss 0.08854672312736511, fake loss 0.13494521379470825\tGenerator: loss 12.853313446044922\n","Epoch 90, batch 161/240:\tDiscriminator: real loss 0.13153380155563354, fake loss 0.04943110793828964\tGenerator: loss 11.34482192993164\n","Epoch 90, batch 162/240:\tDiscriminator: real loss 0.08403617888689041, fake loss 0.2837846875190735\tGenerator: loss 12.1735258102417\n","Epoch 90, batch 163/240:\tDiscriminator: real loss 0.1259211003780365, fake loss 0.09464695304632187\tGenerator: loss 11.768146514892578\n","Epoch 90, batch 164/240:\tDiscriminator: real loss 0.06673000007867813, fake loss 0.13273148238658905\tGenerator: loss 12.811698913574219\n","Epoch 90, batch 165/240:\tDiscriminator: real loss 0.21408095955848694, fake loss 0.21890239417552948\tGenerator: loss 11.612382888793945\n","Epoch 90, batch 166/240:\tDiscriminator: real loss 0.06612371653318405, fake loss 0.11190207302570343\tGenerator: loss 10.463706016540527\n","Epoch 90, batch 167/240:\tDiscriminator: real loss 0.12531833350658417, fake loss 0.1931435614824295\tGenerator: loss 10.728046417236328\n","Epoch 90, batch 168/240:\tDiscriminator: real loss 0.16115820407867432, fake loss 0.0908513069152832\tGenerator: loss 10.119863510131836\n","Epoch 90, batch 169/240:\tDiscriminator: real loss 0.10335088521242142, fake loss 0.15505340695381165\tGenerator: loss 10.663334846496582\n","Epoch 90, batch 170/240:\tDiscriminator: real loss 0.07020343095064163, fake loss 0.09515693783760071\tGenerator: loss 11.091448783874512\n","Epoch 90, batch 171/240:\tDiscriminator: real loss 0.13017308712005615, fake loss 0.1834244728088379\tGenerator: loss 10.097119331359863\n","Epoch 90, batch 172/240:\tDiscriminator: real loss 0.029305288568139076, fake loss 0.16220036149024963\tGenerator: loss 11.603898048400879\n","Epoch 90, batch 173/240:\tDiscriminator: real loss 0.11527429521083832, fake loss 0.15435442328453064\tGenerator: loss 13.008928298950195\n","Epoch 90, batch 174/240:\tDiscriminator: real loss 0.09243463724851608, fake loss 0.022633112967014313\tGenerator: loss 12.401423454284668\n","Epoch 90, batch 175/240:\tDiscriminator: real loss 0.08989810943603516, fake loss 0.12946094572544098\tGenerator: loss 11.449707984924316\n","Epoch 90, batch 176/240:\tDiscriminator: real loss 0.07305081188678741, fake loss 0.12464417517185211\tGenerator: loss 13.048669815063477\n","Epoch 90, batch 177/240:\tDiscriminator: real loss 0.109162338078022, fake loss 0.26173263788223267\tGenerator: loss 13.338714599609375\n","Epoch 90, batch 178/240:\tDiscriminator: real loss 0.11267655342817307, fake loss 0.146943137049675\tGenerator: loss 15.912677764892578\n","Epoch 90, batch 179/240:\tDiscriminator: real loss 0.17590810358524323, fake loss 0.08358389139175415\tGenerator: loss 14.283023834228516\n","Epoch 90, batch 180/240:\tDiscriminator: real loss 0.10340209305286407, fake loss 0.15966808795928955\tGenerator: loss 13.415722846984863\n","Epoch 90, batch 181/240:\tDiscriminator: real loss 0.1379847675561905, fake loss 0.1312658190727234\tGenerator: loss 12.672616958618164\n","Epoch 90, batch 182/240:\tDiscriminator: real loss 0.06972070783376694, fake loss 0.17648492753505707\tGenerator: loss 14.169577598571777\n","Epoch 90, batch 183/240:\tDiscriminator: real loss 0.16993841528892517, fake loss 0.08479326218366623\tGenerator: loss 11.754194259643555\n","Epoch 90, batch 184/240:\tDiscriminator: real loss 0.11634551733732224, fake loss 0.2448938488960266\tGenerator: loss 12.004424095153809\n","Epoch 90, batch 185/240:\tDiscriminator: real loss 0.09643642604351044, fake loss 0.1422453075647354\tGenerator: loss 12.834814071655273\n","Epoch 90, batch 186/240:\tDiscriminator: real loss 0.07225716859102249, fake loss 0.07780127972364426\tGenerator: loss 14.841241836547852\n","Epoch 90, batch 187/240:\tDiscriminator: real loss 0.1309453547000885, fake loss 0.10376933962106705\tGenerator: loss 14.181392669677734\n","Epoch 90, batch 188/240:\tDiscriminator: real loss 0.07866205275058746, fake loss 0.1079057902097702\tGenerator: loss 13.218273162841797\n","Epoch 90, batch 189/240:\tDiscriminator: real loss 0.09220865368843079, fake loss 0.3239530622959137\tGenerator: loss 13.6111421585083\n","Epoch 90, batch 190/240:\tDiscriminator: real loss 0.12342888116836548, fake loss 0.06848718971014023\tGenerator: loss 11.910440444946289\n","Epoch 90, batch 191/240:\tDiscriminator: real loss 0.08244508504867554, fake loss 0.13477174937725067\tGenerator: loss 12.477416038513184\n","Epoch 90, batch 192/240:\tDiscriminator: real loss 0.091964490711689, fake loss 0.18975891172885895\tGenerator: loss 13.5873384475708\n","Epoch 90, batch 193/240:\tDiscriminator: real loss 0.20494836568832397, fake loss 0.16324253380298615\tGenerator: loss 16.14790153503418\n","Epoch 90, batch 194/240:\tDiscriminator: real loss 0.21405738592147827, fake loss 0.1467467099428177\tGenerator: loss 15.517260551452637\n","Epoch 90, batch 195/240:\tDiscriminator: real loss 0.07153607159852982, fake loss 0.08360065519809723\tGenerator: loss 15.852370262145996\n","Epoch 90, batch 196/240:\tDiscriminator: real loss 0.19037868082523346, fake loss 0.11596351861953735\tGenerator: loss 13.18449592590332\n","Epoch 90, batch 197/240:\tDiscriminator: real loss 0.05486169829964638, fake loss 0.15663659572601318\tGenerator: loss 14.275151252746582\n","Epoch 90, batch 198/240:\tDiscriminator: real loss 0.04655807837843895, fake loss 0.1745608150959015\tGenerator: loss 16.01673126220703\n","Epoch 90, batch 199/240:\tDiscriminator: real loss 0.12098880112171173, fake loss 0.0930945873260498\tGenerator: loss 14.890619277954102\n","Epoch 90, batch 200/240:\tDiscriminator: real loss 0.17712804675102234, fake loss 0.13948200643062592\tGenerator: loss 12.555787086486816\n","Epoch 90, batch 201/240:\tDiscriminator: real loss 0.0640939325094223, fake loss 0.24418503046035767\tGenerator: loss 12.085071563720703\n","Epoch 90, batch 202/240:\tDiscriminator: real loss 0.10923677682876587, fake loss 0.2733204662799835\tGenerator: loss 13.508179664611816\n","Epoch 90, batch 203/240:\tDiscriminator: real loss 0.10096108168363571, fake loss 0.09791851788759232\tGenerator: loss 13.958290100097656\n","Epoch 90, batch 204/240:\tDiscriminator: real loss 0.15876652300357819, fake loss 0.041533950716257095\tGenerator: loss 12.429374694824219\n","Epoch 90, batch 205/240:\tDiscriminator: real loss 0.1616930514574051, fake loss 0.180007204413414\tGenerator: loss 10.411843299865723\n","Epoch 90, batch 206/240:\tDiscriminator: real loss 0.04547084495425224, fake loss 0.2079271823167801\tGenerator: loss 11.885249137878418\n","Epoch 90, batch 207/240:\tDiscriminator: real loss 0.09241078048944473, fake loss 0.15556341409683228\tGenerator: loss 11.241150856018066\n","Epoch 90, batch 208/240:\tDiscriminator: real loss 0.29428353905677795, fake loss 0.16619935631752014\tGenerator: loss 13.113359451293945\n","Epoch 90, batch 209/240:\tDiscriminator: real loss 0.057719625532627106, fake loss 0.29064103960990906\tGenerator: loss 15.183145523071289\n","Epoch 90, batch 210/240:\tDiscriminator: real loss 0.13183268904685974, fake loss 0.13678494095802307\tGenerator: loss 13.452139854431152\n","Epoch 90, batch 211/240:\tDiscriminator: real loss 0.07365823537111282, fake loss 0.12769657373428345\tGenerator: loss 13.516548156738281\n","Epoch 90, batch 212/240:\tDiscriminator: real loss 0.23593267798423767, fake loss 0.02461124211549759\tGenerator: loss 11.782998085021973\n","Epoch 90, batch 213/240:\tDiscriminator: real loss 0.04967253655195236, fake loss 0.3188510239124298\tGenerator: loss 12.847481727600098\n","Epoch 90, batch 214/240:\tDiscriminator: real loss 0.05427359417080879, fake loss 0.12603884935379028\tGenerator: loss 15.401117324829102\n","Epoch 90, batch 215/240:\tDiscriminator: real loss 0.18453891575336456, fake loss 0.2755603492259979\tGenerator: loss 13.196985244750977\n","Epoch 90, batch 216/240:\tDiscriminator: real loss 0.14917711913585663, fake loss 0.10086897015571594\tGenerator: loss 12.36849594116211\n","Epoch 90, batch 217/240:\tDiscriminator: real loss 0.10695774108171463, fake loss 0.13461905717849731\tGenerator: loss 12.405686378479004\n","Epoch 90, batch 218/240:\tDiscriminator: real loss 0.07533540576696396, fake loss 0.10566528141498566\tGenerator: loss 10.094188690185547\n","Epoch 90, batch 219/240:\tDiscriminator: real loss 0.10458295792341232, fake loss 0.13140922784805298\tGenerator: loss 11.477477073669434\n","Epoch 90, batch 220/240:\tDiscriminator: real loss 0.08721065521240234, fake loss 0.15837350487709045\tGenerator: loss 11.10312271118164\n","Epoch 90, batch 221/240:\tDiscriminator: real loss 0.11646352708339691, fake loss 0.200190469622612\tGenerator: loss 11.656630516052246\n","Epoch 90, batch 222/240:\tDiscriminator: real loss 0.09424768388271332, fake loss 0.13867591321468353\tGenerator: loss 13.168374061584473\n","Epoch 90, batch 223/240:\tDiscriminator: real loss 0.15559695661067963, fake loss 0.09272582828998566\tGenerator: loss 11.958507537841797\n","Epoch 90, batch 224/240:\tDiscriminator: real loss 0.13977743685245514, fake loss 0.1256607174873352\tGenerator: loss 11.309409141540527\n","Epoch 90, batch 225/240:\tDiscriminator: real loss 0.06796898692846298, fake loss 0.21531322598457336\tGenerator: loss 10.415521621704102\n","Epoch 90, batch 226/240:\tDiscriminator: real loss 0.060944393277168274, fake loss 0.22903770208358765\tGenerator: loss 13.130474090576172\n","Epoch 90, batch 227/240:\tDiscriminator: real loss 0.1267886608839035, fake loss 0.09963972121477127\tGenerator: loss 12.913904190063477\n","Epoch 90, batch 228/240:\tDiscriminator: real loss 0.15838736295700073, fake loss 0.27591294050216675\tGenerator: loss 14.490159034729004\n","Epoch 90, batch 229/240:\tDiscriminator: real loss 0.10886219143867493, fake loss 0.08940210938453674\tGenerator: loss 13.3429594039917\n","Epoch 90, batch 230/240:\tDiscriminator: real loss 0.0915154293179512, fake loss 0.08700914680957794\tGenerator: loss 12.33951187133789\n","Epoch 90, batch 231/240:\tDiscriminator: real loss 0.2188662737607956, fake loss 0.19756099581718445\tGenerator: loss 13.237578392028809\n","Epoch 90, batch 232/240:\tDiscriminator: real loss 0.048799749463796616, fake loss 0.2550813555717468\tGenerator: loss 13.196496963500977\n","Epoch 90, batch 233/240:\tDiscriminator: real loss 0.09359022974967957, fake loss 0.15342934429645538\tGenerator: loss 14.674169540405273\n","Epoch 90, batch 234/240:\tDiscriminator: real loss 0.16145898401737213, fake loss 0.10650066286325455\tGenerator: loss 13.546370506286621\n","Epoch 90, batch 235/240:\tDiscriminator: real loss 0.12357953935861588, fake loss 0.11732237786054611\tGenerator: loss 12.691082000732422\n","Epoch 90, batch 236/240:\tDiscriminator: real loss 0.12179384380578995, fake loss 0.09000009298324585\tGenerator: loss 9.784520149230957\n","Epoch 90, batch 237/240:\tDiscriminator: real loss 0.056602612137794495, fake loss 0.16624929010868073\tGenerator: loss 9.93970012664795\n","Epoch 90, batch 238/240:\tDiscriminator: real loss 0.08700814843177795, fake loss 0.24525949358940125\tGenerator: loss 12.058488845825195\n","Epoch 90, batch 239/240:\tDiscriminator: real loss 0.11120820045471191, fake loss 0.09106817841529846\tGenerator: loss 13.849989891052246\n","Epoch 90, batch 240/240:\tDiscriminator: real loss 0.08659707009792328, fake loss 0.06112135574221611\tGenerator: loss 12.936263084411621\n","Epoch 91, batch 1/240:\tDiscriminator: real loss 0.12193594872951508, fake loss 0.12411336600780487\tGenerator: loss 11.66342544555664\n","Epoch 91, batch 2/240:\tDiscriminator: real loss 0.05788464844226837, fake loss 0.10408813506364822\tGenerator: loss 11.566859245300293\n","Epoch 91, batch 3/240:\tDiscriminator: real loss 0.1524391919374466, fake loss 0.2433268129825592\tGenerator: loss 12.220858573913574\n","Epoch 91, batch 4/240:\tDiscriminator: real loss 0.12260233610868454, fake loss 0.25307536125183105\tGenerator: loss 12.086605072021484\n","Epoch 91, batch 5/240:\tDiscriminator: real loss 0.17347858846187592, fake loss 0.19585534930229187\tGenerator: loss 11.617959022521973\n","Epoch 91, batch 6/240:\tDiscriminator: real loss 0.0931151881814003, fake loss 0.05005723610520363\tGenerator: loss 9.789959907531738\n","Epoch 91, batch 7/240:\tDiscriminator: real loss 0.06441086530685425, fake loss 0.07178447395563126\tGenerator: loss 9.836311340332031\n","Epoch 91, batch 8/240:\tDiscriminator: real loss 0.06350136548280716, fake loss 0.18216699361801147\tGenerator: loss 10.816710472106934\n","Epoch 91, batch 9/240:\tDiscriminator: real loss 0.11165730655193329, fake loss 0.11412127315998077\tGenerator: loss 9.965325355529785\n","Epoch 91, batch 10/240:\tDiscriminator: real loss 0.07771651446819305, fake loss 0.21292196214199066\tGenerator: loss 10.100815773010254\n","Epoch 91, batch 11/240:\tDiscriminator: real loss 0.2170901894569397, fake loss 0.17413049936294556\tGenerator: loss 11.777159690856934\n","Epoch 91, batch 12/240:\tDiscriminator: real loss 0.09473428875207901, fake loss 0.15234467387199402\tGenerator: loss 13.999892234802246\n","Epoch 91, batch 13/240:\tDiscriminator: real loss 0.16914594173431396, fake loss 0.10494563728570938\tGenerator: loss 10.18979549407959\n","Epoch 91, batch 14/240:\tDiscriminator: real loss 0.114695243537426, fake loss 0.20063382387161255\tGenerator: loss 8.682622909545898\n","Epoch 91, batch 15/240:\tDiscriminator: real loss 0.10704731196165085, fake loss 0.16528287529945374\tGenerator: loss 8.247074127197266\n","Epoch 91, batch 16/240:\tDiscriminator: real loss 0.0963117778301239, fake loss 0.1464841514825821\tGenerator: loss 8.804720878601074\n","Epoch 91, batch 17/240:\tDiscriminator: real loss 0.10244636237621307, fake loss 0.08164110779762268\tGenerator: loss 10.79081916809082\n","Epoch 91, batch 18/240:\tDiscriminator: real loss 0.1829911768436432, fake loss 0.39237648248672485\tGenerator: loss 11.197789192199707\n","Epoch 91, batch 19/240:\tDiscriminator: real loss 0.08445705473423004, fake loss 0.10112421214580536\tGenerator: loss 10.828105926513672\n","Epoch 91, batch 20/240:\tDiscriminator: real loss 0.15910828113555908, fake loss 0.13137821853160858\tGenerator: loss 11.501750946044922\n","Epoch 91, batch 21/240:\tDiscriminator: real loss 0.12610678374767303, fake loss 0.21731983125209808\tGenerator: loss 12.316186904907227\n","Epoch 91, batch 22/240:\tDiscriminator: real loss 0.08180233091115952, fake loss 0.1396937519311905\tGenerator: loss 12.0029878616333\n","Epoch 91, batch 23/240:\tDiscriminator: real loss 0.20101499557495117, fake loss 0.17616447806358337\tGenerator: loss 10.289700508117676\n","Epoch 91, batch 24/240:\tDiscriminator: real loss 0.1470659226179123, fake loss 0.3206143081188202\tGenerator: loss 11.182612419128418\n","Epoch 91, batch 25/240:\tDiscriminator: real loss 0.14192229509353638, fake loss 0.120712049305439\tGenerator: loss 12.732355117797852\n","Epoch 91, batch 26/240:\tDiscriminator: real loss 0.11047679930925369, fake loss 0.1421671360731125\tGenerator: loss 11.999290466308594\n","Epoch 91, batch 27/240:\tDiscriminator: real loss 0.14133886992931366, fake loss 0.16303089261054993\tGenerator: loss 9.952735900878906\n","Epoch 91, batch 28/240:\tDiscriminator: real loss 0.07980041205883026, fake loss 0.11290118843317032\tGenerator: loss 11.539185523986816\n","Epoch 91, batch 29/240:\tDiscriminator: real loss 0.11396178603172302, fake loss 0.1048993468284607\tGenerator: loss 10.054302215576172\n","Epoch 91, batch 30/240:\tDiscriminator: real loss 0.08889858424663544, fake loss 0.09516113996505737\tGenerator: loss 10.890654563903809\n","Epoch 91, batch 31/240:\tDiscriminator: real loss 0.09010873734951019, fake loss 0.24150489270687103\tGenerator: loss 11.678359031677246\n","Epoch 91, batch 32/240:\tDiscriminator: real loss 0.2185511589050293, fake loss 0.1771509051322937\tGenerator: loss 11.495148658752441\n","Epoch 91, batch 33/240:\tDiscriminator: real loss 0.12061359733343124, fake loss 0.1408664435148239\tGenerator: loss 11.602463722229004\n","Epoch 91, batch 34/240:\tDiscriminator: real loss 0.1657228022813797, fake loss 0.10456188023090363\tGenerator: loss 12.822839736938477\n","Epoch 91, batch 35/240:\tDiscriminator: real loss 0.061918068677186966, fake loss 0.15283332765102386\tGenerator: loss 11.322447776794434\n","Epoch 91, batch 36/240:\tDiscriminator: real loss 0.0762251541018486, fake loss 0.22992868721485138\tGenerator: loss 12.272391319274902\n","Epoch 91, batch 37/240:\tDiscriminator: real loss 0.09214343875646591, fake loss 0.09576188027858734\tGenerator: loss 14.876333236694336\n","Epoch 91, batch 38/240:\tDiscriminator: real loss 0.16998323798179626, fake loss 0.1947452425956726\tGenerator: loss 14.252649307250977\n","Epoch 91, batch 39/240:\tDiscriminator: real loss 0.14825427532196045, fake loss 0.050884347409009933\tGenerator: loss 13.337179183959961\n","Epoch 91, batch 40/240:\tDiscriminator: real loss 0.08529090881347656, fake loss 0.30629539489746094\tGenerator: loss 13.857671737670898\n","Epoch 91, batch 41/240:\tDiscriminator: real loss 0.09541276842355728, fake loss 0.08097004145383835\tGenerator: loss 11.442509651184082\n","Epoch 91, batch 42/240:\tDiscriminator: real loss 0.06449338048696518, fake loss 0.1624588966369629\tGenerator: loss 12.929408073425293\n","Epoch 91, batch 43/240:\tDiscriminator: real loss 0.06499096751213074, fake loss 0.17365027964115143\tGenerator: loss 13.623000144958496\n","Epoch 91, batch 44/240:\tDiscriminator: real loss 0.14291073381900787, fake loss 0.34267905354499817\tGenerator: loss 11.357217788696289\n","Epoch 91, batch 45/240:\tDiscriminator: real loss 0.23483878374099731, fake loss 0.08176220953464508\tGenerator: loss 11.352988243103027\n","Epoch 91, batch 46/240:\tDiscriminator: real loss 0.18536648154258728, fake loss 0.1956881284713745\tGenerator: loss 10.889089584350586\n","Epoch 91, batch 47/240:\tDiscriminator: real loss 0.03677946701645851, fake loss 0.23184610903263092\tGenerator: loss 11.471932411193848\n","Epoch 91, batch 48/240:\tDiscriminator: real loss 0.12483028322458267, fake loss 0.16395726799964905\tGenerator: loss 11.974400520324707\n","Epoch 91, batch 49/240:\tDiscriminator: real loss 0.16727283596992493, fake loss 0.16954933106899261\tGenerator: loss 12.565208435058594\n","Epoch 91, batch 50/240:\tDiscriminator: real loss 0.09746434539556503, fake loss 0.11357096582651138\tGenerator: loss 12.698403358459473\n","Epoch 91, batch 51/240:\tDiscriminator: real loss 0.11483710259199142, fake loss 0.12191800773143768\tGenerator: loss 13.904170989990234\n","Epoch 91, batch 52/240:\tDiscriminator: real loss 0.12492100894451141, fake loss 0.1565415859222412\tGenerator: loss 12.741464614868164\n","Epoch 91, batch 53/240:\tDiscriminator: real loss 0.1808079183101654, fake loss 0.040099501609802246\tGenerator: loss 11.76702880859375\n","Epoch 91, batch 54/240:\tDiscriminator: real loss 0.08784829825162888, fake loss 0.1822309046983719\tGenerator: loss 12.195941925048828\n","Epoch 91, batch 55/240:\tDiscriminator: real loss 0.06036752834916115, fake loss 0.18662577867507935\tGenerator: loss 14.495838165283203\n","Epoch 91, batch 56/240:\tDiscriminator: real loss 0.06448803842067719, fake loss 0.20434218645095825\tGenerator: loss 13.705327987670898\n","Epoch 91, batch 57/240:\tDiscriminator: real loss 0.16815157234668732, fake loss 0.09798795729875565\tGenerator: loss 13.721088409423828\n","Epoch 91, batch 58/240:\tDiscriminator: real loss 0.09933995455503464, fake loss 0.0874982476234436\tGenerator: loss 12.95340347290039\n","Epoch 91, batch 59/240:\tDiscriminator: real loss 0.11875393241643906, fake loss 0.07450419664382935\tGenerator: loss 13.878579139709473\n","Epoch 91, batch 60/240:\tDiscriminator: real loss 0.08171602338552475, fake loss 0.3174874186515808\tGenerator: loss 13.164109230041504\n","Epoch 91, batch 61/240:\tDiscriminator: real loss 0.09239858388900757, fake loss 0.07819721102714539\tGenerator: loss 12.6970796585083\n","Epoch 91, batch 62/240:\tDiscriminator: real loss 0.1061265841126442, fake loss 0.036505356431007385\tGenerator: loss 10.737574577331543\n","Epoch 91, batch 63/240:\tDiscriminator: real loss 0.11522900313138962, fake loss 0.17050449550151825\tGenerator: loss 11.645194053649902\n","Epoch 91, batch 64/240:\tDiscriminator: real loss 0.08759833127260208, fake loss 0.12518657743930817\tGenerator: loss 10.224505424499512\n","Epoch 91, batch 65/240:\tDiscriminator: real loss 0.13208496570587158, fake loss 0.11610206961631775\tGenerator: loss 10.477242469787598\n","Epoch 91, batch 66/240:\tDiscriminator: real loss 0.07176122814416885, fake loss 0.13960188627243042\tGenerator: loss 9.45067310333252\n","Epoch 91, batch 67/240:\tDiscriminator: real loss 0.09437032788991928, fake loss 0.11873234808444977\tGenerator: loss 9.201715469360352\n","Epoch 91, batch 68/240:\tDiscriminator: real loss 0.07856903970241547, fake loss 0.1323881298303604\tGenerator: loss 10.027780532836914\n","Epoch 91, batch 69/240:\tDiscriminator: real loss 0.13099537789821625, fake loss 0.16170734167099\tGenerator: loss 12.851213455200195\n","Epoch 91, batch 70/240:\tDiscriminator: real loss 0.06266342848539352, fake loss 0.1699238270521164\tGenerator: loss 12.288313865661621\n","Epoch 91, batch 71/240:\tDiscriminator: real loss 0.06680545955896378, fake loss 0.0862356647849083\tGenerator: loss 12.9722261428833\n","Epoch 91, batch 72/240:\tDiscriminator: real loss 0.1593414694070816, fake loss 0.10486891120672226\tGenerator: loss 13.587759971618652\n","Epoch 91, batch 73/240:\tDiscriminator: real loss 0.11794847249984741, fake loss 0.29486095905303955\tGenerator: loss 12.497117042541504\n","Epoch 91, batch 74/240:\tDiscriminator: real loss 0.08014471083879471, fake loss 0.2533402740955353\tGenerator: loss 13.416760444641113\n","Epoch 91, batch 75/240:\tDiscriminator: real loss 0.15992218255996704, fake loss 0.0502200573682785\tGenerator: loss 11.593411445617676\n","Epoch 91, batch 76/240:\tDiscriminator: real loss 0.16029655933380127, fake loss 0.10006938874721527\tGenerator: loss 10.733614921569824\n","Epoch 91, batch 77/240:\tDiscriminator: real loss 0.13282909989356995, fake loss 0.16478709876537323\tGenerator: loss 11.211221694946289\n","Epoch 91, batch 78/240:\tDiscriminator: real loss 0.08183801919221878, fake loss 0.10364288091659546\tGenerator: loss 11.744685173034668\n","Epoch 91, batch 79/240:\tDiscriminator: real loss 0.06189153715968132, fake loss 0.1175747886300087\tGenerator: loss 11.7938814163208\n","Epoch 91, batch 80/240:\tDiscriminator: real loss 0.1721852421760559, fake loss 0.2678663730621338\tGenerator: loss 12.041970252990723\n","Epoch 91, batch 81/240:\tDiscriminator: real loss 0.15264125168323517, fake loss 0.2370011955499649\tGenerator: loss 13.840668678283691\n","Epoch 91, batch 82/240:\tDiscriminator: real loss 0.13559919595718384, fake loss 0.07891172915697098\tGenerator: loss 11.923117637634277\n","Epoch 91, batch 83/240:\tDiscriminator: real loss 0.1694088727235794, fake loss 0.13396801054477692\tGenerator: loss 9.291769981384277\n","Epoch 91, batch 84/240:\tDiscriminator: real loss 0.0598485954105854, fake loss 0.21185718476772308\tGenerator: loss 10.038302421569824\n","Epoch 91, batch 85/240:\tDiscriminator: real loss 0.11041311174631119, fake loss 0.1310969740152359\tGenerator: loss 11.152758598327637\n","Epoch 91, batch 86/240:\tDiscriminator: real loss 0.14320386946201324, fake loss 0.13951808214187622\tGenerator: loss 10.416064262390137\n","Epoch 91, batch 87/240:\tDiscriminator: real loss 0.09161670506000519, fake loss 0.080596923828125\tGenerator: loss 9.774862289428711\n","Epoch 91, batch 88/240:\tDiscriminator: real loss 0.0796159878373146, fake loss 0.3168984651565552\tGenerator: loss 11.358738899230957\n","Epoch 91, batch 89/240:\tDiscriminator: real loss 0.15747889876365662, fake loss 0.1654834747314453\tGenerator: loss 12.490605354309082\n","Epoch 91, batch 90/240:\tDiscriminator: real loss 0.18673309683799744, fake loss 0.12125261127948761\tGenerator: loss 10.092353820800781\n","Epoch 91, batch 91/240:\tDiscriminator: real loss 0.10969438403844833, fake loss 0.047051139175891876\tGenerator: loss 10.370383262634277\n","Epoch 91, batch 92/240:\tDiscriminator: real loss 0.09559617936611176, fake loss 0.10625462234020233\tGenerator: loss 10.177796363830566\n","Epoch 91, batch 93/240:\tDiscriminator: real loss 0.05716944858431816, fake loss 0.27162420749664307\tGenerator: loss 11.825090408325195\n","Epoch 91, batch 94/240:\tDiscriminator: real loss 0.11887792497873306, fake loss 0.22604161500930786\tGenerator: loss 13.832259178161621\n","Epoch 91, batch 95/240:\tDiscriminator: real loss 0.21134500205516815, fake loss 0.11747945845127106\tGenerator: loss 12.082252502441406\n","Epoch 91, batch 96/240:\tDiscriminator: real loss 0.17012256383895874, fake loss 0.1876964122056961\tGenerator: loss 11.547673225402832\n","Epoch 91, batch 97/240:\tDiscriminator: real loss 0.0861515924334526, fake loss 0.19063636660575867\tGenerator: loss 10.892717361450195\n","Epoch 91, batch 98/240:\tDiscriminator: real loss 0.09204535186290741, fake loss 0.13018423318862915\tGenerator: loss 10.971741676330566\n","Epoch 91, batch 99/240:\tDiscriminator: real loss 0.09125848114490509, fake loss 0.07163762301206589\tGenerator: loss 11.557075500488281\n","Epoch 91, batch 100/240:\tDiscriminator: real loss 0.15303507447242737, fake loss 0.09256349503993988\tGenerator: loss 11.754593849182129\n","Epoch 91, batch 101/240:\tDiscriminator: real loss 0.0635261982679367, fake loss 0.2542382776737213\tGenerator: loss 13.086614608764648\n","Epoch 91, batch 102/240:\tDiscriminator: real loss 0.09066560119390488, fake loss 0.19592590630054474\tGenerator: loss 14.1460542678833\n","Epoch 91, batch 103/240:\tDiscriminator: real loss 0.2541239857673645, fake loss 0.15586751699447632\tGenerator: loss 12.270221710205078\n","Epoch 91, batch 104/240:\tDiscriminator: real loss 0.07503646612167358, fake loss 0.19141742587089539\tGenerator: loss 13.610294342041016\n","Epoch 91, batch 105/240:\tDiscriminator: real loss 0.10015705227851868, fake loss 0.20304718613624573\tGenerator: loss 11.801111221313477\n","Epoch 91, batch 106/240:\tDiscriminator: real loss 0.12340209633111954, fake loss 0.011915774084627628\tGenerator: loss 9.413198471069336\n","Epoch 91, batch 107/240:\tDiscriminator: real loss 0.13906507194042206, fake loss 0.24538253247737885\tGenerator: loss 10.404191970825195\n","Epoch 91, batch 108/240:\tDiscriminator: real loss 0.10210217535495758, fake loss 0.24787822365760803\tGenerator: loss 10.954450607299805\n","Epoch 91, batch 109/240:\tDiscriminator: real loss 0.24297645688056946, fake loss 0.24835322797298431\tGenerator: loss 12.700401306152344\n","Epoch 91, batch 110/240:\tDiscriminator: real loss 0.14264868199825287, fake loss 0.15486136078834534\tGenerator: loss 12.721074104309082\n","Epoch 91, batch 111/240:\tDiscriminator: real loss 0.2192211151123047, fake loss 0.1447436362504959\tGenerator: loss 11.06064224243164\n","Epoch 91, batch 112/240:\tDiscriminator: real loss 0.09025023132562637, fake loss 0.17358139157295227\tGenerator: loss 10.018094062805176\n","Epoch 91, batch 113/240:\tDiscriminator: real loss 0.1705917865037918, fake loss 0.1382773071527481\tGenerator: loss 8.70288372039795\n","Epoch 91, batch 114/240:\tDiscriminator: real loss 0.14499768614768982, fake loss 0.13087648153305054\tGenerator: loss 8.95254898071289\n","Epoch 91, batch 115/240:\tDiscriminator: real loss 0.14030110836029053, fake loss 0.3615848124027252\tGenerator: loss 11.914058685302734\n","Epoch 91, batch 116/240:\tDiscriminator: real loss 0.13688135147094727, fake loss 0.048802390694618225\tGenerator: loss 12.345887184143066\n","Epoch 91, batch 117/240:\tDiscriminator: real loss 0.07069717347621918, fake loss 0.23430012166500092\tGenerator: loss 13.540907859802246\n","Epoch 91, batch 118/240:\tDiscriminator: real loss 0.07268286496400833, fake loss 0.05192792788147926\tGenerator: loss 12.067122459411621\n","Epoch 91, batch 119/240:\tDiscriminator: real loss 0.08526059240102768, fake loss 0.11373618990182877\tGenerator: loss 13.276935577392578\n","Epoch 91, batch 120/240:\tDiscriminator: real loss 0.09225531667470932, fake loss 0.08962716162204742\tGenerator: loss 15.707047462463379\n","Epoch 91, batch 121/240:\tDiscriminator: real loss 0.1494750827550888, fake loss 0.2355269193649292\tGenerator: loss 12.965524673461914\n","Epoch 91, batch 122/240:\tDiscriminator: real loss 0.05625127628445625, fake loss 0.31224334239959717\tGenerator: loss 12.13768196105957\n","Epoch 91, batch 123/240:\tDiscriminator: real loss 0.12909692525863647, fake loss 0.14675848186016083\tGenerator: loss 14.63232707977295\n","Epoch 91, batch 124/240:\tDiscriminator: real loss 0.1867891252040863, fake loss 0.19116318225860596\tGenerator: loss 12.269801139831543\n","Epoch 91, batch 125/240:\tDiscriminator: real loss 0.24823884665966034, fake loss 0.21353252232074738\tGenerator: loss 12.871416091918945\n","Epoch 91, batch 126/240:\tDiscriminator: real loss 0.09610246866941452, fake loss 0.14688728749752045\tGenerator: loss 10.698799133300781\n","Epoch 91, batch 127/240:\tDiscriminator: real loss 0.10765982419252396, fake loss 0.14116010069847107\tGenerator: loss 11.40478229522705\n","Epoch 91, batch 128/240:\tDiscriminator: real loss 0.1739412248134613, fake loss 0.07442790269851685\tGenerator: loss 12.86230182647705\n","Epoch 91, batch 129/240:\tDiscriminator: real loss 0.0907192975282669, fake loss 0.21808567643165588\tGenerator: loss 13.95667839050293\n","Epoch 91, batch 130/240:\tDiscriminator: real loss 0.1538604497909546, fake loss 0.11966735869646072\tGenerator: loss 11.083290100097656\n","Epoch 91, batch 131/240:\tDiscriminator: real loss 0.10637151449918747, fake loss 0.1154460683465004\tGenerator: loss 11.327613830566406\n","Epoch 91, batch 132/240:\tDiscriminator: real loss 0.10400880128145218, fake loss 0.08204944431781769\tGenerator: loss 10.930502891540527\n","Epoch 91, batch 133/240:\tDiscriminator: real loss 0.10570863634347916, fake loss 0.08847066760063171\tGenerator: loss 8.065600395202637\n","Epoch 91, batch 134/240:\tDiscriminator: real loss 0.042858295142650604, fake loss 0.14604182541370392\tGenerator: loss 9.48697280883789\n","Epoch 91, batch 135/240:\tDiscriminator: real loss 0.1498330533504486, fake loss 0.24188724160194397\tGenerator: loss 10.747982025146484\n","Epoch 91, batch 136/240:\tDiscriminator: real loss 0.11720770597457886, fake loss 0.08629289269447327\tGenerator: loss 12.351324081420898\n","Epoch 91, batch 137/240:\tDiscriminator: real loss 0.1489783674478531, fake loss 0.2277485728263855\tGenerator: loss 12.237008094787598\n","Epoch 91, batch 138/240:\tDiscriminator: real loss 0.08871286362409592, fake loss 0.1064673587679863\tGenerator: loss 13.124403953552246\n","Epoch 91, batch 139/240:\tDiscriminator: real loss 0.07507568597793579, fake loss 0.13868993520736694\tGenerator: loss 13.152172088623047\n","Epoch 91, batch 140/240:\tDiscriminator: real loss 0.13486358523368835, fake loss 0.1298399567604065\tGenerator: loss 12.478105545043945\n","Epoch 91, batch 141/240:\tDiscriminator: real loss 0.17114421725273132, fake loss 0.252460241317749\tGenerator: loss 10.650232315063477\n","Epoch 91, batch 142/240:\tDiscriminator: real loss 0.12235774844884872, fake loss 0.2306475043296814\tGenerator: loss 10.477826118469238\n","Epoch 91, batch 143/240:\tDiscriminator: real loss 0.15457946062088013, fake loss 0.1506303995847702\tGenerator: loss 10.753301620483398\n","Epoch 91, batch 144/240:\tDiscriminator: real loss 0.07127212733030319, fake loss 0.09247507154941559\tGenerator: loss 10.736249923706055\n","Epoch 91, batch 145/240:\tDiscriminator: real loss 0.1411513090133667, fake loss 0.08529842644929886\tGenerator: loss 12.427289009094238\n","Epoch 91, batch 146/240:\tDiscriminator: real loss 0.09587379544973373, fake loss 0.11092434078454971\tGenerator: loss 11.140689849853516\n","Epoch 91, batch 147/240:\tDiscriminator: real loss 0.0915566086769104, fake loss 0.16814811527729034\tGenerator: loss 10.13863754272461\n","Epoch 91, batch 148/240:\tDiscriminator: real loss 0.09779831022024155, fake loss 0.1797618418931961\tGenerator: loss 12.014283180236816\n","Epoch 91, batch 149/240:\tDiscriminator: real loss 0.07576420158147812, fake loss 0.12209615856409073\tGenerator: loss 13.10948371887207\n","Epoch 91, batch 150/240:\tDiscriminator: real loss 0.15713977813720703, fake loss 0.20117825269699097\tGenerator: loss 12.291778564453125\n","Epoch 91, batch 151/240:\tDiscriminator: real loss 0.247909277677536, fake loss 0.11218984425067902\tGenerator: loss 8.092098236083984\n","Epoch 91, batch 152/240:\tDiscriminator: real loss 0.09993117302656174, fake loss 0.10633304715156555\tGenerator: loss 7.535433769226074\n","Epoch 91, batch 153/240:\tDiscriminator: real loss 0.04488270357251167, fake loss 0.26308199763298035\tGenerator: loss 10.3017578125\n","Epoch 91, batch 154/240:\tDiscriminator: real loss 0.18151578307151794, fake loss 0.05296334624290466\tGenerator: loss 10.723742485046387\n","Epoch 91, batch 155/240:\tDiscriminator: real loss 0.0472775474190712, fake loss 0.14515255391597748\tGenerator: loss 11.809420585632324\n","Epoch 91, batch 156/240:\tDiscriminator: real loss 0.06579912453889847, fake loss 0.20636627078056335\tGenerator: loss 11.897456169128418\n","Epoch 91, batch 157/240:\tDiscriminator: real loss 0.3094869554042816, fake loss 0.23970557749271393\tGenerator: loss 10.886380195617676\n","Epoch 91, batch 158/240:\tDiscriminator: real loss 0.0772966742515564, fake loss 0.1642739325761795\tGenerator: loss 10.796844482421875\n","Epoch 91, batch 159/240:\tDiscriminator: real loss 0.06492498517036438, fake loss 0.1380016952753067\tGenerator: loss 13.200340270996094\n","Epoch 91, batch 160/240:\tDiscriminator: real loss 0.12706772983074188, fake loss 0.1271655112504959\tGenerator: loss 11.215402603149414\n","Epoch 91, batch 161/240:\tDiscriminator: real loss 0.17020730674266815, fake loss 0.31687793135643005\tGenerator: loss 9.5358247756958\n","Epoch 91, batch 162/240:\tDiscriminator: real loss 0.14435893297195435, fake loss 0.20316089689731598\tGenerator: loss 7.784236431121826\n","Epoch 91, batch 163/240:\tDiscriminator: real loss 0.24672996997833252, fake loss 0.15425725281238556\tGenerator: loss 8.681461334228516\n","Epoch 91, batch 164/240:\tDiscriminator: real loss 0.09897682070732117, fake loss 0.11274489760398865\tGenerator: loss 10.855413436889648\n","Epoch 91, batch 165/240:\tDiscriminator: real loss 0.04188944026827812, fake loss 0.1266135424375534\tGenerator: loss 11.810211181640625\n","Epoch 91, batch 166/240:\tDiscriminator: real loss 0.15021561086177826, fake loss 0.27384474873542786\tGenerator: loss 14.913132667541504\n","Epoch 91, batch 167/240:\tDiscriminator: real loss 0.19817258417606354, fake loss 0.16514357924461365\tGenerator: loss 14.883520126342773\n","Epoch 91, batch 168/240:\tDiscriminator: real loss 0.1817304939031601, fake loss 0.12419433891773224\tGenerator: loss 14.623202323913574\n","Epoch 91, batch 169/240:\tDiscriminator: real loss 0.08319717645645142, fake loss 0.16365794837474823\tGenerator: loss 15.415555000305176\n","Epoch 91, batch 170/240:\tDiscriminator: real loss 0.09301269799470901, fake loss 0.06696445494890213\tGenerator: loss 15.749163627624512\n","Epoch 91, batch 171/240:\tDiscriminator: real loss 0.13781915605068207, fake loss 0.26282015442848206\tGenerator: loss 14.407955169677734\n","Epoch 91, batch 172/240:\tDiscriminator: real loss 0.07918345183134079, fake loss 0.15772293508052826\tGenerator: loss 14.041387557983398\n","Epoch 91, batch 173/240:\tDiscriminator: real loss 0.22857698798179626, fake loss 0.12215525656938553\tGenerator: loss 13.024262428283691\n","Epoch 91, batch 174/240:\tDiscriminator: real loss 0.09642797708511353, fake loss 0.18393169343471527\tGenerator: loss 12.780621528625488\n","Epoch 91, batch 175/240:\tDiscriminator: real loss 0.14396266639232635, fake loss 0.2044856995344162\tGenerator: loss 13.990030288696289\n","Epoch 91, batch 176/240:\tDiscriminator: real loss 0.12807956337928772, fake loss 0.11018361896276474\tGenerator: loss 12.88972282409668\n","Epoch 91, batch 177/240:\tDiscriminator: real loss 0.11272739619016647, fake loss 0.3474714159965515\tGenerator: loss 14.43763542175293\n","Epoch 91, batch 178/240:\tDiscriminator: real loss 0.07476504147052765, fake loss 0.03003469854593277\tGenerator: loss 13.133867263793945\n","Epoch 91, batch 179/240:\tDiscriminator: real loss 0.18213199079036713, fake loss 0.07740792632102966\tGenerator: loss 12.52999496459961\n","Epoch 91, batch 180/240:\tDiscriminator: real loss 0.050742436200380325, fake loss 0.20792411267757416\tGenerator: loss 11.060428619384766\n","Epoch 91, batch 181/240:\tDiscriminator: real loss 0.13477180898189545, fake loss 0.09595295041799545\tGenerator: loss 10.468060493469238\n","Epoch 91, batch 182/240:\tDiscriminator: real loss 0.07785838097333908, fake loss 0.14942488074302673\tGenerator: loss 10.847187042236328\n","Epoch 91, batch 183/240:\tDiscriminator: real loss 0.17312699556350708, fake loss 0.22059574723243713\tGenerator: loss 12.167049407958984\n","Epoch 91, batch 184/240:\tDiscriminator: real loss 0.14177574217319489, fake loss 0.1392950713634491\tGenerator: loss 13.03205680847168\n","Epoch 91, batch 185/240:\tDiscriminator: real loss 0.13129526376724243, fake loss 0.2442377209663391\tGenerator: loss 13.705307960510254\n","Epoch 91, batch 186/240:\tDiscriminator: real loss 0.09535074979066849, fake loss 0.10370407998561859\tGenerator: loss 14.936014175415039\n","Epoch 91, batch 187/240:\tDiscriminator: real loss 0.132080540060997, fake loss 0.12277846038341522\tGenerator: loss 14.471088409423828\n","Epoch 91, batch 188/240:\tDiscriminator: real loss 0.1673983335494995, fake loss 0.11124741286039352\tGenerator: loss 12.887259483337402\n","Epoch 91, batch 189/240:\tDiscriminator: real loss 0.043002236634492874, fake loss 0.09130744636058807\tGenerator: loss 13.489461898803711\n","Epoch 91, batch 190/240:\tDiscriminator: real loss 0.05668669566512108, fake loss 0.298913836479187\tGenerator: loss 14.453841209411621\n","Epoch 91, batch 191/240:\tDiscriminator: real loss 0.12968020141124725, fake loss 0.131199449300766\tGenerator: loss 13.711006164550781\n","Epoch 91, batch 192/240:\tDiscriminator: real loss 0.10049240291118622, fake loss 0.23533424735069275\tGenerator: loss 13.470307350158691\n","Epoch 91, batch 193/240:\tDiscriminator: real loss 0.16043704748153687, fake loss 0.05880686640739441\tGenerator: loss 13.045121192932129\n","Epoch 91, batch 194/240:\tDiscriminator: real loss 0.11845429241657257, fake loss 0.11207911372184753\tGenerator: loss 11.221810340881348\n","Epoch 91, batch 195/240:\tDiscriminator: real loss 0.06774857640266418, fake loss 0.10037592053413391\tGenerator: loss 10.323836326599121\n","Epoch 91, batch 196/240:\tDiscriminator: real loss 0.13011763989925385, fake loss 0.32473045587539673\tGenerator: loss 13.116354942321777\n","Epoch 91, batch 197/240:\tDiscriminator: real loss 0.10479149222373962, fake loss 0.13237227499485016\tGenerator: loss 14.124211311340332\n","Epoch 91, batch 198/240:\tDiscriminator: real loss 0.15944108366966248, fake loss 0.15709395706653595\tGenerator: loss 14.386794090270996\n","Epoch 91, batch 199/240:\tDiscriminator: real loss 0.13115282356739044, fake loss 0.04945647343993187\tGenerator: loss 13.369224548339844\n","Epoch 91, batch 200/240:\tDiscriminator: real loss 0.06046823039650917, fake loss 0.18400275707244873\tGenerator: loss 14.914416313171387\n","Epoch 91, batch 201/240:\tDiscriminator: real loss 0.08072783797979355, fake loss 0.15953589975833893\tGenerator: loss 14.469293594360352\n","Epoch 91, batch 202/240:\tDiscriminator: real loss 0.1460939347743988, fake loss 0.14990653097629547\tGenerator: loss 15.5210542678833\n","Epoch 91, batch 203/240:\tDiscriminator: real loss 0.10365018993616104, fake loss 0.14102573692798615\tGenerator: loss 12.823734283447266\n","Epoch 91, batch 204/240:\tDiscriminator: real loss 0.07885769009590149, fake loss 0.13135303556919098\tGenerator: loss 12.30614948272705\n","Epoch 91, batch 205/240:\tDiscriminator: real loss 0.17132426798343658, fake loss 0.1199539378285408\tGenerator: loss 12.28857135772705\n","Epoch 91, batch 206/240:\tDiscriminator: real loss 0.07270431518554688, fake loss 0.22485582530498505\tGenerator: loss 12.021293640136719\n","Epoch 91, batch 207/240:\tDiscriminator: real loss 0.10574150085449219, fake loss 0.20235075056552887\tGenerator: loss 14.468871116638184\n","Epoch 91, batch 208/240:\tDiscriminator: real loss 0.11995081603527069, fake loss 0.11325202882289886\tGenerator: loss 13.146866798400879\n","Epoch 91, batch 209/240:\tDiscriminator: real loss 0.14305105805397034, fake loss 0.15747199952602386\tGenerator: loss 12.837194442749023\n","Epoch 91, batch 210/240:\tDiscriminator: real loss 0.1613810658454895, fake loss 0.24200691282749176\tGenerator: loss 13.02471923828125\n","Epoch 91, batch 211/240:\tDiscriminator: real loss 0.08337941765785217, fake loss 0.13530860841274261\tGenerator: loss 13.110223770141602\n","Epoch 91, batch 212/240:\tDiscriminator: real loss 0.15175849199295044, fake loss 0.16698478162288666\tGenerator: loss 12.118877410888672\n","Epoch 91, batch 213/240:\tDiscriminator: real loss 0.10752740502357483, fake loss 0.055985480546951294\tGenerator: loss 9.975761413574219\n","Epoch 91, batch 214/240:\tDiscriminator: real loss 0.07393096387386322, fake loss 0.07392820715904236\tGenerator: loss 9.065950393676758\n","Epoch 91, batch 215/240:\tDiscriminator: real loss 0.08088240027427673, fake loss 0.2399546504020691\tGenerator: loss 9.907171249389648\n","Epoch 91, batch 216/240:\tDiscriminator: real loss 0.1225641667842865, fake loss 0.030564580112695694\tGenerator: loss 11.22683334350586\n","Epoch 91, batch 217/240:\tDiscriminator: real loss 0.08602715283632278, fake loss 0.23806920647621155\tGenerator: loss 11.391636848449707\n","Epoch 91, batch 218/240:\tDiscriminator: real loss 0.046028777956962585, fake loss 0.1661442369222641\tGenerator: loss 12.003671646118164\n","Epoch 91, batch 219/240:\tDiscriminator: real loss 0.1865631639957428, fake loss 0.063939668238163\tGenerator: loss 10.166131973266602\n","Epoch 91, batch 220/240:\tDiscriminator: real loss 0.07954572886228561, fake loss 0.10615825653076172\tGenerator: loss 10.126748085021973\n","Epoch 91, batch 221/240:\tDiscriminator: real loss 0.18088339269161224, fake loss 0.2829785943031311\tGenerator: loss 13.450267791748047\n","Epoch 91, batch 222/240:\tDiscriminator: real loss 0.057926617562770844, fake loss 0.09958039224147797\tGenerator: loss 17.061826705932617\n","Epoch 91, batch 223/240:\tDiscriminator: real loss 0.1122395321726799, fake loss 0.07917659729719162\tGenerator: loss 14.559266090393066\n","Epoch 91, batch 224/240:\tDiscriminator: real loss 0.06403034180402756, fake loss 0.3377031087875366\tGenerator: loss 14.472877502441406\n","Epoch 91, batch 225/240:\tDiscriminator: real loss 0.13294431567192078, fake loss 0.2098826915025711\tGenerator: loss 13.318597793579102\n","Epoch 91, batch 226/240:\tDiscriminator: real loss 0.09825561195611954, fake loss 0.21226876974105835\tGenerator: loss 13.799687385559082\n","Epoch 91, batch 227/240:\tDiscriminator: real loss 0.13423249125480652, fake loss 0.11488178372383118\tGenerator: loss 13.462518692016602\n","Epoch 91, batch 228/240:\tDiscriminator: real loss 0.2742152810096741, fake loss 0.18900269269943237\tGenerator: loss 12.851524353027344\n","Epoch 91, batch 229/240:\tDiscriminator: real loss 0.10408385097980499, fake loss 0.16479171812534332\tGenerator: loss 11.573741912841797\n","Epoch 91, batch 230/240:\tDiscriminator: real loss 0.07969226688146591, fake loss 0.14318431913852692\tGenerator: loss 12.029731750488281\n","Epoch 91, batch 231/240:\tDiscriminator: real loss 0.05713198706507683, fake loss 0.07026069611310959\tGenerator: loss 10.608734130859375\n","Epoch 91, batch 232/240:\tDiscriminator: real loss 0.05201621353626251, fake loss 0.1689426302909851\tGenerator: loss 12.476490020751953\n","Epoch 91, batch 233/240:\tDiscriminator: real loss 0.16658562421798706, fake loss 0.12772326171398163\tGenerator: loss 13.311662673950195\n","Epoch 91, batch 234/240:\tDiscriminator: real loss 0.12463892251253128, fake loss 0.16691793501377106\tGenerator: loss 11.592206954956055\n","Epoch 91, batch 235/240:\tDiscriminator: real loss 0.10446467995643616, fake loss 0.22564511001110077\tGenerator: loss 13.153573036193848\n","Epoch 91, batch 236/240:\tDiscriminator: real loss 0.08799846470355988, fake loss 0.1645093411207199\tGenerator: loss 11.44589614868164\n","Epoch 91, batch 237/240:\tDiscriminator: real loss 0.15390197932720184, fake loss 0.1881737858057022\tGenerator: loss 11.311566352844238\n","Epoch 91, batch 238/240:\tDiscriminator: real loss 0.084671251475811, fake loss 0.08753321319818497\tGenerator: loss 10.461578369140625\n","Epoch 91, batch 239/240:\tDiscriminator: real loss 0.12040980160236359, fake loss 0.2905571162700653\tGenerator: loss 11.210153579711914\n","Epoch 91, batch 240/240:\tDiscriminator: real loss 0.09588295221328735, fake loss 0.05178853124380112\tGenerator: loss 11.14402961730957\n","Epoch 92, batch 1/240:\tDiscriminator: real loss 0.11931821703910828, fake loss 0.11476700752973557\tGenerator: loss 10.576075553894043\n","Epoch 92, batch 2/240:\tDiscriminator: real loss 0.14133431017398834, fake loss 0.12056069076061249\tGenerator: loss 10.040011405944824\n","Epoch 92, batch 3/240:\tDiscriminator: real loss 0.06328537315130234, fake loss 0.18762001395225525\tGenerator: loss 11.046177864074707\n","Epoch 92, batch 4/240:\tDiscriminator: real loss 0.07352226972579956, fake loss 0.13764385879039764\tGenerator: loss 10.99338150024414\n","Epoch 92, batch 5/240:\tDiscriminator: real loss 0.12139788269996643, fake loss 0.08974821120500565\tGenerator: loss 10.221427917480469\n","Epoch 92, batch 6/240:\tDiscriminator: real loss 0.08517373353242874, fake loss 0.14916540682315826\tGenerator: loss 11.721363067626953\n","Epoch 92, batch 7/240:\tDiscriminator: real loss 0.14322319626808167, fake loss 0.19792993366718292\tGenerator: loss 8.609724044799805\n","Epoch 92, batch 8/240:\tDiscriminator: real loss 0.08477995544672012, fake loss 0.035895396023988724\tGenerator: loss 7.667581558227539\n","Epoch 92, batch 9/240:\tDiscriminator: real loss 0.09147527813911438, fake loss 0.11838933080434799\tGenerator: loss 9.347100257873535\n","Epoch 92, batch 10/240:\tDiscriminator: real loss 0.09612738341093063, fake loss 0.15548264980316162\tGenerator: loss 10.854065895080566\n","Epoch 92, batch 11/240:\tDiscriminator: real loss 0.08609995245933533, fake loss 0.23298583924770355\tGenerator: loss 12.162200927734375\n","Epoch 92, batch 12/240:\tDiscriminator: real loss 0.17629501223564148, fake loss 0.1968275010585785\tGenerator: loss 12.225594520568848\n","Epoch 92, batch 13/240:\tDiscriminator: real loss 0.2399487942457199, fake loss 0.08512634038925171\tGenerator: loss 11.547528266906738\n","Epoch 92, batch 14/240:\tDiscriminator: real loss 0.07093276083469391, fake loss 0.1680605560541153\tGenerator: loss 11.04806900024414\n","Epoch 92, batch 15/240:\tDiscriminator: real loss 0.08524683117866516, fake loss 0.1037478819489479\tGenerator: loss 11.763339042663574\n","Epoch 92, batch 16/240:\tDiscriminator: real loss 0.10310476273298264, fake loss 0.05856432020664215\tGenerator: loss 10.951813697814941\n","Epoch 92, batch 17/240:\tDiscriminator: real loss 0.04669685661792755, fake loss 0.13985630869865417\tGenerator: loss 10.958335876464844\n","Epoch 92, batch 18/240:\tDiscriminator: real loss 0.1232430711388588, fake loss 0.16639778017997742\tGenerator: loss 10.048248291015625\n","Epoch 92, batch 19/240:\tDiscriminator: real loss 0.0848151370882988, fake loss 0.07573627680540085\tGenerator: loss 11.633249282836914\n","Epoch 92, batch 20/240:\tDiscriminator: real loss 0.06074589118361473, fake loss 0.17418883740901947\tGenerator: loss 12.737508773803711\n","Epoch 92, batch 21/240:\tDiscriminator: real loss 0.15879406034946442, fake loss 0.15960513055324554\tGenerator: loss 11.406468391418457\n","Epoch 92, batch 22/240:\tDiscriminator: real loss 0.08446219563484192, fake loss 0.006152115296572447\tGenerator: loss 9.508231163024902\n","Epoch 92, batch 23/240:\tDiscriminator: real loss 0.21892152726650238, fake loss 0.12513530254364014\tGenerator: loss 11.069519996643066\n","Epoch 92, batch 24/240:\tDiscriminator: real loss 0.02836013399064541, fake loss 0.2543632388114929\tGenerator: loss 13.197630882263184\n","Epoch 92, batch 25/240:\tDiscriminator: real loss 0.06599348038434982, fake loss 0.20755115151405334\tGenerator: loss 13.229747772216797\n","Epoch 92, batch 26/240:\tDiscriminator: real loss 0.1699008345603943, fake loss 0.08752904832363129\tGenerator: loss 12.584275245666504\n","Epoch 92, batch 27/240:\tDiscriminator: real loss 0.1461813896894455, fake loss 0.19830326735973358\tGenerator: loss 11.894733428955078\n","Epoch 92, batch 28/240:\tDiscriminator: real loss 0.0687645748257637, fake loss 0.18967995047569275\tGenerator: loss 10.14535140991211\n","Epoch 92, batch 29/240:\tDiscriminator: real loss 0.13860227167606354, fake loss 0.07102534174919128\tGenerator: loss 9.706984519958496\n","Epoch 92, batch 30/240:\tDiscriminator: real loss 0.10514229536056519, fake loss 0.21970634162425995\tGenerator: loss 10.550519943237305\n","Epoch 92, batch 31/240:\tDiscriminator: real loss 0.048118047416210175, fake loss 0.12013354897499084\tGenerator: loss 11.778039932250977\n","Epoch 92, batch 32/240:\tDiscriminator: real loss 0.16589796543121338, fake loss 0.13628320395946503\tGenerator: loss 11.533617973327637\n","Epoch 92, batch 33/240:\tDiscriminator: real loss 0.14051848649978638, fake loss 0.16802145540714264\tGenerator: loss 10.765776634216309\n","Epoch 92, batch 34/240:\tDiscriminator: real loss 0.061165761202573776, fake loss 0.11155534535646439\tGenerator: loss 12.445422172546387\n","Epoch 92, batch 35/240:\tDiscriminator: real loss 0.1291998326778412, fake loss 0.0913800448179245\tGenerator: loss 12.462785720825195\n","Epoch 92, batch 36/240:\tDiscriminator: real loss 0.04604456573724747, fake loss 0.09994851052761078\tGenerator: loss 12.891146659851074\n","Epoch 92, batch 37/240:\tDiscriminator: real loss 0.06973860412836075, fake loss 0.08540323376655579\tGenerator: loss 11.706354141235352\n","Epoch 92, batch 38/240:\tDiscriminator: real loss 0.10008011758327484, fake loss 0.15644550323486328\tGenerator: loss 10.403972625732422\n","Epoch 92, batch 39/240:\tDiscriminator: real loss 0.06969502568244934, fake loss 0.13618798553943634\tGenerator: loss 10.331277847290039\n","Epoch 92, batch 40/240:\tDiscriminator: real loss 0.16843624413013458, fake loss 0.06328999996185303\tGenerator: loss 11.138916969299316\n","Epoch 92, batch 41/240:\tDiscriminator: real loss 0.10615053027868271, fake loss 0.23533043265342712\tGenerator: loss 12.840981483459473\n","Epoch 92, batch 42/240:\tDiscriminator: real loss 0.10351375490427017, fake loss 0.14238621294498444\tGenerator: loss 11.979914665222168\n","Epoch 92, batch 43/240:\tDiscriminator: real loss 0.08109176903963089, fake loss 0.19242088496685028\tGenerator: loss 11.465130805969238\n","Epoch 92, batch 44/240:\tDiscriminator: real loss 0.12332023680210114, fake loss 0.08545936644077301\tGenerator: loss 10.234246253967285\n","Epoch 92, batch 45/240:\tDiscriminator: real loss 0.07452444732189178, fake loss 0.15510064363479614\tGenerator: loss 10.052562713623047\n","Epoch 92, batch 46/240:\tDiscriminator: real loss 0.17284400761127472, fake loss 0.09192052483558655\tGenerator: loss 8.664813041687012\n","Epoch 92, batch 47/240:\tDiscriminator: real loss 0.07777777314186096, fake loss 0.20047393441200256\tGenerator: loss 9.321791648864746\n","Epoch 92, batch 48/240:\tDiscriminator: real loss 0.121136873960495, fake loss 0.14108477532863617\tGenerator: loss 11.567980766296387\n","Epoch 92, batch 49/240:\tDiscriminator: real loss 0.08452119678258896, fake loss 0.07549925893545151\tGenerator: loss 11.040501594543457\n","Epoch 92, batch 50/240:\tDiscriminator: real loss 0.17473286390304565, fake loss 0.13624832034111023\tGenerator: loss 12.273154258728027\n","Epoch 92, batch 51/240:\tDiscriminator: real loss 0.028142891824245453, fake loss 0.17742817103862762\tGenerator: loss 13.60900592803955\n","Epoch 92, batch 52/240:\tDiscriminator: real loss 0.13036136329174042, fake loss 0.13748224079608917\tGenerator: loss 16.034263610839844\n","Epoch 92, batch 53/240:\tDiscriminator: real loss 0.08950063586235046, fake loss 0.2093500941991806\tGenerator: loss 16.441184997558594\n","Epoch 92, batch 54/240:\tDiscriminator: real loss 0.15429174900054932, fake loss 0.17982134222984314\tGenerator: loss 14.254555702209473\n","Epoch 92, batch 55/240:\tDiscriminator: real loss 0.1222350150346756, fake loss 0.15894366800785065\tGenerator: loss 11.940378189086914\n","Epoch 92, batch 56/240:\tDiscriminator: real loss 0.10779868811368942, fake loss 0.10458669066429138\tGenerator: loss 13.94216537475586\n","Epoch 92, batch 57/240:\tDiscriminator: real loss 0.06999106705188751, fake loss 0.11582354456186295\tGenerator: loss 12.850533485412598\n","Epoch 92, batch 58/240:\tDiscriminator: real loss 0.12777145206928253, fake loss 0.0643777921795845\tGenerator: loss 12.151985168457031\n","Epoch 92, batch 59/240:\tDiscriminator: real loss 0.04239318519830704, fake loss 0.29469090700149536\tGenerator: loss 13.874072074890137\n","Epoch 92, batch 60/240:\tDiscriminator: real loss 0.13368503749370575, fake loss 0.10049070417881012\tGenerator: loss 14.003501892089844\n","Epoch 92, batch 61/240:\tDiscriminator: real loss 0.18722252547740936, fake loss 0.2023700773715973\tGenerator: loss 11.106853485107422\n","Epoch 92, batch 62/240:\tDiscriminator: real loss 0.0993078425526619, fake loss 0.0489366389811039\tGenerator: loss 11.454212188720703\n","Epoch 92, batch 63/240:\tDiscriminator: real loss 0.0677526667714119, fake loss 0.161027729511261\tGenerator: loss 13.362486839294434\n","Epoch 92, batch 64/240:\tDiscriminator: real loss 0.061888281255960464, fake loss 0.16006392240524292\tGenerator: loss 15.227591514587402\n","Epoch 92, batch 65/240:\tDiscriminator: real loss 0.1312340497970581, fake loss 0.14388975501060486\tGenerator: loss 12.151300430297852\n","Epoch 92, batch 66/240:\tDiscriminator: real loss 0.18644265830516815, fake loss 0.1078898012638092\tGenerator: loss 11.290910720825195\n","Epoch 92, batch 67/240:\tDiscriminator: real loss 0.05110156163573265, fake loss 0.22280238568782806\tGenerator: loss 11.987125396728516\n","Epoch 92, batch 68/240:\tDiscriminator: real loss 0.12337186932563782, fake loss 0.24734117090702057\tGenerator: loss 10.73959732055664\n","Epoch 92, batch 69/240:\tDiscriminator: real loss 0.18285681307315826, fake loss 0.1289302259683609\tGenerator: loss 10.956149101257324\n","Epoch 92, batch 70/240:\tDiscriminator: real loss 0.1843239665031433, fake loss 0.17152118682861328\tGenerator: loss 10.198036193847656\n","Epoch 92, batch 71/240:\tDiscriminator: real loss 0.07390674948692322, fake loss 0.13482804596424103\tGenerator: loss 10.245458602905273\n","Epoch 92, batch 72/240:\tDiscriminator: real loss 0.13339745998382568, fake loss 0.1516837328672409\tGenerator: loss 11.007226943969727\n","Epoch 92, batch 73/240:\tDiscriminator: real loss 0.10966818034648895, fake loss 0.07885801047086716\tGenerator: loss 9.96609115600586\n","Epoch 92, batch 74/240:\tDiscriminator: real loss 0.0671769455075264, fake loss 0.2827140688896179\tGenerator: loss 10.387115478515625\n","Epoch 92, batch 75/240:\tDiscriminator: real loss 0.21250736713409424, fake loss 0.24189861118793488\tGenerator: loss 11.966670989990234\n","Epoch 92, batch 76/240:\tDiscriminator: real loss 0.2414974570274353, fake loss 0.07161840796470642\tGenerator: loss 10.681916236877441\n","Epoch 92, batch 77/240:\tDiscriminator: real loss 0.04047577828168869, fake loss 0.19121713936328888\tGenerator: loss 11.33003044128418\n","Epoch 92, batch 78/240:\tDiscriminator: real loss 0.06613967567682266, fake loss 0.10382253676652908\tGenerator: loss 9.501992225646973\n","Epoch 92, batch 79/240:\tDiscriminator: real loss 0.10698685795068741, fake loss 0.14129459857940674\tGenerator: loss 13.180258750915527\n","Epoch 92, batch 80/240:\tDiscriminator: real loss 0.0928405374288559, fake loss 0.11242733895778656\tGenerator: loss 14.28454303741455\n","Epoch 92, batch 81/240:\tDiscriminator: real loss 0.11065580695867538, fake loss 0.08740554004907608\tGenerator: loss 12.836626052856445\n","Epoch 92, batch 82/240:\tDiscriminator: real loss 0.032246146351099014, fake loss 0.10386435687541962\tGenerator: loss 13.835840225219727\n","Epoch 92, batch 83/240:\tDiscriminator: real loss 0.12608566880226135, fake loss 0.33915451169013977\tGenerator: loss 12.642356872558594\n","Epoch 92, batch 84/240:\tDiscriminator: real loss 0.10936857014894485, fake loss 0.1148705929517746\tGenerator: loss 11.805468559265137\n","Epoch 92, batch 85/240:\tDiscriminator: real loss 0.10276748985052109, fake loss 0.11501172184944153\tGenerator: loss 12.85029411315918\n","Epoch 92, batch 86/240:\tDiscriminator: real loss 0.08887522667646408, fake loss 0.3285953402519226\tGenerator: loss 12.005125999450684\n","Epoch 92, batch 87/240:\tDiscriminator: real loss 0.15826231241226196, fake loss 0.0755026564002037\tGenerator: loss 11.570028305053711\n","Epoch 92, batch 88/240:\tDiscriminator: real loss 0.10522518306970596, fake loss 0.09178543090820312\tGenerator: loss 11.495977401733398\n","Epoch 92, batch 89/240:\tDiscriminator: real loss 0.1326659619808197, fake loss 0.25406739115715027\tGenerator: loss 11.328125\n","Epoch 92, batch 90/240:\tDiscriminator: real loss 0.0936337262392044, fake loss 0.10357074439525604\tGenerator: loss 12.764897346496582\n","Epoch 92, batch 91/240:\tDiscriminator: real loss 0.11564179509878159, fake loss 0.23616331815719604\tGenerator: loss 12.496284484863281\n","Epoch 92, batch 92/240:\tDiscriminator: real loss 0.13290990889072418, fake loss 0.06511079519987106\tGenerator: loss 12.947492599487305\n","Epoch 92, batch 93/240:\tDiscriminator: real loss 0.12332306057214737, fake loss 0.18103362619876862\tGenerator: loss 10.843481063842773\n","Epoch 92, batch 94/240:\tDiscriminator: real loss 0.09251956641674042, fake loss 0.06068161502480507\tGenerator: loss 10.818277359008789\n","Epoch 92, batch 95/240:\tDiscriminator: real loss 0.10526755452156067, fake loss 0.26636362075805664\tGenerator: loss 10.697608947753906\n","Epoch 92, batch 96/240:\tDiscriminator: real loss 0.08244279772043228, fake loss 0.15034888684749603\tGenerator: loss 12.222580909729004\n","Epoch 92, batch 97/240:\tDiscriminator: real loss 0.23594027757644653, fake loss 0.11368405073881149\tGenerator: loss 12.531170845031738\n","Epoch 92, batch 98/240:\tDiscriminator: real loss 0.06090457737445831, fake loss 0.07015035301446915\tGenerator: loss 13.380677223205566\n","Epoch 92, batch 99/240:\tDiscriminator: real loss 0.1646115928888321, fake loss 0.24713154137134552\tGenerator: loss 11.497130393981934\n","Epoch 92, batch 100/240:\tDiscriminator: real loss 0.08593427389860153, fake loss 0.09049329906702042\tGenerator: loss 10.886717796325684\n","Epoch 92, batch 101/240:\tDiscriminator: real loss 0.10301215946674347, fake loss 0.3618311285972595\tGenerator: loss 13.147655487060547\n","Epoch 92, batch 102/240:\tDiscriminator: real loss 0.16837194561958313, fake loss 0.09762859344482422\tGenerator: loss 12.193520545959473\n","Epoch 92, batch 103/240:\tDiscriminator: real loss 0.21646225452423096, fake loss 0.215067520737648\tGenerator: loss 12.053382873535156\n","Epoch 92, batch 104/240:\tDiscriminator: real loss 0.07930578291416168, fake loss 0.1695639044046402\tGenerator: loss 12.776541709899902\n","Epoch 92, batch 105/240:\tDiscriminator: real loss 0.1166706383228302, fake loss 0.18440718948841095\tGenerator: loss 11.756141662597656\n","Epoch 92, batch 106/240:\tDiscriminator: real loss 0.10502831637859344, fake loss 0.1945764720439911\tGenerator: loss 11.924036979675293\n","Epoch 92, batch 107/240:\tDiscriminator: real loss 0.13863950967788696, fake loss 0.17427244782447815\tGenerator: loss 12.396941184997559\n","Epoch 92, batch 108/240:\tDiscriminator: real loss 0.11903584748506546, fake loss 0.07197590172290802\tGenerator: loss 13.340622901916504\n","Epoch 92, batch 109/240:\tDiscriminator: real loss 0.147351935505867, fake loss 0.21190044283866882\tGenerator: loss 13.459674835205078\n","Epoch 92, batch 110/240:\tDiscriminator: real loss 0.11501527577638626, fake loss 0.17740672826766968\tGenerator: loss 14.704416275024414\n","Epoch 92, batch 111/240:\tDiscriminator: real loss 0.06548807770013809, fake loss 0.07031155377626419\tGenerator: loss 13.871310234069824\n","Epoch 92, batch 112/240:\tDiscriminator: real loss 0.10404306650161743, fake loss 0.10828477144241333\tGenerator: loss 12.320965766906738\n","Epoch 92, batch 113/240:\tDiscriminator: real loss 0.05545393005013466, fake loss 0.27089837193489075\tGenerator: loss 14.061119079589844\n","Epoch 92, batch 114/240:\tDiscriminator: real loss 0.1678621470928192, fake loss 0.20996524393558502\tGenerator: loss 14.88806438446045\n","Epoch 92, batch 115/240:\tDiscriminator: real loss 0.2808557450771332, fake loss 0.22394981980323792\tGenerator: loss 12.125761985778809\n","Epoch 92, batch 116/240:\tDiscriminator: real loss 0.1673269271850586, fake loss 0.11288785934448242\tGenerator: loss 11.358367919921875\n","Epoch 92, batch 117/240:\tDiscriminator: real loss 0.11873115599155426, fake loss 0.177677720785141\tGenerator: loss 11.63302993774414\n","Epoch 92, batch 118/240:\tDiscriminator: real loss 0.08769049495458603, fake loss 0.05398118123412132\tGenerator: loss 10.850388526916504\n","Epoch 92, batch 119/240:\tDiscriminator: real loss 0.11482167989015579, fake loss 0.18437765538692474\tGenerator: loss 10.505359649658203\n","Epoch 92, batch 120/240:\tDiscriminator: real loss 0.0782231017947197, fake loss 0.21029667556285858\tGenerator: loss 10.892542839050293\n","Epoch 92, batch 121/240:\tDiscriminator: real loss 0.08898065239191055, fake loss 0.2091667503118515\tGenerator: loss 12.717233657836914\n","Epoch 92, batch 122/240:\tDiscriminator: real loss 0.12143880873918533, fake loss 0.06650067120790482\tGenerator: loss 12.290519714355469\n","Epoch 92, batch 123/240:\tDiscriminator: real loss 0.1939966231584549, fake loss 0.09832153469324112\tGenerator: loss 12.768082618713379\n","Epoch 92, batch 124/240:\tDiscriminator: real loss 0.12367132306098938, fake loss 0.23583689332008362\tGenerator: loss 13.431447982788086\n","Epoch 92, batch 125/240:\tDiscriminator: real loss 0.08059484511613846, fake loss 0.11666423827409744\tGenerator: loss 13.160510063171387\n","Epoch 92, batch 126/240:\tDiscriminator: real loss 0.11504118889570236, fake loss 0.14858506619930267\tGenerator: loss 11.789209365844727\n","Epoch 92, batch 127/240:\tDiscriminator: real loss 0.08125493675470352, fake loss 0.1408219188451767\tGenerator: loss 12.808568000793457\n","Epoch 92, batch 128/240:\tDiscriminator: real loss 0.14942201972007751, fake loss 0.25569087266921997\tGenerator: loss 15.393978118896484\n","Epoch 92, batch 129/240:\tDiscriminator: real loss 0.09272398054599762, fake loss 0.19181804358959198\tGenerator: loss 13.627305030822754\n","Epoch 92, batch 130/240:\tDiscriminator: real loss 0.09124206751585007, fake loss 0.05719827488064766\tGenerator: loss 13.672513008117676\n","Epoch 92, batch 131/240:\tDiscriminator: real loss 0.11291837692260742, fake loss 0.12987887859344482\tGenerator: loss 12.5438871383667\n","Epoch 92, batch 132/240:\tDiscriminator: real loss 0.12344834208488464, fake loss 0.1751069277524948\tGenerator: loss 12.372775077819824\n","Epoch 92, batch 133/240:\tDiscriminator: real loss 0.0677580013871193, fake loss 0.09192463755607605\tGenerator: loss 12.292987823486328\n","Epoch 92, batch 134/240:\tDiscriminator: real loss 0.08043373376131058, fake loss 0.10664983093738556\tGenerator: loss 12.53481674194336\n","Epoch 92, batch 135/240:\tDiscriminator: real loss 0.09880511462688446, fake loss 0.25676628947257996\tGenerator: loss 10.974664688110352\n","Epoch 92, batch 136/240:\tDiscriminator: real loss 0.1145908385515213, fake loss 0.14305974543094635\tGenerator: loss 12.139578819274902\n","Epoch 92, batch 137/240:\tDiscriminator: real loss 0.15814299881458282, fake loss 0.1339189112186432\tGenerator: loss 12.540745735168457\n","Epoch 92, batch 138/240:\tDiscriminator: real loss 0.12925994396209717, fake loss 0.21195246279239655\tGenerator: loss 11.813028335571289\n","Epoch 92, batch 139/240:\tDiscriminator: real loss 0.135271355509758, fake loss 0.1581704467535019\tGenerator: loss 13.71959114074707\n","Epoch 92, batch 140/240:\tDiscriminator: real loss 0.19941119849681854, fake loss 0.06796469539403915\tGenerator: loss 11.01865005493164\n","Epoch 92, batch 141/240:\tDiscriminator: real loss 0.06507152318954468, fake loss 0.05752916261553764\tGenerator: loss 9.711146354675293\n","Epoch 92, batch 142/240:\tDiscriminator: real loss 0.07548508048057556, fake loss 0.26604485511779785\tGenerator: loss 9.24081802368164\n","Epoch 92, batch 143/240:\tDiscriminator: real loss 0.03778712823987007, fake loss 0.05974734202027321\tGenerator: loss 10.508949279785156\n","Epoch 92, batch 144/240:\tDiscriminator: real loss 0.32755959033966064, fake loss 0.1605713665485382\tGenerator: loss 11.2133150100708\n","Epoch 92, batch 145/240:\tDiscriminator: real loss 0.10929055511951447, fake loss 0.39615398645401\tGenerator: loss 12.332061767578125\n","Epoch 92, batch 146/240:\tDiscriminator: real loss 0.08788634091615677, fake loss 0.18290595710277557\tGenerator: loss 11.77017593383789\n","Epoch 92, batch 147/240:\tDiscriminator: real loss 0.23245029151439667, fake loss 0.029619891196489334\tGenerator: loss 8.65703010559082\n","Epoch 92, batch 148/240:\tDiscriminator: real loss 0.04092421010136604, fake loss 0.18285593390464783\tGenerator: loss 8.963517189025879\n","Epoch 92, batch 149/240:\tDiscriminator: real loss 0.09686078876256943, fake loss 0.15860912203788757\tGenerator: loss 11.772479057312012\n","Epoch 92, batch 150/240:\tDiscriminator: real loss 0.11711744964122772, fake loss 0.1830875277519226\tGenerator: loss 11.49604606628418\n","Epoch 92, batch 151/240:\tDiscriminator: real loss 0.12051854282617569, fake loss 0.13456511497497559\tGenerator: loss 10.262182235717773\n","Epoch 92, batch 152/240:\tDiscriminator: real loss 0.07064510881900787, fake loss 0.15071983635425568\tGenerator: loss 10.512452125549316\n","Epoch 92, batch 153/240:\tDiscriminator: real loss 0.11944259703159332, fake loss 0.15629278123378754\tGenerator: loss 9.512823104858398\n","Epoch 92, batch 154/240:\tDiscriminator: real loss 0.17285510897636414, fake loss 0.10477307438850403\tGenerator: loss 10.532153129577637\n","Epoch 92, batch 155/240:\tDiscriminator: real loss 0.06300429254770279, fake loss 0.06911156326532364\tGenerator: loss 10.322216033935547\n","Epoch 92, batch 156/240:\tDiscriminator: real loss 0.08717994391918182, fake loss 0.22530311346054077\tGenerator: loss 11.810259819030762\n","Epoch 92, batch 157/240:\tDiscriminator: real loss 0.061345815658569336, fake loss 0.09520254284143448\tGenerator: loss 11.928797721862793\n","Epoch 92, batch 158/240:\tDiscriminator: real loss 0.14565801620483398, fake loss 0.18813887238502502\tGenerator: loss 11.764887809753418\n","Epoch 92, batch 159/240:\tDiscriminator: real loss 0.16571088135242462, fake loss 0.22136059403419495\tGenerator: loss 12.123019218444824\n","Epoch 92, batch 160/240:\tDiscriminator: real loss 0.18016572296619415, fake loss 0.050665076822042465\tGenerator: loss 11.589385986328125\n","Epoch 92, batch 161/240:\tDiscriminator: real loss 0.16452081501483917, fake loss 0.4343041181564331\tGenerator: loss 14.581106185913086\n","Epoch 92, batch 162/240:\tDiscriminator: real loss 0.13614661991596222, fake loss 0.18834657967090607\tGenerator: loss 16.282211303710938\n","Epoch 92, batch 163/240:\tDiscriminator: real loss 0.16657942533493042, fake loss 0.12162276357412338\tGenerator: loss 12.059708595275879\n","Epoch 92, batch 164/240:\tDiscriminator: real loss 0.08276231586933136, fake loss 0.1514625996351242\tGenerator: loss 11.86357307434082\n","Epoch 92, batch 165/240:\tDiscriminator: real loss 0.07199013978242874, fake loss 0.165493443608284\tGenerator: loss 12.266029357910156\n","Epoch 92, batch 166/240:\tDiscriminator: real loss 0.2334606945514679, fake loss 0.11975975334644318\tGenerator: loss 10.704856872558594\n","Epoch 92, batch 167/240:\tDiscriminator: real loss 0.06508038192987442, fake loss 0.22452445328235626\tGenerator: loss 11.920158386230469\n","Epoch 92, batch 168/240:\tDiscriminator: real loss 0.15101507306098938, fake loss 0.13565954566001892\tGenerator: loss 12.271510124206543\n","Epoch 92, batch 169/240:\tDiscriminator: real loss 0.05534873530268669, fake loss 0.14566880464553833\tGenerator: loss 11.808154106140137\n","Epoch 92, batch 170/240:\tDiscriminator: real loss 0.11709103733301163, fake loss 0.16636711359024048\tGenerator: loss 12.877934455871582\n","Epoch 92, batch 171/240:\tDiscriminator: real loss 0.11872360110282898, fake loss 0.3035773038864136\tGenerator: loss 11.532600402832031\n","Epoch 92, batch 172/240:\tDiscriminator: real loss 0.2913244366645813, fake loss 0.16853080689907074\tGenerator: loss 9.624805450439453\n","Epoch 92, batch 173/240:\tDiscriminator: real loss 0.08694349974393845, fake loss 0.15066099166870117\tGenerator: loss 10.9495267868042\n","Epoch 92, batch 174/240:\tDiscriminator: real loss 0.14955316483974457, fake loss 0.12958577275276184\tGenerator: loss 9.565524101257324\n","Epoch 92, batch 175/240:\tDiscriminator: real loss 0.0844859704375267, fake loss 0.07146728783845901\tGenerator: loss 11.153491020202637\n","Epoch 92, batch 176/240:\tDiscriminator: real loss 0.08171284943819046, fake loss 0.09340736269950867\tGenerator: loss 11.375831604003906\n","Epoch 92, batch 177/240:\tDiscriminator: real loss 0.05193750560283661, fake loss 0.13758786022663116\tGenerator: loss 11.766132354736328\n","Epoch 92, batch 178/240:\tDiscriminator: real loss 0.057927455753088, fake loss 0.14642125368118286\tGenerator: loss 11.441100120544434\n","Epoch 92, batch 179/240:\tDiscriminator: real loss 0.08652997016906738, fake loss 0.05170663818717003\tGenerator: loss 10.832938194274902\n","Epoch 92, batch 180/240:\tDiscriminator: real loss 0.09779082983732224, fake loss 0.2857006788253784\tGenerator: loss 12.296381950378418\n","Epoch 92, batch 181/240:\tDiscriminator: real loss 0.10564473271369934, fake loss 0.2151535451412201\tGenerator: loss 12.751864433288574\n","Epoch 92, batch 182/240:\tDiscriminator: real loss 0.1311836689710617, fake loss 0.1327279806137085\tGenerator: loss 12.643512725830078\n","Epoch 92, batch 183/240:\tDiscriminator: real loss 0.1601153016090393, fake loss 0.09688974171876907\tGenerator: loss 11.585902214050293\n","Epoch 92, batch 184/240:\tDiscriminator: real loss 0.13874784111976624, fake loss 0.1923452764749527\tGenerator: loss 10.98486614227295\n","Epoch 92, batch 185/240:\tDiscriminator: real loss 0.10667230933904648, fake loss 0.28645843267440796\tGenerator: loss 12.550856590270996\n","Epoch 92, batch 186/240:\tDiscriminator: real loss 0.115643709897995, fake loss 0.10652466118335724\tGenerator: loss 12.999189376831055\n","Epoch 92, batch 187/240:\tDiscriminator: real loss 0.14284345507621765, fake loss 0.1608712524175644\tGenerator: loss 10.139182090759277\n","Epoch 92, batch 188/240:\tDiscriminator: real loss 0.09740516543388367, fake loss 0.24950386583805084\tGenerator: loss 11.911181449890137\n","Epoch 92, batch 189/240:\tDiscriminator: real loss 0.20381931960582733, fake loss 0.18973147869110107\tGenerator: loss 12.974346160888672\n","Epoch 92, batch 190/240:\tDiscriminator: real loss 0.10360045731067657, fake loss 0.2147199809551239\tGenerator: loss 12.067113876342773\n","Epoch 92, batch 191/240:\tDiscriminator: real loss 0.11208909004926682, fake loss 0.19408464431762695\tGenerator: loss 13.382481575012207\n","Epoch 92, batch 192/240:\tDiscriminator: real loss 0.25124552845954895, fake loss 0.13045328855514526\tGenerator: loss 11.93065071105957\n","Epoch 92, batch 193/240:\tDiscriminator: real loss 0.10020044445991516, fake loss 0.20531339943408966\tGenerator: loss 12.506972312927246\n","Epoch 92, batch 194/240:\tDiscriminator: real loss 0.11012573540210724, fake loss 0.16201335191726685\tGenerator: loss 12.416038513183594\n","Epoch 92, batch 195/240:\tDiscriminator: real loss 0.17798498272895813, fake loss 0.14961831271648407\tGenerator: loss 13.145750999450684\n","Epoch 92, batch 196/240:\tDiscriminator: real loss 0.13162608444690704, fake loss 0.1569114625453949\tGenerator: loss 13.973052978515625\n","Epoch 92, batch 197/240:\tDiscriminator: real loss 0.07495719194412231, fake loss 0.06105224788188934\tGenerator: loss 16.347824096679688\n","Epoch 92, batch 198/240:\tDiscriminator: real loss 0.12346094101667404, fake loss 0.26250922679901123\tGenerator: loss 14.060962677001953\n","Epoch 92, batch 199/240:\tDiscriminator: real loss 0.12712088227272034, fake loss 0.17041634023189545\tGenerator: loss 13.584036827087402\n","Epoch 92, batch 200/240:\tDiscriminator: real loss 0.10288030654191971, fake loss 0.1318526417016983\tGenerator: loss 13.441429138183594\n","Epoch 92, batch 201/240:\tDiscriminator: real loss 0.15317994356155396, fake loss 0.3635782301425934\tGenerator: loss 13.903029441833496\n","Epoch 92, batch 202/240:\tDiscriminator: real loss 0.22398346662521362, fake loss 0.07275746017694473\tGenerator: loss 13.024889945983887\n","Epoch 92, batch 203/240:\tDiscriminator: real loss 0.12505097687244415, fake loss 0.11747383326292038\tGenerator: loss 10.996720314025879\n","Epoch 92, batch 204/240:\tDiscriminator: real loss 0.06157192215323448, fake loss 0.46617698669433594\tGenerator: loss 11.704690933227539\n","Epoch 92, batch 205/240:\tDiscriminator: real loss 0.17447681725025177, fake loss 0.18701907992362976\tGenerator: loss 13.193389892578125\n","Epoch 92, batch 206/240:\tDiscriminator: real loss 0.16731125116348267, fake loss 0.12065540254116058\tGenerator: loss 11.868464469909668\n","Epoch 92, batch 207/240:\tDiscriminator: real loss 0.2480807900428772, fake loss 0.21040008962154388\tGenerator: loss 11.097397804260254\n","Epoch 92, batch 208/240:\tDiscriminator: real loss 0.10669796913862228, fake loss 0.14132097363471985\tGenerator: loss 11.433646202087402\n","Epoch 92, batch 209/240:\tDiscriminator: real loss 0.14795738458633423, fake loss 0.128193199634552\tGenerator: loss 12.190567970275879\n","Epoch 92, batch 210/240:\tDiscriminator: real loss 0.13162460923194885, fake loss 0.11189296841621399\tGenerator: loss 11.589001655578613\n","Epoch 92, batch 211/240:\tDiscriminator: real loss 0.10263173282146454, fake loss 0.2504584789276123\tGenerator: loss 11.602970123291016\n","Epoch 92, batch 212/240:\tDiscriminator: real loss 0.07357661426067352, fake loss 0.1295107901096344\tGenerator: loss 8.995037078857422\n","Epoch 92, batch 213/240:\tDiscriminator: real loss 0.09017638862133026, fake loss 0.05504266917705536\tGenerator: loss 11.709593772888184\n","Epoch 92, batch 214/240:\tDiscriminator: real loss 0.11746475100517273, fake loss 0.2384219765663147\tGenerator: loss 12.893436431884766\n","Epoch 92, batch 215/240:\tDiscriminator: real loss 0.12607406079769135, fake loss 0.08519716560840607\tGenerator: loss 13.607044219970703\n","Epoch 92, batch 216/240:\tDiscriminator: real loss 0.059898920357227325, fake loss 0.22859089076519012\tGenerator: loss 14.806855201721191\n","Epoch 92, batch 217/240:\tDiscriminator: real loss 0.18954017758369446, fake loss 0.07619420439004898\tGenerator: loss 11.7301664352417\n","Epoch 92, batch 218/240:\tDiscriminator: real loss 0.1614806354045868, fake loss 0.25346556305885315\tGenerator: loss 10.359314918518066\n","Epoch 92, batch 219/240:\tDiscriminator: real loss 0.12054844200611115, fake loss 0.34616169333457947\tGenerator: loss 13.557150840759277\n","Epoch 92, batch 220/240:\tDiscriminator: real loss 0.2744995355606079, fake loss 0.12308019399642944\tGenerator: loss 11.923174858093262\n","Epoch 92, batch 221/240:\tDiscriminator: real loss 0.16183215379714966, fake loss 0.2630470395088196\tGenerator: loss 11.1570405960083\n","Epoch 92, batch 222/240:\tDiscriminator: real loss 0.22319212555885315, fake loss 0.18426552414894104\tGenerator: loss 11.822726249694824\n","Epoch 92, batch 223/240:\tDiscriminator: real loss 0.09520488977432251, fake loss 0.06717279553413391\tGenerator: loss 12.493206024169922\n","Epoch 92, batch 224/240:\tDiscriminator: real loss 0.06912773102521896, fake loss 0.18857698142528534\tGenerator: loss 12.18041706085205\n","Epoch 92, batch 225/240:\tDiscriminator: real loss 0.10216788947582245, fake loss 0.2027987241744995\tGenerator: loss 11.318568229675293\n","Epoch 92, batch 226/240:\tDiscriminator: real loss 0.08020216226577759, fake loss 0.06692717224359512\tGenerator: loss 10.058389663696289\n","Epoch 92, batch 227/240:\tDiscriminator: real loss 0.18093009293079376, fake loss 0.23100022971630096\tGenerator: loss 11.219311714172363\n","Epoch 92, batch 228/240:\tDiscriminator: real loss 0.1364974081516266, fake loss 0.07625482231378555\tGenerator: loss 11.077335357666016\n","Epoch 92, batch 229/240:\tDiscriminator: real loss 0.09560037404298782, fake loss 0.2307359278202057\tGenerator: loss 10.481356620788574\n","Epoch 92, batch 230/240:\tDiscriminator: real loss 0.144097238779068, fake loss 0.09874309599399567\tGenerator: loss 9.095817565917969\n","Epoch 92, batch 231/240:\tDiscriminator: real loss 0.13786841928958893, fake loss 0.06994275003671646\tGenerator: loss 9.541813850402832\n","Epoch 92, batch 232/240:\tDiscriminator: real loss 0.05797642841935158, fake loss 0.19773000478744507\tGenerator: loss 9.676043510437012\n","Epoch 92, batch 233/240:\tDiscriminator: real loss 0.1347237229347229, fake loss 0.047710880637168884\tGenerator: loss 11.50442886352539\n","Epoch 92, batch 234/240:\tDiscriminator: real loss 0.08819682151079178, fake loss 0.2027447372674942\tGenerator: loss 10.809391021728516\n","Epoch 92, batch 235/240:\tDiscriminator: real loss 0.06965578347444534, fake loss 0.06685283035039902\tGenerator: loss 12.870285987854004\n","Epoch 92, batch 236/240:\tDiscriminator: real loss 0.12413261085748672, fake loss 0.39947593212127686\tGenerator: loss 15.054298400878906\n","Epoch 92, batch 237/240:\tDiscriminator: real loss 0.23309825360774994, fake loss 0.054804373532533646\tGenerator: loss 11.890493392944336\n","Epoch 92, batch 238/240:\tDiscriminator: real loss 0.18922168016433716, fake loss 0.2020338475704193\tGenerator: loss 9.786439895629883\n","Epoch 92, batch 239/240:\tDiscriminator: real loss 0.07516669481992722, fake loss 0.22952575981616974\tGenerator: loss 9.991325378417969\n","Epoch 92, batch 240/240:\tDiscriminator: real loss 0.06914544105529785, fake loss 0.08632108569145203\tGenerator: loss 9.944050788879395\n","Epoch 93, batch 1/240:\tDiscriminator: real loss 0.12800359725952148, fake loss 0.12879568338394165\tGenerator: loss 11.823515892028809\n","Epoch 93, batch 2/240:\tDiscriminator: real loss 0.19552640616893768, fake loss 0.21361282467842102\tGenerator: loss 9.87548542022705\n","Epoch 93, batch 3/240:\tDiscriminator: real loss 0.17459991574287415, fake loss 0.15934902429580688\tGenerator: loss 10.072792053222656\n","Epoch 93, batch 4/240:\tDiscriminator: real loss 0.10382026433944702, fake loss 0.19757120311260223\tGenerator: loss 11.451918601989746\n","Epoch 93, batch 5/240:\tDiscriminator: real loss 0.12455975264310837, fake loss 0.1585402637720108\tGenerator: loss 12.75257682800293\n","Epoch 93, batch 6/240:\tDiscriminator: real loss 0.21408811211585999, fake loss 0.11781049519777298\tGenerator: loss 10.429454803466797\n","Epoch 93, batch 7/240:\tDiscriminator: real loss 0.07263169437646866, fake loss 0.12836632132530212\tGenerator: loss 10.902390480041504\n","Epoch 93, batch 8/240:\tDiscriminator: real loss 0.08902688324451447, fake loss 0.21654818952083588\tGenerator: loss 11.054058074951172\n","Epoch 93, batch 9/240:\tDiscriminator: real loss 0.15833798050880432, fake loss 0.18544258177280426\tGenerator: loss 11.305403709411621\n","Epoch 93, batch 10/240:\tDiscriminator: real loss 0.13148432970046997, fake loss 0.10602603852748871\tGenerator: loss 12.038786888122559\n","Epoch 93, batch 11/240:\tDiscriminator: real loss 0.13195578753948212, fake loss 0.1477843075990677\tGenerator: loss 10.40444564819336\n","Epoch 93, batch 12/240:\tDiscriminator: real loss 0.07725773006677628, fake loss 0.05394115298986435\tGenerator: loss 9.467093467712402\n","Epoch 93, batch 13/240:\tDiscriminator: real loss 0.10229446738958359, fake loss 0.16894781589508057\tGenerator: loss 10.392376899719238\n","Epoch 93, batch 14/240:\tDiscriminator: real loss 0.09455800801515579, fake loss 0.19386474788188934\tGenerator: loss 11.414891242980957\n","Epoch 93, batch 15/240:\tDiscriminator: real loss 0.11395519226789474, fake loss 0.07477127015590668\tGenerator: loss 10.165946006774902\n","Epoch 93, batch 16/240:\tDiscriminator: real loss 0.11166097968816757, fake loss 0.19108997285366058\tGenerator: loss 11.465394020080566\n","Epoch 93, batch 17/240:\tDiscriminator: real loss 0.19710606336593628, fake loss 0.2742422819137573\tGenerator: loss 10.383508682250977\n","Epoch 93, batch 18/240:\tDiscriminator: real loss 0.11003832519054413, fake loss 0.052877966314554214\tGenerator: loss 8.945691108703613\n","Epoch 93, batch 19/240:\tDiscriminator: real loss 0.12888097763061523, fake loss 0.18776653707027435\tGenerator: loss 9.625961303710938\n","Epoch 93, batch 20/240:\tDiscriminator: real loss 0.14720548689365387, fake loss 0.19072642922401428\tGenerator: loss 13.337597846984863\n","Epoch 93, batch 21/240:\tDiscriminator: real loss 0.2002159059047699, fake loss 0.150454580783844\tGenerator: loss 11.103824615478516\n","Epoch 93, batch 22/240:\tDiscriminator: real loss 0.04750875383615494, fake loss 0.14443735778331757\tGenerator: loss 9.919519424438477\n","Epoch 93, batch 23/240:\tDiscriminator: real loss 0.050371814519166946, fake loss 0.18133209645748138\tGenerator: loss 10.941493034362793\n","Epoch 93, batch 24/240:\tDiscriminator: real loss 0.06822091341018677, fake loss 0.16531775891780853\tGenerator: loss 11.471593856811523\n","Epoch 93, batch 25/240:\tDiscriminator: real loss 0.1126679927110672, fake loss 0.12444069981575012\tGenerator: loss 12.100994110107422\n","Epoch 93, batch 26/240:\tDiscriminator: real loss 0.09418316185474396, fake loss 0.1368049830198288\tGenerator: loss 12.700736045837402\n","Epoch 93, batch 27/240:\tDiscriminator: real loss 0.1566077023744583, fake loss 0.15259866416454315\tGenerator: loss 11.857891082763672\n","Epoch 93, batch 28/240:\tDiscriminator: real loss 0.09814592450857162, fake loss 0.1983519196510315\tGenerator: loss 13.744885444641113\n","Epoch 93, batch 29/240:\tDiscriminator: real loss 0.15417161583900452, fake loss 0.1422881782054901\tGenerator: loss 14.220693588256836\n","Epoch 93, batch 30/240:\tDiscriminator: real loss 0.1033797636628151, fake loss 0.16317254304885864\tGenerator: loss 14.129829406738281\n","Epoch 93, batch 31/240:\tDiscriminator: real loss 0.14456544816493988, fake loss 0.18642164766788483\tGenerator: loss 14.538786888122559\n","Epoch 93, batch 32/240:\tDiscriminator: real loss 0.07570245116949081, fake loss 0.17972120642662048\tGenerator: loss 15.738677978515625\n","Epoch 93, batch 33/240:\tDiscriminator: real loss 0.12003030627965927, fake loss 0.16898559033870697\tGenerator: loss 14.05963134765625\n","Epoch 93, batch 34/240:\tDiscriminator: real loss 0.13043779134750366, fake loss 0.07817047089338303\tGenerator: loss 13.17007064819336\n","Epoch 93, batch 35/240:\tDiscriminator: real loss 0.14773766696453094, fake loss 0.10677580535411835\tGenerator: loss 11.529842376708984\n","Epoch 93, batch 36/240:\tDiscriminator: real loss 0.07453954219818115, fake loss 0.13120131194591522\tGenerator: loss 12.723163604736328\n","Epoch 93, batch 37/240:\tDiscriminator: real loss 0.086668461561203, fake loss 0.31400153040885925\tGenerator: loss 13.839258193969727\n","Epoch 93, batch 38/240:\tDiscriminator: real loss 0.08335845917463303, fake loss 0.20229405164718628\tGenerator: loss 16.288951873779297\n","Epoch 93, batch 39/240:\tDiscriminator: real loss 0.11563468724489212, fake loss 0.11032810062170029\tGenerator: loss 15.318354606628418\n","Epoch 93, batch 40/240:\tDiscriminator: real loss 0.12755464017391205, fake loss 0.17118850350379944\tGenerator: loss 15.147150039672852\n","Epoch 93, batch 41/240:\tDiscriminator: real loss 0.10762348026037216, fake loss 0.05635770410299301\tGenerator: loss 13.284446716308594\n","Epoch 93, batch 42/240:\tDiscriminator: real loss 0.13606487214565277, fake loss 0.14639341831207275\tGenerator: loss 11.292923927307129\n","Epoch 93, batch 43/240:\tDiscriminator: real loss 0.07376842200756073, fake loss 0.05442076548933983\tGenerator: loss 10.495121002197266\n","Epoch 93, batch 44/240:\tDiscriminator: real loss 0.09197113662958145, fake loss 0.3447445034980774\tGenerator: loss 13.700918197631836\n","Epoch 93, batch 45/240:\tDiscriminator: real loss 0.160299152135849, fake loss 0.09185820817947388\tGenerator: loss 14.374212265014648\n","Epoch 93, batch 46/240:\tDiscriminator: real loss 0.12734439969062805, fake loss 0.23624633252620697\tGenerator: loss 14.113511085510254\n","Epoch 93, batch 47/240:\tDiscriminator: real loss 0.058462925255298615, fake loss 0.06917907297611237\tGenerator: loss 11.790538787841797\n","Epoch 93, batch 48/240:\tDiscriminator: real loss 0.1349537968635559, fake loss 0.1430668979883194\tGenerator: loss 10.168427467346191\n","Epoch 93, batch 49/240:\tDiscriminator: real loss 0.11238422244787216, fake loss 0.2564783990383148\tGenerator: loss 11.53700065612793\n","Epoch 93, batch 50/240:\tDiscriminator: real loss 0.13362504541873932, fake loss 0.08967838436365128\tGenerator: loss 11.469115257263184\n","Epoch 93, batch 51/240:\tDiscriminator: real loss 0.05782374367117882, fake loss 0.12605583667755127\tGenerator: loss 11.172945976257324\n","Epoch 93, batch 52/240:\tDiscriminator: real loss 0.12859104573726654, fake loss 0.07690291106700897\tGenerator: loss 12.771798133850098\n","Epoch 93, batch 53/240:\tDiscriminator: real loss 0.11715719848871231, fake loss 0.07906505465507507\tGenerator: loss 12.536421775817871\n","Epoch 93, batch 54/240:\tDiscriminator: real loss 0.04924573749303818, fake loss 0.3090093433856964\tGenerator: loss 12.824862480163574\n","Epoch 93, batch 55/240:\tDiscriminator: real loss 0.1280795931816101, fake loss 0.23326221108436584\tGenerator: loss 13.395669937133789\n","Epoch 93, batch 56/240:\tDiscriminator: real loss 0.07707805931568146, fake loss 0.09973543882369995\tGenerator: loss 13.875445365905762\n","Epoch 93, batch 57/240:\tDiscriminator: real loss 0.13026702404022217, fake loss 0.13790757954120636\tGenerator: loss 12.77761459350586\n","Epoch 93, batch 58/240:\tDiscriminator: real loss 0.09099340438842773, fake loss 0.048764750361442566\tGenerator: loss 10.772000312805176\n","Epoch 93, batch 59/240:\tDiscriminator: real loss 0.1298055499792099, fake loss 0.18508844077587128\tGenerator: loss 10.918395042419434\n","Epoch 93, batch 60/240:\tDiscriminator: real loss 0.10425301641225815, fake loss 0.09191335737705231\tGenerator: loss 11.174483299255371\n","Epoch 93, batch 61/240:\tDiscriminator: real loss 0.05594853311777115, fake loss 0.2319713532924652\tGenerator: loss 13.190251350402832\n","Epoch 93, batch 62/240:\tDiscriminator: real loss 0.10476928949356079, fake loss 0.21595777571201324\tGenerator: loss 15.42578125\n","Epoch 93, batch 63/240:\tDiscriminator: real loss 0.23435501754283905, fake loss 0.13034024834632874\tGenerator: loss 11.500572204589844\n","Epoch 93, batch 64/240:\tDiscriminator: real loss 0.1230282112956047, fake loss 0.1591053158044815\tGenerator: loss 12.259441375732422\n","Epoch 93, batch 65/240:\tDiscriminator: real loss 0.10292971879243851, fake loss 0.3189423084259033\tGenerator: loss 11.915631294250488\n","Epoch 93, batch 66/240:\tDiscriminator: real loss 0.22404144704341888, fake loss 0.10506456345319748\tGenerator: loss 9.67498779296875\n","Epoch 93, batch 67/240:\tDiscriminator: real loss 0.10038918256759644, fake loss 0.1099742129445076\tGenerator: loss 9.385856628417969\n","Epoch 93, batch 68/240:\tDiscriminator: real loss 0.08093112707138062, fake loss 0.12291070818901062\tGenerator: loss 8.846652030944824\n","Epoch 93, batch 69/240:\tDiscriminator: real loss 0.21561093628406525, fake loss 0.11857782304286957\tGenerator: loss 10.31751823425293\n","Epoch 93, batch 70/240:\tDiscriminator: real loss 0.06057359650731087, fake loss 0.15569132566452026\tGenerator: loss 11.643287658691406\n","Epoch 93, batch 71/240:\tDiscriminator: real loss 0.0849703997373581, fake loss 0.14593449234962463\tGenerator: loss 11.421984672546387\n","Epoch 93, batch 72/240:\tDiscriminator: real loss 0.14439772069454193, fake loss 0.09952806681394577\tGenerator: loss 11.334303855895996\n","Epoch 93, batch 73/240:\tDiscriminator: real loss 0.12403711676597595, fake loss 0.22631998360157013\tGenerator: loss 10.925861358642578\n","Epoch 93, batch 74/240:\tDiscriminator: real loss 0.08165057003498077, fake loss 0.18372231721878052\tGenerator: loss 11.122673034667969\n","Epoch 93, batch 75/240:\tDiscriminator: real loss 0.17153529822826385, fake loss 0.20442554354667664\tGenerator: loss 10.500497817993164\n","Epoch 93, batch 76/240:\tDiscriminator: real loss 0.1301765888929367, fake loss 0.11252062022686005\tGenerator: loss 10.25961685180664\n","Epoch 93, batch 77/240:\tDiscriminator: real loss 0.13435375690460205, fake loss 0.2076188027858734\tGenerator: loss 10.361035346984863\n","Epoch 93, batch 78/240:\tDiscriminator: real loss 0.13849863409996033, fake loss 0.14190955460071564\tGenerator: loss 10.007698059082031\n","Epoch 93, batch 79/240:\tDiscriminator: real loss 0.11494377255439758, fake loss 0.2793174982070923\tGenerator: loss 10.378501892089844\n","Epoch 93, batch 80/240:\tDiscriminator: real loss 0.11359552294015884, fake loss 0.053704939782619476\tGenerator: loss 8.734880447387695\n","Epoch 93, batch 81/240:\tDiscriminator: real loss 0.1008259579539299, fake loss 0.1509661078453064\tGenerator: loss 10.194636344909668\n","Epoch 93, batch 82/240:\tDiscriminator: real loss 0.06417859345674515, fake loss 0.07929269224405289\tGenerator: loss 10.675625801086426\n","Epoch 93, batch 83/240:\tDiscriminator: real loss 0.12253553420305252, fake loss 0.27847716212272644\tGenerator: loss 12.011157035827637\n","Epoch 93, batch 84/240:\tDiscriminator: real loss 0.10964027047157288, fake loss 0.23788872361183167\tGenerator: loss 11.076738357543945\n","Epoch 93, batch 85/240:\tDiscriminator: real loss 0.22292663156986237, fake loss 0.14444272220134735\tGenerator: loss 10.186060905456543\n","Epoch 93, batch 86/240:\tDiscriminator: real loss 0.0732477605342865, fake loss 0.24354465305805206\tGenerator: loss 11.583026885986328\n","Epoch 93, batch 87/240:\tDiscriminator: real loss 0.2386295348405838, fake loss 0.15307413041591644\tGenerator: loss 9.039987564086914\n","Epoch 93, batch 88/240:\tDiscriminator: real loss 0.1208053007721901, fake loss 0.2915072739124298\tGenerator: loss 11.989651679992676\n","Epoch 93, batch 89/240:\tDiscriminator: real loss 0.100467748939991, fake loss 0.14091730117797852\tGenerator: loss 11.647910118103027\n","Epoch 93, batch 90/240:\tDiscriminator: real loss 0.12003124505281448, fake loss 0.06955093145370483\tGenerator: loss 10.583047866821289\n","Epoch 93, batch 91/240:\tDiscriminator: real loss 0.10450628399848938, fake loss 0.10233712941408157\tGenerator: loss 10.967548370361328\n","Epoch 93, batch 92/240:\tDiscriminator: real loss 0.11517903208732605, fake loss 0.10993881523609161\tGenerator: loss 9.424883842468262\n","Epoch 93, batch 93/240:\tDiscriminator: real loss 0.09477207809686661, fake loss 0.28949904441833496\tGenerator: loss 9.336368560791016\n","Epoch 93, batch 94/240:\tDiscriminator: real loss 0.16961295902729034, fake loss 0.15737584233283997\tGenerator: loss 10.107367515563965\n","Epoch 93, batch 95/240:\tDiscriminator: real loss 0.09630841016769409, fake loss 0.20019103586673737\tGenerator: loss 11.606478691101074\n","Epoch 93, batch 96/240:\tDiscriminator: real loss 0.1596803367137909, fake loss 0.31080326437950134\tGenerator: loss 9.911105155944824\n","Epoch 93, batch 97/240:\tDiscriminator: real loss 0.31381484866142273, fake loss 0.16282843053340912\tGenerator: loss 9.472039222717285\n","Epoch 93, batch 98/240:\tDiscriminator: real loss 0.06886137276887894, fake loss 0.18132591247558594\tGenerator: loss 10.533339500427246\n","Epoch 93, batch 99/240:\tDiscriminator: real loss 0.13674479722976685, fake loss 0.14166104793548584\tGenerator: loss 10.0370454788208\n","Epoch 93, batch 100/240:\tDiscriminator: real loss 0.11676492542028427, fake loss 0.10064030438661575\tGenerator: loss 10.269617080688477\n","Epoch 93, batch 101/240:\tDiscriminator: real loss 0.12898798286914825, fake loss 0.26280537247657776\tGenerator: loss 10.188385009765625\n","Epoch 93, batch 102/240:\tDiscriminator: real loss 0.09514924883842468, fake loss 0.07471662759780884\tGenerator: loss 10.69044303894043\n","Epoch 93, batch 103/240:\tDiscriminator: real loss 0.14057832956314087, fake loss 0.1578812301158905\tGenerator: loss 8.913344383239746\n","Epoch 93, batch 104/240:\tDiscriminator: real loss 0.1107974648475647, fake loss 0.23011383414268494\tGenerator: loss 11.260380744934082\n","Epoch 93, batch 105/240:\tDiscriminator: real loss 0.13907599449157715, fake loss 0.1910952925682068\tGenerator: loss 12.696310997009277\n","Epoch 93, batch 106/240:\tDiscriminator: real loss 0.10782518237829208, fake loss 0.18283943831920624\tGenerator: loss 12.698080062866211\n","Epoch 93, batch 107/240:\tDiscriminator: real loss 0.1568407416343689, fake loss 0.09766371548175812\tGenerator: loss 11.502379417419434\n","Epoch 93, batch 108/240:\tDiscriminator: real loss 0.21336159110069275, fake loss 0.130439892411232\tGenerator: loss 10.615704536437988\n","Epoch 93, batch 109/240:\tDiscriminator: real loss 0.07595804333686829, fake loss 0.1854179948568344\tGenerator: loss 11.855871200561523\n","Epoch 93, batch 110/240:\tDiscriminator: real loss 0.1625678986310959, fake loss 0.12066324055194855\tGenerator: loss 12.281172752380371\n","Epoch 93, batch 111/240:\tDiscriminator: real loss 0.0849294438958168, fake loss 0.11092235893011093\tGenerator: loss 12.385405540466309\n","Epoch 93, batch 112/240:\tDiscriminator: real loss 0.1512593775987625, fake loss 0.19996698200702667\tGenerator: loss 10.477766990661621\n","Epoch 93, batch 113/240:\tDiscriminator: real loss 0.0979628786444664, fake loss 0.3421561121940613\tGenerator: loss 15.249754905700684\n","Epoch 93, batch 114/240:\tDiscriminator: real loss 0.2731018364429474, fake loss 0.09208828210830688\tGenerator: loss 13.264195442199707\n","Epoch 93, batch 115/240:\tDiscriminator: real loss 0.22518759965896606, fake loss 0.31516677141189575\tGenerator: loss 14.429703712463379\n","Epoch 93, batch 116/240:\tDiscriminator: real loss 0.07929342985153198, fake loss 0.23511844873428345\tGenerator: loss 14.187023162841797\n","Epoch 93, batch 117/240:\tDiscriminator: real loss 0.08558603376150131, fake loss 0.07916221767663956\tGenerator: loss 12.8384370803833\n","Epoch 93, batch 118/240:\tDiscriminator: real loss 0.11583791673183441, fake loss 0.16124221682548523\tGenerator: loss 11.034400939941406\n","Epoch 93, batch 119/240:\tDiscriminator: real loss 0.13333578407764435, fake loss 0.15108996629714966\tGenerator: loss 12.204828262329102\n","Epoch 93, batch 120/240:\tDiscriminator: real loss 0.10358721762895584, fake loss 0.09983056038618088\tGenerator: loss 11.857666015625\n","Epoch 93, batch 121/240:\tDiscriminator: real loss 0.07630861550569534, fake loss 0.24428580701351166\tGenerator: loss 13.891352653503418\n","Epoch 93, batch 122/240:\tDiscriminator: real loss 0.156558096408844, fake loss 0.10570015013217926\tGenerator: loss 13.844917297363281\n","Epoch 93, batch 123/240:\tDiscriminator: real loss 0.10353686660528183, fake loss 0.24356673657894135\tGenerator: loss 13.235668182373047\n","Epoch 93, batch 124/240:\tDiscriminator: real loss 0.17236334085464478, fake loss 0.14774082601070404\tGenerator: loss 14.460212707519531\n","Epoch 93, batch 125/240:\tDiscriminator: real loss 0.2048664689064026, fake loss 0.19973689317703247\tGenerator: loss 13.993924140930176\n","Epoch 93, batch 126/240:\tDiscriminator: real loss 0.1271212249994278, fake loss 0.14999990165233612\tGenerator: loss 13.68161392211914\n","Epoch 93, batch 127/240:\tDiscriminator: real loss 0.06764113157987595, fake loss 0.17954158782958984\tGenerator: loss 15.154282569885254\n","Epoch 93, batch 128/240:\tDiscriminator: real loss 0.13707345724105835, fake loss 0.19185878336429596\tGenerator: loss 12.6724214553833\n","Epoch 93, batch 129/240:\tDiscriminator: real loss 0.09435822814702988, fake loss 0.18144626915454865\tGenerator: loss 13.251935958862305\n","Epoch 93, batch 130/240:\tDiscriminator: real loss 0.09152501821517944, fake loss 0.1207042708992958\tGenerator: loss 14.883452415466309\n","Epoch 93, batch 131/240:\tDiscriminator: real loss 0.11969122290611267, fake loss 0.04331184923648834\tGenerator: loss 13.14779281616211\n","Epoch 93, batch 132/240:\tDiscriminator: real loss 0.04256470501422882, fake loss 0.16642522811889648\tGenerator: loss 12.812117576599121\n","Epoch 93, batch 133/240:\tDiscriminator: real loss 0.10396936535835266, fake loss 0.1837058663368225\tGenerator: loss 12.099597930908203\n","Epoch 93, batch 134/240:\tDiscriminator: real loss 0.11792444437742233, fake loss 0.07009944319725037\tGenerator: loss 11.911847114562988\n","Epoch 93, batch 135/240:\tDiscriminator: real loss 0.0997384637594223, fake loss 0.20624122023582458\tGenerator: loss 9.78672981262207\n","Epoch 93, batch 136/240:\tDiscriminator: real loss 0.08855728805065155, fake loss 0.3677171468734741\tGenerator: loss 11.378628730773926\n","Epoch 93, batch 137/240:\tDiscriminator: real loss 0.1948516070842743, fake loss 0.1262803077697754\tGenerator: loss 13.218053817749023\n","Epoch 93, batch 138/240:\tDiscriminator: real loss 0.14951424300670624, fake loss 0.07388904690742493\tGenerator: loss 12.549284934997559\n","Epoch 93, batch 139/240:\tDiscriminator: real loss 0.12323080003261566, fake loss 0.28750815987586975\tGenerator: loss 12.176580429077148\n","Epoch 93, batch 140/240:\tDiscriminator: real loss 0.15833516418933868, fake loss 0.28878679871559143\tGenerator: loss 12.986284255981445\n","Epoch 93, batch 141/240:\tDiscriminator: real loss 0.12412098050117493, fake loss 0.05175914615392685\tGenerator: loss 14.364540100097656\n","Epoch 93, batch 142/240:\tDiscriminator: real loss 0.14284077286720276, fake loss 0.12965905666351318\tGenerator: loss 13.80923843383789\n","Epoch 93, batch 143/240:\tDiscriminator: real loss 0.1264559030532837, fake loss 0.17445728182792664\tGenerator: loss 12.731223106384277\n","Epoch 93, batch 144/240:\tDiscriminator: real loss 0.11980751156806946, fake loss 0.2712486982345581\tGenerator: loss 13.658727645874023\n","Epoch 93, batch 145/240:\tDiscriminator: real loss 0.14392632246017456, fake loss 0.05904560908675194\tGenerator: loss 12.296470642089844\n","Epoch 93, batch 146/240:\tDiscriminator: real loss 0.09029653668403625, fake loss 0.12074916064739227\tGenerator: loss 11.918420791625977\n","Epoch 93, batch 147/240:\tDiscriminator: real loss 0.05598858371376991, fake loss 0.07780864089727402\tGenerator: loss 11.01480484008789\n","Epoch 93, batch 148/240:\tDiscriminator: real loss 0.07571489363908768, fake loss 0.17310835421085358\tGenerator: loss 11.995160102844238\n","Epoch 93, batch 149/240:\tDiscriminator: real loss 0.10376741737127304, fake loss 0.19469553232192993\tGenerator: loss 13.052922248840332\n","Epoch 93, batch 150/240:\tDiscriminator: real loss 0.1712644249200821, fake loss 0.14992572367191315\tGenerator: loss 13.670490264892578\n","Epoch 93, batch 151/240:\tDiscriminator: real loss 0.10987506806850433, fake loss 0.08217082172632217\tGenerator: loss 13.864188194274902\n","Epoch 93, batch 152/240:\tDiscriminator: real loss 0.15041372179985046, fake loss 0.08314357697963715\tGenerator: loss 10.986130714416504\n","Epoch 93, batch 153/240:\tDiscriminator: real loss 0.11264979094266891, fake loss 0.33808889985084534\tGenerator: loss 10.888928413391113\n","Epoch 93, batch 154/240:\tDiscriminator: real loss 0.18130382895469666, fake loss 0.16516529023647308\tGenerator: loss 10.954239845275879\n","Epoch 93, batch 155/240:\tDiscriminator: real loss 0.07255701720714569, fake loss 0.1325124055147171\tGenerator: loss 11.078646659851074\n","Epoch 93, batch 156/240:\tDiscriminator: real loss 0.2626926898956299, fake loss 0.13358932733535767\tGenerator: loss 11.192222595214844\n","Epoch 93, batch 157/240:\tDiscriminator: real loss 0.04438987746834755, fake loss 0.19443316757678986\tGenerator: loss 11.995187759399414\n","Epoch 93, batch 158/240:\tDiscriminator: real loss 0.16516746580600739, fake loss 0.2967343330383301\tGenerator: loss 12.657447814941406\n","Epoch 93, batch 159/240:\tDiscriminator: real loss 0.1059541329741478, fake loss 0.18145859241485596\tGenerator: loss 10.903599739074707\n","Epoch 93, batch 160/240:\tDiscriminator: real loss 0.14975234866142273, fake loss 0.10699217021465302\tGenerator: loss 10.896763801574707\n","Epoch 93, batch 161/240:\tDiscriminator: real loss 0.19825708866119385, fake loss 0.16911433637142181\tGenerator: loss 10.456233024597168\n","Epoch 93, batch 162/240:\tDiscriminator: real loss 0.13735473155975342, fake loss 0.06792854517698288\tGenerator: loss 10.872964859008789\n","Epoch 93, batch 163/240:\tDiscriminator: real loss 0.06464476883411407, fake loss 0.37720832228660583\tGenerator: loss 12.358467102050781\n","Epoch 93, batch 164/240:\tDiscriminator: real loss 0.10953610390424728, fake loss 0.11128827929496765\tGenerator: loss 12.953330993652344\n","Epoch 93, batch 165/240:\tDiscriminator: real loss 0.17520564794540405, fake loss 0.1300005316734314\tGenerator: loss 10.255321502685547\n","Epoch 93, batch 166/240:\tDiscriminator: real loss 0.13067403435707092, fake loss 0.09195827692747116\tGenerator: loss 8.6118745803833\n","Epoch 93, batch 167/240:\tDiscriminator: real loss 0.05834955349564552, fake loss 0.15874165296554565\tGenerator: loss 8.876358032226562\n","Epoch 93, batch 168/240:\tDiscriminator: real loss 0.10493879020214081, fake loss 0.15815620124340057\tGenerator: loss 9.506656646728516\n","Epoch 93, batch 169/240:\tDiscriminator: real loss 0.15094847977161407, fake loss 0.14038561284542084\tGenerator: loss 11.140231132507324\n","Epoch 93, batch 170/240:\tDiscriminator: real loss 0.10813756287097931, fake loss 0.18516594171524048\tGenerator: loss 12.852259635925293\n","Epoch 93, batch 171/240:\tDiscriminator: real loss 0.2762085795402527, fake loss 0.14211036264896393\tGenerator: loss 11.144013404846191\n","Epoch 93, batch 172/240:\tDiscriminator: real loss 0.07211949676275253, fake loss 0.23841843008995056\tGenerator: loss 13.049274444580078\n","Epoch 93, batch 173/240:\tDiscriminator: real loss 0.14199647307395935, fake loss 0.14936985075473785\tGenerator: loss 13.068964958190918\n","Epoch 93, batch 174/240:\tDiscriminator: real loss 0.09606050699949265, fake loss 0.21823526918888092\tGenerator: loss 13.722054481506348\n","Epoch 93, batch 175/240:\tDiscriminator: real loss 0.1665012687444687, fake loss 0.1515936255455017\tGenerator: loss 11.128942489624023\n","Epoch 93, batch 176/240:\tDiscriminator: real loss 0.10831024497747421, fake loss 0.12333940714597702\tGenerator: loss 11.53303337097168\n","Epoch 93, batch 177/240:\tDiscriminator: real loss 0.10911832749843597, fake loss 0.21893173456192017\tGenerator: loss 12.25019645690918\n","Epoch 93, batch 178/240:\tDiscriminator: real loss 0.12318164855241776, fake loss 0.16553111374378204\tGenerator: loss 13.249134063720703\n","Epoch 93, batch 179/240:\tDiscriminator: real loss 0.10577854514122009, fake loss 0.19114373624324799\tGenerator: loss 13.845014572143555\n","Epoch 93, batch 180/240:\tDiscriminator: real loss 0.16974079608917236, fake loss 0.18456964194774628\tGenerator: loss 11.789180755615234\n","Epoch 93, batch 181/240:\tDiscriminator: real loss 0.1392083615064621, fake loss 0.09483218938112259\tGenerator: loss 11.951194763183594\n","Epoch 93, batch 182/240:\tDiscriminator: real loss 0.07891795784235, fake loss 0.2588742971420288\tGenerator: loss 12.702286720275879\n","Epoch 93, batch 183/240:\tDiscriminator: real loss 0.25571563839912415, fake loss 0.18817229568958282\tGenerator: loss 14.870826721191406\n","Epoch 93, batch 184/240:\tDiscriminator: real loss 0.15911482274532318, fake loss 0.18260560929775238\tGenerator: loss 14.107377052307129\n","Epoch 93, batch 185/240:\tDiscriminator: real loss 0.14633721113204956, fake loss 0.11408340185880661\tGenerator: loss 11.389362335205078\n","Epoch 93, batch 186/240:\tDiscriminator: real loss 0.07380101084709167, fake loss 0.044773463159799576\tGenerator: loss 11.96238899230957\n","Epoch 93, batch 187/240:\tDiscriminator: real loss 0.024323945865035057, fake loss 0.13528940081596375\tGenerator: loss 12.588361740112305\n","Epoch 93, batch 188/240:\tDiscriminator: real loss 0.1384352147579193, fake loss 0.16226904094219208\tGenerator: loss 13.196698188781738\n","Epoch 93, batch 189/240:\tDiscriminator: real loss 0.07343718409538269, fake loss 0.2152232527732849\tGenerator: loss 12.762619972229004\n","Epoch 93, batch 190/240:\tDiscriminator: real loss 0.09563997387886047, fake loss 0.25507211685180664\tGenerator: loss 12.987208366394043\n","Epoch 93, batch 191/240:\tDiscriminator: real loss 0.16940274834632874, fake loss 0.16610103845596313\tGenerator: loss 11.016907691955566\n","Epoch 93, batch 192/240:\tDiscriminator: real loss 0.0629863291978836, fake loss 0.18817806243896484\tGenerator: loss 10.672497749328613\n","Epoch 93, batch 193/240:\tDiscriminator: real loss 0.1762973815202713, fake loss 0.16089634597301483\tGenerator: loss 11.09606647491455\n","Epoch 93, batch 194/240:\tDiscriminator: real loss 0.08960741758346558, fake loss 0.19397710263729095\tGenerator: loss 10.805203437805176\n","Epoch 93, batch 195/240:\tDiscriminator: real loss 0.14533211290836334, fake loss 0.11883898079395294\tGenerator: loss 11.064737319946289\n","Epoch 93, batch 196/240:\tDiscriminator: real loss 0.12096881866455078, fake loss 0.12171213328838348\tGenerator: loss 13.06840705871582\n","Epoch 93, batch 197/240:\tDiscriminator: real loss 0.05376311391592026, fake loss 0.11736096441745758\tGenerator: loss 12.242981910705566\n","Epoch 93, batch 198/240:\tDiscriminator: real loss 0.09659603238105774, fake loss 0.13305529952049255\tGenerator: loss 11.832250595092773\n","Epoch 93, batch 199/240:\tDiscriminator: real loss 0.07356387376785278, fake loss 0.13553671538829803\tGenerator: loss 11.538256645202637\n","Epoch 93, batch 200/240:\tDiscriminator: real loss 0.1985863447189331, fake loss 0.07906410098075867\tGenerator: loss 13.940914154052734\n","Epoch 93, batch 201/240:\tDiscriminator: real loss 0.06988754868507385, fake loss 0.09345909208059311\tGenerator: loss 12.548713684082031\n","Epoch 93, batch 202/240:\tDiscriminator: real loss 0.06588152796030045, fake loss 0.1263643205165863\tGenerator: loss 11.775530815124512\n","Epoch 93, batch 203/240:\tDiscriminator: real loss 0.08000856637954712, fake loss 0.189945787191391\tGenerator: loss 11.794388771057129\n","Epoch 93, batch 204/240:\tDiscriminator: real loss 0.09441621601581573, fake loss 0.06607072055339813\tGenerator: loss 12.309770584106445\n","Epoch 93, batch 205/240:\tDiscriminator: real loss 0.15753747522830963, fake loss 0.1500300019979477\tGenerator: loss 12.046928405761719\n","Epoch 93, batch 206/240:\tDiscriminator: real loss 0.0400080569088459, fake loss 0.30968573689460754\tGenerator: loss 13.504505157470703\n","Epoch 93, batch 207/240:\tDiscriminator: real loss 0.1531272679567337, fake loss 0.07118472456932068\tGenerator: loss 11.800309181213379\n","Epoch 93, batch 208/240:\tDiscriminator: real loss 0.121007040143013, fake loss 0.18469832837581635\tGenerator: loss 10.865918159484863\n","Epoch 93, batch 209/240:\tDiscriminator: real loss 0.08710817247629166, fake loss 0.15653733909130096\tGenerator: loss 12.540556907653809\n","Epoch 93, batch 210/240:\tDiscriminator: real loss 0.1381681114435196, fake loss 0.09613367170095444\tGenerator: loss 10.191071510314941\n","Epoch 93, batch 211/240:\tDiscriminator: real loss 0.07022306323051453, fake loss 0.24117164313793182\tGenerator: loss 12.600159645080566\n","Epoch 93, batch 212/240:\tDiscriminator: real loss 0.09121942520141602, fake loss 0.10235567390918732\tGenerator: loss 10.247051239013672\n","Epoch 93, batch 213/240:\tDiscriminator: real loss 0.15332569181919098, fake loss 0.14265882968902588\tGenerator: loss 11.342436790466309\n","Epoch 93, batch 214/240:\tDiscriminator: real loss 0.07549341022968292, fake loss 0.08817683905363083\tGenerator: loss 11.731911659240723\n","Epoch 93, batch 215/240:\tDiscriminator: real loss 0.09866512566804886, fake loss 0.1840607076883316\tGenerator: loss 12.856411933898926\n","Epoch 93, batch 216/240:\tDiscriminator: real loss 0.09166324883699417, fake loss 0.3051619231700897\tGenerator: loss 15.331233978271484\n","Epoch 93, batch 217/240:\tDiscriminator: real loss 0.24174240231513977, fake loss 0.19420254230499268\tGenerator: loss 12.623950958251953\n","Epoch 93, batch 218/240:\tDiscriminator: real loss 0.21290193498134613, fake loss 0.16300727427005768\tGenerator: loss 10.04416275024414\n","Epoch 93, batch 219/240:\tDiscriminator: real loss 0.04542413726449013, fake loss 0.2136925756931305\tGenerator: loss 12.182992935180664\n","Epoch 93, batch 220/240:\tDiscriminator: real loss 0.12641942501068115, fake loss 0.15901468694210052\tGenerator: loss 10.707167625427246\n","Epoch 93, batch 221/240:\tDiscriminator: real loss 0.19629926979541779, fake loss 0.05281773954629898\tGenerator: loss 9.519793510437012\n","Epoch 93, batch 222/240:\tDiscriminator: real loss 0.05773897096514702, fake loss 0.15879219770431519\tGenerator: loss 9.685410499572754\n","Epoch 93, batch 223/240:\tDiscriminator: real loss 0.0772857591509819, fake loss 0.2082386463880539\tGenerator: loss 9.970160484313965\n","Epoch 93, batch 224/240:\tDiscriminator: real loss 0.13952702283859253, fake loss 0.1096692681312561\tGenerator: loss 9.00427532196045\n","Epoch 93, batch 225/240:\tDiscriminator: real loss 0.08110694587230682, fake loss 0.14787061512470245\tGenerator: loss 10.496048927307129\n","Epoch 93, batch 226/240:\tDiscriminator: real loss 0.17806178331375122, fake loss 0.2140229046344757\tGenerator: loss 11.489143371582031\n","Epoch 93, batch 227/240:\tDiscriminator: real loss 0.13418567180633545, fake loss 0.06824913620948792\tGenerator: loss 12.31525993347168\n","Epoch 93, batch 228/240:\tDiscriminator: real loss 0.17966625094413757, fake loss 0.15146063268184662\tGenerator: loss 10.920546531677246\n","Epoch 93, batch 229/240:\tDiscriminator: real loss 0.0686158835887909, fake loss 0.10327072441577911\tGenerator: loss 9.810138702392578\n","Epoch 93, batch 230/240:\tDiscriminator: real loss 0.05504943057894707, fake loss 0.12446510046720505\tGenerator: loss 10.91109848022461\n","Epoch 93, batch 231/240:\tDiscriminator: real loss 0.09929555654525757, fake loss 0.26422300934791565\tGenerator: loss 10.756669998168945\n","Epoch 93, batch 232/240:\tDiscriminator: real loss 0.12333078682422638, fake loss 0.17293107509613037\tGenerator: loss 11.673358917236328\n","Epoch 93, batch 233/240:\tDiscriminator: real loss 0.0845721885561943, fake loss 0.17365913093090057\tGenerator: loss 13.668728828430176\n","Epoch 93, batch 234/240:\tDiscriminator: real loss 0.21727973222732544, fake loss 0.2265513837337494\tGenerator: loss 13.535120964050293\n","Epoch 93, batch 235/240:\tDiscriminator: real loss 0.09199276566505432, fake loss 0.1063147485256195\tGenerator: loss 14.486618995666504\n","Epoch 93, batch 236/240:\tDiscriminator: real loss 0.25457480549812317, fake loss 0.1541394293308258\tGenerator: loss 11.42243766784668\n","Epoch 93, batch 237/240:\tDiscriminator: real loss 0.053032755851745605, fake loss 0.2326112985610962\tGenerator: loss 12.43718147277832\n","Epoch 93, batch 238/240:\tDiscriminator: real loss 0.1317979097366333, fake loss 0.21398529410362244\tGenerator: loss 13.795254707336426\n","Epoch 93, batch 239/240:\tDiscriminator: real loss 0.1425810009241104, fake loss 0.031737472862005234\tGenerator: loss 11.467463493347168\n","Epoch 93, batch 240/240:\tDiscriminator: real loss 0.14009970426559448, fake loss 0.18217134475708008\tGenerator: loss 10.884005546569824\n","Epoch 94, batch 1/240:\tDiscriminator: real loss 0.06428051739931107, fake loss 0.22024744749069214\tGenerator: loss 11.480238914489746\n","Epoch 94, batch 2/240:\tDiscriminator: real loss 0.1199449822306633, fake loss 0.1973223239183426\tGenerator: loss 12.738154411315918\n","Epoch 94, batch 3/240:\tDiscriminator: real loss 0.1262437105178833, fake loss 0.13930028676986694\tGenerator: loss 11.519028663635254\n","Epoch 94, batch 4/240:\tDiscriminator: real loss 0.13816893100738525, fake loss 0.16963998973369598\tGenerator: loss 11.75082015991211\n","Epoch 94, batch 5/240:\tDiscriminator: real loss 0.13253818452358246, fake loss 0.11684992909431458\tGenerator: loss 11.608176231384277\n","Epoch 94, batch 6/240:\tDiscriminator: real loss 0.15885943174362183, fake loss 0.18210944533348083\tGenerator: loss 13.378767967224121\n","Epoch 94, batch 7/240:\tDiscriminator: real loss 0.0871371328830719, fake loss 0.21434202790260315\tGenerator: loss 11.488426208496094\n","Epoch 94, batch 8/240:\tDiscriminator: real loss 0.1247982308268547, fake loss 0.10592029243707657\tGenerator: loss 10.044839859008789\n","Epoch 94, batch 9/240:\tDiscriminator: real loss 0.13089464604854584, fake loss 0.22195877134799957\tGenerator: loss 10.635723114013672\n","Epoch 94, batch 10/240:\tDiscriminator: real loss 0.08928143233060837, fake loss 0.17398399114608765\tGenerator: loss 9.110612869262695\n","Epoch 94, batch 11/240:\tDiscriminator: real loss 0.10187476873397827, fake loss 0.07804390788078308\tGenerator: loss 10.076309204101562\n","Epoch 94, batch 12/240:\tDiscriminator: real loss 0.12015804648399353, fake loss 0.10450973361730576\tGenerator: loss 8.168390274047852\n","Epoch 94, batch 13/240:\tDiscriminator: real loss 0.03944913297891617, fake loss 0.19980694353580475\tGenerator: loss 8.814828872680664\n","Epoch 94, batch 14/240:\tDiscriminator: real loss 0.10754603147506714, fake loss 0.20351341366767883\tGenerator: loss 10.024544715881348\n","Epoch 94, batch 15/240:\tDiscriminator: real loss 0.13188566267490387, fake loss 0.13517171144485474\tGenerator: loss 9.268445014953613\n","Epoch 94, batch 16/240:\tDiscriminator: real loss 0.12131381034851074, fake loss 0.16003471612930298\tGenerator: loss 9.466659545898438\n","Epoch 94, batch 17/240:\tDiscriminator: real loss 0.12557347118854523, fake loss 0.14635218679904938\tGenerator: loss 11.836994171142578\n","Epoch 94, batch 18/240:\tDiscriminator: real loss 0.12019994109869003, fake loss 0.0643903836607933\tGenerator: loss 10.958590507507324\n","Epoch 94, batch 19/240:\tDiscriminator: real loss 0.07193538546562195, fake loss 0.27538344264030457\tGenerator: loss 11.09238052368164\n","Epoch 94, batch 20/240:\tDiscriminator: real loss 0.08237022161483765, fake loss 0.19011928141117096\tGenerator: loss 11.438560485839844\n","Epoch 94, batch 21/240:\tDiscriminator: real loss 0.22379417717456818, fake loss 0.07800623774528503\tGenerator: loss 9.168502807617188\n","Epoch 94, batch 22/240:\tDiscriminator: real loss 0.07862850278615952, fake loss 0.0900169089436531\tGenerator: loss 8.703166961669922\n","Epoch 94, batch 23/240:\tDiscriminator: real loss 0.07632021605968475, fake loss 0.21785488724708557\tGenerator: loss 9.0364408493042\n","Epoch 94, batch 24/240:\tDiscriminator: real loss 0.09499979019165039, fake loss 0.3014843463897705\tGenerator: loss 9.608489990234375\n","Epoch 94, batch 25/240:\tDiscriminator: real loss 0.07821578532457352, fake loss 0.07441353797912598\tGenerator: loss 10.040491104125977\n","Epoch 94, batch 26/240:\tDiscriminator: real loss 0.20367500185966492, fake loss 0.19808053970336914\tGenerator: loss 10.022469520568848\n","Epoch 94, batch 27/240:\tDiscriminator: real loss 0.054541923105716705, fake loss 0.06511792540550232\tGenerator: loss 10.85229206085205\n","Epoch 94, batch 28/240:\tDiscriminator: real loss 0.04856063425540924, fake loss 0.16740606725215912\tGenerator: loss 10.526784896850586\n","Epoch 94, batch 29/240:\tDiscriminator: real loss 0.06241088733077049, fake loss 0.10974506288766861\tGenerator: loss 11.528247833251953\n","Epoch 94, batch 30/240:\tDiscriminator: real loss 0.13492487370967865, fake loss 0.12344915419816971\tGenerator: loss 11.717385292053223\n","Epoch 94, batch 31/240:\tDiscriminator: real loss 0.10383806377649307, fake loss 0.11358476430177689\tGenerator: loss 9.725170135498047\n","Epoch 94, batch 32/240:\tDiscriminator: real loss 0.07704918086528778, fake loss 0.3058713674545288\tGenerator: loss 11.068729400634766\n","Epoch 94, batch 33/240:\tDiscriminator: real loss 0.12392694503068924, fake loss 0.15606532990932465\tGenerator: loss 11.106371879577637\n","Epoch 94, batch 34/240:\tDiscriminator: real loss 0.12739792466163635, fake loss 0.16452354192733765\tGenerator: loss 10.969019889831543\n","Epoch 94, batch 35/240:\tDiscriminator: real loss 0.21219387650489807, fake loss 0.16105106472969055\tGenerator: loss 10.656200408935547\n","Epoch 94, batch 36/240:\tDiscriminator: real loss 0.09619592875242233, fake loss 0.12648172676563263\tGenerator: loss 11.016505241394043\n","Epoch 94, batch 37/240:\tDiscriminator: real loss 0.14120419323444366, fake loss 0.18196991086006165\tGenerator: loss 10.596646308898926\n","Epoch 94, batch 38/240:\tDiscriminator: real loss 0.1344364732503891, fake loss 0.17678646743297577\tGenerator: loss 10.039502143859863\n","Epoch 94, batch 39/240:\tDiscriminator: real loss 0.11558131873607635, fake loss 0.07773008942604065\tGenerator: loss 11.882094383239746\n","Epoch 94, batch 40/240:\tDiscriminator: real loss 0.1101718544960022, fake loss 0.15105324983596802\tGenerator: loss 11.712791442871094\n","Epoch 94, batch 41/240:\tDiscriminator: real loss 0.07339423894882202, fake loss 0.10770067572593689\tGenerator: loss 11.412566184997559\n","Epoch 94, batch 42/240:\tDiscriminator: real loss 0.07667841017246246, fake loss 0.1810009628534317\tGenerator: loss 11.879744529724121\n","Epoch 94, batch 43/240:\tDiscriminator: real loss 0.09677121043205261, fake loss 0.06234686076641083\tGenerator: loss 11.389245986938477\n","Epoch 94, batch 44/240:\tDiscriminator: real loss 0.11413760483264923, fake loss 0.27117183804512024\tGenerator: loss 10.772008895874023\n","Epoch 94, batch 45/240:\tDiscriminator: real loss 0.11012369394302368, fake loss 0.14273256063461304\tGenerator: loss 12.908853530883789\n","Epoch 94, batch 46/240:\tDiscriminator: real loss 0.16967950761318207, fake loss 0.07157854735851288\tGenerator: loss 10.73542594909668\n","Epoch 94, batch 47/240:\tDiscriminator: real loss 0.09914045035839081, fake loss 0.13505324721336365\tGenerator: loss 11.210857391357422\n","Epoch 94, batch 48/240:\tDiscriminator: real loss 0.05449327826499939, fake loss 0.09764379262924194\tGenerator: loss 11.046908378601074\n","Epoch 94, batch 49/240:\tDiscriminator: real loss 0.11500035971403122, fake loss 0.2781047821044922\tGenerator: loss 12.404824256896973\n","Epoch 94, batch 50/240:\tDiscriminator: real loss 0.22418728470802307, fake loss 0.3118228018283844\tGenerator: loss 13.164076805114746\n","Epoch 94, batch 51/240:\tDiscriminator: real loss 0.17358827590942383, fake loss 0.18713051080703735\tGenerator: loss 11.785970687866211\n","Epoch 94, batch 52/240:\tDiscriminator: real loss 0.18155327439308167, fake loss 0.28715193271636963\tGenerator: loss 12.049072265625\n","Epoch 94, batch 53/240:\tDiscriminator: real loss 0.10720277577638626, fake loss 0.1283418983221054\tGenerator: loss 13.274139404296875\n","Epoch 94, batch 54/240:\tDiscriminator: real loss 0.1394551396369934, fake loss 0.07016237080097198\tGenerator: loss 11.36059856414795\n","Epoch 94, batch 55/240:\tDiscriminator: real loss 0.15419889986515045, fake loss 0.223155677318573\tGenerator: loss 11.38238525390625\n","Epoch 94, batch 56/240:\tDiscriminator: real loss 0.08648818731307983, fake loss 0.1075982078909874\tGenerator: loss 9.582657814025879\n","Epoch 94, batch 57/240:\tDiscriminator: real loss 0.09146766364574432, fake loss 0.21054090559482574\tGenerator: loss 11.561697006225586\n","Epoch 94, batch 58/240:\tDiscriminator: real loss 0.15306119620800018, fake loss 0.09317789226770401\tGenerator: loss 11.686327934265137\n","Epoch 94, batch 59/240:\tDiscriminator: real loss 0.10470004379749298, fake loss 0.12990865111351013\tGenerator: loss 9.721198081970215\n","Epoch 94, batch 60/240:\tDiscriminator: real loss 0.041336994618177414, fake loss 0.10944835841655731\tGenerator: loss 10.435340881347656\n","Epoch 94, batch 61/240:\tDiscriminator: real loss 0.09375271946191788, fake loss 0.11723612993955612\tGenerator: loss 11.61727523803711\n","Epoch 94, batch 62/240:\tDiscriminator: real loss 0.11350252479314804, fake loss 0.10144668817520142\tGenerator: loss 11.759934425354004\n","Epoch 94, batch 63/240:\tDiscriminator: real loss 0.0919460579752922, fake loss 0.14796438813209534\tGenerator: loss 12.058370590209961\n","Epoch 94, batch 64/240:\tDiscriminator: real loss 0.14332406222820282, fake loss 0.20752784609794617\tGenerator: loss 14.824167251586914\n","Epoch 94, batch 65/240:\tDiscriminator: real loss 0.06929054111242294, fake loss 0.3614078462123871\tGenerator: loss 13.960254669189453\n","Epoch 94, batch 66/240:\tDiscriminator: real loss 0.189571812748909, fake loss 0.16255521774291992\tGenerator: loss 12.010946273803711\n","Epoch 94, batch 67/240:\tDiscriminator: real loss 0.18449240922927856, fake loss 0.28354546427726746\tGenerator: loss 11.014762878417969\n","Epoch 94, batch 68/240:\tDiscriminator: real loss 0.08433566987514496, fake loss 0.07495436072349548\tGenerator: loss 10.499930381774902\n","Epoch 94, batch 69/240:\tDiscriminator: real loss 0.17290903627872467, fake loss 0.18839849531650543\tGenerator: loss 11.530784606933594\n","Epoch 94, batch 70/240:\tDiscriminator: real loss 0.0985901802778244, fake loss 0.14297041296958923\tGenerator: loss 11.406574249267578\n","Epoch 94, batch 71/240:\tDiscriminator: real loss 0.08111490309238434, fake loss 0.32795611023902893\tGenerator: loss 11.954829216003418\n","Epoch 94, batch 72/240:\tDiscriminator: real loss 0.1291806548833847, fake loss 0.178724467754364\tGenerator: loss 10.833662986755371\n","Epoch 94, batch 73/240:\tDiscriminator: real loss 0.16501469910144806, fake loss 0.08511264622211456\tGenerator: loss 9.067291259765625\n","Epoch 94, batch 74/240:\tDiscriminator: real loss 0.09325334429740906, fake loss 0.08880111575126648\tGenerator: loss 9.10989761352539\n","Epoch 94, batch 75/240:\tDiscriminator: real loss 0.06906019896268845, fake loss 0.19248394668102264\tGenerator: loss 9.102217674255371\n","Epoch 94, batch 76/240:\tDiscriminator: real loss 0.07108348608016968, fake loss 0.1798437535762787\tGenerator: loss 9.764425277709961\n","Epoch 94, batch 77/240:\tDiscriminator: real loss 0.09697586297988892, fake loss 0.1649532914161682\tGenerator: loss 10.113425254821777\n","Epoch 94, batch 78/240:\tDiscriminator: real loss 0.1784815937280655, fake loss 0.2072174847126007\tGenerator: loss 10.504210472106934\n","Epoch 94, batch 79/240:\tDiscriminator: real loss 0.10052955895662308, fake loss 0.279212087392807\tGenerator: loss 11.615921974182129\n","Epoch 94, batch 80/240:\tDiscriminator: real loss 0.1283087581396103, fake loss 0.09270434081554413\tGenerator: loss 9.056971549987793\n","Epoch 94, batch 81/240:\tDiscriminator: real loss 0.21816898882389069, fake loss 0.2390519380569458\tGenerator: loss 9.829497337341309\n","Epoch 94, batch 82/240:\tDiscriminator: real loss 0.13370279967784882, fake loss 0.10838743299245834\tGenerator: loss 7.195550441741943\n","Epoch 94, batch 83/240:\tDiscriminator: real loss 0.13084791600704193, fake loss 0.1578194499015808\tGenerator: loss 9.001461029052734\n","Epoch 94, batch 84/240:\tDiscriminator: real loss 0.16293759644031525, fake loss 0.13521890342235565\tGenerator: loss 11.990983009338379\n","Epoch 94, batch 85/240:\tDiscriminator: real loss 0.06081519275903702, fake loss 0.09619979560375214\tGenerator: loss 14.013221740722656\n","Epoch 94, batch 86/240:\tDiscriminator: real loss 0.12118400633335114, fake loss 0.1208239495754242\tGenerator: loss 13.822104454040527\n","Epoch 94, batch 87/240:\tDiscriminator: real loss 0.07919171452522278, fake loss 0.15667566657066345\tGenerator: loss 10.981832504272461\n","Epoch 94, batch 88/240:\tDiscriminator: real loss 0.07919836789369583, fake loss 0.09383133798837662\tGenerator: loss 11.441254615783691\n","Epoch 94, batch 89/240:\tDiscriminator: real loss 0.0688444972038269, fake loss 0.1960717737674713\tGenerator: loss 13.742278099060059\n","Epoch 94, batch 90/240:\tDiscriminator: real loss 0.1299399435520172, fake loss 0.0710517019033432\tGenerator: loss 13.169319152832031\n","Epoch 94, batch 91/240:\tDiscriminator: real loss 0.11004631966352463, fake loss 0.2702113091945648\tGenerator: loss 13.868368148803711\n","Epoch 94, batch 92/240:\tDiscriminator: real loss 0.10736802965402603, fake loss 0.21979030966758728\tGenerator: loss 13.03361701965332\n","Epoch 94, batch 93/240:\tDiscriminator: real loss 0.20788446068763733, fake loss 0.19219520688056946\tGenerator: loss 13.52093505859375\n","Epoch 94, batch 94/240:\tDiscriminator: real loss 0.21354013681411743, fake loss 0.14675240218639374\tGenerator: loss 14.015233039855957\n","Epoch 94, batch 95/240:\tDiscriminator: real loss 0.08021558821201324, fake loss 0.09343688189983368\tGenerator: loss 13.679115295410156\n","Epoch 94, batch 96/240:\tDiscriminator: real loss 0.12972839176654816, fake loss 0.27925336360931396\tGenerator: loss 12.989895820617676\n","Epoch 94, batch 97/240:\tDiscriminator: real loss 0.10620596259832382, fake loss 0.14479416608810425\tGenerator: loss 12.24782943725586\n","Epoch 94, batch 98/240:\tDiscriminator: real loss 0.1327264904975891, fake loss 0.17236661911010742\tGenerator: loss 11.349623680114746\n","Epoch 94, batch 99/240:\tDiscriminator: real loss 0.18516317009925842, fake loss 0.0703800767660141\tGenerator: loss 13.443122863769531\n","Epoch 94, batch 100/240:\tDiscriminator: real loss 0.06607113778591156, fake loss 0.25847628712654114\tGenerator: loss 12.125829696655273\n","Epoch 94, batch 101/240:\tDiscriminator: real loss 0.04945271462202072, fake loss 0.21630969643592834\tGenerator: loss 13.52633285522461\n","Epoch 94, batch 102/240:\tDiscriminator: real loss 0.1049150675535202, fake loss 0.13794606924057007\tGenerator: loss 12.561127662658691\n","Epoch 94, batch 103/240:\tDiscriminator: real loss 0.17718380689620972, fake loss 0.08019702881574631\tGenerator: loss 12.765921592712402\n","Epoch 94, batch 104/240:\tDiscriminator: real loss 0.13480105996131897, fake loss 0.11105851083993912\tGenerator: loss 14.704322814941406\n","Epoch 94, batch 105/240:\tDiscriminator: real loss 0.12754806876182556, fake loss 0.13206727802753448\tGenerator: loss 13.302674293518066\n","Epoch 94, batch 106/240:\tDiscriminator: real loss 0.045704420655965805, fake loss 0.14006833732128143\tGenerator: loss 13.986868858337402\n","Epoch 94, batch 107/240:\tDiscriminator: real loss 0.08858136832714081, fake loss 0.19486881792545319\tGenerator: loss 12.414798736572266\n","Epoch 94, batch 108/240:\tDiscriminator: real loss 0.08619843423366547, fake loss 0.18853752315044403\tGenerator: loss 12.613351821899414\n","Epoch 94, batch 109/240:\tDiscriminator: real loss 0.1478002816438675, fake loss 0.03759199008345604\tGenerator: loss 10.917716979980469\n","Epoch 94, batch 110/240:\tDiscriminator: real loss 0.09287834167480469, fake loss 0.17784786224365234\tGenerator: loss 11.245769500732422\n","Epoch 94, batch 111/240:\tDiscriminator: real loss 0.0929533988237381, fake loss 0.14460623264312744\tGenerator: loss 14.149218559265137\n","Epoch 94, batch 112/240:\tDiscriminator: real loss 0.1946607083082199, fake loss 0.2713086009025574\tGenerator: loss 11.825669288635254\n","Epoch 94, batch 113/240:\tDiscriminator: real loss 0.09127912670373917, fake loss 0.11713573336601257\tGenerator: loss 11.467996597290039\n","Epoch 94, batch 114/240:\tDiscriminator: real loss 0.1163649931550026, fake loss 0.1698325127363205\tGenerator: loss 11.207221984863281\n","Epoch 94, batch 115/240:\tDiscriminator: real loss 0.13469260931015015, fake loss 0.15741240978240967\tGenerator: loss 12.181593894958496\n","Epoch 94, batch 116/240:\tDiscriminator: real loss 0.12211807072162628, fake loss 0.25037848949432373\tGenerator: loss 13.127933502197266\n","Epoch 94, batch 117/240:\tDiscriminator: real loss 0.23395591974258423, fake loss 0.033666834235191345\tGenerator: loss 11.669211387634277\n","Epoch 94, batch 118/240:\tDiscriminator: real loss 0.07430118322372437, fake loss 0.30371809005737305\tGenerator: loss 10.198921203613281\n","Epoch 94, batch 119/240:\tDiscriminator: real loss 0.07881364226341248, fake loss 0.06344564259052277\tGenerator: loss 10.456358909606934\n","Epoch 94, batch 120/240:\tDiscriminator: real loss 0.14302875101566315, fake loss 0.12277702242136002\tGenerator: loss 11.310489654541016\n","Epoch 94, batch 121/240:\tDiscriminator: real loss 0.15442441403865814, fake loss 0.22892780601978302\tGenerator: loss 12.075758934020996\n","Epoch 94, batch 122/240:\tDiscriminator: real loss 0.08837125450372696, fake loss 0.13315735757350922\tGenerator: loss 10.826776504516602\n","Epoch 94, batch 123/240:\tDiscriminator: real loss 0.06777650117874146, fake loss 0.19057685136795044\tGenerator: loss 12.037113189697266\n","Epoch 94, batch 124/240:\tDiscriminator: real loss 0.178755983710289, fake loss 0.16244174540042877\tGenerator: loss 12.266371726989746\n","Epoch 94, batch 125/240:\tDiscriminator: real loss 0.09120683372020721, fake loss 0.3135019540786743\tGenerator: loss 14.121550559997559\n","Epoch 94, batch 126/240:\tDiscriminator: real loss 0.20122113823890686, fake loss 0.07414510846138\tGenerator: loss 13.178627014160156\n","Epoch 94, batch 127/240:\tDiscriminator: real loss 0.09732301533222198, fake loss 0.32596030831336975\tGenerator: loss 13.354362487792969\n","Epoch 94, batch 128/240:\tDiscriminator: real loss 0.17906694114208221, fake loss 0.10102929174900055\tGenerator: loss 13.527985572814941\n","Epoch 94, batch 129/240:\tDiscriminator: real loss 0.10488517582416534, fake loss 0.11978848278522491\tGenerator: loss 12.268243789672852\n","Epoch 94, batch 130/240:\tDiscriminator: real loss 0.14984068274497986, fake loss 0.2935846149921417\tGenerator: loss 11.184162139892578\n","Epoch 94, batch 131/240:\tDiscriminator: real loss 0.16893059015274048, fake loss 0.09400343149900436\tGenerator: loss 11.47842788696289\n","Epoch 94, batch 132/240:\tDiscriminator: real loss 0.06477810442447662, fake loss 0.18650376796722412\tGenerator: loss 10.844417572021484\n","Epoch 94, batch 133/240:\tDiscriminator: real loss 0.11053937673568726, fake loss 0.11247162520885468\tGenerator: loss 10.162636756896973\n","Epoch 94, batch 134/240:\tDiscriminator: real loss 0.13789567351341248, fake loss 0.19325214624404907\tGenerator: loss 13.66033935546875\n","Epoch 94, batch 135/240:\tDiscriminator: real loss 0.07138244062662125, fake loss 0.11211204528808594\tGenerator: loss 13.641742706298828\n","Epoch 94, batch 136/240:\tDiscriminator: real loss 0.17279823124408722, fake loss 0.06892071664333344\tGenerator: loss 10.087952613830566\n","Epoch 94, batch 137/240:\tDiscriminator: real loss 0.04302726686000824, fake loss 0.2069568634033203\tGenerator: loss 10.167377471923828\n","Epoch 94, batch 138/240:\tDiscriminator: real loss 0.12100694328546524, fake loss 0.09263972193002701\tGenerator: loss 10.505361557006836\n","Epoch 94, batch 139/240:\tDiscriminator: real loss 0.12191152572631836, fake loss 0.36431884765625\tGenerator: loss 12.633706092834473\n","Epoch 94, batch 140/240:\tDiscriminator: real loss 0.1275349259376526, fake loss 0.05735784396529198\tGenerator: loss 11.975539207458496\n","Epoch 94, batch 141/240:\tDiscriminator: real loss 0.0897236168384552, fake loss 0.21734432876110077\tGenerator: loss 12.096417427062988\n","Epoch 94, batch 142/240:\tDiscriminator: real loss 0.20063652098178864, fake loss 0.09968597441911697\tGenerator: loss 13.117164611816406\n","Epoch 94, batch 143/240:\tDiscriminator: real loss 0.0999639481306076, fake loss 0.15045922994613647\tGenerator: loss 15.045160293579102\n","Epoch 94, batch 144/240:\tDiscriminator: real loss 0.1459246128797531, fake loss 0.09928427636623383\tGenerator: loss 13.232475280761719\n","Epoch 94, batch 145/240:\tDiscriminator: real loss 0.11732567101716995, fake loss 0.24146834015846252\tGenerator: loss 13.964033126831055\n","Epoch 94, batch 146/240:\tDiscriminator: real loss 0.04551546275615692, fake loss 0.19967788457870483\tGenerator: loss 15.802338600158691\n","Epoch 94, batch 147/240:\tDiscriminator: real loss 0.1375335454940796, fake loss 0.1736404001712799\tGenerator: loss 16.44820785522461\n","Epoch 94, batch 148/240:\tDiscriminator: real loss 0.2611362338066101, fake loss 0.15006165206432343\tGenerator: loss 12.085797309875488\n","Epoch 94, batch 149/240:\tDiscriminator: real loss 0.12005248665809631, fake loss 0.20581188797950745\tGenerator: loss 10.872364044189453\n","Epoch 94, batch 150/240:\tDiscriminator: real loss 0.08689722418785095, fake loss 0.0963185578584671\tGenerator: loss 9.909687042236328\n","Epoch 94, batch 151/240:\tDiscriminator: real loss 0.06530794501304626, fake loss 0.17525173723697662\tGenerator: loss 11.048602104187012\n","Epoch 94, batch 152/240:\tDiscriminator: real loss 0.16819238662719727, fake loss 0.13916677236557007\tGenerator: loss 10.727394104003906\n","Epoch 94, batch 153/240:\tDiscriminator: real loss 0.1404300332069397, fake loss 0.18912120163440704\tGenerator: loss 11.196894645690918\n","Epoch 94, batch 154/240:\tDiscriminator: real loss 0.15846239030361176, fake loss 0.2212667465209961\tGenerator: loss 10.172433853149414\n","Epoch 94, batch 155/240:\tDiscriminator: real loss 0.300022691488266, fake loss 0.1278734654188156\tGenerator: loss 10.208902359008789\n","Epoch 94, batch 156/240:\tDiscriminator: real loss 0.12963394820690155, fake loss 0.11703439801931381\tGenerator: loss 10.949088096618652\n","Epoch 94, batch 157/240:\tDiscriminator: real loss 0.03696298971772194, fake loss 0.3180539011955261\tGenerator: loss 10.99626350402832\n","Epoch 94, batch 158/240:\tDiscriminator: real loss 0.1795327216386795, fake loss 0.2668358087539673\tGenerator: loss 9.261053085327148\n","Epoch 94, batch 159/240:\tDiscriminator: real loss 0.1416405290365219, fake loss 0.1504630744457245\tGenerator: loss 10.668643951416016\n","Epoch 94, batch 160/240:\tDiscriminator: real loss 0.22891002893447876, fake loss 0.11851777881383896\tGenerator: loss 10.03634262084961\n","Epoch 94, batch 161/240:\tDiscriminator: real loss 0.13645392656326294, fake loss 0.11555096507072449\tGenerator: loss 8.10986042022705\n","Epoch 94, batch 162/240:\tDiscriminator: real loss 0.04717874899506569, fake loss 0.15050899982452393\tGenerator: loss 9.853553771972656\n","Epoch 94, batch 163/240:\tDiscriminator: real loss 0.06422504782676697, fake loss 0.11212051659822464\tGenerator: loss 11.658543586730957\n","Epoch 94, batch 164/240:\tDiscriminator: real loss 0.06932726502418518, fake loss 0.244530588388443\tGenerator: loss 13.143314361572266\n","Epoch 94, batch 165/240:\tDiscriminator: real loss 0.14654608070850372, fake loss 0.06579238176345825\tGenerator: loss 13.345776557922363\n","Epoch 94, batch 166/240:\tDiscriminator: real loss 0.1531742811203003, fake loss 0.1589145064353943\tGenerator: loss 12.705400466918945\n","Epoch 94, batch 167/240:\tDiscriminator: real loss 0.1447717547416687, fake loss 0.23270350694656372\tGenerator: loss 12.492927551269531\n","Epoch 94, batch 168/240:\tDiscriminator: real loss 0.10934692621231079, fake loss 0.21415847539901733\tGenerator: loss 13.64638900756836\n","Epoch 94, batch 169/240:\tDiscriminator: real loss 0.09900069236755371, fake loss 0.1594460904598236\tGenerator: loss 13.743663787841797\n","Epoch 94, batch 170/240:\tDiscriminator: real loss 0.1895022839307785, fake loss 0.26213452219963074\tGenerator: loss 14.411096572875977\n","Epoch 94, batch 171/240:\tDiscriminator: real loss 0.15803806483745575, fake loss 0.12032570689916611\tGenerator: loss 13.593292236328125\n","Epoch 94, batch 172/240:\tDiscriminator: real loss 0.09669245779514313, fake loss 0.17915678024291992\tGenerator: loss 11.637502670288086\n","Epoch 94, batch 173/240:\tDiscriminator: real loss 0.26832228899002075, fake loss 0.16681025922298431\tGenerator: loss 11.15029525756836\n","Epoch 94, batch 174/240:\tDiscriminator: real loss 0.053142208606004715, fake loss 0.21205772459506989\tGenerator: loss 12.68945598602295\n","Epoch 94, batch 175/240:\tDiscriminator: real loss 0.10004741698503494, fake loss 0.10834258049726486\tGenerator: loss 13.864027976989746\n","Epoch 94, batch 176/240:\tDiscriminator: real loss 0.10306555777788162, fake loss 0.16881705820560455\tGenerator: loss 14.624390602111816\n","Epoch 94, batch 177/240:\tDiscriminator: real loss 0.16038326919078827, fake loss 0.07816806435585022\tGenerator: loss 13.626457214355469\n","Epoch 94, batch 178/240:\tDiscriminator: real loss 0.049693599343299866, fake loss 0.11415930092334747\tGenerator: loss 12.506714820861816\n","Epoch 94, batch 179/240:\tDiscriminator: real loss 0.08789882808923721, fake loss 0.18426069617271423\tGenerator: loss 13.011967658996582\n","Epoch 94, batch 180/240:\tDiscriminator: real loss 0.09385814517736435, fake loss 0.11099440604448318\tGenerator: loss 13.998557090759277\n","Epoch 94, batch 181/240:\tDiscriminator: real loss 0.15404696762561798, fake loss 0.15607178211212158\tGenerator: loss 11.947356224060059\n","Epoch 94, batch 182/240:\tDiscriminator: real loss 0.05500694364309311, fake loss 0.10710590332746506\tGenerator: loss 11.266670227050781\n","Epoch 94, batch 183/240:\tDiscriminator: real loss 0.12876096367835999, fake loss 0.1676032990217209\tGenerator: loss 13.086994171142578\n","Epoch 94, batch 184/240:\tDiscriminator: real loss 0.09499229490756989, fake loss 0.16193683445453644\tGenerator: loss 12.653162002563477\n","Epoch 94, batch 185/240:\tDiscriminator: real loss 0.08727462589740753, fake loss 0.08251660317182541\tGenerator: loss 13.614715576171875\n","Epoch 94, batch 186/240:\tDiscriminator: real loss 0.13413459062576294, fake loss 0.228372722864151\tGenerator: loss 12.489692687988281\n","Epoch 94, batch 187/240:\tDiscriminator: real loss 0.09132318198680878, fake loss 0.21751029789447784\tGenerator: loss 12.580321311950684\n","Epoch 94, batch 188/240:\tDiscriminator: real loss 0.1362191140651703, fake loss 0.16410699486732483\tGenerator: loss 11.738534927368164\n","Epoch 94, batch 189/240:\tDiscriminator: real loss 0.1429407149553299, fake loss 0.20373345911502838\tGenerator: loss 12.83631706237793\n","Epoch 94, batch 190/240:\tDiscriminator: real loss 0.11689256876707077, fake loss 0.2087683081626892\tGenerator: loss 14.234627723693848\n","Epoch 94, batch 191/240:\tDiscriminator: real loss 0.145951047539711, fake loss 0.1000104695558548\tGenerator: loss 13.665092468261719\n","Epoch 94, batch 192/240:\tDiscriminator: real loss 0.1125606894493103, fake loss 0.1259569376707077\tGenerator: loss 11.991064071655273\n","Epoch 94, batch 193/240:\tDiscriminator: real loss 0.13437910377979279, fake loss 0.2188519984483719\tGenerator: loss 14.059001922607422\n","Epoch 94, batch 194/240:\tDiscriminator: real loss 0.16536478698253632, fake loss 0.04388566315174103\tGenerator: loss 12.6052885055542\n","Epoch 94, batch 195/240:\tDiscriminator: real loss 0.06456553190946579, fake loss 0.26945656538009644\tGenerator: loss 13.924997329711914\n","Epoch 94, batch 196/240:\tDiscriminator: real loss 0.08449957519769669, fake loss 0.20059949159622192\tGenerator: loss 15.123512268066406\n","Epoch 94, batch 197/240:\tDiscriminator: real loss 0.18018564581871033, fake loss 0.16355587542057037\tGenerator: loss 11.6688814163208\n","Epoch 94, batch 198/240:\tDiscriminator: real loss 0.19660983979701996, fake loss 0.1012808233499527\tGenerator: loss 11.087238311767578\n","Epoch 94, batch 199/240:\tDiscriminator: real loss 0.05254960432648659, fake loss 0.4237530827522278\tGenerator: loss 12.590648651123047\n","Epoch 94, batch 200/240:\tDiscriminator: real loss 0.15538345277309418, fake loss 0.15511326491832733\tGenerator: loss 13.468859672546387\n","Epoch 94, batch 201/240:\tDiscriminator: real loss 0.2704838514328003, fake loss 0.20991337299346924\tGenerator: loss 14.03039264678955\n","Epoch 94, batch 202/240:\tDiscriminator: real loss 0.08381509780883789, fake loss 0.14755688607692719\tGenerator: loss 13.019674301147461\n","Epoch 94, batch 203/240:\tDiscriminator: real loss 0.10570400208234787, fake loss 0.22794456779956818\tGenerator: loss 11.709059715270996\n","Epoch 94, batch 204/240:\tDiscriminator: real loss 0.24147190153598785, fake loss 0.1761428415775299\tGenerator: loss 12.610452651977539\n","Epoch 94, batch 205/240:\tDiscriminator: real loss 0.11535923928022385, fake loss 0.12018080800771713\tGenerator: loss 10.891881942749023\n","Epoch 94, batch 206/240:\tDiscriminator: real loss 0.06754029542207718, fake loss 0.2638967037200928\tGenerator: loss 9.852474212646484\n","Epoch 94, batch 207/240:\tDiscriminator: real loss 0.08848107606172562, fake loss 0.1715514361858368\tGenerator: loss 10.811567306518555\n","Epoch 94, batch 208/240:\tDiscriminator: real loss 0.2316339612007141, fake loss 0.10899050533771515\tGenerator: loss 10.013216972351074\n","Epoch 94, batch 209/240:\tDiscriminator: real loss 0.23092475533485413, fake loss 0.19618897140026093\tGenerator: loss 9.938846588134766\n","Epoch 94, batch 210/240:\tDiscriminator: real loss 0.09792500734329224, fake loss 0.324945330619812\tGenerator: loss 10.593832969665527\n","Epoch 94, batch 211/240:\tDiscriminator: real loss 0.1406378298997879, fake loss 0.13242463767528534\tGenerator: loss 10.851768493652344\n","Epoch 94, batch 212/240:\tDiscriminator: real loss 0.08445685356855392, fake loss 0.1380329132080078\tGenerator: loss 11.081762313842773\n","Epoch 94, batch 213/240:\tDiscriminator: real loss 0.07590886205434799, fake loss 0.19776760041713715\tGenerator: loss 12.806275367736816\n","Epoch 94, batch 214/240:\tDiscriminator: real loss 0.17476151883602142, fake loss 0.14082157611846924\tGenerator: loss 12.199429512023926\n","Epoch 94, batch 215/240:\tDiscriminator: real loss 0.15505415201187134, fake loss 0.1338934749364853\tGenerator: loss 10.063484191894531\n","Epoch 94, batch 216/240:\tDiscriminator: real loss 0.07730156183242798, fake loss 0.0617181770503521\tGenerator: loss 8.859914779663086\n","Epoch 94, batch 217/240:\tDiscriminator: real loss 0.0724002867937088, fake loss 0.20333556830883026\tGenerator: loss 9.802127838134766\n","Epoch 94, batch 218/240:\tDiscriminator: real loss 0.12728410959243774, fake loss 0.17760588228702545\tGenerator: loss 9.609780311584473\n","Epoch 94, batch 219/240:\tDiscriminator: real loss 0.12152896821498871, fake loss 0.2614644765853882\tGenerator: loss 11.50119400024414\n","Epoch 94, batch 220/240:\tDiscriminator: real loss 0.07124301046133041, fake loss 0.2577151656150818\tGenerator: loss 11.078686714172363\n","Epoch 94, batch 221/240:\tDiscriminator: real loss 0.29801908135414124, fake loss 0.26345354318618774\tGenerator: loss 9.245282173156738\n","Epoch 94, batch 222/240:\tDiscriminator: real loss 0.1544383466243744, fake loss 0.0689239427447319\tGenerator: loss 7.810809135437012\n","Epoch 94, batch 223/240:\tDiscriminator: real loss 0.07899866253137589, fake loss 0.16145393252372742\tGenerator: loss 9.482098579406738\n","Epoch 94, batch 224/240:\tDiscriminator: real loss 0.12848377227783203, fake loss 0.2047545462846756\tGenerator: loss 10.522266387939453\n","Epoch 94, batch 225/240:\tDiscriminator: real loss 0.142704576253891, fake loss 0.2016260325908661\tGenerator: loss 11.842065811157227\n","Epoch 94, batch 226/240:\tDiscriminator: real loss 0.09351958334445953, fake loss 0.11285869777202606\tGenerator: loss 11.869482040405273\n","Epoch 94, batch 227/240:\tDiscriminator: real loss 0.1330793797969818, fake loss 0.11847015470266342\tGenerator: loss 11.123154640197754\n","Epoch 94, batch 228/240:\tDiscriminator: real loss 0.11460359394550323, fake loss 0.1873842030763626\tGenerator: loss 13.368346214294434\n","Epoch 94, batch 229/240:\tDiscriminator: real loss 0.13329844176769257, fake loss 0.13064634799957275\tGenerator: loss 12.9453763961792\n","Epoch 94, batch 230/240:\tDiscriminator: real loss 0.09621059149503708, fake loss 0.12803685665130615\tGenerator: loss 11.388638496398926\n","Epoch 94, batch 231/240:\tDiscriminator: real loss 0.09685295075178146, fake loss 0.3492209315299988\tGenerator: loss 14.067091941833496\n","Epoch 94, batch 232/240:\tDiscriminator: real loss 0.16943632066249847, fake loss 0.03407035768032074\tGenerator: loss 12.519808769226074\n","Epoch 94, batch 233/240:\tDiscriminator: real loss 0.15717287361621857, fake loss 0.24941252171993256\tGenerator: loss 12.349077224731445\n","Epoch 94, batch 234/240:\tDiscriminator: real loss 0.09946779161691666, fake loss 0.1603468358516693\tGenerator: loss 14.20973014831543\n","Epoch 94, batch 235/240:\tDiscriminator: real loss 0.15691731870174408, fake loss 0.2059059590101242\tGenerator: loss 11.974950790405273\n","Epoch 94, batch 236/240:\tDiscriminator: real loss 0.14961497485637665, fake loss 0.24533787369728088\tGenerator: loss 11.88182258605957\n","Epoch 94, batch 237/240:\tDiscriminator: real loss 0.10124754160642624, fake loss 0.29191288352012634\tGenerator: loss 10.775476455688477\n","Epoch 94, batch 238/240:\tDiscriminator: real loss 0.15035805106163025, fake loss 0.07669840008020401\tGenerator: loss 11.204360008239746\n","Epoch 94, batch 239/240:\tDiscriminator: real loss 0.215183824300766, fake loss 0.32515421509742737\tGenerator: loss 10.868741035461426\n","Epoch 94, batch 240/240:\tDiscriminator: real loss 0.2522388696670532, fake loss 0.09384884685277939\tGenerator: loss 11.015645980834961\n","Epoch 95, batch 1/240:\tDiscriminator: real loss 0.14067953824996948, fake loss 0.2555352449417114\tGenerator: loss 11.289739608764648\n","Epoch 95, batch 2/240:\tDiscriminator: real loss 0.15028084814548492, fake loss 0.11039575934410095\tGenerator: loss 12.770923614501953\n","Epoch 95, batch 3/240:\tDiscriminator: real loss 0.111137256026268, fake loss 0.3115045428276062\tGenerator: loss 13.226061820983887\n","Epoch 95, batch 4/240:\tDiscriminator: real loss 0.2004816234111786, fake loss 0.22851039469242096\tGenerator: loss 13.552236557006836\n","Epoch 95, batch 5/240:\tDiscriminator: real loss 0.12483222037553787, fake loss 0.0772017389535904\tGenerator: loss 11.189440727233887\n","Epoch 95, batch 6/240:\tDiscriminator: real loss 0.10696002840995789, fake loss 0.12475575506687164\tGenerator: loss 10.667798042297363\n","Epoch 95, batch 7/240:\tDiscriminator: real loss 0.06605767458677292, fake loss 0.24088697135448456\tGenerator: loss 12.478384017944336\n","Epoch 95, batch 8/240:\tDiscriminator: real loss 0.15223008394241333, fake loss 0.09475671499967575\tGenerator: loss 9.763821601867676\n","Epoch 95, batch 9/240:\tDiscriminator: real loss 0.10709411650896072, fake loss 0.2184107005596161\tGenerator: loss 11.340149879455566\n","Epoch 95, batch 10/240:\tDiscriminator: real loss 0.08149547874927521, fake loss 0.16409419476985931\tGenerator: loss 11.773571014404297\n","Epoch 95, batch 11/240:\tDiscriminator: real loss 0.09926353394985199, fake loss 0.18065300583839417\tGenerator: loss 12.916651725769043\n","Epoch 95, batch 12/240:\tDiscriminator: real loss 0.11617368459701538, fake loss 0.15354427695274353\tGenerator: loss 11.526206016540527\n","Epoch 95, batch 13/240:\tDiscriminator: real loss 0.17054130136966705, fake loss 0.12013126164674759\tGenerator: loss 13.750537872314453\n","Epoch 95, batch 14/240:\tDiscriminator: real loss 0.12524449825286865, fake loss 0.08857547491788864\tGenerator: loss 13.585417747497559\n","Epoch 95, batch 15/240:\tDiscriminator: real loss 0.10174304991960526, fake loss 0.22977983951568604\tGenerator: loss 13.979477882385254\n","Epoch 95, batch 16/240:\tDiscriminator: real loss 0.16349634528160095, fake loss 0.13257382810115814\tGenerator: loss 12.188481330871582\n","Epoch 95, batch 17/240:\tDiscriminator: real loss 0.10012204200029373, fake loss 0.17742213606834412\tGenerator: loss 12.914628982543945\n","Epoch 95, batch 18/240:\tDiscriminator: real loss 0.15298610925674438, fake loss 0.1625571846961975\tGenerator: loss 11.536079406738281\n","Epoch 95, batch 19/240:\tDiscriminator: real loss 0.16392835974693298, fake loss 0.1447450965642929\tGenerator: loss 10.561168670654297\n","Epoch 95, batch 20/240:\tDiscriminator: real loss 0.12432962656021118, fake loss 0.1805724948644638\tGenerator: loss 10.182270050048828\n","Epoch 95, batch 21/240:\tDiscriminator: real loss 0.056972865015268326, fake loss 0.08051677793264389\tGenerator: loss 10.048389434814453\n","Epoch 95, batch 22/240:\tDiscriminator: real loss 0.0698905736207962, fake loss 0.19320820271968842\tGenerator: loss 12.518993377685547\n","Epoch 95, batch 23/240:\tDiscriminator: real loss 0.11632503569126129, fake loss 0.1685303896665573\tGenerator: loss 16.379928588867188\n","Epoch 95, batch 24/240:\tDiscriminator: real loss 0.18320293724536896, fake loss 0.15113519132137299\tGenerator: loss 13.68107795715332\n","Epoch 95, batch 25/240:\tDiscriminator: real loss 0.1664811074733734, fake loss 0.08807100355625153\tGenerator: loss 14.473858833312988\n","Epoch 95, batch 26/240:\tDiscriminator: real loss 0.08695921301841736, fake loss 0.2533130943775177\tGenerator: loss 15.685359954833984\n","Epoch 95, batch 27/240:\tDiscriminator: real loss 0.11136122792959213, fake loss 0.04176586493849754\tGenerator: loss 15.096196174621582\n","Epoch 95, batch 28/240:\tDiscriminator: real loss 0.118934765458107, fake loss 0.2201184779405594\tGenerator: loss 13.404959678649902\n","Epoch 95, batch 29/240:\tDiscriminator: real loss 0.1604451984167099, fake loss 0.18125206232070923\tGenerator: loss 12.696161270141602\n","Epoch 95, batch 30/240:\tDiscriminator: real loss 0.06932434439659119, fake loss 0.1937161237001419\tGenerator: loss 14.860376358032227\n","Epoch 95, batch 31/240:\tDiscriminator: real loss 0.14058588445186615, fake loss 0.1037055030465126\tGenerator: loss 12.693556785583496\n","Epoch 95, batch 32/240:\tDiscriminator: real loss 0.1435558795928955, fake loss 0.08520103245973587\tGenerator: loss 12.352851867675781\n","Epoch 95, batch 33/240:\tDiscriminator: real loss 0.07632644474506378, fake loss 0.13999232649803162\tGenerator: loss 13.588837623596191\n","Epoch 95, batch 34/240:\tDiscriminator: real loss 0.12343838810920715, fake loss 0.2101707011461258\tGenerator: loss 13.237044334411621\n","Epoch 95, batch 35/240:\tDiscriminator: real loss 0.06260399520397186, fake loss 0.07533075660467148\tGenerator: loss 14.325399398803711\n","Epoch 95, batch 36/240:\tDiscriminator: real loss 0.08356745541095734, fake loss 0.17038065195083618\tGenerator: loss 14.703832626342773\n","Epoch 95, batch 37/240:\tDiscriminator: real loss 0.20479074120521545, fake loss 0.1159391701221466\tGenerator: loss 14.565585136413574\n","Epoch 95, batch 38/240:\tDiscriminator: real loss 0.0951683446764946, fake loss 0.2105170488357544\tGenerator: loss 13.761963844299316\n","Epoch 95, batch 39/240:\tDiscriminator: real loss 0.08721084892749786, fake loss 0.21147283911705017\tGenerator: loss 15.360810279846191\n","Epoch 95, batch 40/240:\tDiscriminator: real loss 0.14904722571372986, fake loss 0.3042493164539337\tGenerator: loss 14.707812309265137\n","Epoch 95, batch 41/240:\tDiscriminator: real loss 0.16796430945396423, fake loss 0.1315135508775711\tGenerator: loss 11.755200386047363\n","Epoch 95, batch 42/240:\tDiscriminator: real loss 0.14638319611549377, fake loss 0.11354457587003708\tGenerator: loss 11.407200813293457\n","Epoch 95, batch 43/240:\tDiscriminator: real loss 0.14497974514961243, fake loss 0.21431030333042145\tGenerator: loss 11.657983779907227\n","Epoch 95, batch 44/240:\tDiscriminator: real loss 0.04357583448290825, fake loss 0.1749664545059204\tGenerator: loss 12.264593124389648\n","Epoch 95, batch 45/240:\tDiscriminator: real loss 0.11599282920360565, fake loss 0.07340111583471298\tGenerator: loss 13.249730110168457\n","Epoch 95, batch 46/240:\tDiscriminator: real loss 0.17175188660621643, fake loss 0.2538904845714569\tGenerator: loss 11.089250564575195\n","Epoch 95, batch 47/240:\tDiscriminator: real loss 0.06658389419317245, fake loss 0.07915745675563812\tGenerator: loss 11.063346862792969\n","Epoch 95, batch 48/240:\tDiscriminator: real loss 0.17077727615833282, fake loss 0.1377892792224884\tGenerator: loss 11.153990745544434\n","Epoch 95, batch 49/240:\tDiscriminator: real loss 0.0792912095785141, fake loss 0.19180366396903992\tGenerator: loss 12.919057846069336\n","Epoch 95, batch 50/240:\tDiscriminator: real loss 0.08528296649456024, fake loss 0.1887599527835846\tGenerator: loss 15.523531913757324\n","Epoch 95, batch 51/240:\tDiscriminator: real loss 0.30332913994789124, fake loss 0.13850779831409454\tGenerator: loss 14.409899711608887\n","Epoch 95, batch 52/240:\tDiscriminator: real loss 0.14320701360702515, fake loss 0.22764647006988525\tGenerator: loss 12.444805145263672\n","Epoch 95, batch 53/240:\tDiscriminator: real loss 0.049251727759838104, fake loss 0.21269027888774872\tGenerator: loss 15.3380126953125\n","Epoch 95, batch 54/240:\tDiscriminator: real loss 0.18034254014492035, fake loss 0.10780427604913712\tGenerator: loss 12.201883316040039\n","Epoch 95, batch 55/240:\tDiscriminator: real loss 0.0839695855975151, fake loss 0.0656827837228775\tGenerator: loss 11.737399101257324\n","Epoch 95, batch 56/240:\tDiscriminator: real loss 0.08668455481529236, fake loss 0.3387426435947418\tGenerator: loss 13.324196815490723\n","Epoch 95, batch 57/240:\tDiscriminator: real loss 0.23393410444259644, fake loss 0.055755406618118286\tGenerator: loss 11.104491233825684\n","Epoch 95, batch 58/240:\tDiscriminator: real loss 0.08931151032447815, fake loss 0.3053581416606903\tGenerator: loss 9.739398956298828\n","Epoch 95, batch 59/240:\tDiscriminator: real loss 0.10473579168319702, fake loss 0.1883823424577713\tGenerator: loss 9.971497535705566\n","Epoch 95, batch 60/240:\tDiscriminator: real loss 0.11719333380460739, fake loss 0.06837353855371475\tGenerator: loss 10.314566612243652\n","Epoch 95, batch 61/240:\tDiscriminator: real loss 0.12936437129974365, fake loss 0.150182843208313\tGenerator: loss 8.97425365447998\n","Epoch 95, batch 62/240:\tDiscriminator: real loss 0.0711698830127716, fake loss 0.15085208415985107\tGenerator: loss 9.635363578796387\n","Epoch 95, batch 63/240:\tDiscriminator: real loss 0.08796689659357071, fake loss 0.06880249083042145\tGenerator: loss 9.551257133483887\n","Epoch 95, batch 64/240:\tDiscriminator: real loss 0.1329251229763031, fake loss 0.23161107301712036\tGenerator: loss 8.501689910888672\n","Epoch 95, batch 65/240:\tDiscriminator: real loss 0.11921460926532745, fake loss 0.22371409833431244\tGenerator: loss 9.769943237304688\n","Epoch 95, batch 66/240:\tDiscriminator: real loss 0.11104387044906616, fake loss 0.1736554354429245\tGenerator: loss 9.731346130371094\n","Epoch 95, batch 67/240:\tDiscriminator: real loss 0.20496901869773865, fake loss 0.09670308232307434\tGenerator: loss 10.322254180908203\n","Epoch 95, batch 68/240:\tDiscriminator: real loss 0.08019308745861053, fake loss 0.1065489649772644\tGenerator: loss 10.007171630859375\n","Epoch 95, batch 69/240:\tDiscriminator: real loss 0.07059839367866516, fake loss 0.18788862228393555\tGenerator: loss 11.838912010192871\n","Epoch 95, batch 70/240:\tDiscriminator: real loss 0.15032310783863068, fake loss 0.10958313196897507\tGenerator: loss 11.513055801391602\n","Epoch 95, batch 71/240:\tDiscriminator: real loss 0.10261396318674088, fake loss 0.19517360627651215\tGenerator: loss 12.225295066833496\n","Epoch 95, batch 72/240:\tDiscriminator: real loss 0.1123475581407547, fake loss 0.06578340381383896\tGenerator: loss 14.249393463134766\n","Epoch 95, batch 73/240:\tDiscriminator: real loss 0.12058699876070023, fake loss 0.2985382080078125\tGenerator: loss 14.454078674316406\n","Epoch 95, batch 74/240:\tDiscriminator: real loss 0.07241730391979218, fake loss 0.06313446164131165\tGenerator: loss 15.260262489318848\n","Epoch 95, batch 75/240:\tDiscriminator: real loss 0.13484254479408264, fake loss 0.16652388870716095\tGenerator: loss 13.233314514160156\n","Epoch 95, batch 76/240:\tDiscriminator: real loss 0.06240583583712578, fake loss 0.10335297882556915\tGenerator: loss 14.309584617614746\n","Epoch 95, batch 77/240:\tDiscriminator: real loss 0.17139314115047455, fake loss 0.20159202814102173\tGenerator: loss 16.473386764526367\n","Epoch 95, batch 78/240:\tDiscriminator: real loss 0.14311367273330688, fake loss 0.23517490923404694\tGenerator: loss 14.929145812988281\n","Epoch 95, batch 79/240:\tDiscriminator: real loss 0.19294138252735138, fake loss 0.1526561677455902\tGenerator: loss 12.439531326293945\n","Epoch 95, batch 80/240:\tDiscriminator: real loss 0.16286155581474304, fake loss 0.137956902384758\tGenerator: loss 12.1122465133667\n","Epoch 95, batch 81/240:\tDiscriminator: real loss 0.08719892799854279, fake loss 0.280666321516037\tGenerator: loss 14.012079238891602\n","Epoch 95, batch 82/240:\tDiscriminator: real loss 0.1049167662858963, fake loss 0.1147240623831749\tGenerator: loss 16.768260955810547\n","Epoch 95, batch 83/240:\tDiscriminator: real loss 0.14186708629131317, fake loss 0.165050208568573\tGenerator: loss 15.276183128356934\n","Epoch 95, batch 84/240:\tDiscriminator: real loss 0.14971521496772766, fake loss 0.21773681044578552\tGenerator: loss 13.455777168273926\n","Epoch 95, batch 85/240:\tDiscriminator: real loss 0.10367529094219208, fake loss 0.18325385451316833\tGenerator: loss 13.382126808166504\n","Epoch 95, batch 86/240:\tDiscriminator: real loss 0.13348020613193512, fake loss 0.21700966358184814\tGenerator: loss 13.828407287597656\n","Epoch 95, batch 87/240:\tDiscriminator: real loss 0.12335382401943207, fake loss 0.2130267322063446\tGenerator: loss 15.985544204711914\n","Epoch 95, batch 88/240:\tDiscriminator: real loss 0.17953582108020782, fake loss 0.1176648736000061\tGenerator: loss 16.23531723022461\n","Epoch 95, batch 89/240:\tDiscriminator: real loss 0.10367946326732635, fake loss 0.21997803449630737\tGenerator: loss 15.221940994262695\n","Epoch 95, batch 90/240:\tDiscriminator: real loss 0.19574031233787537, fake loss 0.11354639381170273\tGenerator: loss 16.819713592529297\n","Epoch 95, batch 91/240:\tDiscriminator: real loss 0.11649343371391296, fake loss 0.16956909000873566\tGenerator: loss 16.616409301757812\n","Epoch 95, batch 92/240:\tDiscriminator: real loss 0.11323778331279755, fake loss 0.26305457949638367\tGenerator: loss 16.382530212402344\n","Epoch 95, batch 93/240:\tDiscriminator: real loss 0.08383041620254517, fake loss 0.15688709914684296\tGenerator: loss 15.12591552734375\n","Epoch 95, batch 94/240:\tDiscriminator: real loss 0.13718217611312866, fake loss 0.10222812741994858\tGenerator: loss 15.260506629943848\n","Epoch 95, batch 95/240:\tDiscriminator: real loss 0.10149386525154114, fake loss 0.1467207670211792\tGenerator: loss 17.974428176879883\n","Epoch 95, batch 96/240:\tDiscriminator: real loss 0.09814489632844925, fake loss 0.1658049076795578\tGenerator: loss 16.30974578857422\n","Epoch 95, batch 97/240:\tDiscriminator: real loss 0.12392149865627289, fake loss 0.22867374122142792\tGenerator: loss 16.402172088623047\n","Epoch 95, batch 98/240:\tDiscriminator: real loss 0.20772483944892883, fake loss 0.2381535768508911\tGenerator: loss 15.077781677246094\n","Epoch 95, batch 99/240:\tDiscriminator: real loss 0.13542869687080383, fake loss 0.10918595641851425\tGenerator: loss 17.068225860595703\n","Epoch 95, batch 100/240:\tDiscriminator: real loss 0.21409094333648682, fake loss 0.3367069959640503\tGenerator: loss 13.896106719970703\n","Epoch 95, batch 101/240:\tDiscriminator: real loss 0.11843106895685196, fake loss 0.07513371109962463\tGenerator: loss 14.202098846435547\n","Epoch 95, batch 102/240:\tDiscriminator: real loss 0.13660360872745514, fake loss 0.24162372946739197\tGenerator: loss 12.844951629638672\n","Epoch 95, batch 103/240:\tDiscriminator: real loss 0.06254800409078598, fake loss 0.05330335721373558\tGenerator: loss 13.92846965789795\n","Epoch 95, batch 104/240:\tDiscriminator: real loss 0.06770455092191696, fake loss 0.1353328824043274\tGenerator: loss 14.441145896911621\n","Epoch 95, batch 105/240:\tDiscriminator: real loss 0.12589101493358612, fake loss 0.1330372393131256\tGenerator: loss 13.629886627197266\n","Epoch 95, batch 106/240:\tDiscriminator: real loss 0.09396267682313919, fake loss 0.10958799719810486\tGenerator: loss 12.531518936157227\n","Epoch 95, batch 107/240:\tDiscriminator: real loss 0.14747869968414307, fake loss 0.30694425106048584\tGenerator: loss 11.856921195983887\n","Epoch 95, batch 108/240:\tDiscriminator: real loss 0.10559459775686264, fake loss 0.22282825410366058\tGenerator: loss 13.494791030883789\n","Epoch 95, batch 109/240:\tDiscriminator: real loss 0.24693073332309723, fake loss 0.18072979152202606\tGenerator: loss 14.594244003295898\n","Epoch 95, batch 110/240:\tDiscriminator: real loss 0.09913823753595352, fake loss 0.14765073359012604\tGenerator: loss 15.24120807647705\n","Epoch 95, batch 111/240:\tDiscriminator: real loss 0.2496056705713272, fake loss 0.21202296018600464\tGenerator: loss 13.14980697631836\n","Epoch 95, batch 112/240:\tDiscriminator: real loss 0.13252978026866913, fake loss 0.13863132894039154\tGenerator: loss 13.960423469543457\n","Epoch 95, batch 113/240:\tDiscriminator: real loss 0.17899560928344727, fake loss 0.242310032248497\tGenerator: loss 13.64905071258545\n","Epoch 95, batch 114/240:\tDiscriminator: real loss 0.07181122153997421, fake loss 0.2468383014202118\tGenerator: loss 13.300772666931152\n","Epoch 95, batch 115/240:\tDiscriminator: real loss 0.13114488124847412, fake loss 0.06416059285402298\tGenerator: loss 11.491171836853027\n","Epoch 95, batch 116/240:\tDiscriminator: real loss 0.1862034648656845, fake loss 0.22112950682640076\tGenerator: loss 13.664005279541016\n","Epoch 95, batch 117/240:\tDiscriminator: real loss 0.17121198773384094, fake loss 0.1521492749452591\tGenerator: loss 14.241551399230957\n","Epoch 95, batch 118/240:\tDiscriminator: real loss 0.08773203194141388, fake loss 0.09279186278581619\tGenerator: loss 13.23263168334961\n","Epoch 95, batch 119/240:\tDiscriminator: real loss 0.12230785191059113, fake loss 0.112687848508358\tGenerator: loss 12.469505310058594\n","Epoch 95, batch 120/240:\tDiscriminator: real loss 0.09566552937030792, fake loss 0.17648513615131378\tGenerator: loss 12.266587257385254\n","Epoch 95, batch 121/240:\tDiscriminator: real loss 0.08280947059392929, fake loss 0.12762261927127838\tGenerator: loss 13.628684997558594\n","Epoch 95, batch 122/240:\tDiscriminator: real loss 0.12938588857650757, fake loss 0.12883269786834717\tGenerator: loss 12.75408935546875\n","Epoch 95, batch 123/240:\tDiscriminator: real loss 0.06208686903119087, fake loss 0.32953888177871704\tGenerator: loss 16.036222457885742\n","Epoch 95, batch 124/240:\tDiscriminator: real loss 0.16857250034809113, fake loss 0.12527957558631897\tGenerator: loss 13.587121963500977\n","Epoch 95, batch 125/240:\tDiscriminator: real loss 0.1170450896024704, fake loss 0.16211864352226257\tGenerator: loss 11.631599426269531\n","Epoch 95, batch 126/240:\tDiscriminator: real loss 0.16687726974487305, fake loss 0.1190602034330368\tGenerator: loss 12.502946853637695\n","Epoch 95, batch 127/240:\tDiscriminator: real loss 0.07557719200849533, fake loss 0.18058429658412933\tGenerator: loss 12.498775482177734\n","Epoch 95, batch 128/240:\tDiscriminator: real loss 0.10883583873510361, fake loss 0.14949554204940796\tGenerator: loss 10.780457496643066\n","Epoch 95, batch 129/240:\tDiscriminator: real loss 0.10790310800075531, fake loss 0.16320161521434784\tGenerator: loss 8.94530963897705\n","Epoch 95, batch 130/240:\tDiscriminator: real loss 0.08569032698869705, fake loss 0.327412486076355\tGenerator: loss 10.893621444702148\n","Epoch 95, batch 131/240:\tDiscriminator: real loss 0.2695079445838928, fake loss 0.13484901189804077\tGenerator: loss 10.482414245605469\n","Epoch 95, batch 132/240:\tDiscriminator: real loss 0.17677225172519684, fake loss 0.0942935198545456\tGenerator: loss 8.801712989807129\n","Epoch 95, batch 133/240:\tDiscriminator: real loss 0.05578352510929108, fake loss 0.2004132866859436\tGenerator: loss 11.148324012756348\n","Epoch 95, batch 134/240:\tDiscriminator: real loss 0.09149536490440369, fake loss 0.40556222200393677\tGenerator: loss 10.183670043945312\n","Epoch 95, batch 135/240:\tDiscriminator: real loss 0.16147491335868835, fake loss 0.10127118229866028\tGenerator: loss 8.045654296875\n","Epoch 95, batch 136/240:\tDiscriminator: real loss 0.21818053722381592, fake loss 0.15197643637657166\tGenerator: loss 7.765821933746338\n","Epoch 95, batch 137/240:\tDiscriminator: real loss 0.12927740812301636, fake loss 0.08254261314868927\tGenerator: loss 7.3395771980285645\n","Epoch 95, batch 138/240:\tDiscriminator: real loss 0.08645571768283844, fake loss 0.34729716181755066\tGenerator: loss 8.634452819824219\n","Epoch 95, batch 139/240:\tDiscriminator: real loss 0.13963544368743896, fake loss 0.10142761468887329\tGenerator: loss 10.979637145996094\n","Epoch 95, batch 140/240:\tDiscriminator: real loss 0.15143702924251556, fake loss 0.1348441243171692\tGenerator: loss 12.200160026550293\n","Epoch 95, batch 141/240:\tDiscriminator: real loss 0.09600498527288437, fake loss 0.17829293012619019\tGenerator: loss 11.247269630432129\n","Epoch 95, batch 142/240:\tDiscriminator: real loss 0.11799581348896027, fake loss 0.14169842004776\tGenerator: loss 12.460559844970703\n","Epoch 95, batch 143/240:\tDiscriminator: real loss 0.12748059630393982, fake loss 0.34894776344299316\tGenerator: loss 10.379775047302246\n","Epoch 95, batch 144/240:\tDiscriminator: real loss 0.19197742640972137, fake loss 0.13224652409553528\tGenerator: loss 9.04696273803711\n","Epoch 95, batch 145/240:\tDiscriminator: real loss 0.15298514068126678, fake loss 0.047910820692777634\tGenerator: loss 9.169784545898438\n","Epoch 95, batch 146/240:\tDiscriminator: real loss 0.04425768926739693, fake loss 0.21228499710559845\tGenerator: loss 8.895071983337402\n","Epoch 95, batch 147/240:\tDiscriminator: real loss 0.0872417613863945, fake loss 0.19276706874370575\tGenerator: loss 9.581727027893066\n","Epoch 95, batch 148/240:\tDiscriminator: real loss 0.12668128311634064, fake loss 0.17314332723617554\tGenerator: loss 11.620484352111816\n","Epoch 95, batch 149/240:\tDiscriminator: real loss 0.08689318597316742, fake loss 0.10233014822006226\tGenerator: loss 11.10543441772461\n","Epoch 95, batch 150/240:\tDiscriminator: real loss 0.1611449122428894, fake loss 0.10461357235908508\tGenerator: loss 10.652104377746582\n","Epoch 95, batch 151/240:\tDiscriminator: real loss 0.08378583192825317, fake loss 0.13391005992889404\tGenerator: loss 11.792139053344727\n","Epoch 95, batch 152/240:\tDiscriminator: real loss 0.06370511651039124, fake loss 0.1748390793800354\tGenerator: loss 11.839421272277832\n","Epoch 95, batch 153/240:\tDiscriminator: real loss 0.11402145028114319, fake loss 0.14412251114845276\tGenerator: loss 14.258508682250977\n","Epoch 95, batch 154/240:\tDiscriminator: real loss 0.12616276741027832, fake loss 0.2961712181568146\tGenerator: loss 13.223916053771973\n","Epoch 95, batch 155/240:\tDiscriminator: real loss 0.08910993486642838, fake loss 0.15456163883209229\tGenerator: loss 14.115009307861328\n","Epoch 95, batch 156/240:\tDiscriminator: real loss 0.1668151468038559, fake loss 0.23913657665252686\tGenerator: loss 15.522191047668457\n","Epoch 95, batch 157/240:\tDiscriminator: real loss 0.19023877382278442, fake loss 0.052000608295202255\tGenerator: loss 15.35257339477539\n","Epoch 95, batch 158/240:\tDiscriminator: real loss 0.18065014481544495, fake loss 0.21521896123886108\tGenerator: loss 13.487909317016602\n","Epoch 95, batch 159/240:\tDiscriminator: real loss 0.05804355442523956, fake loss 0.2707667946815491\tGenerator: loss 14.390961647033691\n","Epoch 95, batch 160/240:\tDiscriminator: real loss 0.14772675931453705, fake loss 0.17257334291934967\tGenerator: loss 12.479832649230957\n","Epoch 95, batch 161/240:\tDiscriminator: real loss 0.14773130416870117, fake loss 0.11049444228410721\tGenerator: loss 13.508110046386719\n","Epoch 95, batch 162/240:\tDiscriminator: real loss 0.1887439787387848, fake loss 0.13417652249336243\tGenerator: loss 11.966474533081055\n","Epoch 95, batch 163/240:\tDiscriminator: real loss 0.0923660472035408, fake loss 0.18053431808948517\tGenerator: loss 13.081293106079102\n","Epoch 95, batch 164/240:\tDiscriminator: real loss 0.06383537501096725, fake loss 0.25109443068504333\tGenerator: loss 12.900002479553223\n","Epoch 95, batch 165/240:\tDiscriminator: real loss 0.2648031711578369, fake loss 0.17876045405864716\tGenerator: loss 12.444113731384277\n","Epoch 95, batch 166/240:\tDiscriminator: real loss 0.11197049915790558, fake loss 0.2658098638057709\tGenerator: loss 14.5194091796875\n","Epoch 95, batch 167/240:\tDiscriminator: real loss 0.18306468427181244, fake loss 0.15565435588359833\tGenerator: loss 13.995290756225586\n","Epoch 95, batch 168/240:\tDiscriminator: real loss 0.20385783910751343, fake loss 0.2019304633140564\tGenerator: loss 13.843963623046875\n","Epoch 95, batch 169/240:\tDiscriminator: real loss 0.06326741725206375, fake loss 0.15371987223625183\tGenerator: loss 13.95921516418457\n","Epoch 95, batch 170/240:\tDiscriminator: real loss 0.12652088701725006, fake loss 0.195496067404747\tGenerator: loss 12.071205139160156\n","Epoch 95, batch 171/240:\tDiscriminator: real loss 0.10184919089078903, fake loss 0.15790951251983643\tGenerator: loss 13.657878875732422\n","Epoch 95, batch 172/240:\tDiscriminator: real loss 0.09679460525512695, fake loss 0.13888481259346008\tGenerator: loss 12.81568717956543\n","Epoch 95, batch 173/240:\tDiscriminator: real loss 0.1753198504447937, fake loss 0.15093103051185608\tGenerator: loss 10.748710632324219\n","Epoch 95, batch 174/240:\tDiscriminator: real loss 0.07128176093101501, fake loss 0.17803673446178436\tGenerator: loss 11.265746116638184\n","Epoch 95, batch 175/240:\tDiscriminator: real loss 0.12686224281787872, fake loss 0.11903361231088638\tGenerator: loss 11.314897537231445\n","Epoch 95, batch 176/240:\tDiscriminator: real loss 0.09340736269950867, fake loss 0.2979657053947449\tGenerator: loss 13.863569259643555\n","Epoch 95, batch 177/240:\tDiscriminator: real loss 0.13696621358394623, fake loss 0.08101699501276016\tGenerator: loss 12.030701637268066\n","Epoch 95, batch 178/240:\tDiscriminator: real loss 0.11457350105047226, fake loss 0.2672225534915924\tGenerator: loss 15.107277870178223\n","Epoch 95, batch 179/240:\tDiscriminator: real loss 0.1591186672449112, fake loss 0.033920615911483765\tGenerator: loss 13.745444297790527\n","Epoch 95, batch 180/240:\tDiscriminator: real loss 0.07084273546934128, fake loss 0.22240200638771057\tGenerator: loss 13.583771705627441\n","Epoch 95, batch 181/240:\tDiscriminator: real loss 0.09209524095058441, fake loss 0.14280198514461517\tGenerator: loss 12.359180450439453\n","Epoch 95, batch 182/240:\tDiscriminator: real loss 0.1590619534254074, fake loss 0.04854220896959305\tGenerator: loss 13.353294372558594\n","Epoch 95, batch 183/240:\tDiscriminator: real loss 0.06678907573223114, fake loss 0.19103017449378967\tGenerator: loss 10.908061981201172\n","Epoch 95, batch 184/240:\tDiscriminator: real loss 0.07787183672189713, fake loss 0.1602395474910736\tGenerator: loss 13.162958145141602\n","Epoch 95, batch 185/240:\tDiscriminator: real loss 0.06555512547492981, fake loss 0.1607733517885208\tGenerator: loss 12.643599510192871\n","Epoch 95, batch 186/240:\tDiscriminator: real loss 0.18662379682064056, fake loss 0.16863422095775604\tGenerator: loss 13.644033432006836\n","Epoch 95, batch 187/240:\tDiscriminator: real loss 0.14652127027511597, fake loss 0.19423671066761017\tGenerator: loss 10.510882377624512\n","Epoch 95, batch 188/240:\tDiscriminator: real loss 0.08101193606853485, fake loss 0.08458593487739563\tGenerator: loss 10.707119941711426\n","Epoch 95, batch 189/240:\tDiscriminator: real loss 0.06988748908042908, fake loss 0.1477101892232895\tGenerator: loss 11.196541786193848\n","Epoch 95, batch 190/240:\tDiscriminator: real loss 0.07504604756832123, fake loss 0.3162497282028198\tGenerator: loss 13.771384239196777\n","Epoch 95, batch 191/240:\tDiscriminator: real loss 0.21136540174484253, fake loss 0.09400495886802673\tGenerator: loss 13.271678924560547\n","Epoch 95, batch 192/240:\tDiscriminator: real loss 0.2072324901819229, fake loss 0.07799084484577179\tGenerator: loss 11.875205039978027\n","Epoch 95, batch 193/240:\tDiscriminator: real loss 0.08798980712890625, fake loss 0.23627860844135284\tGenerator: loss 13.513245582580566\n","Epoch 95, batch 194/240:\tDiscriminator: real loss 0.11016134917736053, fake loss 0.24553337693214417\tGenerator: loss 13.333966255187988\n","Epoch 95, batch 195/240:\tDiscriminator: real loss 0.1512071192264557, fake loss 0.10256435722112656\tGenerator: loss 12.190361022949219\n","Epoch 95, batch 196/240:\tDiscriminator: real loss 0.20664413273334503, fake loss 0.19004487991333008\tGenerator: loss 12.354697227478027\n","Epoch 95, batch 197/240:\tDiscriminator: real loss 0.13411639630794525, fake loss 0.09637931734323502\tGenerator: loss 10.404947280883789\n","Epoch 95, batch 198/240:\tDiscriminator: real loss 0.17145858705043793, fake loss 0.2961322069168091\tGenerator: loss 12.800868034362793\n","Epoch 95, batch 199/240:\tDiscriminator: real loss 0.11326950788497925, fake loss 0.18796104192733765\tGenerator: loss 12.613791465759277\n","Epoch 95, batch 200/240:\tDiscriminator: real loss 0.13385355472564697, fake loss 0.17518505454063416\tGenerator: loss 12.851783752441406\n","Epoch 95, batch 201/240:\tDiscriminator: real loss 0.1740318089723587, fake loss 0.12813624739646912\tGenerator: loss 10.355184555053711\n","Epoch 95, batch 202/240:\tDiscriminator: real loss 0.11954757571220398, fake loss 0.26471638679504395\tGenerator: loss 11.051575660705566\n","Epoch 95, batch 203/240:\tDiscriminator: real loss 0.11800981312990189, fake loss 0.16420093178749084\tGenerator: loss 11.637019157409668\n","Epoch 95, batch 204/240:\tDiscriminator: real loss 0.21923546493053436, fake loss 0.16577385365962982\tGenerator: loss 11.755611419677734\n","Epoch 95, batch 205/240:\tDiscriminator: real loss 0.15996499359607697, fake loss 0.10731958597898483\tGenerator: loss 11.458409309387207\n","Epoch 95, batch 206/240:\tDiscriminator: real loss 0.13916513323783875, fake loss 0.10036937892436981\tGenerator: loss 11.330050468444824\n","Epoch 95, batch 207/240:\tDiscriminator: real loss 0.04280921816825867, fake loss 0.08771619200706482\tGenerator: loss 13.582170486450195\n","Epoch 95, batch 208/240:\tDiscriminator: real loss 0.07524994015693665, fake loss 0.18323639035224915\tGenerator: loss 14.590005874633789\n","Epoch 95, batch 209/240:\tDiscriminator: real loss 0.0765213891863823, fake loss 0.1991536170244217\tGenerator: loss 14.498176574707031\n","Epoch 95, batch 210/240:\tDiscriminator: real loss 0.1275905966758728, fake loss 0.19468539953231812\tGenerator: loss 14.084617614746094\n","Epoch 95, batch 211/240:\tDiscriminator: real loss 0.18798881769180298, fake loss 0.13293588161468506\tGenerator: loss 13.75378704071045\n","Epoch 95, batch 212/240:\tDiscriminator: real loss 0.1852831095457077, fake loss 0.23431217670440674\tGenerator: loss 15.4891939163208\n","Epoch 95, batch 213/240:\tDiscriminator: real loss 0.12039468437433243, fake loss 0.1393897384405136\tGenerator: loss 14.767809867858887\n","Epoch 95, batch 214/240:\tDiscriminator: real loss 0.18077249825000763, fake loss 0.1309056580066681\tGenerator: loss 10.024543762207031\n","Epoch 95, batch 215/240:\tDiscriminator: real loss 0.08830077201128006, fake loss 0.19436126947402954\tGenerator: loss 11.490758895874023\n","Epoch 95, batch 216/240:\tDiscriminator: real loss 0.22906917333602905, fake loss 0.27709564566612244\tGenerator: loss 14.081338882446289\n","Epoch 95, batch 217/240:\tDiscriminator: real loss 0.10466185212135315, fake loss 0.15071214735507965\tGenerator: loss 17.104354858398438\n","Epoch 95, batch 218/240:\tDiscriminator: real loss 0.18193015456199646, fake loss 0.16040068864822388\tGenerator: loss 15.913360595703125\n","Epoch 95, batch 219/240:\tDiscriminator: real loss 0.10665512084960938, fake loss 0.19013676047325134\tGenerator: loss 15.051774024963379\n","Epoch 95, batch 220/240:\tDiscriminator: real loss 0.17620888352394104, fake loss 0.09626299142837524\tGenerator: loss 13.865326881408691\n","Epoch 95, batch 221/240:\tDiscriminator: real loss 0.1153126135468483, fake loss 0.2631411850452423\tGenerator: loss 17.565229415893555\n","Epoch 95, batch 222/240:\tDiscriminator: real loss 0.0796021968126297, fake loss 0.08454462140798569\tGenerator: loss 15.25982666015625\n","Epoch 95, batch 223/240:\tDiscriminator: real loss 0.15207397937774658, fake loss 0.18041929602622986\tGenerator: loss 15.626359939575195\n","Epoch 95, batch 224/240:\tDiscriminator: real loss 0.14142504334449768, fake loss 0.15726928412914276\tGenerator: loss 15.869449615478516\n","Epoch 95, batch 225/240:\tDiscriminator: real loss 0.090638667345047, fake loss 0.15338774025440216\tGenerator: loss 17.238304138183594\n","Epoch 95, batch 226/240:\tDiscriminator: real loss 0.26765328645706177, fake loss 0.2205812633037567\tGenerator: loss 14.741708755493164\n","Epoch 95, batch 227/240:\tDiscriminator: real loss 0.11996039748191833, fake loss 0.09284962713718414\tGenerator: loss 15.155193328857422\n","Epoch 95, batch 228/240:\tDiscriminator: real loss 0.06717688590288162, fake loss 0.16278493404388428\tGenerator: loss 14.753190040588379\n","Epoch 95, batch 229/240:\tDiscriminator: real loss 0.062271129339933395, fake loss 0.15301430225372314\tGenerator: loss 14.858415603637695\n","Epoch 95, batch 230/240:\tDiscriminator: real loss 0.10053996741771698, fake loss 0.10968076437711716\tGenerator: loss 13.751181602478027\n","Epoch 95, batch 231/240:\tDiscriminator: real loss 0.14269787073135376, fake loss 0.1407909244298935\tGenerator: loss 12.973557472229004\n","Epoch 95, batch 232/240:\tDiscriminator: real loss 0.08351455628871918, fake loss 0.14982767403125763\tGenerator: loss 13.353658676147461\n","Epoch 95, batch 233/240:\tDiscriminator: real loss 0.1355847269296646, fake loss 0.21178695559501648\tGenerator: loss 15.8997802734375\n","Epoch 95, batch 234/240:\tDiscriminator: real loss 0.27666619420051575, fake loss 0.12092406302690506\tGenerator: loss 15.405416488647461\n","Epoch 95, batch 235/240:\tDiscriminator: real loss 0.14603790640830994, fake loss 0.2361069619655609\tGenerator: loss 14.960919380187988\n","Epoch 95, batch 236/240:\tDiscriminator: real loss 0.07221071422100067, fake loss 0.09613991528749466\tGenerator: loss 15.22262954711914\n","Epoch 95, batch 237/240:\tDiscriminator: real loss 0.09772641211748123, fake loss 0.16256313025951385\tGenerator: loss 13.948478698730469\n","Epoch 95, batch 238/240:\tDiscriminator: real loss 0.07931403815746307, fake loss 0.05388876423239708\tGenerator: loss 11.831729888916016\n","Epoch 95, batch 239/240:\tDiscriminator: real loss 0.05857619643211365, fake loss 0.24702243506908417\tGenerator: loss 14.463789939880371\n","Epoch 95, batch 240/240:\tDiscriminator: real loss 0.2425515502691269, fake loss 0.14575254917144775\tGenerator: loss 14.32192611694336\n","Epoch 96, batch 1/240:\tDiscriminator: real loss 0.14646059274673462, fake loss 0.1272774189710617\tGenerator: loss 12.892077445983887\n","Epoch 96, batch 2/240:\tDiscriminator: real loss 0.1720084398984909, fake loss 0.2753751873970032\tGenerator: loss 13.30451774597168\n","Epoch 96, batch 3/240:\tDiscriminator: real loss 0.1196703165769577, fake loss 0.14646656811237335\tGenerator: loss 12.607032775878906\n","Epoch 96, batch 4/240:\tDiscriminator: real loss 0.15056836605072021, fake loss 0.12641441822052002\tGenerator: loss 11.904937744140625\n","Epoch 96, batch 5/240:\tDiscriminator: real loss 0.12243717163801193, fake loss 0.2578209638595581\tGenerator: loss 13.207380294799805\n","Epoch 96, batch 6/240:\tDiscriminator: real loss 0.20192302763462067, fake loss 0.12220935523509979\tGenerator: loss 12.094354629516602\n","Epoch 96, batch 7/240:\tDiscriminator: real loss 0.07807400077581406, fake loss 0.12736864387989044\tGenerator: loss 11.569480895996094\n","Epoch 96, batch 8/240:\tDiscriminator: real loss 0.15970033407211304, fake loss 0.10956846177577972\tGenerator: loss 8.309260368347168\n","Epoch 96, batch 9/240:\tDiscriminator: real loss 0.08961387723684311, fake loss 0.18110498785972595\tGenerator: loss 8.989752769470215\n","Epoch 96, batch 10/240:\tDiscriminator: real loss 0.14314734935760498, fake loss 0.15905800461769104\tGenerator: loss 11.61943244934082\n","Epoch 96, batch 11/240:\tDiscriminator: real loss 0.09353681653738022, fake loss 0.2075158655643463\tGenerator: loss 12.971996307373047\n","Epoch 96, batch 12/240:\tDiscriminator: real loss 0.1427105814218521, fake loss 0.11552491784095764\tGenerator: loss 12.903583526611328\n","Epoch 96, batch 13/240:\tDiscriminator: real loss 0.1065693274140358, fake loss 0.17609970271587372\tGenerator: loss 13.036606788635254\n","Epoch 96, batch 14/240:\tDiscriminator: real loss 0.13535894453525543, fake loss 0.04207146167755127\tGenerator: loss 12.442481994628906\n","Epoch 96, batch 15/240:\tDiscriminator: real loss 0.10847596079111099, fake loss 0.11276639997959137\tGenerator: loss 11.783260345458984\n","Epoch 96, batch 16/240:\tDiscriminator: real loss 0.08079710602760315, fake loss 0.14927881956100464\tGenerator: loss 12.553297996520996\n","Epoch 96, batch 17/240:\tDiscriminator: real loss 0.051212720572948456, fake loss 0.25589385628700256\tGenerator: loss 13.328779220581055\n","Epoch 96, batch 18/240:\tDiscriminator: real loss 0.1331387311220169, fake loss 0.0775577574968338\tGenerator: loss 12.819243431091309\n","Epoch 96, batch 19/240:\tDiscriminator: real loss 0.1393841803073883, fake loss 0.15301513671875\tGenerator: loss 10.863188743591309\n","Epoch 96, batch 20/240:\tDiscriminator: real loss 0.13344734907150269, fake loss 0.1383221447467804\tGenerator: loss 10.989684104919434\n","Epoch 96, batch 21/240:\tDiscriminator: real loss 0.10758586972951889, fake loss 0.06247958168387413\tGenerator: loss 10.604805946350098\n","Epoch 96, batch 22/240:\tDiscriminator: real loss 0.04352671653032303, fake loss 0.19209536910057068\tGenerator: loss 11.005061149597168\n","Epoch 96, batch 23/240:\tDiscriminator: real loss 0.0671415627002716, fake loss 0.07450956106185913\tGenerator: loss 10.816903114318848\n","Epoch 96, batch 24/240:\tDiscriminator: real loss 0.21906410157680511, fake loss 0.29812249541282654\tGenerator: loss 9.811290740966797\n","Epoch 96, batch 25/240:\tDiscriminator: real loss 0.10276731848716736, fake loss 0.05047332122921944\tGenerator: loss 10.1326322555542\n","Epoch 96, batch 26/240:\tDiscriminator: real loss 0.13699962198734283, fake loss 0.06609947979450226\tGenerator: loss 8.701362609863281\n","Epoch 96, batch 27/240:\tDiscriminator: real loss 0.03905162215232849, fake loss 0.2480921596288681\tGenerator: loss 9.29345989227295\n","Epoch 96, batch 28/240:\tDiscriminator: real loss 0.0643436461687088, fake loss 0.11144223809242249\tGenerator: loss 10.582860946655273\n","Epoch 96, batch 29/240:\tDiscriminator: real loss 0.21088136732578278, fake loss 0.11277681589126587\tGenerator: loss 10.819169044494629\n","Epoch 96, batch 30/240:\tDiscriminator: real loss 0.12462317198514938, fake loss 0.11148276925086975\tGenerator: loss 10.009398460388184\n","Epoch 96, batch 31/240:\tDiscriminator: real loss 0.05285697802901268, fake loss 0.18036849796772003\tGenerator: loss 10.639104843139648\n","Epoch 96, batch 32/240:\tDiscriminator: real loss 0.07588274031877518, fake loss 0.16204583644866943\tGenerator: loss 10.030892372131348\n","Epoch 96, batch 33/240:\tDiscriminator: real loss 0.12330582737922668, fake loss 0.035789843648672104\tGenerator: loss 8.362458229064941\n","Epoch 96, batch 34/240:\tDiscriminator: real loss 0.1762193739414215, fake loss 0.27720439434051514\tGenerator: loss 9.740592002868652\n","Epoch 96, batch 35/240:\tDiscriminator: real loss 0.051497481763362885, fake loss 0.09085815399885178\tGenerator: loss 11.370284080505371\n","Epoch 96, batch 36/240:\tDiscriminator: real loss 0.10616768151521683, fake loss 0.15323291718959808\tGenerator: loss 11.834999084472656\n","Epoch 96, batch 37/240:\tDiscriminator: real loss 0.127961203455925, fake loss 0.2433108538389206\tGenerator: loss 11.3511381149292\n","Epoch 96, batch 38/240:\tDiscriminator: real loss 0.11296867579221725, fake loss 0.20046430826187134\tGenerator: loss 11.62325668334961\n","Epoch 96, batch 39/240:\tDiscriminator: real loss 0.3048347234725952, fake loss 0.17212988436222076\tGenerator: loss 11.533068656921387\n","Epoch 96, batch 40/240:\tDiscriminator: real loss 0.13009890913963318, fake loss 0.19078892469406128\tGenerator: loss 11.734026908874512\n","Epoch 96, batch 41/240:\tDiscriminator: real loss 0.07669294625520706, fake loss 0.03857399523258209\tGenerator: loss 10.99962043762207\n","Epoch 96, batch 42/240:\tDiscriminator: real loss 0.06013628840446472, fake loss 0.32984787225723267\tGenerator: loss 12.602250099182129\n","Epoch 96, batch 43/240:\tDiscriminator: real loss 0.155127614736557, fake loss 0.10594186186790466\tGenerator: loss 11.944148063659668\n","Epoch 96, batch 44/240:\tDiscriminator: real loss 0.11605757474899292, fake loss 0.036028798669576645\tGenerator: loss 11.969322204589844\n","Epoch 96, batch 45/240:\tDiscriminator: real loss 0.1016700267791748, fake loss 0.28462865948677063\tGenerator: loss 11.35620403289795\n","Epoch 96, batch 46/240:\tDiscriminator: real loss 0.08112259209156036, fake loss 0.29402634501457214\tGenerator: loss 14.991908073425293\n","Epoch 96, batch 47/240:\tDiscriminator: real loss 0.1937137097120285, fake loss 0.08478851616382599\tGenerator: loss 13.731362342834473\n","Epoch 96, batch 48/240:\tDiscriminator: real loss 0.15899835526943207, fake loss 0.20101068913936615\tGenerator: loss 12.440556526184082\n","Epoch 96, batch 49/240:\tDiscriminator: real loss 0.04993260279297829, fake loss 0.2266732007265091\tGenerator: loss 14.090131759643555\n","Epoch 96, batch 50/240:\tDiscriminator: real loss 0.13283537328243256, fake loss 0.11898698657751083\tGenerator: loss 14.284893989562988\n","Epoch 96, batch 51/240:\tDiscriminator: real loss 0.10913709551095963, fake loss 0.09118106216192245\tGenerator: loss 12.498269081115723\n","Epoch 96, batch 52/240:\tDiscriminator: real loss 0.16769836843013763, fake loss 0.190225750207901\tGenerator: loss 9.023526191711426\n","Epoch 96, batch 53/240:\tDiscriminator: real loss 0.049278851598501205, fake loss 0.2213762253522873\tGenerator: loss 8.789989471435547\n","Epoch 96, batch 54/240:\tDiscriminator: real loss 0.16095183789730072, fake loss 0.202077254652977\tGenerator: loss 11.166089057922363\n","Epoch 96, batch 55/240:\tDiscriminator: real loss 0.20419320464134216, fake loss 0.2145688235759735\tGenerator: loss 9.482544898986816\n","Epoch 96, batch 56/240:\tDiscriminator: real loss 0.06841880083084106, fake loss 0.12201490253210068\tGenerator: loss 9.633374214172363\n","Epoch 96, batch 57/240:\tDiscriminator: real loss 0.09507697820663452, fake loss 0.19103015959262848\tGenerator: loss 10.000991821289062\n","Epoch 96, batch 58/240:\tDiscriminator: real loss 0.15415826439857483, fake loss 0.21341194212436676\tGenerator: loss 11.744118690490723\n","Epoch 96, batch 59/240:\tDiscriminator: real loss 0.12228319048881531, fake loss 0.21031011641025543\tGenerator: loss 12.747912406921387\n","Epoch 96, batch 60/240:\tDiscriminator: real loss 0.11128507554531097, fake loss 0.15157894790172577\tGenerator: loss 14.58658218383789\n","Epoch 96, batch 61/240:\tDiscriminator: real loss 0.19212670624256134, fake loss 0.17363521456718445\tGenerator: loss 13.662642478942871\n","Epoch 96, batch 62/240:\tDiscriminator: real loss 0.09220586717128754, fake loss 0.11082546412944794\tGenerator: loss 12.534611701965332\n","Epoch 96, batch 63/240:\tDiscriminator: real loss 0.06818155944347382, fake loss 0.08016286790370941\tGenerator: loss 12.301250457763672\n","Epoch 96, batch 64/240:\tDiscriminator: real loss 0.06716888397932053, fake loss 0.1951216161251068\tGenerator: loss 12.616924285888672\n","Epoch 96, batch 65/240:\tDiscriminator: real loss 0.12589317560195923, fake loss 0.14266414940357208\tGenerator: loss 12.094879150390625\n","Epoch 96, batch 66/240:\tDiscriminator: real loss 0.2085759937763214, fake loss 0.13746070861816406\tGenerator: loss 12.88409423828125\n","Epoch 96, batch 67/240:\tDiscriminator: real loss 0.10181546211242676, fake loss 0.23871415853500366\tGenerator: loss 14.635952949523926\n","Epoch 96, batch 68/240:\tDiscriminator: real loss 0.18390943109989166, fake loss 0.13475827872753143\tGenerator: loss 10.386444091796875\n","Epoch 96, batch 69/240:\tDiscriminator: real loss 0.06827762722969055, fake loss 0.0689895898103714\tGenerator: loss 10.353150367736816\n","Epoch 96, batch 70/240:\tDiscriminator: real loss 0.12002305686473846, fake loss 0.06518066674470901\tGenerator: loss 11.263762474060059\n","Epoch 96, batch 71/240:\tDiscriminator: real loss 0.052044354379177094, fake loss 0.2952668368816376\tGenerator: loss 10.983251571655273\n","Epoch 96, batch 72/240:\tDiscriminator: real loss 0.07528997212648392, fake loss 0.19562764465808868\tGenerator: loss 11.18100357055664\n","Epoch 96, batch 73/240:\tDiscriminator: real loss 0.25817322731018066, fake loss 0.1830417513847351\tGenerator: loss 15.224040985107422\n","Epoch 96, batch 74/240:\tDiscriminator: real loss 0.13576340675354004, fake loss 0.09504285454750061\tGenerator: loss 14.593537330627441\n","Epoch 96, batch 75/240:\tDiscriminator: real loss 0.08860745280981064, fake loss 0.15907007455825806\tGenerator: loss 13.591238975524902\n","Epoch 96, batch 76/240:\tDiscriminator: real loss 0.07334752380847931, fake loss 0.17431358993053436\tGenerator: loss 13.429948806762695\n","Epoch 96, batch 77/240:\tDiscriminator: real loss 0.14156611263751984, fake loss 0.18483036756515503\tGenerator: loss 12.31344223022461\n","Epoch 96, batch 78/240:\tDiscriminator: real loss 0.06919372826814651, fake loss 0.16140705347061157\tGenerator: loss 11.875152587890625\n","Epoch 96, batch 79/240:\tDiscriminator: real loss 0.16394825279712677, fake loss 0.1617937982082367\tGenerator: loss 10.410513877868652\n","Epoch 96, batch 80/240:\tDiscriminator: real loss 0.12738536298274994, fake loss 0.16984133422374725\tGenerator: loss 11.351398468017578\n","Epoch 96, batch 81/240:\tDiscriminator: real loss 0.16639336943626404, fake loss 0.13699781894683838\tGenerator: loss 11.23145866394043\n","Epoch 96, batch 82/240:\tDiscriminator: real loss 0.09265124052762985, fake loss 0.21747295558452606\tGenerator: loss 10.687712669372559\n","Epoch 96, batch 83/240:\tDiscriminator: real loss 0.12031878530979156, fake loss 0.1032295823097229\tGenerator: loss 9.679540634155273\n","Epoch 96, batch 84/240:\tDiscriminator: real loss 0.11063317954540253, fake loss 0.08610276877880096\tGenerator: loss 10.017452239990234\n","Epoch 96, batch 85/240:\tDiscriminator: real loss 0.21343612670898438, fake loss 0.23008230328559875\tGenerator: loss 11.99996566772461\n","Epoch 96, batch 86/240:\tDiscriminator: real loss 0.06011465564370155, fake loss 0.1290089190006256\tGenerator: loss 12.726841926574707\n","Epoch 96, batch 87/240:\tDiscriminator: real loss 0.09882334619760513, fake loss 0.4196171462535858\tGenerator: loss 11.653870582580566\n","Epoch 96, batch 88/240:\tDiscriminator: real loss 0.16140154004096985, fake loss 0.13341115415096283\tGenerator: loss 10.521096229553223\n","Epoch 96, batch 89/240:\tDiscriminator: real loss 0.1798720508813858, fake loss 0.21681460738182068\tGenerator: loss 10.420248985290527\n","Epoch 96, batch 90/240:\tDiscriminator: real loss 0.11386276036500931, fake loss 0.09202932566404343\tGenerator: loss 12.220874786376953\n","Epoch 96, batch 91/240:\tDiscriminator: real loss 0.17852464318275452, fake loss 0.15518413484096527\tGenerator: loss 11.01968002319336\n","Epoch 96, batch 92/240:\tDiscriminator: real loss 0.13733644783496857, fake loss 0.1759687215089798\tGenerator: loss 8.939193725585938\n","Epoch 96, batch 93/240:\tDiscriminator: real loss 0.05399494618177414, fake loss 0.1371094137430191\tGenerator: loss 10.646540641784668\n","Epoch 96, batch 94/240:\tDiscriminator: real loss 0.08640997856855392, fake loss 0.1187700480222702\tGenerator: loss 10.735159873962402\n","Epoch 96, batch 95/240:\tDiscriminator: real loss 0.1732795685529709, fake loss 0.13622666895389557\tGenerator: loss 10.917444229125977\n","Epoch 96, batch 96/240:\tDiscriminator: real loss 0.09957046806812286, fake loss 0.13991133868694305\tGenerator: loss 13.896148681640625\n","Epoch 96, batch 97/240:\tDiscriminator: real loss 0.07316146790981293, fake loss 0.16916315257549286\tGenerator: loss 14.825557708740234\n","Epoch 96, batch 98/240:\tDiscriminator: real loss 0.19217559695243835, fake loss 0.08990190178155899\tGenerator: loss 12.02405071258545\n","Epoch 96, batch 99/240:\tDiscriminator: real loss 0.055828168988227844, fake loss 0.2571181654930115\tGenerator: loss 11.475539207458496\n","Epoch 96, batch 100/240:\tDiscriminator: real loss 0.0559544675052166, fake loss 0.07510652393102646\tGenerator: loss 12.220545768737793\n","Epoch 96, batch 101/240:\tDiscriminator: real loss 0.26148703694343567, fake loss 0.19535507261753082\tGenerator: loss 12.132482528686523\n","Epoch 96, batch 102/240:\tDiscriminator: real loss 0.0846884548664093, fake loss 0.10569833964109421\tGenerator: loss 12.326934814453125\n","Epoch 96, batch 103/240:\tDiscriminator: real loss 0.16206367313861847, fake loss 0.1720089316368103\tGenerator: loss 12.443716049194336\n","Epoch 96, batch 104/240:\tDiscriminator: real loss 0.0760640799999237, fake loss 0.16139140725135803\tGenerator: loss 13.450937271118164\n","Epoch 96, batch 105/240:\tDiscriminator: real loss 0.053709689527750015, fake loss 0.09407972544431686\tGenerator: loss 14.251531600952148\n","Epoch 96, batch 106/240:\tDiscriminator: real loss 0.10792496055364609, fake loss 0.23708343505859375\tGenerator: loss 15.0151948928833\n","Epoch 96, batch 107/240:\tDiscriminator: real loss 0.15040265023708344, fake loss 0.243123397231102\tGenerator: loss 13.89123821258545\n","Epoch 96, batch 108/240:\tDiscriminator: real loss 0.28414615988731384, fake loss 0.12813463807106018\tGenerator: loss 12.787284851074219\n","Epoch 96, batch 109/240:\tDiscriminator: real loss 0.12389770150184631, fake loss 0.19079194962978363\tGenerator: loss 12.594435691833496\n","Epoch 96, batch 110/240:\tDiscriminator: real loss 0.08374582231044769, fake loss 0.05842088162899017\tGenerator: loss 12.142049789428711\n","Epoch 96, batch 111/240:\tDiscriminator: real loss 0.07437211275100708, fake loss 0.2196332812309265\tGenerator: loss 14.609871864318848\n","Epoch 96, batch 112/240:\tDiscriminator: real loss 0.07113190740346909, fake loss 0.20987530052661896\tGenerator: loss 13.718949317932129\n","Epoch 96, batch 113/240:\tDiscriminator: real loss 0.18206138908863068, fake loss 0.15753775835037231\tGenerator: loss 13.766317367553711\n","Epoch 96, batch 114/240:\tDiscriminator: real loss 0.16129924356937408, fake loss 0.0996142029762268\tGenerator: loss 11.667895317077637\n","Epoch 96, batch 115/240:\tDiscriminator: real loss 0.05065426975488663, fake loss 0.23487259447574615\tGenerator: loss 13.133411407470703\n","Epoch 96, batch 116/240:\tDiscriminator: real loss 0.08991093933582306, fake loss 0.11836180835962296\tGenerator: loss 12.914299011230469\n","Epoch 96, batch 117/240:\tDiscriminator: real loss 0.16011133790016174, fake loss 0.19077187776565552\tGenerator: loss 12.635930061340332\n","Epoch 96, batch 118/240:\tDiscriminator: real loss 0.13525283336639404, fake loss 0.15334518253803253\tGenerator: loss 12.206350326538086\n","Epoch 96, batch 119/240:\tDiscriminator: real loss 0.13896861672401428, fake loss 0.20840679109096527\tGenerator: loss 12.862565040588379\n","Epoch 96, batch 120/240:\tDiscriminator: real loss 0.14986953139305115, fake loss 0.1010151356458664\tGenerator: loss 12.424803733825684\n","Epoch 96, batch 121/240:\tDiscriminator: real loss 0.15367262065410614, fake loss 0.12154746800661087\tGenerator: loss 12.357294082641602\n","Epoch 96, batch 122/240:\tDiscriminator: real loss 0.06438346207141876, fake loss 0.15762817859649658\tGenerator: loss 12.297405242919922\n","Epoch 96, batch 123/240:\tDiscriminator: real loss 0.1422843039035797, fake loss 0.19639559090137482\tGenerator: loss 12.180761337280273\n","Epoch 96, batch 124/240:\tDiscriminator: real loss 0.12981361150741577, fake loss 0.17232903838157654\tGenerator: loss 10.525184631347656\n","Epoch 96, batch 125/240:\tDiscriminator: real loss 0.12926830351352692, fake loss 0.13030007481575012\tGenerator: loss 10.941946029663086\n","Epoch 96, batch 126/240:\tDiscriminator: real loss 0.08639823645353317, fake loss 0.15499930083751678\tGenerator: loss 11.407034873962402\n","Epoch 96, batch 127/240:\tDiscriminator: real loss 0.11580356955528259, fake loss 0.10570913553237915\tGenerator: loss 12.436776161193848\n","Epoch 96, batch 128/240:\tDiscriminator: real loss 0.10376289486885071, fake loss 0.11430976539850235\tGenerator: loss 11.986053466796875\n","Epoch 96, batch 129/240:\tDiscriminator: real loss 0.08503580838441849, fake loss 0.24239513278007507\tGenerator: loss 13.669608116149902\n","Epoch 96, batch 130/240:\tDiscriminator: real loss 0.10710825771093369, fake loss 0.08253172785043716\tGenerator: loss 13.962575912475586\n","Epoch 96, batch 131/240:\tDiscriminator: real loss 0.15601718425750732, fake loss 0.21198217570781708\tGenerator: loss 13.54261589050293\n","Epoch 96, batch 132/240:\tDiscriminator: real loss 0.060326989740133286, fake loss 0.06890467554330826\tGenerator: loss 13.975358963012695\n","Epoch 96, batch 133/240:\tDiscriminator: real loss 0.06995358318090439, fake loss 0.17880652844905853\tGenerator: loss 13.129796981811523\n","Epoch 96, batch 134/240:\tDiscriminator: real loss 0.06271274387836456, fake loss 0.1388707011938095\tGenerator: loss 13.418717384338379\n","Epoch 96, batch 135/240:\tDiscriminator: real loss 0.09219770133495331, fake loss 0.04138518497347832\tGenerator: loss 16.229259490966797\n","Epoch 96, batch 136/240:\tDiscriminator: real loss 0.11588799208402634, fake loss 0.1791144609451294\tGenerator: loss 14.435225486755371\n","Epoch 96, batch 137/240:\tDiscriminator: real loss 0.09083135426044464, fake loss 0.16336384415626526\tGenerator: loss 14.158943176269531\n","Epoch 96, batch 138/240:\tDiscriminator: real loss 0.14199179410934448, fake loss 0.07556764036417007\tGenerator: loss 14.864790916442871\n","Epoch 96, batch 139/240:\tDiscriminator: real loss 0.08704125136137009, fake loss 0.16600774228572845\tGenerator: loss 13.448469161987305\n","Epoch 96, batch 140/240:\tDiscriminator: real loss 0.07648540288209915, fake loss 0.25868260860443115\tGenerator: loss 13.81517219543457\n","Epoch 96, batch 141/240:\tDiscriminator: real loss 0.09447288513183594, fake loss 0.06857109069824219\tGenerator: loss 10.71943473815918\n","Epoch 96, batch 142/240:\tDiscriminator: real loss 0.13217899203300476, fake loss 0.2423628270626068\tGenerator: loss 14.50109577178955\n","Epoch 96, batch 143/240:\tDiscriminator: real loss 0.11883971095085144, fake loss 0.18059328198432922\tGenerator: loss 14.127899169921875\n","Epoch 96, batch 144/240:\tDiscriminator: real loss 0.15945635735988617, fake loss 0.11820545792579651\tGenerator: loss 11.826577186584473\n","Epoch 96, batch 145/240:\tDiscriminator: real loss 0.1072826012969017, fake loss 0.2362896203994751\tGenerator: loss 13.409894943237305\n","Epoch 96, batch 146/240:\tDiscriminator: real loss 0.09414072334766388, fake loss 0.13256071507930756\tGenerator: loss 14.339887619018555\n","Epoch 96, batch 147/240:\tDiscriminator: real loss 0.10716596245765686, fake loss 0.06975648552179337\tGenerator: loss 12.737205505371094\n","Epoch 96, batch 148/240:\tDiscriminator: real loss 0.1497921347618103, fake loss 0.2361687868833542\tGenerator: loss 14.188690185546875\n","Epoch 96, batch 149/240:\tDiscriminator: real loss 0.13647393882274628, fake loss 0.1611045002937317\tGenerator: loss 15.677913665771484\n","Epoch 96, batch 150/240:\tDiscriminator: real loss 0.11373081803321838, fake loss 0.06090434640645981\tGenerator: loss 15.576220512390137\n","Epoch 96, batch 151/240:\tDiscriminator: real loss 0.08540599048137665, fake loss 0.11562761664390564\tGenerator: loss 13.050368309020996\n","Epoch 96, batch 152/240:\tDiscriminator: real loss 0.04770074784755707, fake loss 0.17322678864002228\tGenerator: loss 15.001591682434082\n","Epoch 96, batch 153/240:\tDiscriminator: real loss 0.09765411168336868, fake loss 0.12670858204364777\tGenerator: loss 15.324113845825195\n","Epoch 96, batch 154/240:\tDiscriminator: real loss 0.18019211292266846, fake loss 0.17409084737300873\tGenerator: loss 13.984142303466797\n","Epoch 96, batch 155/240:\tDiscriminator: real loss 0.060978032648563385, fake loss 0.13065604865550995\tGenerator: loss 13.033075332641602\n","Epoch 96, batch 156/240:\tDiscriminator: real loss 0.12387698143720627, fake loss 0.0984945073723793\tGenerator: loss 14.09390640258789\n","Epoch 96, batch 157/240:\tDiscriminator: real loss 0.11615447700023651, fake loss 0.08489824086427689\tGenerator: loss 15.221192359924316\n","Epoch 96, batch 158/240:\tDiscriminator: real loss 0.03732540085911751, fake loss 0.15148812532424927\tGenerator: loss 15.603338241577148\n","Epoch 96, batch 159/240:\tDiscriminator: real loss 0.09247585386037827, fake loss 0.1661505103111267\tGenerator: loss 17.0727596282959\n","Epoch 96, batch 160/240:\tDiscriminator: real loss 0.13548095524311066, fake loss 0.09487465769052505\tGenerator: loss 14.549840927124023\n","Epoch 96, batch 161/240:\tDiscriminator: real loss 0.06311099231243134, fake loss 0.1487644761800766\tGenerator: loss 14.35004997253418\n","Epoch 96, batch 162/240:\tDiscriminator: real loss 0.12585408985614777, fake loss 0.1126936599612236\tGenerator: loss 13.55795669555664\n","Epoch 96, batch 163/240:\tDiscriminator: real loss 0.07992326468229294, fake loss 0.07811347395181656\tGenerator: loss 14.28409194946289\n","Epoch 96, batch 164/240:\tDiscriminator: real loss 0.06652089953422546, fake loss 0.17495913803577423\tGenerator: loss 13.715789794921875\n","Epoch 96, batch 165/240:\tDiscriminator: real loss 0.1411031186580658, fake loss 0.06486707925796509\tGenerator: loss 15.732645034790039\n","Epoch 96, batch 166/240:\tDiscriminator: real loss 0.05333571881055832, fake loss 0.20025308430194855\tGenerator: loss 14.766366958618164\n","Epoch 96, batch 167/240:\tDiscriminator: real loss 0.08682483434677124, fake loss 0.17786109447479248\tGenerator: loss 16.74568748474121\n","Epoch 96, batch 168/240:\tDiscriminator: real loss 0.13068801164627075, fake loss 0.12923943996429443\tGenerator: loss 16.108612060546875\n","Epoch 96, batch 169/240:\tDiscriminator: real loss 0.10407211631536484, fake loss 0.11843347549438477\tGenerator: loss 16.813777923583984\n","Epoch 96, batch 170/240:\tDiscriminator: real loss 0.05003015697002411, fake loss 0.15640883147716522\tGenerator: loss 17.61833953857422\n","Epoch 96, batch 171/240:\tDiscriminator: real loss 0.09249193221330643, fake loss 0.18115495145320892\tGenerator: loss 16.70857810974121\n","Epoch 96, batch 172/240:\tDiscriminator: real loss 0.23458820581436157, fake loss 0.1831560879945755\tGenerator: loss 15.231717109680176\n","Epoch 96, batch 173/240:\tDiscriminator: real loss 0.09507784992456436, fake loss 0.09385160356760025\tGenerator: loss 16.789451599121094\n","Epoch 96, batch 174/240:\tDiscriminator: real loss 0.14148488640785217, fake loss 0.2851231098175049\tGenerator: loss 17.79157257080078\n","Epoch 96, batch 175/240:\tDiscriminator: real loss 0.12604838609695435, fake loss 0.2283739447593689\tGenerator: loss 18.7110538482666\n","Epoch 96, batch 176/240:\tDiscriminator: real loss 0.08262930065393448, fake loss 0.08115498721599579\tGenerator: loss 20.1014404296875\n","Epoch 96, batch 177/240:\tDiscriminator: real loss 0.16575491428375244, fake loss 0.04469055309891701\tGenerator: loss 18.78716468811035\n","Epoch 96, batch 178/240:\tDiscriminator: real loss 0.10924291610717773, fake loss 0.137272909283638\tGenerator: loss 18.895483016967773\n","Epoch 96, batch 179/240:\tDiscriminator: real loss 0.13101008534431458, fake loss 0.24637119472026825\tGenerator: loss 17.079265594482422\n","Epoch 96, batch 180/240:\tDiscriminator: real loss 0.04385572299361229, fake loss 0.06246045231819153\tGenerator: loss 16.331558227539062\n","Epoch 96, batch 181/240:\tDiscriminator: real loss 0.06758241355419159, fake loss 0.18196308612823486\tGenerator: loss 15.871892929077148\n","Epoch 96, batch 182/240:\tDiscriminator: real loss 0.06277381628751755, fake loss 0.13012319803237915\tGenerator: loss 17.14208221435547\n","Epoch 96, batch 183/240:\tDiscriminator: real loss 0.14800506830215454, fake loss 0.07169054448604584\tGenerator: loss 17.548124313354492\n","Epoch 96, batch 184/240:\tDiscriminator: real loss 0.1694147288799286, fake loss 0.23857082426548004\tGenerator: loss 19.197677612304688\n","Epoch 96, batch 185/240:\tDiscriminator: real loss 0.05112345516681671, fake loss 0.0643378421664238\tGenerator: loss 17.959604263305664\n","Epoch 96, batch 186/240:\tDiscriminator: real loss 0.07366921752691269, fake loss 0.1653001755475998\tGenerator: loss 16.563138961791992\n","Epoch 96, batch 187/240:\tDiscriminator: real loss 0.09370037168264389, fake loss 0.0879414826631546\tGenerator: loss 17.782623291015625\n","Epoch 96, batch 188/240:\tDiscriminator: real loss 0.12015952169895172, fake loss 0.10229082405567169\tGenerator: loss 15.433929443359375\n","Epoch 96, batch 189/240:\tDiscriminator: real loss 0.1069229319691658, fake loss 0.15356631577014923\tGenerator: loss 17.01763343811035\n","Epoch 96, batch 190/240:\tDiscriminator: real loss 0.06116984039545059, fake loss 0.06399010866880417\tGenerator: loss 15.967926979064941\n","Epoch 96, batch 191/240:\tDiscriminator: real loss 0.08943958580493927, fake loss 0.1625184565782547\tGenerator: loss 18.497995376586914\n","Epoch 96, batch 192/240:\tDiscriminator: real loss 0.11429306864738464, fake loss 0.2833023965358734\tGenerator: loss 16.694671630859375\n","Epoch 96, batch 193/240:\tDiscriminator: real loss 0.0950169637799263, fake loss 0.03561268374323845\tGenerator: loss 16.83566665649414\n","Epoch 96, batch 194/240:\tDiscriminator: real loss 0.08660812675952911, fake loss 0.1431795209646225\tGenerator: loss 18.280471801757812\n","Epoch 96, batch 195/240:\tDiscriminator: real loss 0.18094410002231598, fake loss 0.10377678275108337\tGenerator: loss 16.542171478271484\n","Epoch 96, batch 196/240:\tDiscriminator: real loss 0.08843629062175751, fake loss 0.270315945148468\tGenerator: loss 18.91885757446289\n","Epoch 96, batch 197/240:\tDiscriminator: real loss 0.16431359946727753, fake loss 0.31935447454452515\tGenerator: loss 18.274160385131836\n","Epoch 96, batch 198/240:\tDiscriminator: real loss 0.17846983671188354, fake loss 0.019948754459619522\tGenerator: loss 16.39464569091797\n","Epoch 96, batch 199/240:\tDiscriminator: real loss 0.13054245710372925, fake loss 0.25370779633522034\tGenerator: loss 16.347366333007812\n","Epoch 96, batch 200/240:\tDiscriminator: real loss 0.1533401608467102, fake loss 0.14605563879013062\tGenerator: loss 16.21451759338379\n","Epoch 96, batch 201/240:\tDiscriminator: real loss 0.08592557162046432, fake loss 0.17472214996814728\tGenerator: loss 15.017655372619629\n","Epoch 96, batch 202/240:\tDiscriminator: real loss 0.11074775457382202, fake loss 0.10393373668193817\tGenerator: loss 12.941878318786621\n","Epoch 96, batch 203/240:\tDiscriminator: real loss 0.1309359222650528, fake loss 0.14518892765045166\tGenerator: loss 11.840371131896973\n","Epoch 96, batch 204/240:\tDiscriminator: real loss 0.08225185424089432, fake loss 0.17936965823173523\tGenerator: loss 12.980639457702637\n","Epoch 96, batch 205/240:\tDiscriminator: real loss 0.14372241497039795, fake loss 0.12772953510284424\tGenerator: loss 12.843950271606445\n","Epoch 96, batch 206/240:\tDiscriminator: real loss 0.0609627440571785, fake loss 0.2101912945508957\tGenerator: loss 13.672384262084961\n","Epoch 96, batch 207/240:\tDiscriminator: real loss 0.10115842521190643, fake loss 0.11076486855745316\tGenerator: loss 14.622289657592773\n","Epoch 96, batch 208/240:\tDiscriminator: real loss 0.15010756254196167, fake loss 0.07507868111133575\tGenerator: loss 13.895015716552734\n","Epoch 96, batch 209/240:\tDiscriminator: real loss 0.11479119956493378, fake loss 0.374775767326355\tGenerator: loss 15.087635040283203\n","Epoch 96, batch 210/240:\tDiscriminator: real loss 0.1556410938501358, fake loss 0.0744803324341774\tGenerator: loss 13.568699836730957\n","Epoch 96, batch 211/240:\tDiscriminator: real loss 0.13178853690624237, fake loss 0.13016779720783234\tGenerator: loss 14.290953636169434\n","Epoch 96, batch 212/240:\tDiscriminator: real loss 0.1459571123123169, fake loss 0.17751803994178772\tGenerator: loss 13.357283592224121\n","Epoch 96, batch 213/240:\tDiscriminator: real loss 0.1503198742866516, fake loss 0.05790053308010101\tGenerator: loss 13.316850662231445\n","Epoch 96, batch 214/240:\tDiscriminator: real loss 0.07974466681480408, fake loss 0.21976713836193085\tGenerator: loss 12.592201232910156\n","Epoch 96, batch 215/240:\tDiscriminator: real loss 0.08082542568445206, fake loss 0.17399536073207855\tGenerator: loss 14.954188346862793\n","Epoch 96, batch 216/240:\tDiscriminator: real loss 0.10032400488853455, fake loss 0.07173962891101837\tGenerator: loss 14.12304401397705\n","Epoch 96, batch 217/240:\tDiscriminator: real loss 0.12214946746826172, fake loss 0.2250269502401352\tGenerator: loss 14.708584785461426\n","Epoch 96, batch 218/240:\tDiscriminator: real loss 0.12680859863758087, fake loss 0.1745283454656601\tGenerator: loss 15.745404243469238\n","Epoch 96, batch 219/240:\tDiscriminator: real loss 0.16958025097846985, fake loss 0.2243220955133438\tGenerator: loss 16.371456146240234\n","Epoch 96, batch 220/240:\tDiscriminator: real loss 0.15505748987197876, fake loss 0.11781232804059982\tGenerator: loss 14.921225547790527\n","Epoch 96, batch 221/240:\tDiscriminator: real loss 0.14049430191516876, fake loss 0.2544799745082855\tGenerator: loss 12.657706260681152\n","Epoch 96, batch 222/240:\tDiscriminator: real loss 0.24270875751972198, fake loss 0.1596948504447937\tGenerator: loss 16.20024871826172\n","Epoch 96, batch 223/240:\tDiscriminator: real loss 0.10686203092336655, fake loss 0.18101492524147034\tGenerator: loss 15.872272491455078\n","Epoch 96, batch 224/240:\tDiscriminator: real loss 0.07337082922458649, fake loss 0.2783905267715454\tGenerator: loss 18.870145797729492\n","Epoch 96, batch 225/240:\tDiscriminator: real loss 0.19319920241832733, fake loss 0.23893903195858002\tGenerator: loss 16.34913444519043\n","Epoch 96, batch 226/240:\tDiscriminator: real loss 0.12443286925554276, fake loss 0.15768861770629883\tGenerator: loss 15.163773536682129\n","Epoch 96, batch 227/240:\tDiscriminator: real loss 0.18558020889759064, fake loss 0.07564200460910797\tGenerator: loss 15.514575004577637\n","Epoch 96, batch 228/240:\tDiscriminator: real loss 0.09231627732515335, fake loss 0.35980406403541565\tGenerator: loss 15.870408058166504\n","Epoch 96, batch 229/240:\tDiscriminator: real loss 0.14603252708911896, fake loss 0.054093360900878906\tGenerator: loss 14.187603950500488\n","Epoch 96, batch 230/240:\tDiscriminator: real loss 0.0751613974571228, fake loss 0.1814996302127838\tGenerator: loss 15.595978736877441\n","Epoch 96, batch 231/240:\tDiscriminator: real loss 0.10397781431674957, fake loss 0.21562278270721436\tGenerator: loss 16.809850692749023\n","Epoch 96, batch 232/240:\tDiscriminator: real loss 0.14897210896015167, fake loss 0.11056096106767654\tGenerator: loss 14.766670227050781\n","Epoch 96, batch 233/240:\tDiscriminator: real loss 0.1406668722629547, fake loss 0.14859791100025177\tGenerator: loss 16.818376541137695\n","Epoch 96, batch 234/240:\tDiscriminator: real loss 0.12563343346118927, fake loss 0.15985900163650513\tGenerator: loss 15.603477478027344\n","Epoch 96, batch 235/240:\tDiscriminator: real loss 0.1366289258003235, fake loss 0.13366857171058655\tGenerator: loss 13.09607219696045\n","Epoch 96, batch 236/240:\tDiscriminator: real loss 0.1648716777563095, fake loss 0.2419402301311493\tGenerator: loss 14.72260856628418\n","Epoch 96, batch 237/240:\tDiscriminator: real loss 0.13725152611732483, fake loss 0.12672197818756104\tGenerator: loss 15.550066947937012\n","Epoch 96, batch 238/240:\tDiscriminator: real loss 0.19471651315689087, fake loss 0.10210316628217697\tGenerator: loss 11.129201889038086\n","Epoch 96, batch 239/240:\tDiscriminator: real loss 0.12410297244787216, fake loss 0.17235946655273438\tGenerator: loss 11.038055419921875\n","Epoch 96, batch 240/240:\tDiscriminator: real loss 0.15087281167507172, fake loss 0.19127941131591797\tGenerator: loss 13.332843780517578\n","Epoch 97, batch 1/240:\tDiscriminator: real loss 0.043095022439956665, fake loss 0.15234500169754028\tGenerator: loss 15.49801254272461\n","Epoch 97, batch 2/240:\tDiscriminator: real loss 0.10986834764480591, fake loss 0.11049012839794159\tGenerator: loss 13.921069145202637\n","Epoch 97, batch 3/240:\tDiscriminator: real loss 0.160008043050766, fake loss 0.1406954526901245\tGenerator: loss 12.585357666015625\n","Epoch 97, batch 4/240:\tDiscriminator: real loss 0.0743606686592102, fake loss 0.13205012679100037\tGenerator: loss 12.211169242858887\n","Epoch 97, batch 5/240:\tDiscriminator: real loss 0.12863770127296448, fake loss 0.21391862630844116\tGenerator: loss 10.641963005065918\n","Epoch 97, batch 6/240:\tDiscriminator: real loss 0.02533935010433197, fake loss 0.09100410342216492\tGenerator: loss 12.643261909484863\n","Epoch 97, batch 7/240:\tDiscriminator: real loss 0.1298842430114746, fake loss 0.12477383017539978\tGenerator: loss 12.751826286315918\n","Epoch 97, batch 8/240:\tDiscriminator: real loss 0.0852523148059845, fake loss 0.1605663150548935\tGenerator: loss 12.423713684082031\n","Epoch 97, batch 9/240:\tDiscriminator: real loss 0.09061156958341599, fake loss 0.16726060211658478\tGenerator: loss 15.330484390258789\n","Epoch 97, batch 10/240:\tDiscriminator: real loss 0.18432888388633728, fake loss 0.1172691062092781\tGenerator: loss 12.221745491027832\n","Epoch 97, batch 11/240:\tDiscriminator: real loss 0.1628561019897461, fake loss 0.14443226158618927\tGenerator: loss 15.166833877563477\n","Epoch 97, batch 12/240:\tDiscriminator: real loss 0.07743031531572342, fake loss 0.25049346685409546\tGenerator: loss 15.265290260314941\n","Epoch 97, batch 13/240:\tDiscriminator: real loss 0.12136158347129822, fake loss 0.13567590713500977\tGenerator: loss 13.690849304199219\n","Epoch 97, batch 14/240:\tDiscriminator: real loss 0.09874964505434036, fake loss 0.255754292011261\tGenerator: loss 14.4871187210083\n","Epoch 97, batch 15/240:\tDiscriminator: real loss 0.09074077010154724, fake loss 0.14904412627220154\tGenerator: loss 15.298108100891113\n","Epoch 97, batch 16/240:\tDiscriminator: real loss 0.15866418182849884, fake loss 0.11696392297744751\tGenerator: loss 14.131077766418457\n","Epoch 97, batch 17/240:\tDiscriminator: real loss 0.1112137958407402, fake loss 0.13273248076438904\tGenerator: loss 14.696450233459473\n","Epoch 97, batch 18/240:\tDiscriminator: real loss 0.04872133210301399, fake loss 0.1283065676689148\tGenerator: loss 15.263705253601074\n","Epoch 97, batch 19/240:\tDiscriminator: real loss 0.11939943581819534, fake loss 0.27551648020744324\tGenerator: loss 16.581241607666016\n","Epoch 97, batch 20/240:\tDiscriminator: real loss 0.2756634056568146, fake loss 0.08138933032751083\tGenerator: loss 14.042230606079102\n","Epoch 97, batch 21/240:\tDiscriminator: real loss 0.08700086921453476, fake loss 0.07095614820718765\tGenerator: loss 11.116004943847656\n","Epoch 97, batch 22/240:\tDiscriminator: real loss 0.053375180810689926, fake loss 0.2990560233592987\tGenerator: loss 12.96053695678711\n","Epoch 97, batch 23/240:\tDiscriminator: real loss 0.09278910607099533, fake loss 0.18899936974048615\tGenerator: loss 12.061383247375488\n","Epoch 97, batch 24/240:\tDiscriminator: real loss 0.13139984011650085, fake loss 0.1540692299604416\tGenerator: loss 12.794731140136719\n","Epoch 97, batch 25/240:\tDiscriminator: real loss 0.17367704212665558, fake loss 0.2633231282234192\tGenerator: loss 12.746678352355957\n","Epoch 97, batch 26/240:\tDiscriminator: real loss 0.18982063233852386, fake loss 0.0848587155342102\tGenerator: loss 10.06686782836914\n","Epoch 97, batch 27/240:\tDiscriminator: real loss 0.2863042950630188, fake loss 0.1613379269838333\tGenerator: loss 10.119373321533203\n","Epoch 97, batch 28/240:\tDiscriminator: real loss 0.05369916930794716, fake loss 0.2449316382408142\tGenerator: loss 13.51416015625\n","Epoch 97, batch 29/240:\tDiscriminator: real loss 0.06400749832391739, fake loss 0.15599681437015533\tGenerator: loss 13.541930198669434\n","Epoch 97, batch 30/240:\tDiscriminator: real loss 0.3279793858528137, fake loss 0.10140373557806015\tGenerator: loss 8.92934799194336\n","Epoch 97, batch 31/240:\tDiscriminator: real loss 0.08786371350288391, fake loss 0.1945277750492096\tGenerator: loss 8.180582046508789\n","Epoch 97, batch 32/240:\tDiscriminator: real loss 0.16471624374389648, fake loss 0.13851439952850342\tGenerator: loss 9.473448753356934\n","Epoch 97, batch 33/240:\tDiscriminator: real loss 0.06921426206827164, fake loss 0.1949671357870102\tGenerator: loss 10.208041191101074\n","Epoch 97, batch 34/240:\tDiscriminator: real loss 0.08738026022911072, fake loss 0.11166137456893921\tGenerator: loss 10.775544166564941\n","Epoch 97, batch 35/240:\tDiscriminator: real loss 0.20091941952705383, fake loss 0.08898363262414932\tGenerator: loss 10.081764221191406\n","Epoch 97, batch 36/240:\tDiscriminator: real loss 0.06523724645376205, fake loss 0.14774292707443237\tGenerator: loss 10.63722038269043\n","Epoch 97, batch 37/240:\tDiscriminator: real loss 0.07678015530109406, fake loss 0.2005816400051117\tGenerator: loss 10.947275161743164\n","Epoch 97, batch 38/240:\tDiscriminator: real loss 0.0705876424908638, fake loss 0.19952915608882904\tGenerator: loss 14.694807052612305\n","Epoch 97, batch 39/240:\tDiscriminator: real loss 0.1629301905632019, fake loss 0.05234171450138092\tGenerator: loss 12.614208221435547\n","Epoch 97, batch 40/240:\tDiscriminator: real loss 0.056883540004491806, fake loss 0.13162530958652496\tGenerator: loss 12.563536643981934\n","Epoch 97, batch 41/240:\tDiscriminator: real loss 0.09026070684194565, fake loss 0.15403693914413452\tGenerator: loss 12.268152236938477\n","Epoch 97, batch 42/240:\tDiscriminator: real loss 0.07599881291389465, fake loss 0.21455799043178558\tGenerator: loss 12.670104026794434\n","Epoch 97, batch 43/240:\tDiscriminator: real loss 0.1864418089389801, fake loss 0.06755177676677704\tGenerator: loss 11.987112045288086\n","Epoch 97, batch 44/240:\tDiscriminator: real loss 0.06060321629047394, fake loss 0.2019127905368805\tGenerator: loss 13.668970108032227\n","Epoch 97, batch 45/240:\tDiscriminator: real loss 0.09512054175138474, fake loss 0.1880311369895935\tGenerator: loss 13.669829368591309\n","Epoch 97, batch 46/240:\tDiscriminator: real loss 0.13750311732292175, fake loss 0.11623484641313553\tGenerator: loss 12.970329284667969\n","Epoch 97, batch 47/240:\tDiscriminator: real loss 0.07063189148902893, fake loss 0.17689155042171478\tGenerator: loss 13.85946273803711\n","Epoch 97, batch 48/240:\tDiscriminator: real loss 0.2402675449848175, fake loss 0.10811124742031097\tGenerator: loss 11.11142349243164\n","Epoch 97, batch 49/240:\tDiscriminator: real loss 0.10299979150295258, fake loss 0.18685342371463776\tGenerator: loss 12.416778564453125\n","Epoch 97, batch 50/240:\tDiscriminator: real loss 0.12344398349523544, fake loss 0.13620999455451965\tGenerator: loss 10.82998275756836\n","Epoch 97, batch 51/240:\tDiscriminator: real loss 0.12197456508874893, fake loss 0.09580100327730179\tGenerator: loss 11.167394638061523\n","Epoch 97, batch 52/240:\tDiscriminator: real loss 0.07237276434898376, fake loss 0.12379444390535355\tGenerator: loss 12.338866233825684\n","Epoch 97, batch 53/240:\tDiscriminator: real loss 0.04892315715551376, fake loss 0.13510662317276\tGenerator: loss 14.0236234664917\n","Epoch 97, batch 54/240:\tDiscriminator: real loss 0.10202880203723907, fake loss 0.11629520356655121\tGenerator: loss 13.014850616455078\n","Epoch 97, batch 55/240:\tDiscriminator: real loss 0.12624837458133698, fake loss 0.065598264336586\tGenerator: loss 13.430251121520996\n","Epoch 97, batch 56/240:\tDiscriminator: real loss 0.09351758658885956, fake loss 0.2077377438545227\tGenerator: loss 12.190896987915039\n","Epoch 97, batch 57/240:\tDiscriminator: real loss 0.11264487355947495, fake loss 0.30979615449905396\tGenerator: loss 12.243992805480957\n","Epoch 97, batch 58/240:\tDiscriminator: real loss 0.14832402765750885, fake loss 0.1258683204650879\tGenerator: loss 13.76245403289795\n","Epoch 97, batch 59/240:\tDiscriminator: real loss 0.20512282848358154, fake loss 0.13100019097328186\tGenerator: loss 10.06463623046875\n","Epoch 97, batch 60/240:\tDiscriminator: real loss 0.133004292845726, fake loss 0.2472923994064331\tGenerator: loss 12.098414421081543\n","Epoch 97, batch 61/240:\tDiscriminator: real loss 0.08724399656057358, fake loss 0.023994533345103264\tGenerator: loss 11.610013008117676\n","Epoch 97, batch 62/240:\tDiscriminator: real loss 0.12253511697053909, fake loss 0.19688919186592102\tGenerator: loss 9.563408851623535\n","Epoch 97, batch 63/240:\tDiscriminator: real loss 0.029043816030025482, fake loss 0.12331096827983856\tGenerator: loss 9.688075065612793\n","Epoch 97, batch 64/240:\tDiscriminator: real loss 0.043680936098098755, fake loss 0.079955093562603\tGenerator: loss 10.902996063232422\n","Epoch 97, batch 65/240:\tDiscriminator: real loss 0.15044239163398743, fake loss 0.17116126418113708\tGenerator: loss 11.682573318481445\n","Epoch 97, batch 66/240:\tDiscriminator: real loss 0.09881673753261566, fake loss 0.28120726346969604\tGenerator: loss 12.71229362487793\n","Epoch 97, batch 67/240:\tDiscriminator: real loss 0.16379410028457642, fake loss 0.09312228858470917\tGenerator: loss 12.331812858581543\n","Epoch 97, batch 68/240:\tDiscriminator: real loss 0.1175147071480751, fake loss 0.2838767170906067\tGenerator: loss 11.433209419250488\n","Epoch 97, batch 69/240:\tDiscriminator: real loss 0.08089586347341537, fake loss 0.11545122414827347\tGenerator: loss 12.440206527709961\n","Epoch 97, batch 70/240:\tDiscriminator: real loss 0.22759650647640228, fake loss 0.11973302066326141\tGenerator: loss 11.829532623291016\n","Epoch 97, batch 71/240:\tDiscriminator: real loss 0.11686732620000839, fake loss 0.2540951669216156\tGenerator: loss 12.486279487609863\n","Epoch 97, batch 72/240:\tDiscriminator: real loss 0.13848522305488586, fake loss 0.2107289880514145\tGenerator: loss 12.015869140625\n","Epoch 97, batch 73/240:\tDiscriminator: real loss 0.11710149049758911, fake loss 0.18644146621227264\tGenerator: loss 13.256386756896973\n","Epoch 97, batch 74/240:\tDiscriminator: real loss 0.1655227243900299, fake loss 0.06559746712446213\tGenerator: loss 11.967607498168945\n","Epoch 97, batch 75/240:\tDiscriminator: real loss 0.0999092310667038, fake loss 0.19244705140590668\tGenerator: loss 10.982671737670898\n","Epoch 97, batch 76/240:\tDiscriminator: real loss 0.16324463486671448, fake loss 0.23479463160037994\tGenerator: loss 12.895429611206055\n","Epoch 97, batch 77/240:\tDiscriminator: real loss 0.12373583018779755, fake loss 0.1354759931564331\tGenerator: loss 14.293527603149414\n","Epoch 97, batch 78/240:\tDiscriminator: real loss 0.10595230013132095, fake loss 0.1432308554649353\tGenerator: loss 13.621426582336426\n","Epoch 97, batch 79/240:\tDiscriminator: real loss 0.1597503125667572, fake loss 0.15449248254299164\tGenerator: loss 12.893489837646484\n","Epoch 97, batch 80/240:\tDiscriminator: real loss 0.08659101277589798, fake loss 0.10824122279882431\tGenerator: loss 12.390437126159668\n","Epoch 97, batch 81/240:\tDiscriminator: real loss 0.08667243272066116, fake loss 0.1389704942703247\tGenerator: loss 12.989916801452637\n","Epoch 97, batch 82/240:\tDiscriminator: real loss 0.047563906759023666, fake loss 0.14939600229263306\tGenerator: loss 14.050171852111816\n","Epoch 97, batch 83/240:\tDiscriminator: real loss 0.10025474429130554, fake loss 0.10207546502351761\tGenerator: loss 14.240561485290527\n","Epoch 97, batch 84/240:\tDiscriminator: real loss 0.13114148378372192, fake loss 0.2357911318540573\tGenerator: loss 13.294583320617676\n","Epoch 97, batch 85/240:\tDiscriminator: real loss 0.10269001871347427, fake loss 0.14109957218170166\tGenerator: loss 14.972064018249512\n","Epoch 97, batch 86/240:\tDiscriminator: real loss 0.1408783346414566, fake loss 0.08476826548576355\tGenerator: loss 14.212729454040527\n","Epoch 97, batch 87/240:\tDiscriminator: real loss 0.10279590636491776, fake loss 0.32836398482322693\tGenerator: loss 14.42740249633789\n","Epoch 97, batch 88/240:\tDiscriminator: real loss 0.20327310264110565, fake loss 0.0545831061899662\tGenerator: loss 14.564549446105957\n","Epoch 97, batch 89/240:\tDiscriminator: real loss 0.1412564069032669, fake loss 0.25958672165870667\tGenerator: loss 13.972391128540039\n","Epoch 97, batch 90/240:\tDiscriminator: real loss 0.12256178259849548, fake loss 0.1345135122537613\tGenerator: loss 14.151978492736816\n","Epoch 97, batch 91/240:\tDiscriminator: real loss 0.07902466505765915, fake loss 0.2000851035118103\tGenerator: loss 15.313773155212402\n","Epoch 97, batch 92/240:\tDiscriminator: real loss 0.12276840955018997, fake loss 0.26922607421875\tGenerator: loss 15.234838485717773\n","Epoch 97, batch 93/240:\tDiscriminator: real loss 0.25716477632522583, fake loss 0.17050258815288544\tGenerator: loss 14.065199851989746\n","Epoch 97, batch 94/240:\tDiscriminator: real loss 0.06129717826843262, fake loss 0.07146294414997101\tGenerator: loss 12.64345932006836\n","Epoch 97, batch 95/240:\tDiscriminator: real loss 0.08246748149394989, fake loss 0.21242545545101166\tGenerator: loss 12.192588806152344\n","Epoch 97, batch 96/240:\tDiscriminator: real loss 0.09587335586547852, fake loss 0.15481974184513092\tGenerator: loss 12.776092529296875\n","Epoch 97, batch 97/240:\tDiscriminator: real loss 0.21950209140777588, fake loss 0.11261899024248123\tGenerator: loss 12.009970664978027\n","Epoch 97, batch 98/240:\tDiscriminator: real loss 0.12287504225969315, fake loss 0.09606754034757614\tGenerator: loss 11.764130592346191\n","Epoch 97, batch 99/240:\tDiscriminator: real loss 0.05468785762786865, fake loss 0.23926150798797607\tGenerator: loss 13.038376808166504\n","Epoch 97, batch 100/240:\tDiscriminator: real loss 0.11326000094413757, fake loss 0.11036287248134613\tGenerator: loss 13.399749755859375\n","Epoch 97, batch 101/240:\tDiscriminator: real loss 0.1268036663532257, fake loss 0.09224646538496017\tGenerator: loss 12.4657621383667\n","Epoch 97, batch 102/240:\tDiscriminator: real loss 0.09338685125112534, fake loss 0.08849647641181946\tGenerator: loss 12.349593162536621\n","Epoch 97, batch 103/240:\tDiscriminator: real loss 0.04631299525499344, fake loss 0.43978941440582275\tGenerator: loss 14.50084114074707\n","Epoch 97, batch 104/240:\tDiscriminator: real loss 0.17384395003318787, fake loss 0.08614030480384827\tGenerator: loss 13.108492851257324\n","Epoch 97, batch 105/240:\tDiscriminator: real loss 0.3050922155380249, fake loss 0.17134350538253784\tGenerator: loss 13.364583969116211\n","Epoch 97, batch 106/240:\tDiscriminator: real loss 0.11809942126274109, fake loss 0.3207980692386627\tGenerator: loss 13.859068870544434\n","Epoch 97, batch 107/240:\tDiscriminator: real loss 0.08439154922962189, fake loss 0.16712667047977448\tGenerator: loss 13.039860725402832\n","Epoch 97, batch 108/240:\tDiscriminator: real loss 0.18587768077850342, fake loss 0.060756005346775055\tGenerator: loss 10.656525611877441\n","Epoch 97, batch 109/240:\tDiscriminator: real loss 0.10613378882408142, fake loss 0.2661581337451935\tGenerator: loss 12.477071762084961\n","Epoch 97, batch 110/240:\tDiscriminator: real loss 0.12200109660625458, fake loss 0.11164204776287079\tGenerator: loss 12.421606063842773\n","Epoch 97, batch 111/240:\tDiscriminator: real loss 0.12725624442100525, fake loss 0.15283797681331635\tGenerator: loss 12.256773948669434\n","Epoch 97, batch 112/240:\tDiscriminator: real loss 0.07572923600673676, fake loss 0.12253791838884354\tGenerator: loss 13.046721458435059\n","Epoch 97, batch 113/240:\tDiscriminator: real loss 0.1394815593957901, fake loss 0.09718260914087296\tGenerator: loss 12.253959655761719\n","Epoch 97, batch 114/240:\tDiscriminator: real loss 0.08903219550848007, fake loss 0.20283499360084534\tGenerator: loss 11.691230773925781\n","Epoch 97, batch 115/240:\tDiscriminator: real loss 0.08941354602575302, fake loss 0.24985504150390625\tGenerator: loss 12.833338737487793\n","Epoch 97, batch 116/240:\tDiscriminator: real loss 0.179804727435112, fake loss 0.10652158409357071\tGenerator: loss 12.791600227355957\n","Epoch 97, batch 117/240:\tDiscriminator: real loss 0.14668990671634674, fake loss 0.10806545615196228\tGenerator: loss 11.524188995361328\n","Epoch 97, batch 118/240:\tDiscriminator: real loss 0.09638510644435883, fake loss 0.11723186820745468\tGenerator: loss 10.464909553527832\n","Epoch 97, batch 119/240:\tDiscriminator: real loss 0.03467941656708717, fake loss 0.06964066624641418\tGenerator: loss 10.233994483947754\n","Epoch 97, batch 120/240:\tDiscriminator: real loss 0.048260584473609924, fake loss 0.2160947620868683\tGenerator: loss 11.922415733337402\n","Epoch 97, batch 121/240:\tDiscriminator: real loss 0.08474810421466827, fake loss 0.21701328456401825\tGenerator: loss 13.901959419250488\n","Epoch 97, batch 122/240:\tDiscriminator: real loss 0.13631713390350342, fake loss 0.12740778923034668\tGenerator: loss 11.829493522644043\n","Epoch 97, batch 123/240:\tDiscriminator: real loss 0.09209361672401428, fake loss 0.2647891938686371\tGenerator: loss 12.466643333435059\n","Epoch 97, batch 124/240:\tDiscriminator: real loss 0.13714870810508728, fake loss 0.12197509407997131\tGenerator: loss 12.339707374572754\n","Epoch 97, batch 125/240:\tDiscriminator: real loss 0.11499395221471786, fake loss 0.08108889311552048\tGenerator: loss 10.205511093139648\n","Epoch 97, batch 126/240:\tDiscriminator: real loss 0.16539199650287628, fake loss 0.14098961651325226\tGenerator: loss 10.578692436218262\n","Epoch 97, batch 127/240:\tDiscriminator: real loss 0.06063386797904968, fake loss 0.2296069711446762\tGenerator: loss 13.300719261169434\n","Epoch 97, batch 128/240:\tDiscriminator: real loss 0.11750473082065582, fake loss 0.07190763205289841\tGenerator: loss 14.84886360168457\n","Epoch 97, batch 129/240:\tDiscriminator: real loss 0.08454948663711548, fake loss 0.19603465497493744\tGenerator: loss 13.308793067932129\n","Epoch 97, batch 130/240:\tDiscriminator: real loss 0.1485898345708847, fake loss 0.19741059839725494\tGenerator: loss 15.388413429260254\n","Epoch 97, batch 131/240:\tDiscriminator: real loss 0.1308092325925827, fake loss 0.11460184305906296\tGenerator: loss 13.484352111816406\n","Epoch 97, batch 132/240:\tDiscriminator: real loss 0.2260315865278244, fake loss 0.21957437694072723\tGenerator: loss 13.223959922790527\n","Epoch 97, batch 133/240:\tDiscriminator: real loss 0.05095028877258301, fake loss 0.3817461431026459\tGenerator: loss 15.427786827087402\n","Epoch 97, batch 134/240:\tDiscriminator: real loss 0.17641082406044006, fake loss 0.06498228758573532\tGenerator: loss 12.626338005065918\n","Epoch 97, batch 135/240:\tDiscriminator: real loss 0.18268311023712158, fake loss 0.1238531842827797\tGenerator: loss 12.503539085388184\n","Epoch 97, batch 136/240:\tDiscriminator: real loss 0.1948334276676178, fake loss 0.3969895839691162\tGenerator: loss 12.456036567687988\n","Epoch 97, batch 137/240:\tDiscriminator: real loss 0.07536409050226212, fake loss 0.22726291418075562\tGenerator: loss 13.947579383850098\n","Epoch 97, batch 138/240:\tDiscriminator: real loss 0.15165092051029205, fake loss 0.0909290537238121\tGenerator: loss 13.497586250305176\n","Epoch 97, batch 139/240:\tDiscriminator: real loss 0.2054947316646576, fake loss 0.11127883940935135\tGenerator: loss 10.977352142333984\n","Epoch 97, batch 140/240:\tDiscriminator: real loss 0.07349462807178497, fake loss 0.2575870156288147\tGenerator: loss 11.196510314941406\n","Epoch 97, batch 141/240:\tDiscriminator: real loss 0.08704884350299835, fake loss 0.1967839002609253\tGenerator: loss 11.427655220031738\n","Epoch 97, batch 142/240:\tDiscriminator: real loss 0.206760972738266, fake loss 0.07676559686660767\tGenerator: loss 11.6871337890625\n","Epoch 97, batch 143/240:\tDiscriminator: real loss 0.10987585037946701, fake loss 0.11690583825111389\tGenerator: loss 10.961324691772461\n","Epoch 97, batch 144/240:\tDiscriminator: real loss 0.13546858727931976, fake loss 0.1776125729084015\tGenerator: loss 13.374929428100586\n","Epoch 97, batch 145/240:\tDiscriminator: real loss 0.09924629330635071, fake loss 0.06670869141817093\tGenerator: loss 12.337658882141113\n","Epoch 97, batch 146/240:\tDiscriminator: real loss 0.05256479233503342, fake loss 0.16089114546775818\tGenerator: loss 12.526435852050781\n","Epoch 97, batch 147/240:\tDiscriminator: real loss 0.059840306639671326, fake loss 0.20988456904888153\tGenerator: loss 14.308531761169434\n","Epoch 97, batch 148/240:\tDiscriminator: real loss 0.146137535572052, fake loss 0.1309388130903244\tGenerator: loss 15.998059272766113\n","Epoch 97, batch 149/240:\tDiscriminator: real loss 0.16228251159191132, fake loss 0.07061690092086792\tGenerator: loss 13.19680404663086\n","Epoch 97, batch 150/240:\tDiscriminator: real loss 0.08124519139528275, fake loss 0.1281982958316803\tGenerator: loss 12.9367094039917\n","Epoch 97, batch 151/240:\tDiscriminator: real loss 0.04850392788648605, fake loss 0.20630334317684174\tGenerator: loss 13.400042533874512\n","Epoch 97, batch 152/240:\tDiscriminator: real loss 0.12164590507745743, fake loss 0.18309298157691956\tGenerator: loss 12.408195495605469\n","Epoch 97, batch 153/240:\tDiscriminator: real loss 0.1636948585510254, fake loss 0.1252211332321167\tGenerator: loss 11.092455863952637\n","Epoch 97, batch 154/240:\tDiscriminator: real loss 0.10487900674343109, fake loss 0.1741981953382492\tGenerator: loss 11.268479347229004\n","Epoch 97, batch 155/240:\tDiscriminator: real loss 0.14316792786121368, fake loss 0.14648817479610443\tGenerator: loss 11.766583442687988\n","Epoch 97, batch 156/240:\tDiscriminator: real loss 0.10157926380634308, fake loss 0.16323792934417725\tGenerator: loss 11.767085075378418\n","Epoch 97, batch 157/240:\tDiscriminator: real loss 0.13571706414222717, fake loss 0.19793584942817688\tGenerator: loss 11.296416282653809\n","Epoch 97, batch 158/240:\tDiscriminator: real loss 0.09365633130073547, fake loss 0.09280003607273102\tGenerator: loss 10.830278396606445\n","Epoch 97, batch 159/240:\tDiscriminator: real loss 0.164093017578125, fake loss 0.13772514462471008\tGenerator: loss 7.991439342498779\n","Epoch 97, batch 160/240:\tDiscriminator: real loss 0.07746221870183945, fake loss 0.2851736843585968\tGenerator: loss 8.352134704589844\n","Epoch 97, batch 161/240:\tDiscriminator: real loss 0.25268879532814026, fake loss 0.19337576627731323\tGenerator: loss 12.890056610107422\n","Epoch 97, batch 162/240:\tDiscriminator: real loss 0.15600907802581787, fake loss 0.266292929649353\tGenerator: loss 15.01860237121582\n","Epoch 97, batch 163/240:\tDiscriminator: real loss 0.21628834307193756, fake loss 0.10556742548942566\tGenerator: loss 12.821490287780762\n","Epoch 97, batch 164/240:\tDiscriminator: real loss 0.10956191271543503, fake loss 0.07207944989204407\tGenerator: loss 12.628644943237305\n","Epoch 97, batch 165/240:\tDiscriminator: real loss 0.11013729870319366, fake loss 0.22583907842636108\tGenerator: loss 12.336544036865234\n","Epoch 97, batch 166/240:\tDiscriminator: real loss 0.07824752479791641, fake loss 0.3471162021160126\tGenerator: loss 14.824475288391113\n","Epoch 97, batch 167/240:\tDiscriminator: real loss 0.24489223957061768, fake loss 0.30670106410980225\tGenerator: loss 15.901861190795898\n","Epoch 97, batch 168/240:\tDiscriminator: real loss 0.14417359232902527, fake loss 0.22437308728694916\tGenerator: loss 14.701258659362793\n","Epoch 97, batch 169/240:\tDiscriminator: real loss 0.3120616376399994, fake loss 0.1854410171508789\tGenerator: loss 11.402409553527832\n","Epoch 97, batch 170/240:\tDiscriminator: real loss 0.10069561004638672, fake loss 0.12482799589633942\tGenerator: loss 11.223702430725098\n","Epoch 97, batch 171/240:\tDiscriminator: real loss 0.10696670413017273, fake loss 0.20304258167743683\tGenerator: loss 13.243409156799316\n","Epoch 97, batch 172/240:\tDiscriminator: real loss 0.11648201197385788, fake loss 0.1983875334262848\tGenerator: loss 13.475398063659668\n","Epoch 97, batch 173/240:\tDiscriminator: real loss 0.14537519216537476, fake loss 0.2580852806568146\tGenerator: loss 14.63248062133789\n","Epoch 97, batch 174/240:\tDiscriminator: real loss 0.17608922719955444, fake loss 0.1406550258398056\tGenerator: loss 14.392620086669922\n","Epoch 97, batch 175/240:\tDiscriminator: real loss 0.1641177535057068, fake loss 0.15744470059871674\tGenerator: loss 14.578243255615234\n","Epoch 97, batch 176/240:\tDiscriminator: real loss 0.1295996904373169, fake loss 0.23632362484931946\tGenerator: loss 13.421792030334473\n","Epoch 97, batch 177/240:\tDiscriminator: real loss 0.1925116777420044, fake loss 0.19092121720314026\tGenerator: loss 10.769994735717773\n","Epoch 97, batch 178/240:\tDiscriminator: real loss 0.23822765052318573, fake loss 0.14157703518867493\tGenerator: loss 10.541548728942871\n","Epoch 97, batch 179/240:\tDiscriminator: real loss 0.0768761932849884, fake loss 0.19023144245147705\tGenerator: loss 11.122859001159668\n","Epoch 97, batch 180/240:\tDiscriminator: real loss 0.04540552198886871, fake loss 0.3758868873119354\tGenerator: loss 12.875693321228027\n","Epoch 97, batch 181/240:\tDiscriminator: real loss 0.2299836277961731, fake loss 0.13276302814483643\tGenerator: loss 10.532148361206055\n","Epoch 97, batch 182/240:\tDiscriminator: real loss 0.1609741598367691, fake loss 0.19585800170898438\tGenerator: loss 10.088891983032227\n","Epoch 97, batch 183/240:\tDiscriminator: real loss 0.23355373740196228, fake loss 0.32268989086151123\tGenerator: loss 10.821490287780762\n","Epoch 97, batch 184/240:\tDiscriminator: real loss 0.19682246446609497, fake loss 0.24389083683490753\tGenerator: loss 12.823221206665039\n","Epoch 97, batch 185/240:\tDiscriminator: real loss 0.10003035515546799, fake loss 0.19669295847415924\tGenerator: loss 11.964177131652832\n","Epoch 97, batch 186/240:\tDiscriminator: real loss 0.11598344147205353, fake loss 0.23078066110610962\tGenerator: loss 11.905130386352539\n","Epoch 97, batch 187/240:\tDiscriminator: real loss 0.3962823450565338, fake loss 0.15117202699184418\tGenerator: loss 8.804704666137695\n","Epoch 97, batch 188/240:\tDiscriminator: real loss 0.08799021691083908, fake loss 0.08025383204221725\tGenerator: loss 8.983325958251953\n","Epoch 97, batch 189/240:\tDiscriminator: real loss 0.05768902599811554, fake loss 0.19949311017990112\tGenerator: loss 10.951825141906738\n","Epoch 97, batch 190/240:\tDiscriminator: real loss 0.0635543242096901, fake loss 0.18047897517681122\tGenerator: loss 13.319008827209473\n","Epoch 97, batch 191/240:\tDiscriminator: real loss 0.12492698431015015, fake loss 0.18362383544445038\tGenerator: loss 13.254219055175781\n","Epoch 97, batch 192/240:\tDiscriminator: real loss 0.11180441081523895, fake loss 0.15021473169326782\tGenerator: loss 13.465731620788574\n","Epoch 97, batch 193/240:\tDiscriminator: real loss 0.11161232739686966, fake loss 0.06561744213104248\tGenerator: loss 12.752676010131836\n","Epoch 97, batch 194/240:\tDiscriminator: real loss 0.09610714763402939, fake loss 0.1118842214345932\tGenerator: loss 11.914040565490723\n","Epoch 97, batch 195/240:\tDiscriminator: real loss 0.10875125229358673, fake loss 0.13702745735645294\tGenerator: loss 12.304762840270996\n","Epoch 97, batch 196/240:\tDiscriminator: real loss 0.07745745778083801, fake loss 0.16106730699539185\tGenerator: loss 13.12369155883789\n","Epoch 97, batch 197/240:\tDiscriminator: real loss 0.12088506668806076, fake loss 0.08739259839057922\tGenerator: loss 11.257732391357422\n","Epoch 97, batch 198/240:\tDiscriminator: real loss 0.20950841903686523, fake loss 0.22375932335853577\tGenerator: loss 9.981243133544922\n","Epoch 97, batch 199/240:\tDiscriminator: real loss 0.057232413440942764, fake loss 0.2931722402572632\tGenerator: loss 10.726191520690918\n","Epoch 97, batch 200/240:\tDiscriminator: real loss 0.22642025351524353, fake loss 0.2205367088317871\tGenerator: loss 13.26723861694336\n","Epoch 97, batch 201/240:\tDiscriminator: real loss 0.12432865053415298, fake loss 0.1773594319820404\tGenerator: loss 13.431408882141113\n","Epoch 97, batch 202/240:\tDiscriminator: real loss 0.16558539867401123, fake loss 0.15375350415706635\tGenerator: loss 10.634367942810059\n","Epoch 97, batch 203/240:\tDiscriminator: real loss 0.14172647893428802, fake loss 0.11778991669416428\tGenerator: loss 10.231563568115234\n","Epoch 97, batch 204/240:\tDiscriminator: real loss 0.11711330711841583, fake loss 0.2686440944671631\tGenerator: loss 11.213113784790039\n","Epoch 97, batch 205/240:\tDiscriminator: real loss 0.10052721947431564, fake loss 0.22393807768821716\tGenerator: loss 11.53894329071045\n","Epoch 97, batch 206/240:\tDiscriminator: real loss 0.12311846762895584, fake loss 0.17243030667304993\tGenerator: loss 13.836071968078613\n","Epoch 97, batch 207/240:\tDiscriminator: real loss 0.13352525234222412, fake loss 0.24293699860572815\tGenerator: loss 10.58001708984375\n","Epoch 97, batch 208/240:\tDiscriminator: real loss 0.08400039374828339, fake loss 0.12530744075775146\tGenerator: loss 11.782087326049805\n","Epoch 97, batch 209/240:\tDiscriminator: real loss 0.16805103421211243, fake loss 0.10803220421075821\tGenerator: loss 11.811406135559082\n","Epoch 97, batch 210/240:\tDiscriminator: real loss 0.16180452704429626, fake loss 0.11128614097833633\tGenerator: loss 10.305423736572266\n","Epoch 97, batch 211/240:\tDiscriminator: real loss 0.10007204115390778, fake loss 0.17867423593997955\tGenerator: loss 11.573522567749023\n","Epoch 97, batch 212/240:\tDiscriminator: real loss 0.10275475680828094, fake loss 0.38887718319892883\tGenerator: loss 11.693964958190918\n","Epoch 97, batch 213/240:\tDiscriminator: real loss 0.08700807392597198, fake loss 0.0656559020280838\tGenerator: loss 12.505745887756348\n","Epoch 97, batch 214/240:\tDiscriminator: real loss 0.18238723278045654, fake loss 0.10508499294519424\tGenerator: loss 12.076360702514648\n","Epoch 97, batch 215/240:\tDiscriminator: real loss 0.23314422369003296, fake loss 0.12230121344327927\tGenerator: loss 12.433555603027344\n","Epoch 97, batch 216/240:\tDiscriminator: real loss 0.10932722687721252, fake loss 0.15792858600616455\tGenerator: loss 11.712961196899414\n","Epoch 97, batch 217/240:\tDiscriminator: real loss 0.03963334113359451, fake loss 0.20629601180553436\tGenerator: loss 13.010533332824707\n","Epoch 97, batch 218/240:\tDiscriminator: real loss 0.06694790720939636, fake loss 0.21573950350284576\tGenerator: loss 12.64278793334961\n","Epoch 97, batch 219/240:\tDiscriminator: real loss 0.1733819544315338, fake loss 0.19250261783599854\tGenerator: loss 13.824444770812988\n","Epoch 97, batch 220/240:\tDiscriminator: real loss 0.10110852867364883, fake loss 0.08179646730422974\tGenerator: loss 12.945452690124512\n","Epoch 97, batch 221/240:\tDiscriminator: real loss 0.2636936902999878, fake loss 0.22232414782047272\tGenerator: loss 13.397109031677246\n","Epoch 97, batch 222/240:\tDiscriminator: real loss 0.05868823453783989, fake loss 0.11943095922470093\tGenerator: loss 13.676114082336426\n","Epoch 97, batch 223/240:\tDiscriminator: real loss 0.030744286254048347, fake loss 0.035606708377599716\tGenerator: loss 13.854388236999512\n","Epoch 97, batch 224/240:\tDiscriminator: real loss 0.07313700765371323, fake loss 0.30901557207107544\tGenerator: loss 14.472070693969727\n","Epoch 97, batch 225/240:\tDiscriminator: real loss 0.20555686950683594, fake loss 0.10679169744253159\tGenerator: loss 14.335577011108398\n","Epoch 97, batch 226/240:\tDiscriminator: real loss 0.09829501807689667, fake loss 0.060964327305555344\tGenerator: loss 13.327945709228516\n","Epoch 97, batch 227/240:\tDiscriminator: real loss 0.10702739655971527, fake loss 0.22892749309539795\tGenerator: loss 15.893106460571289\n","Epoch 97, batch 228/240:\tDiscriminator: real loss 0.12903399765491486, fake loss 0.1392562985420227\tGenerator: loss 14.324559211730957\n","Epoch 97, batch 229/240:\tDiscriminator: real loss 0.15387260913848877, fake loss 0.21214017271995544\tGenerator: loss 13.45986557006836\n","Epoch 97, batch 230/240:\tDiscriminator: real loss 0.11072104424238205, fake loss 0.2510148882865906\tGenerator: loss 12.772514343261719\n","Epoch 97, batch 231/240:\tDiscriminator: real loss 0.15718023478984833, fake loss 0.19608458876609802\tGenerator: loss 12.673004150390625\n","Epoch 97, batch 232/240:\tDiscriminator: real loss 0.14300355315208435, fake loss 0.12245321273803711\tGenerator: loss 11.411421775817871\n","Epoch 97, batch 233/240:\tDiscriminator: real loss 0.24760133028030396, fake loss 0.24424785375595093\tGenerator: loss 10.103413581848145\n","Epoch 97, batch 234/240:\tDiscriminator: real loss 0.05124752223491669, fake loss 0.18982315063476562\tGenerator: loss 11.3224458694458\n","Epoch 97, batch 235/240:\tDiscriminator: real loss 0.07283810526132584, fake loss 0.20083141326904297\tGenerator: loss 11.5479736328125\n","Epoch 97, batch 236/240:\tDiscriminator: real loss 0.13981550931930542, fake loss 0.08999297767877579\tGenerator: loss 11.002336502075195\n","Epoch 97, batch 237/240:\tDiscriminator: real loss 0.15741850435733795, fake loss 0.09778282046318054\tGenerator: loss 10.947749137878418\n","Epoch 97, batch 238/240:\tDiscriminator: real loss 0.13716764748096466, fake loss 0.2008364498615265\tGenerator: loss 11.570255279541016\n","Epoch 97, batch 239/240:\tDiscriminator: real loss 0.11840792000293732, fake loss 0.15040147304534912\tGenerator: loss 10.254158973693848\n","Epoch 97, batch 240/240:\tDiscriminator: real loss 0.09915819764137268, fake loss 0.2431964874267578\tGenerator: loss 11.976482391357422\n","Epoch 98, batch 1/240:\tDiscriminator: real loss 0.17430830001831055, fake loss 0.18352901935577393\tGenerator: loss 10.534523963928223\n","Epoch 98, batch 2/240:\tDiscriminator: real loss 0.1534966677427292, fake loss 0.09909336268901825\tGenerator: loss 7.736700534820557\n","Epoch 98, batch 3/240:\tDiscriminator: real loss 0.08816096186637878, fake loss 0.30938979983329773\tGenerator: loss 10.471837997436523\n","Epoch 98, batch 4/240:\tDiscriminator: real loss 0.09896749258041382, fake loss 0.08474371582269669\tGenerator: loss 12.023929595947266\n","Epoch 98, batch 5/240:\tDiscriminator: real loss 0.1290329098701477, fake loss 0.1349422186613083\tGenerator: loss 9.308016777038574\n","Epoch 98, batch 6/240:\tDiscriminator: real loss 0.17143560945987701, fake loss 0.16627216339111328\tGenerator: loss 9.867445945739746\n","Epoch 98, batch 7/240:\tDiscriminator: real loss 0.12057565897703171, fake loss 0.2121041864156723\tGenerator: loss 10.918885231018066\n","Epoch 98, batch 8/240:\tDiscriminator: real loss 0.1504492312669754, fake loss 0.1438695192337036\tGenerator: loss 11.954329490661621\n","Epoch 98, batch 9/240:\tDiscriminator: real loss 0.03656573221087456, fake loss 0.29902660846710205\tGenerator: loss 14.150714874267578\n","Epoch 98, batch 10/240:\tDiscriminator: real loss 0.15875235199928284, fake loss 0.13739189505577087\tGenerator: loss 14.005410194396973\n","Epoch 98, batch 11/240:\tDiscriminator: real loss 0.16528375446796417, fake loss 0.11244749277830124\tGenerator: loss 13.67123794555664\n","Epoch 98, batch 12/240:\tDiscriminator: real loss 0.09598380327224731, fake loss 0.14298945665359497\tGenerator: loss 12.64245319366455\n","Epoch 98, batch 13/240:\tDiscriminator: real loss 0.07258227467536926, fake loss 0.16152150928974152\tGenerator: loss 11.681056022644043\n","Epoch 98, batch 14/240:\tDiscriminator: real loss 0.05463876202702522, fake loss 0.08428703993558884\tGenerator: loss 12.85208511352539\n","Epoch 98, batch 15/240:\tDiscriminator: real loss 0.07006467133760452, fake loss 0.12179871648550034\tGenerator: loss 13.377704620361328\n","Epoch 98, batch 16/240:\tDiscriminator: real loss 0.16829340159893036, fake loss 0.17573432624340057\tGenerator: loss 13.766595840454102\n","Epoch 98, batch 17/240:\tDiscriminator: real loss 0.10491477698087692, fake loss 0.16357733309268951\tGenerator: loss 12.632366180419922\n","Epoch 98, batch 18/240:\tDiscriminator: real loss 0.11030693352222443, fake loss 0.23221401870250702\tGenerator: loss 12.4760103225708\n","Epoch 98, batch 19/240:\tDiscriminator: real loss 0.12366032600402832, fake loss 0.1437111794948578\tGenerator: loss 14.560076713562012\n","Epoch 98, batch 20/240:\tDiscriminator: real loss 0.1918085813522339, fake loss 0.21366184949874878\tGenerator: loss 14.141895294189453\n","Epoch 98, batch 21/240:\tDiscriminator: real loss 0.15075305104255676, fake loss 0.14386679232120514\tGenerator: loss 12.618670463562012\n","Epoch 98, batch 22/240:\tDiscriminator: real loss 0.09513160586357117, fake loss 0.14620061218738556\tGenerator: loss 12.238896369934082\n","Epoch 98, batch 23/240:\tDiscriminator: real loss 0.10302118957042694, fake loss 0.2063489556312561\tGenerator: loss 12.489834785461426\n","Epoch 98, batch 24/240:\tDiscriminator: real loss 0.22784262895584106, fake loss 0.12971925735473633\tGenerator: loss 11.87421989440918\n","Epoch 98, batch 25/240:\tDiscriminator: real loss 0.07280141860246658, fake loss 0.16328436136245728\tGenerator: loss 11.781291961669922\n","Epoch 98, batch 26/240:\tDiscriminator: real loss 0.10111751407384872, fake loss 0.12271406501531601\tGenerator: loss 11.15498161315918\n","Epoch 98, batch 27/240:\tDiscriminator: real loss 0.15227629244327545, fake loss 0.1972469687461853\tGenerator: loss 12.405351638793945\n","Epoch 98, batch 28/240:\tDiscriminator: real loss 0.13344380259513855, fake loss 0.18685393035411835\tGenerator: loss 13.323558807373047\n","Epoch 98, batch 29/240:\tDiscriminator: real loss 0.12842220067977905, fake loss 0.10066784173250198\tGenerator: loss 12.767822265625\n","Epoch 98, batch 30/240:\tDiscriminator: real loss 0.0762530267238617, fake loss 0.15593168139457703\tGenerator: loss 11.690465927124023\n","Epoch 98, batch 31/240:\tDiscriminator: real loss 0.1460246592760086, fake loss 0.2396259307861328\tGenerator: loss 13.014795303344727\n","Epoch 98, batch 32/240:\tDiscriminator: real loss 0.09870729595422745, fake loss 0.22956909239292145\tGenerator: loss 13.953899383544922\n","Epoch 98, batch 33/240:\tDiscriminator: real loss 0.21413490176200867, fake loss 0.14259746670722961\tGenerator: loss 15.944385528564453\n","Epoch 98, batch 34/240:\tDiscriminator: real loss 0.2875937521457672, fake loss 0.2048993706703186\tGenerator: loss 12.1071195602417\n","Epoch 98, batch 35/240:\tDiscriminator: real loss 0.08784627169370651, fake loss 0.15679378807544708\tGenerator: loss 13.015048027038574\n","Epoch 98, batch 36/240:\tDiscriminator: real loss 0.04753881320357323, fake loss 0.23064953088760376\tGenerator: loss 12.794323921203613\n","Epoch 98, batch 37/240:\tDiscriminator: real loss 0.1358199268579483, fake loss 0.19252990186214447\tGenerator: loss 13.242541313171387\n","Epoch 98, batch 38/240:\tDiscriminator: real loss 0.17899879813194275, fake loss 0.16272498667240143\tGenerator: loss 12.021489143371582\n","Epoch 98, batch 39/240:\tDiscriminator: real loss 0.06879927963018417, fake loss 0.1620846539735794\tGenerator: loss 13.268022537231445\n","Epoch 98, batch 40/240:\tDiscriminator: real loss 0.2063567042350769, fake loss 0.17948469519615173\tGenerator: loss 10.56430435180664\n","Epoch 98, batch 41/240:\tDiscriminator: real loss 0.16641846299171448, fake loss 0.213698610663414\tGenerator: loss 10.334589958190918\n","Epoch 98, batch 42/240:\tDiscriminator: real loss 0.11044280230998993, fake loss 0.03840746730566025\tGenerator: loss 9.811907768249512\n","Epoch 98, batch 43/240:\tDiscriminator: real loss 0.10772481560707092, fake loss 0.13073450326919556\tGenerator: loss 9.212909698486328\n","Epoch 98, batch 44/240:\tDiscriminator: real loss 0.08609756827354431, fake loss 0.26917803287506104\tGenerator: loss 9.199365615844727\n","Epoch 98, batch 45/240:\tDiscriminator: real loss 0.07648935914039612, fake loss 0.19669750332832336\tGenerator: loss 10.74983024597168\n","Epoch 98, batch 46/240:\tDiscriminator: real loss 0.23588664829730988, fake loss 0.1513960212469101\tGenerator: loss 10.990070343017578\n","Epoch 98, batch 47/240:\tDiscriminator: real loss 0.11098653078079224, fake loss 0.20608443021774292\tGenerator: loss 9.556255340576172\n","Epoch 98, batch 48/240:\tDiscriminator: real loss 0.128200963139534, fake loss 0.14322741329669952\tGenerator: loss 9.047018051147461\n","Epoch 98, batch 49/240:\tDiscriminator: real loss 0.09760443866252899, fake loss 0.11004472523927689\tGenerator: loss 10.747040748596191\n","Epoch 98, batch 50/240:\tDiscriminator: real loss 0.14835453033447266, fake loss 0.2549220323562622\tGenerator: loss 10.8528470993042\n","Epoch 98, batch 51/240:\tDiscriminator: real loss 0.08446651697158813, fake loss 0.11288417875766754\tGenerator: loss 9.932385444641113\n","Epoch 98, batch 52/240:\tDiscriminator: real loss 0.1404682844877243, fake loss 0.13611097633838654\tGenerator: loss 10.801424980163574\n","Epoch 98, batch 53/240:\tDiscriminator: real loss 0.13126297295093536, fake loss 0.13857130706310272\tGenerator: loss 9.143421173095703\n","Epoch 98, batch 54/240:\tDiscriminator: real loss 0.09084382653236389, fake loss 0.18509826064109802\tGenerator: loss 9.597972869873047\n","Epoch 98, batch 55/240:\tDiscriminator: real loss 0.13530506193637848, fake loss 0.05459040030837059\tGenerator: loss 11.889514923095703\n","Epoch 98, batch 56/240:\tDiscriminator: real loss 0.11030354350805283, fake loss 0.1000852957367897\tGenerator: loss 9.6189546585083\n","Epoch 98, batch 57/240:\tDiscriminator: real loss 0.02593522146344185, fake loss 0.2733478248119354\tGenerator: loss 9.988454818725586\n","Epoch 98, batch 58/240:\tDiscriminator: real loss 0.08200329542160034, fake loss 0.10083287209272385\tGenerator: loss 10.352219581604004\n","Epoch 98, batch 59/240:\tDiscriminator: real loss 0.12593017518520355, fake loss 0.1940278857946396\tGenerator: loss 9.912367820739746\n","Epoch 98, batch 60/240:\tDiscriminator: real loss 0.08754591643810272, fake loss 0.06906402856111526\tGenerator: loss 9.546296119689941\n","Epoch 98, batch 61/240:\tDiscriminator: real loss 0.08924897015094757, fake loss 0.19280047714710236\tGenerator: loss 9.580696105957031\n","Epoch 98, batch 62/240:\tDiscriminator: real loss 0.08146017044782639, fake loss 0.1406942903995514\tGenerator: loss 11.790369033813477\n","Epoch 98, batch 63/240:\tDiscriminator: real loss 0.13297276198863983, fake loss 0.10346944630146027\tGenerator: loss 13.112689971923828\n","Epoch 98, batch 64/240:\tDiscriminator: real loss 0.12321752309799194, fake loss 0.1551123708486557\tGenerator: loss 13.088783264160156\n","Epoch 98, batch 65/240:\tDiscriminator: real loss 0.12249203026294708, fake loss 0.1235041618347168\tGenerator: loss 12.012375831604004\n","Epoch 98, batch 66/240:\tDiscriminator: real loss 0.09173635393381119, fake loss 0.18732242286205292\tGenerator: loss 12.243692398071289\n","Epoch 98, batch 67/240:\tDiscriminator: real loss 0.11866007000207901, fake loss 0.098113514482975\tGenerator: loss 11.491015434265137\n","Epoch 98, batch 68/240:\tDiscriminator: real loss 0.09822597354650497, fake loss 0.3035261332988739\tGenerator: loss 13.184648513793945\n","Epoch 98, batch 69/240:\tDiscriminator: real loss 0.16008977591991425, fake loss 0.04435576871037483\tGenerator: loss 11.539083480834961\n","Epoch 98, batch 70/240:\tDiscriminator: real loss 0.12816186249256134, fake loss 0.1489604264497757\tGenerator: loss 10.267193794250488\n","Epoch 98, batch 71/240:\tDiscriminator: real loss 0.0791495069861412, fake loss 0.10209764540195465\tGenerator: loss 9.584884643554688\n","Epoch 98, batch 72/240:\tDiscriminator: real loss 0.07485297322273254, fake loss 0.17545956373214722\tGenerator: loss 12.171184539794922\n","Epoch 98, batch 73/240:\tDiscriminator: real loss 0.10697834193706512, fake loss 0.1331469863653183\tGenerator: loss 11.650657653808594\n","Epoch 98, batch 74/240:\tDiscriminator: real loss 0.08575250953435898, fake loss 0.15531617403030396\tGenerator: loss 12.476008415222168\n","Epoch 98, batch 75/240:\tDiscriminator: real loss 0.0884668156504631, fake loss 0.15427514910697937\tGenerator: loss 11.118790626525879\n","Epoch 98, batch 76/240:\tDiscriminator: real loss 0.1574200689792633, fake loss 0.1420915722846985\tGenerator: loss 11.956204414367676\n","Epoch 98, batch 77/240:\tDiscriminator: real loss 0.1970072239637375, fake loss 0.23423534631729126\tGenerator: loss 10.133304595947266\n","Epoch 98, batch 78/240:\tDiscriminator: real loss 0.10788732767105103, fake loss 0.2016150802373886\tGenerator: loss 10.761138916015625\n","Epoch 98, batch 79/240:\tDiscriminator: real loss 0.20834441483020782, fake loss 0.07748541235923767\tGenerator: loss 11.042557716369629\n","Epoch 98, batch 80/240:\tDiscriminator: real loss 0.08820527046918869, fake loss 0.11169659346342087\tGenerator: loss 10.9813871383667\n","Epoch 98, batch 81/240:\tDiscriminator: real loss 0.05254799872636795, fake loss 0.17809192836284637\tGenerator: loss 11.992712020874023\n","Epoch 98, batch 82/240:\tDiscriminator: real loss 0.10479484498500824, fake loss 0.15259073674678802\tGenerator: loss 13.051530838012695\n","Epoch 98, batch 83/240:\tDiscriminator: real loss 0.16166041791439056, fake loss 0.09472393244504929\tGenerator: loss 11.80208969116211\n","Epoch 98, batch 84/240:\tDiscriminator: real loss 0.09292072057723999, fake loss 0.1877516508102417\tGenerator: loss 11.0352783203125\n","Epoch 98, batch 85/240:\tDiscriminator: real loss 0.08731245249509811, fake loss 0.297595739364624\tGenerator: loss 11.723315238952637\n","Epoch 98, batch 86/240:\tDiscriminator: real loss 0.2603537440299988, fake loss 0.16369201242923737\tGenerator: loss 11.25057601928711\n","Epoch 98, batch 87/240:\tDiscriminator: real loss 0.16431725025177002, fake loss 0.23729857802391052\tGenerator: loss 9.910654067993164\n","Epoch 98, batch 88/240:\tDiscriminator: real loss 0.09754402935504913, fake loss 0.17465466260910034\tGenerator: loss 11.153712272644043\n","Epoch 98, batch 89/240:\tDiscriminator: real loss 0.14652766287326813, fake loss 0.22896991670131683\tGenerator: loss 11.955890655517578\n","Epoch 98, batch 90/240:\tDiscriminator: real loss 0.22180534899234772, fake loss 0.09733124077320099\tGenerator: loss 13.137237548828125\n","Epoch 98, batch 91/240:\tDiscriminator: real loss 0.06366875022649765, fake loss 0.22958655655384064\tGenerator: loss 14.245647430419922\n","Epoch 98, batch 92/240:\tDiscriminator: real loss 0.20474448800086975, fake loss 0.21179494261741638\tGenerator: loss 10.655978202819824\n","Epoch 98, batch 93/240:\tDiscriminator: real loss 0.07647190243005753, fake loss 0.13092999160289764\tGenerator: loss 10.956722259521484\n","Epoch 98, batch 94/240:\tDiscriminator: real loss 0.14347371459007263, fake loss 0.1576632261276245\tGenerator: loss 11.116515159606934\n","Epoch 98, batch 95/240:\tDiscriminator: real loss 0.08573929965496063, fake loss 0.12414299696683884\tGenerator: loss 11.727167129516602\n","Epoch 98, batch 96/240:\tDiscriminator: real loss 0.12221083045005798, fake loss 0.19583994150161743\tGenerator: loss 11.928491592407227\n","Epoch 98, batch 97/240:\tDiscriminator: real loss 0.06490825861692429, fake loss 0.1021151915192604\tGenerator: loss 12.578760147094727\n","Epoch 98, batch 98/240:\tDiscriminator: real loss 0.17810001969337463, fake loss 0.31094399094581604\tGenerator: loss 12.565189361572266\n","Epoch 98, batch 99/240:\tDiscriminator: real loss 0.09842115640640259, fake loss 0.12146177142858505\tGenerator: loss 12.07166862487793\n","Epoch 98, batch 100/240:\tDiscriminator: real loss 0.11668110638856888, fake loss 0.07611963152885437\tGenerator: loss 11.376018524169922\n","Epoch 98, batch 101/240:\tDiscriminator: real loss 0.15664291381835938, fake loss 0.2861131429672241\tGenerator: loss 13.408761978149414\n","Epoch 98, batch 102/240:\tDiscriminator: real loss 0.19224479794502258, fake loss 0.13484521210193634\tGenerator: loss 11.944414138793945\n","Epoch 98, batch 103/240:\tDiscriminator: real loss 0.0659811794757843, fake loss 0.19445274770259857\tGenerator: loss 11.874090194702148\n","Epoch 98, batch 104/240:\tDiscriminator: real loss 0.12920361757278442, fake loss 0.18742705881595612\tGenerator: loss 12.553156852722168\n","Epoch 98, batch 105/240:\tDiscriminator: real loss 0.2688884437084198, fake loss 0.15067295730113983\tGenerator: loss 10.326358795166016\n","Epoch 98, batch 106/240:\tDiscriminator: real loss 0.1027931496500969, fake loss 0.1526137739419937\tGenerator: loss 10.261026382446289\n","Epoch 98, batch 107/240:\tDiscriminator: real loss 0.06375965476036072, fake loss 0.23328125476837158\tGenerator: loss 11.243297576904297\n","Epoch 98, batch 108/240:\tDiscriminator: real loss 0.08845212310552597, fake loss 0.07506608217954636\tGenerator: loss 10.858562469482422\n","Epoch 98, batch 109/240:\tDiscriminator: real loss 0.16695532202720642, fake loss 0.14933151006698608\tGenerator: loss 11.886855125427246\n","Epoch 98, batch 110/240:\tDiscriminator: real loss 0.09046857059001923, fake loss 0.15409229695796967\tGenerator: loss 11.273855209350586\n","Epoch 98, batch 111/240:\tDiscriminator: real loss 0.12919433414936066, fake loss 0.09889262914657593\tGenerator: loss 12.976548194885254\n","Epoch 98, batch 112/240:\tDiscriminator: real loss 0.13780394196510315, fake loss 0.1591435968875885\tGenerator: loss 10.559527397155762\n","Epoch 98, batch 113/240:\tDiscriminator: real loss 0.04987533390522003, fake loss 0.3288501799106598\tGenerator: loss 14.385468482971191\n","Epoch 98, batch 114/240:\tDiscriminator: real loss 0.08424560725688934, fake loss 0.16355134546756744\tGenerator: loss 14.875628471374512\n","Epoch 98, batch 115/240:\tDiscriminator: real loss 0.12220906466245651, fake loss 0.04230285808444023\tGenerator: loss 13.779975891113281\n","Epoch 98, batch 116/240:\tDiscriminator: real loss 0.14309971034526825, fake loss 0.05924340337514877\tGenerator: loss 11.992104530334473\n","Epoch 98, batch 117/240:\tDiscriminator: real loss 0.03122198022902012, fake loss 0.15449941158294678\tGenerator: loss 12.52425765991211\n","Epoch 98, batch 118/240:\tDiscriminator: real loss 0.16033409535884857, fake loss 0.22177544236183167\tGenerator: loss 11.276074409484863\n","Epoch 98, batch 119/240:\tDiscriminator: real loss 0.0857444778084755, fake loss 0.17978091537952423\tGenerator: loss 12.059042930603027\n","Epoch 98, batch 120/240:\tDiscriminator: real loss 0.14650298655033112, fake loss 0.07041855156421661\tGenerator: loss 11.443346977233887\n","Epoch 98, batch 121/240:\tDiscriminator: real loss 0.14141584932804108, fake loss 0.1252313256263733\tGenerator: loss 10.470865249633789\n","Epoch 98, batch 122/240:\tDiscriminator: real loss 0.11066696047782898, fake loss 0.19537058472633362\tGenerator: loss 11.499850273132324\n","Epoch 98, batch 123/240:\tDiscriminator: real loss 0.09816932678222656, fake loss 0.08361366391181946\tGenerator: loss 11.026330947875977\n","Epoch 98, batch 124/240:\tDiscriminator: real loss 0.10220737755298615, fake loss 0.13274681568145752\tGenerator: loss 10.6151704788208\n","Epoch 98, batch 125/240:\tDiscriminator: real loss 0.06426797062158585, fake loss 0.2276173084974289\tGenerator: loss 11.596858978271484\n","Epoch 98, batch 126/240:\tDiscriminator: real loss 0.14904096722602844, fake loss 0.21247169375419617\tGenerator: loss 12.115808486938477\n","Epoch 98, batch 127/240:\tDiscriminator: real loss 0.12736192345619202, fake loss 0.1367751806974411\tGenerator: loss 12.574249267578125\n","Epoch 98, batch 128/240:\tDiscriminator: real loss 0.14340882003307343, fake loss 0.20935454964637756\tGenerator: loss 11.832575798034668\n","Epoch 98, batch 129/240:\tDiscriminator: real loss 0.12810902297496796, fake loss 0.06624437123537064\tGenerator: loss 13.076873779296875\n","Epoch 98, batch 130/240:\tDiscriminator: real loss 0.19766350090503693, fake loss 0.2033698409795761\tGenerator: loss 12.807757377624512\n","Epoch 98, batch 131/240:\tDiscriminator: real loss 0.07539799809455872, fake loss 0.1119362935423851\tGenerator: loss 12.022876739501953\n","Epoch 98, batch 132/240:\tDiscriminator: real loss 0.1511281132698059, fake loss 0.16776089370250702\tGenerator: loss 11.697854042053223\n","Epoch 98, batch 133/240:\tDiscriminator: real loss 0.052336186170578, fake loss 0.18594177067279816\tGenerator: loss 14.612215995788574\n","Epoch 98, batch 134/240:\tDiscriminator: real loss 0.09152010083198547, fake loss 0.12682883441448212\tGenerator: loss 14.173874855041504\n","Epoch 98, batch 135/240:\tDiscriminator: real loss 0.14109547436237335, fake loss 0.11110023409128189\tGenerator: loss 13.977509498596191\n","Epoch 98, batch 136/240:\tDiscriminator: real loss 0.12407861649990082, fake loss 0.19525809586048126\tGenerator: loss 14.224532127380371\n","Epoch 98, batch 137/240:\tDiscriminator: real loss 0.06871958822011948, fake loss 0.09529592841863632\tGenerator: loss 14.509746551513672\n","Epoch 98, batch 138/240:\tDiscriminator: real loss 0.09794831275939941, fake loss 0.20498019456863403\tGenerator: loss 14.520956993103027\n","Epoch 98, batch 139/240:\tDiscriminator: real loss 0.2005540430545807, fake loss 0.22392955422401428\tGenerator: loss 14.5503511428833\n","Epoch 98, batch 140/240:\tDiscriminator: real loss 0.14718322455883026, fake loss 0.09660989791154861\tGenerator: loss 12.535770416259766\n","Epoch 98, batch 141/240:\tDiscriminator: real loss 0.0866183191537857, fake loss 0.15562286972999573\tGenerator: loss 14.019082069396973\n","Epoch 98, batch 142/240:\tDiscriminator: real loss 0.1080997958779335, fake loss 0.24660442769527435\tGenerator: loss 15.370403289794922\n","Epoch 98, batch 143/240:\tDiscriminator: real loss 0.1407516896724701, fake loss 0.031174303963780403\tGenerator: loss 12.408919334411621\n","Epoch 98, batch 144/240:\tDiscriminator: real loss 0.11371929198503494, fake loss 0.13453255593776703\tGenerator: loss 10.863397598266602\n","Epoch 98, batch 145/240:\tDiscriminator: real loss 0.08607538044452667, fake loss 0.17231954634189606\tGenerator: loss 13.489360809326172\n","Epoch 98, batch 146/240:\tDiscriminator: real loss 0.1115090399980545, fake loss 0.2119152843952179\tGenerator: loss 13.921539306640625\n","Epoch 98, batch 147/240:\tDiscriminator: real loss 0.060329925268888474, fake loss 0.2699562609195709\tGenerator: loss 14.643044471740723\n","Epoch 98, batch 148/240:\tDiscriminator: real loss 0.13859909772872925, fake loss 0.07246674597263336\tGenerator: loss 14.0477294921875\n","Epoch 98, batch 149/240:\tDiscriminator: real loss 0.18907594680786133, fake loss 0.14663414657115936\tGenerator: loss 13.781279563903809\n","Epoch 98, batch 150/240:\tDiscriminator: real loss 0.16253970563411713, fake loss 0.26308608055114746\tGenerator: loss 15.994235038757324\n","Epoch 98, batch 151/240:\tDiscriminator: real loss 0.07197747379541397, fake loss 0.18713383376598358\tGenerator: loss 14.463098526000977\n","Epoch 98, batch 152/240:\tDiscriminator: real loss 0.17227138578891754, fake loss 0.10253234207630157\tGenerator: loss 14.182599067687988\n","Epoch 98, batch 153/240:\tDiscriminator: real loss 0.07802480459213257, fake loss 0.21488255262374878\tGenerator: loss 13.876899719238281\n","Epoch 98, batch 154/240:\tDiscriminator: real loss 0.18016517162322998, fake loss 0.08518733829259872\tGenerator: loss 13.190068244934082\n","Epoch 98, batch 155/240:\tDiscriminator: real loss 0.08182913810014725, fake loss 0.1374700963497162\tGenerator: loss 12.267577171325684\n","Epoch 98, batch 156/240:\tDiscriminator: real loss 0.22774329781532288, fake loss 0.1077895388007164\tGenerator: loss 12.891258239746094\n","Epoch 98, batch 157/240:\tDiscriminator: real loss 0.08361972868442535, fake loss 0.16823571920394897\tGenerator: loss 11.914450645446777\n","Epoch 98, batch 158/240:\tDiscriminator: real loss 0.044349998235702515, fake loss 0.05516386032104492\tGenerator: loss 11.746295928955078\n","Epoch 98, batch 159/240:\tDiscriminator: real loss 0.08257994800806046, fake loss 0.1486571729183197\tGenerator: loss 12.804218292236328\n","Epoch 98, batch 160/240:\tDiscriminator: real loss 0.05965554341673851, fake loss 0.11285224556922913\tGenerator: loss 13.186293601989746\n","Epoch 98, batch 161/240:\tDiscriminator: real loss 0.1507231742143631, fake loss 0.19304679334163666\tGenerator: loss 11.843008995056152\n","Epoch 98, batch 162/240:\tDiscriminator: real loss 0.09395632147789001, fake loss 0.17177192866802216\tGenerator: loss 11.443122863769531\n","Epoch 98, batch 163/240:\tDiscriminator: real loss 0.08353983610868454, fake loss 0.0660843551158905\tGenerator: loss 12.228758811950684\n","Epoch 98, batch 164/240:\tDiscriminator: real loss 0.13490815460681915, fake loss 0.09719296544790268\tGenerator: loss 10.626753807067871\n","Epoch 98, batch 165/240:\tDiscriminator: real loss 0.07482253760099411, fake loss 0.15029765665531158\tGenerator: loss 10.947785377502441\n","Epoch 98, batch 166/240:\tDiscriminator: real loss 0.11736604571342468, fake loss 0.19646921753883362\tGenerator: loss 12.092520713806152\n","Epoch 98, batch 167/240:\tDiscriminator: real loss 0.13001732528209686, fake loss 0.05174558609724045\tGenerator: loss 9.64404582977295\n","Epoch 98, batch 168/240:\tDiscriminator: real loss 0.0754462257027626, fake loss 0.18240772187709808\tGenerator: loss 10.625292778015137\n","Epoch 98, batch 169/240:\tDiscriminator: real loss 0.056735020130872726, fake loss 0.14099633693695068\tGenerator: loss 11.16442584991455\n","Epoch 98, batch 170/240:\tDiscriminator: real loss 0.1546022593975067, fake loss 0.14213073253631592\tGenerator: loss 11.256545066833496\n","Epoch 98, batch 171/240:\tDiscriminator: real loss 0.09666126221418381, fake loss 0.0843246653676033\tGenerator: loss 11.046916961669922\n","Epoch 98, batch 172/240:\tDiscriminator: real loss 0.15135401487350464, fake loss 0.17080901563167572\tGenerator: loss 10.697768211364746\n","Epoch 98, batch 173/240:\tDiscriminator: real loss 0.1731712371110916, fake loss 0.1479816734790802\tGenerator: loss 9.967267990112305\n","Epoch 98, batch 174/240:\tDiscriminator: real loss 0.08260712772607803, fake loss 0.11315245926380157\tGenerator: loss 9.808797836303711\n","Epoch 98, batch 175/240:\tDiscriminator: real loss 0.034448448568582535, fake loss 0.23167796432971954\tGenerator: loss 11.626009941101074\n","Epoch 98, batch 176/240:\tDiscriminator: real loss 0.13960227370262146, fake loss 0.1764078289270401\tGenerator: loss 12.603340148925781\n","Epoch 98, batch 177/240:\tDiscriminator: real loss 0.17042182385921478, fake loss 0.05444572493433952\tGenerator: loss 11.488323211669922\n","Epoch 98, batch 178/240:\tDiscriminator: real loss 0.1389690637588501, fake loss 0.18904344737529755\tGenerator: loss 10.417407989501953\n","Epoch 98, batch 179/240:\tDiscriminator: real loss 0.05985723063349724, fake loss 0.11945122480392456\tGenerator: loss 12.728645324707031\n","Epoch 98, batch 180/240:\tDiscriminator: real loss 0.08008727431297302, fake loss 0.12129892408847809\tGenerator: loss 12.73720932006836\n","Epoch 98, batch 181/240:\tDiscriminator: real loss 0.10743219405412674, fake loss 0.22243617475032806\tGenerator: loss 14.300698280334473\n","Epoch 98, batch 182/240:\tDiscriminator: real loss 0.0904059186577797, fake loss 0.13516643643379211\tGenerator: loss 17.544384002685547\n","Epoch 98, batch 183/240:\tDiscriminator: real loss 0.06860567629337311, fake loss 0.07395855337381363\tGenerator: loss 18.94956398010254\n","Epoch 98, batch 184/240:\tDiscriminator: real loss 0.2758067846298218, fake loss 0.16513915359973907\tGenerator: loss 13.817975044250488\n","Epoch 98, batch 185/240:\tDiscriminator: real loss 0.07680876553058624, fake loss 0.0841357484459877\tGenerator: loss 14.861102104187012\n","Epoch 98, batch 186/240:\tDiscriminator: real loss 0.052369192242622375, fake loss 0.10639772564172745\tGenerator: loss 13.471440315246582\n","Epoch 98, batch 187/240:\tDiscriminator: real loss 0.03293883427977562, fake loss 0.15456344187259674\tGenerator: loss 13.855310440063477\n","Epoch 98, batch 188/240:\tDiscriminator: real loss 0.0990949273109436, fake loss 0.08856379240751266\tGenerator: loss 13.572164535522461\n","Epoch 98, batch 189/240:\tDiscriminator: real loss 0.1903318613767624, fake loss 0.19407856464385986\tGenerator: loss 15.39318561553955\n","Epoch 98, batch 190/240:\tDiscriminator: real loss 0.08264248073101044, fake loss 0.0859665647149086\tGenerator: loss 14.689345359802246\n","Epoch 98, batch 191/240:\tDiscriminator: real loss 0.08205464482307434, fake loss 0.17515474557876587\tGenerator: loss 17.335233688354492\n","Epoch 98, batch 192/240:\tDiscriminator: real loss 0.09810519218444824, fake loss 0.045317694544792175\tGenerator: loss 15.441744804382324\n","Epoch 98, batch 193/240:\tDiscriminator: real loss 0.06713844835758209, fake loss 0.16022171080112457\tGenerator: loss 15.762595176696777\n","Epoch 98, batch 194/240:\tDiscriminator: real loss 0.059337928891181946, fake loss 0.10124471038579941\tGenerator: loss 18.522018432617188\n","Epoch 98, batch 195/240:\tDiscriminator: real loss 0.13192406296730042, fake loss 0.043639637529850006\tGenerator: loss 17.628650665283203\n","Epoch 98, batch 196/240:\tDiscriminator: real loss 0.09757854789495468, fake loss 0.21838127076625824\tGenerator: loss 17.60344886779785\n","Epoch 98, batch 197/240:\tDiscriminator: real loss 0.06868121773004532, fake loss 0.06889741122722626\tGenerator: loss 16.75116539001465\n","Epoch 98, batch 198/240:\tDiscriminator: real loss 0.12358522415161133, fake loss 0.32666638493537903\tGenerator: loss 18.289274215698242\n","Epoch 98, batch 199/240:\tDiscriminator: real loss 0.12703397870063782, fake loss 0.12420913577079773\tGenerator: loss 17.379985809326172\n","Epoch 98, batch 200/240:\tDiscriminator: real loss 0.14037856459617615, fake loss 0.08708208054304123\tGenerator: loss 16.657960891723633\n","Epoch 98, batch 201/240:\tDiscriminator: real loss 0.06774967908859253, fake loss 0.04516229033470154\tGenerator: loss 14.545741081237793\n","Epoch 98, batch 202/240:\tDiscriminator: real loss 0.11840856820344925, fake loss 0.4047488272190094\tGenerator: loss 18.63848876953125\n","Epoch 98, batch 203/240:\tDiscriminator: real loss 0.07859084755182266, fake loss 0.12477751076221466\tGenerator: loss 18.264963150024414\n","Epoch 98, batch 204/240:\tDiscriminator: real loss 0.13886283338069916, fake loss 0.07306857407093048\tGenerator: loss 16.660154342651367\n","Epoch 98, batch 205/240:\tDiscriminator: real loss 0.11865630745887756, fake loss 0.12055384367704391\tGenerator: loss 14.748573303222656\n","Epoch 98, batch 206/240:\tDiscriminator: real loss 0.07364892959594727, fake loss 0.11879894137382507\tGenerator: loss 16.0744686126709\n","Epoch 98, batch 207/240:\tDiscriminator: real loss 0.09110812097787857, fake loss 0.04301777854561806\tGenerator: loss 14.51905632019043\n","Epoch 98, batch 208/240:\tDiscriminator: real loss 0.08912376314401627, fake loss 0.14534670114517212\tGenerator: loss 15.077770233154297\n","Epoch 98, batch 209/240:\tDiscriminator: real loss 0.07083621621131897, fake loss 0.14762678742408752\tGenerator: loss 15.44738483428955\n","Epoch 98, batch 210/240:\tDiscriminator: real loss 0.03774358332157135, fake loss 0.1116931214928627\tGenerator: loss 16.414369583129883\n","Epoch 98, batch 211/240:\tDiscriminator: real loss 0.18509332835674286, fake loss 0.1698748618364334\tGenerator: loss 16.684677124023438\n","Epoch 98, batch 212/240:\tDiscriminator: real loss 0.07354677468538284, fake loss 0.1270969808101654\tGenerator: loss 15.539737701416016\n","Epoch 98, batch 213/240:\tDiscriminator: real loss 0.12309064716100693, fake loss 0.12258617579936981\tGenerator: loss 15.935267448425293\n","Epoch 98, batch 214/240:\tDiscriminator: real loss 0.13176439702510834, fake loss 0.20160074532032013\tGenerator: loss 17.262910842895508\n","Epoch 98, batch 215/240:\tDiscriminator: real loss 0.07914983481168747, fake loss 0.23785828053951263\tGenerator: loss 18.02066421508789\n","Epoch 98, batch 216/240:\tDiscriminator: real loss 0.11244861781597137, fake loss 0.09832492470741272\tGenerator: loss 18.576396942138672\n","Epoch 98, batch 217/240:\tDiscriminator: real loss 0.13302426040172577, fake loss 0.12186933308839798\tGenerator: loss 15.911808013916016\n","Epoch 98, batch 218/240:\tDiscriminator: real loss 0.08703011274337769, fake loss 0.21931137144565582\tGenerator: loss 18.919635772705078\n","Epoch 98, batch 219/240:\tDiscriminator: real loss 0.15671764314174652, fake loss 0.09165725111961365\tGenerator: loss 17.917142868041992\n","Epoch 98, batch 220/240:\tDiscriminator: real loss 0.29822826385498047, fake loss 0.13784080743789673\tGenerator: loss 16.61514663696289\n","Epoch 98, batch 221/240:\tDiscriminator: real loss 0.1363988071680069, fake loss 0.32111886143684387\tGenerator: loss 19.14659881591797\n","Epoch 98, batch 222/240:\tDiscriminator: real loss 0.06969593465328217, fake loss 0.2483035922050476\tGenerator: loss 17.95094871520996\n","Epoch 98, batch 223/240:\tDiscriminator: real loss 0.20777374505996704, fake loss 0.08126193284988403\tGenerator: loss 14.381780624389648\n","Epoch 98, batch 224/240:\tDiscriminator: real loss 0.09870362281799316, fake loss 0.17035484313964844\tGenerator: loss 17.163591384887695\n","Epoch 98, batch 225/240:\tDiscriminator: real loss 0.16660350561141968, fake loss 0.07854852825403214\tGenerator: loss 15.243483543395996\n","Epoch 98, batch 226/240:\tDiscriminator: real loss 0.07243215292692184, fake loss 0.13543790578842163\tGenerator: loss 14.254373550415039\n","Epoch 98, batch 227/240:\tDiscriminator: real loss 0.08761913329362869, fake loss 0.06887177377939224\tGenerator: loss 14.744965553283691\n","Epoch 98, batch 228/240:\tDiscriminator: real loss 0.07019814848899841, fake loss 0.16950100660324097\tGenerator: loss 12.597293853759766\n","Epoch 98, batch 229/240:\tDiscriminator: real loss 0.14651460945606232, fake loss 0.14172957837581635\tGenerator: loss 14.303564071655273\n","Epoch 98, batch 230/240:\tDiscriminator: real loss 0.08482085913419724, fake loss 0.19963358342647552\tGenerator: loss 13.393233299255371\n","Epoch 98, batch 231/240:\tDiscriminator: real loss 0.07436300069093704, fake loss 0.04816610738635063\tGenerator: loss 14.049073219299316\n","Epoch 98, batch 232/240:\tDiscriminator: real loss 0.18622425198554993, fake loss 0.2606128752231598\tGenerator: loss 16.566574096679688\n","Epoch 98, batch 233/240:\tDiscriminator: real loss 0.14298652112483978, fake loss 0.0604761466383934\tGenerator: loss 16.287334442138672\n","Epoch 98, batch 234/240:\tDiscriminator: real loss 0.06276800483465195, fake loss 0.0981404110789299\tGenerator: loss 15.272724151611328\n","Epoch 98, batch 235/240:\tDiscriminator: real loss 0.04927223175764084, fake loss 0.2709873914718628\tGenerator: loss 14.979326248168945\n","Epoch 98, batch 236/240:\tDiscriminator: real loss 0.16834501922130585, fake loss 0.04772583022713661\tGenerator: loss 14.762691497802734\n","Epoch 98, batch 237/240:\tDiscriminator: real loss 0.13357561826705933, fake loss 0.31842440366744995\tGenerator: loss 15.893034934997559\n","Epoch 98, batch 238/240:\tDiscriminator: real loss 0.18922491371631622, fake loss 0.09386447817087173\tGenerator: loss 14.786371231079102\n","Epoch 98, batch 239/240:\tDiscriminator: real loss 0.10546588897705078, fake loss 0.15714029967784882\tGenerator: loss 14.480359077453613\n","Epoch 98, batch 240/240:\tDiscriminator: real loss 0.044895559549331665, fake loss 0.0756254717707634\tGenerator: loss 15.746452331542969\n","Epoch 99, batch 1/240:\tDiscriminator: real loss 0.06756605952978134, fake loss 0.16813473403453827\tGenerator: loss 16.16507911682129\n","Epoch 99, batch 2/240:\tDiscriminator: real loss 0.08220537006855011, fake loss 0.08217228949069977\tGenerator: loss 16.620004653930664\n","Epoch 99, batch 3/240:\tDiscriminator: real loss 0.1545150727033615, fake loss 0.29069095849990845\tGenerator: loss 17.440114974975586\n","Epoch 99, batch 4/240:\tDiscriminator: real loss 0.1556313931941986, fake loss 0.10255395621061325\tGenerator: loss 18.979135513305664\n","Epoch 99, batch 5/240:\tDiscriminator: real loss 0.16712705790996552, fake loss 0.22076061367988586\tGenerator: loss 16.760282516479492\n","Epoch 99, batch 6/240:\tDiscriminator: real loss 0.10326205939054489, fake loss 0.08246680349111557\tGenerator: loss 18.185270309448242\n","Epoch 99, batch 7/240:\tDiscriminator: real loss 0.05120906978845596, fake loss 0.26348263025283813\tGenerator: loss 19.202791213989258\n","Epoch 99, batch 8/240:\tDiscriminator: real loss 0.06692185252904892, fake loss 0.12432444840669632\tGenerator: loss 19.850414276123047\n","Epoch 99, batch 9/240:\tDiscriminator: real loss 0.13270829617977142, fake loss 0.11343345046043396\tGenerator: loss 20.392541885375977\n","Epoch 99, batch 10/240:\tDiscriminator: real loss 0.1368928849697113, fake loss 0.17925210297107697\tGenerator: loss 16.629579544067383\n","Epoch 99, batch 11/240:\tDiscriminator: real loss 0.11648062616586685, fake loss 0.13411687314510345\tGenerator: loss 15.971165657043457\n","Epoch 99, batch 12/240:\tDiscriminator: real loss 0.17346717417240143, fake loss 0.06006218492984772\tGenerator: loss 13.486371994018555\n","Epoch 99, batch 13/240:\tDiscriminator: real loss 0.09626664966344833, fake loss 0.20687320828437805\tGenerator: loss 14.461882591247559\n","Epoch 99, batch 14/240:\tDiscriminator: real loss 0.09820860624313354, fake loss 0.07472117245197296\tGenerator: loss 15.493605613708496\n","Epoch 99, batch 15/240:\tDiscriminator: real loss 0.04318186268210411, fake loss 0.15155354142189026\tGenerator: loss 15.702898979187012\n","Epoch 99, batch 16/240:\tDiscriminator: real loss 0.17135433852672577, fake loss 0.13722172379493713\tGenerator: loss 15.610434532165527\n","Epoch 99, batch 17/240:\tDiscriminator: real loss 0.12042371928691864, fake loss 0.19619081914424896\tGenerator: loss 13.581696510314941\n","Epoch 99, batch 18/240:\tDiscriminator: real loss 0.1103300079703331, fake loss 0.2466115951538086\tGenerator: loss 14.663002014160156\n","Epoch 99, batch 19/240:\tDiscriminator: real loss 0.10758167505264282, fake loss 0.1479945033788681\tGenerator: loss 13.769234657287598\n","Epoch 99, batch 20/240:\tDiscriminator: real loss 0.23861533403396606, fake loss 0.14011313021183014\tGenerator: loss 13.533283233642578\n","Epoch 99, batch 21/240:\tDiscriminator: real loss 0.11426463723182678, fake loss 0.11125234514474869\tGenerator: loss 15.623023986816406\n","Epoch 99, batch 22/240:\tDiscriminator: real loss 0.07573176175355911, fake loss 0.13473086059093475\tGenerator: loss 14.628813743591309\n","Epoch 99, batch 23/240:\tDiscriminator: real loss 0.08664915710687637, fake loss 0.05798224359750748\tGenerator: loss 14.952083587646484\n","Epoch 99, batch 24/240:\tDiscriminator: real loss 0.0748034343123436, fake loss 0.44895103573799133\tGenerator: loss 15.101144790649414\n","Epoch 99, batch 25/240:\tDiscriminator: real loss 0.22911140322685242, fake loss 0.09144940972328186\tGenerator: loss 14.052090644836426\n","Epoch 99, batch 26/240:\tDiscriminator: real loss 0.08380474895238876, fake loss 0.05374440178275108\tGenerator: loss 12.943272590637207\n","Epoch 99, batch 27/240:\tDiscriminator: real loss 0.11515645682811737, fake loss 0.18593916296958923\tGenerator: loss 14.242258071899414\n","Epoch 99, batch 28/240:\tDiscriminator: real loss 0.11492389440536499, fake loss 0.1915801465511322\tGenerator: loss 14.953093528747559\n","Epoch 99, batch 29/240:\tDiscriminator: real loss 0.051341842859983444, fake loss 0.2495882362127304\tGenerator: loss 15.088377952575684\n","Epoch 99, batch 30/240:\tDiscriminator: real loss 0.152134507894516, fake loss 0.17759914696216583\tGenerator: loss 14.990264892578125\n","Epoch 99, batch 31/240:\tDiscriminator: real loss 0.08285219222307205, fake loss 0.18699763715267181\tGenerator: loss 13.464478492736816\n","Epoch 99, batch 32/240:\tDiscriminator: real loss 0.1641361266374588, fake loss 0.15196137130260468\tGenerator: loss 13.304040908813477\n","Epoch 99, batch 33/240:\tDiscriminator: real loss 0.07760749012231827, fake loss 0.22422169148921967\tGenerator: loss 13.323955535888672\n","Epoch 99, batch 34/240:\tDiscriminator: real loss 0.13294532895088196, fake loss 0.15600568056106567\tGenerator: loss 16.463581085205078\n","Epoch 99, batch 35/240:\tDiscriminator: real loss 0.16842207312583923, fake loss 0.216298907995224\tGenerator: loss 13.681915283203125\n","Epoch 99, batch 36/240:\tDiscriminator: real loss 0.22447526454925537, fake loss 0.14280451834201813\tGenerator: loss 16.12163734436035\n","Epoch 99, batch 37/240:\tDiscriminator: real loss 0.09905307739973068, fake loss 0.3131653964519501\tGenerator: loss 15.550220489501953\n","Epoch 99, batch 38/240:\tDiscriminator: real loss 0.08099951595067978, fake loss 0.12643638253211975\tGenerator: loss 14.681404113769531\n","Epoch 99, batch 39/240:\tDiscriminator: real loss 0.1751256138086319, fake loss 0.06183423846960068\tGenerator: loss 13.803855895996094\n","Epoch 99, batch 40/240:\tDiscriminator: real loss 0.08736150711774826, fake loss 0.24790360033512115\tGenerator: loss 13.966840744018555\n","Epoch 99, batch 41/240:\tDiscriminator: real loss 0.05607369542121887, fake loss 0.19722789525985718\tGenerator: loss 15.304787635803223\n","Epoch 99, batch 42/240:\tDiscriminator: real loss 0.2524791657924652, fake loss 0.19474242627620697\tGenerator: loss 13.804681777954102\n","Epoch 99, batch 43/240:\tDiscriminator: real loss 0.12794914841651917, fake loss 0.0813915953040123\tGenerator: loss 14.491271018981934\n","Epoch 99, batch 44/240:\tDiscriminator: real loss 0.10010355710983276, fake loss 0.11852683871984482\tGenerator: loss 14.209285736083984\n","Epoch 99, batch 45/240:\tDiscriminator: real loss 0.07560727000236511, fake loss 0.20234034955501556\tGenerator: loss 14.660051345825195\n","Epoch 99, batch 46/240:\tDiscriminator: real loss 0.11358505487442017, fake loss 0.13063521683216095\tGenerator: loss 15.836983680725098\n","Epoch 99, batch 47/240:\tDiscriminator: real loss 0.2068084478378296, fake loss 0.11891081184148788\tGenerator: loss 16.204334259033203\n","Epoch 99, batch 48/240:\tDiscriminator: real loss 0.07992538809776306, fake loss 0.10583560913801193\tGenerator: loss 12.425514221191406\n","Epoch 99, batch 49/240:\tDiscriminator: real loss 0.14355945587158203, fake loss 0.16741223633289337\tGenerator: loss 13.873967170715332\n","Epoch 99, batch 50/240:\tDiscriminator: real loss 0.027747172862291336, fake loss 0.15590046346187592\tGenerator: loss 14.143671989440918\n","Epoch 99, batch 51/240:\tDiscriminator: real loss 0.1753489375114441, fake loss 0.11867525428533554\tGenerator: loss 15.756974220275879\n","Epoch 99, batch 52/240:\tDiscriminator: real loss 0.15421675145626068, fake loss 0.24360541999340057\tGenerator: loss 16.327255249023438\n","Epoch 99, batch 53/240:\tDiscriminator: real loss 0.09623150527477264, fake loss 0.1014215350151062\tGenerator: loss 15.466168403625488\n","Epoch 99, batch 54/240:\tDiscriminator: real loss 0.07924705743789673, fake loss 0.17580217123031616\tGenerator: loss 16.673004150390625\n","Epoch 99, batch 55/240:\tDiscriminator: real loss 0.13475212454795837, fake loss 0.053755488246679306\tGenerator: loss 14.112693786621094\n","Epoch 99, batch 56/240:\tDiscriminator: real loss 0.10259903967380524, fake loss 0.0744953379034996\tGenerator: loss 13.87087631225586\n","Epoch 99, batch 57/240:\tDiscriminator: real loss 0.18965764343738556, fake loss 0.1325361281633377\tGenerator: loss 14.039682388305664\n","Epoch 99, batch 58/240:\tDiscriminator: real loss 0.04005895555019379, fake loss 0.1653604656457901\tGenerator: loss 11.89990520477295\n","Epoch 99, batch 59/240:\tDiscriminator: real loss 0.04916062206029892, fake loss 0.1902444064617157\tGenerator: loss 13.658443450927734\n","Epoch 99, batch 60/240:\tDiscriminator: real loss 0.10899854451417923, fake loss 0.09777960181236267\tGenerator: loss 13.151834487915039\n","Epoch 99, batch 61/240:\tDiscriminator: real loss 0.16449850797653198, fake loss 0.10433884710073471\tGenerator: loss 12.257712364196777\n","Epoch 99, batch 62/240:\tDiscriminator: real loss 0.06399465352296829, fake loss 0.13163363933563232\tGenerator: loss 11.919414520263672\n","Epoch 99, batch 63/240:\tDiscriminator: real loss 0.16750866174697876, fake loss 0.14843198657035828\tGenerator: loss 14.255237579345703\n","Epoch 99, batch 64/240:\tDiscriminator: real loss 0.08834321796894073, fake loss 0.17534808814525604\tGenerator: loss 14.906623840332031\n","Epoch 99, batch 65/240:\tDiscriminator: real loss 0.15155896544456482, fake loss 0.1213252991437912\tGenerator: loss 12.821601867675781\n","Epoch 99, batch 66/240:\tDiscriminator: real loss 0.06666697561740875, fake loss 0.15371422469615936\tGenerator: loss 9.55787181854248\n","Epoch 99, batch 67/240:\tDiscriminator: real loss 0.17380310595035553, fake loss 0.2303171157836914\tGenerator: loss 12.571359634399414\n","Epoch 99, batch 68/240:\tDiscriminator: real loss 0.14715659618377686, fake loss 0.24444183707237244\tGenerator: loss 12.958017349243164\n","Epoch 99, batch 69/240:\tDiscriminator: real loss 0.17774158716201782, fake loss 0.2470150738954544\tGenerator: loss 13.503043174743652\n","Epoch 99, batch 70/240:\tDiscriminator: real loss 0.2095736712217331, fake loss 0.14894960820674896\tGenerator: loss 13.361363410949707\n","Epoch 99, batch 71/240:\tDiscriminator: real loss 0.15316784381866455, fake loss 0.17158417403697968\tGenerator: loss 12.2145357131958\n","Epoch 99, batch 72/240:\tDiscriminator: real loss 0.08879496902227402, fake loss 0.16462291777133942\tGenerator: loss 12.133269309997559\n","Epoch 99, batch 73/240:\tDiscriminator: real loss 0.1095750629901886, fake loss 0.24518217146396637\tGenerator: loss 13.76573371887207\n","Epoch 99, batch 74/240:\tDiscriminator: real loss 0.17606325447559357, fake loss 0.10110563039779663\tGenerator: loss 11.349495887756348\n","Epoch 99, batch 75/240:\tDiscriminator: real loss 0.09647638350725174, fake loss 0.20741194486618042\tGenerator: loss 9.019179344177246\n","Epoch 99, batch 76/240:\tDiscriminator: real loss 0.12485285848379135, fake loss 0.11775887757539749\tGenerator: loss 11.213390350341797\n","Epoch 99, batch 77/240:\tDiscriminator: real loss 0.19398851692676544, fake loss 0.12863054871559143\tGenerator: loss 10.4678316116333\n","Epoch 99, batch 78/240:\tDiscriminator: real loss 0.10955217480659485, fake loss 0.18588685989379883\tGenerator: loss 10.005622863769531\n","Epoch 99, batch 79/240:\tDiscriminator: real loss 0.15807880461215973, fake loss 0.1951591521501541\tGenerator: loss 9.753053665161133\n","Epoch 99, batch 80/240:\tDiscriminator: real loss 0.07417456060647964, fake loss 0.30452537536621094\tGenerator: loss 11.897961616516113\n","Epoch 99, batch 81/240:\tDiscriminator: real loss 0.14545220136642456, fake loss 0.09078805893659592\tGenerator: loss 12.909875869750977\n","Epoch 99, batch 82/240:\tDiscriminator: real loss 0.15660229325294495, fake loss 0.10188152641057968\tGenerator: loss 9.914590835571289\n","Epoch 99, batch 83/240:\tDiscriminator: real loss 0.10717151314020157, fake loss 0.34205877780914307\tGenerator: loss 11.962163925170898\n","Epoch 99, batch 84/240:\tDiscriminator: real loss 0.13598932325839996, fake loss 0.19167068600654602\tGenerator: loss 12.102500915527344\n","Epoch 99, batch 85/240:\tDiscriminator: real loss 0.12055964767932892, fake loss 0.14908559620380402\tGenerator: loss 12.854175567626953\n","Epoch 99, batch 86/240:\tDiscriminator: real loss 0.15152768790721893, fake loss 0.10957905650138855\tGenerator: loss 11.603899002075195\n","Epoch 99, batch 87/240:\tDiscriminator: real loss 0.15393351018428802, fake loss 0.0921752080321312\tGenerator: loss 11.665946006774902\n","Epoch 99, batch 88/240:\tDiscriminator: real loss 0.08543821424245834, fake loss 0.23834343254566193\tGenerator: loss 12.341194152832031\n","Epoch 99, batch 89/240:\tDiscriminator: real loss 0.12410442531108856, fake loss 0.17599962651729584\tGenerator: loss 12.540122985839844\n","Epoch 99, batch 90/240:\tDiscriminator: real loss 0.14272068440914154, fake loss 0.18287277221679688\tGenerator: loss 11.927865982055664\n","Epoch 99, batch 91/240:\tDiscriminator: real loss 0.23516425490379333, fake loss 0.1418958306312561\tGenerator: loss 11.284305572509766\n","Epoch 99, batch 92/240:\tDiscriminator: real loss 0.06122884154319763, fake loss 0.1408059448003769\tGenerator: loss 11.350619316101074\n","Epoch 99, batch 93/240:\tDiscriminator: real loss 0.13648945093154907, fake loss 0.10287781059741974\tGenerator: loss 11.949162483215332\n","Epoch 99, batch 94/240:\tDiscriminator: real loss 0.0323006734251976, fake loss 0.034459713846445084\tGenerator: loss 11.5956392288208\n","Epoch 99, batch 95/240:\tDiscriminator: real loss 0.06431883573532104, fake loss 0.2705720067024231\tGenerator: loss 14.75837516784668\n","Epoch 99, batch 96/240:\tDiscriminator: real loss 0.16696423292160034, fake loss 0.1955145001411438\tGenerator: loss 14.393409729003906\n","Epoch 99, batch 97/240:\tDiscriminator: real loss 0.15251803398132324, fake loss 0.28341057896614075\tGenerator: loss 13.162806510925293\n","Epoch 99, batch 98/240:\tDiscriminator: real loss 0.1825678050518036, fake loss 0.09053958207368851\tGenerator: loss 12.960679054260254\n","Epoch 99, batch 99/240:\tDiscriminator: real loss 0.1094907745718956, fake loss 0.1825718730688095\tGenerator: loss 13.291054725646973\n","Epoch 99, batch 100/240:\tDiscriminator: real loss 0.13964278995990753, fake loss 0.1887250393629074\tGenerator: loss 14.367990493774414\n","Epoch 99, batch 101/240:\tDiscriminator: real loss 0.08058179914951324, fake loss 0.2785634994506836\tGenerator: loss 14.295454978942871\n","Epoch 99, batch 102/240:\tDiscriminator: real loss 0.11102721840143204, fake loss 0.08448310941457748\tGenerator: loss 13.673315048217773\n","Epoch 99, batch 103/240:\tDiscriminator: real loss 0.16030368208885193, fake loss 0.16119913756847382\tGenerator: loss 13.281136512756348\n","Epoch 99, batch 104/240:\tDiscriminator: real loss 0.17720632255077362, fake loss 0.09250508248806\tGenerator: loss 15.559033393859863\n","Epoch 99, batch 105/240:\tDiscriminator: real loss 0.09476573765277863, fake loss 0.15855613350868225\tGenerator: loss 13.50223159790039\n","Epoch 99, batch 106/240:\tDiscriminator: real loss 0.061049629002809525, fake loss 0.28987109661102295\tGenerator: loss 14.523693084716797\n","Epoch 99, batch 107/240:\tDiscriminator: real loss 0.2569539248943329, fake loss 0.15987585484981537\tGenerator: loss 15.896203994750977\n","Epoch 99, batch 108/240:\tDiscriminator: real loss 0.07975400239229202, fake loss 0.18077290058135986\tGenerator: loss 16.020305633544922\n","Epoch 99, batch 109/240:\tDiscriminator: real loss 0.144474595785141, fake loss 0.18816512823104858\tGenerator: loss 17.280160903930664\n","Epoch 99, batch 110/240:\tDiscriminator: real loss 0.2233589142560959, fake loss 0.12353046238422394\tGenerator: loss 15.688725471496582\n","Epoch 99, batch 111/240:\tDiscriminator: real loss 0.1515999138355255, fake loss 0.11651962250471115\tGenerator: loss 13.881553649902344\n","Epoch 99, batch 112/240:\tDiscriminator: real loss 0.04309435933828354, fake loss 0.19695191085338593\tGenerator: loss 16.731014251708984\n","Epoch 99, batch 113/240:\tDiscriminator: real loss 0.06249696761369705, fake loss 0.32340237498283386\tGenerator: loss 16.28665542602539\n","Epoch 99, batch 114/240:\tDiscriminator: real loss 0.2431405484676361, fake loss 0.08108912408351898\tGenerator: loss 17.743488311767578\n","Epoch 99, batch 115/240:\tDiscriminator: real loss 0.06944143027067184, fake loss 0.11644461005926132\tGenerator: loss 16.227195739746094\n","Epoch 99, batch 116/240:\tDiscriminator: real loss 0.09490301460027695, fake loss 0.20581644773483276\tGenerator: loss 16.418848037719727\n","Epoch 99, batch 117/240:\tDiscriminator: real loss 0.09823444485664368, fake loss 0.07315903902053833\tGenerator: loss 15.863041877746582\n","Epoch 99, batch 118/240:\tDiscriminator: real loss 0.1504400372505188, fake loss 0.12256605178117752\tGenerator: loss 13.951163291931152\n","Epoch 99, batch 119/240:\tDiscriminator: real loss 0.2086029052734375, fake loss 0.16587543487548828\tGenerator: loss 14.145978927612305\n","Epoch 99, batch 120/240:\tDiscriminator: real loss 0.04335882142186165, fake loss 0.1896897554397583\tGenerator: loss 15.765893936157227\n","Epoch 99, batch 121/240:\tDiscriminator: real loss 0.13030625879764557, fake loss 0.19498895108699799\tGenerator: loss 16.15949058532715\n","Epoch 99, batch 122/240:\tDiscriminator: real loss 0.1532764881849289, fake loss 0.11034385859966278\tGenerator: loss 14.614985466003418\n","Epoch 99, batch 123/240:\tDiscriminator: real loss 0.12635549902915955, fake loss 0.14254340529441833\tGenerator: loss 12.634235382080078\n","Epoch 99, batch 124/240:\tDiscriminator: real loss 0.07985488325357437, fake loss 0.2200365662574768\tGenerator: loss 13.671107292175293\n","Epoch 99, batch 125/240:\tDiscriminator: real loss 0.11015136539936066, fake loss 0.0906454548239708\tGenerator: loss 12.014091491699219\n","Epoch 99, batch 126/240:\tDiscriminator: real loss 0.15455178916454315, fake loss 0.11827636510133743\tGenerator: loss 10.278432846069336\n","Epoch 99, batch 127/240:\tDiscriminator: real loss 0.06456974148750305, fake loss 0.07999002188444138\tGenerator: loss 9.135392189025879\n","Epoch 99, batch 128/240:\tDiscriminator: real loss 0.13401222229003906, fake loss 0.29443755745887756\tGenerator: loss 12.549555778503418\n","Epoch 99, batch 129/240:\tDiscriminator: real loss 0.10996969044208527, fake loss 0.17081688344478607\tGenerator: loss 12.957939147949219\n","Epoch 99, batch 130/240:\tDiscriminator: real loss 0.10096511989831924, fake loss 0.06482726335525513\tGenerator: loss 11.934767723083496\n","Epoch 99, batch 131/240:\tDiscriminator: real loss 0.10223037749528885, fake loss 0.21523891389369965\tGenerator: loss 10.855874061584473\n","Epoch 99, batch 132/240:\tDiscriminator: real loss 0.2026485651731491, fake loss 0.21636725962162018\tGenerator: loss 13.847107887268066\n","Epoch 99, batch 133/240:\tDiscriminator: real loss 0.06278810650110245, fake loss 0.21290260553359985\tGenerator: loss 15.659546852111816\n","Epoch 99, batch 134/240:\tDiscriminator: real loss 0.11938192695379257, fake loss 0.10424728691577911\tGenerator: loss 12.680342674255371\n","Epoch 99, batch 135/240:\tDiscriminator: real loss 0.10674326121807098, fake loss 0.05567776784300804\tGenerator: loss 11.476663589477539\n","Epoch 99, batch 136/240:\tDiscriminator: real loss 0.16592150926589966, fake loss 0.13571257889270782\tGenerator: loss 11.18153190612793\n","Epoch 99, batch 137/240:\tDiscriminator: real loss 0.11065329611301422, fake loss 0.17988456785678864\tGenerator: loss 13.286953926086426\n","Epoch 99, batch 138/240:\tDiscriminator: real loss 0.08773891627788544, fake loss 0.1415022611618042\tGenerator: loss 14.9494047164917\n","Epoch 99, batch 139/240:\tDiscriminator: real loss 0.06579490005970001, fake loss 0.07615101337432861\tGenerator: loss 14.854177474975586\n","Epoch 99, batch 140/240:\tDiscriminator: real loss 0.1212707906961441, fake loss 0.1419307440519333\tGenerator: loss 14.2379789352417\n","Epoch 99, batch 141/240:\tDiscriminator: real loss 0.13269351422786713, fake loss 0.23889169096946716\tGenerator: loss 15.439373016357422\n","Epoch 99, batch 142/240:\tDiscriminator: real loss 0.11739830672740936, fake loss 0.13478702306747437\tGenerator: loss 14.006566047668457\n","Epoch 99, batch 143/240:\tDiscriminator: real loss 0.09547050297260284, fake loss 0.29362279176712036\tGenerator: loss 17.042600631713867\n","Epoch 99, batch 144/240:\tDiscriminator: real loss 0.15258333086967468, fake loss 0.13430938124656677\tGenerator: loss 16.77165985107422\n","Epoch 99, batch 145/240:\tDiscriminator: real loss 0.24230629205703735, fake loss 0.115696020424366\tGenerator: loss 16.472736358642578\n","Epoch 99, batch 146/240:\tDiscriminator: real loss 0.0849330723285675, fake loss 0.09380772709846497\tGenerator: loss 15.761186599731445\n","Epoch 99, batch 147/240:\tDiscriminator: real loss 0.11610817909240723, fake loss 0.15202727913856506\tGenerator: loss 15.974204063415527\n","Epoch 99, batch 148/240:\tDiscriminator: real loss 0.1264696717262268, fake loss 0.13763673603534698\tGenerator: loss 15.871257781982422\n","Epoch 99, batch 149/240:\tDiscriminator: real loss 0.15465441346168518, fake loss 0.09094024449586868\tGenerator: loss 16.617572784423828\n","Epoch 99, batch 150/240:\tDiscriminator: real loss 0.0948440283536911, fake loss 0.23053386807441711\tGenerator: loss 15.773902893066406\n","Epoch 99, batch 151/240:\tDiscriminator: real loss 0.05240628123283386, fake loss 0.14623603224754333\tGenerator: loss 17.179903030395508\n","Epoch 99, batch 152/240:\tDiscriminator: real loss 0.17386329174041748, fake loss 0.10228561609983444\tGenerator: loss 15.543869972229004\n","Epoch 99, batch 153/240:\tDiscriminator: real loss 0.1126851737499237, fake loss 0.14837662875652313\tGenerator: loss 15.742927551269531\n","Epoch 99, batch 154/240:\tDiscriminator: real loss 0.05739063397049904, fake loss 0.1069900318980217\tGenerator: loss 14.910126686096191\n","Epoch 99, batch 155/240:\tDiscriminator: real loss 0.16688606142997742, fake loss 0.1735050231218338\tGenerator: loss 12.4757661819458\n","Epoch 99, batch 156/240:\tDiscriminator: real loss 0.09448973834514618, fake loss 0.2013060748577118\tGenerator: loss 14.043190002441406\n","Epoch 99, batch 157/240:\tDiscriminator: real loss 0.1977188140153885, fake loss 0.245015487074852\tGenerator: loss 15.311382293701172\n","Epoch 99, batch 158/240:\tDiscriminator: real loss 0.18590252101421356, fake loss 0.1440405696630478\tGenerator: loss 11.049283027648926\n","Epoch 99, batch 159/240:\tDiscriminator: real loss 0.18696613609790802, fake loss 0.15056809782981873\tGenerator: loss 9.102463722229004\n","Epoch 99, batch 160/240:\tDiscriminator: real loss 0.06636767834424973, fake loss 0.16477175056934357\tGenerator: loss 8.886124610900879\n","Epoch 99, batch 161/240:\tDiscriminator: real loss 0.09064033627510071, fake loss 0.1177581325173378\tGenerator: loss 9.42276382446289\n","Epoch 99, batch 162/240:\tDiscriminator: real loss 0.1508398950099945, fake loss 0.07908134162425995\tGenerator: loss 10.370183944702148\n","Epoch 99, batch 163/240:\tDiscriminator: real loss 0.0684874951839447, fake loss 0.14614452421665192\tGenerator: loss 11.017717361450195\n","Epoch 99, batch 164/240:\tDiscriminator: real loss 0.027898423373699188, fake loss 0.22839537262916565\tGenerator: loss 11.718785285949707\n","Epoch 99, batch 165/240:\tDiscriminator: real loss 0.07070867717266083, fake loss 0.17688784003257751\tGenerator: loss 12.077445983886719\n","Epoch 99, batch 166/240:\tDiscriminator: real loss 0.24955067038536072, fake loss 0.10843367874622345\tGenerator: loss 10.652604103088379\n","Epoch 99, batch 167/240:\tDiscriminator: real loss 0.16096606850624084, fake loss 0.10917823761701584\tGenerator: loss 11.143745422363281\n","Epoch 99, batch 168/240:\tDiscriminator: real loss 0.05657850578427315, fake loss 0.21180158853530884\tGenerator: loss 11.773240089416504\n","Epoch 99, batch 169/240:\tDiscriminator: real loss 0.09921535849571228, fake loss 0.21573907136917114\tGenerator: loss 12.673498153686523\n","Epoch 99, batch 170/240:\tDiscriminator: real loss 0.13810186088085175, fake loss 0.0966019257903099\tGenerator: loss 13.215437889099121\n","Epoch 99, batch 171/240:\tDiscriminator: real loss 0.09988383948802948, fake loss 0.19777166843414307\tGenerator: loss 12.218522071838379\n","Epoch 99, batch 172/240:\tDiscriminator: real loss 0.10415668785572052, fake loss 0.2040187120437622\tGenerator: loss 11.352459907531738\n","Epoch 99, batch 173/240:\tDiscriminator: real loss 0.1251949667930603, fake loss 0.1129739060997963\tGenerator: loss 13.384727478027344\n","Epoch 99, batch 174/240:\tDiscriminator: real loss 0.07662983983755112, fake loss 0.16639444231987\tGenerator: loss 14.829794883728027\n","Epoch 99, batch 175/240:\tDiscriminator: real loss 0.18148279190063477, fake loss 0.1640310138463974\tGenerator: loss 15.344213485717773\n","Epoch 99, batch 176/240:\tDiscriminator: real loss 0.07887758314609528, fake loss 0.11369733512401581\tGenerator: loss 15.099267959594727\n","Epoch 99, batch 177/240:\tDiscriminator: real loss 0.09300551563501358, fake loss 0.1581224799156189\tGenerator: loss 14.59849739074707\n","Epoch 99, batch 178/240:\tDiscriminator: real loss 0.10878665745258331, fake loss 0.14097604155540466\tGenerator: loss 14.02219009399414\n","Epoch 99, batch 179/240:\tDiscriminator: real loss 0.1317020058631897, fake loss 0.13983291387557983\tGenerator: loss 15.675675392150879\n","Epoch 99, batch 180/240:\tDiscriminator: real loss 0.1019308865070343, fake loss 0.15782120823860168\tGenerator: loss 14.957474708557129\n","Epoch 99, batch 181/240:\tDiscriminator: real loss 0.2417919933795929, fake loss 0.19104665517807007\tGenerator: loss 13.459036827087402\n","Epoch 99, batch 182/240:\tDiscriminator: real loss 0.08197223395109177, fake loss 0.16490241885185242\tGenerator: loss 15.415985107421875\n","Epoch 99, batch 183/240:\tDiscriminator: real loss 0.10227107256650925, fake loss 0.20360307395458221\tGenerator: loss 15.9672269821167\n","Epoch 99, batch 184/240:\tDiscriminator: real loss 0.1403357833623886, fake loss 0.22390669584274292\tGenerator: loss 13.731535911560059\n","Epoch 99, batch 185/240:\tDiscriminator: real loss 0.18124477565288544, fake loss 0.15673114359378815\tGenerator: loss 13.022106170654297\n","Epoch 99, batch 186/240:\tDiscriminator: real loss 0.1288415789604187, fake loss 0.12617143988609314\tGenerator: loss 13.595081329345703\n","Epoch 99, batch 187/240:\tDiscriminator: real loss 0.10706862807273865, fake loss 0.1652369350194931\tGenerator: loss 13.551100730895996\n","Epoch 99, batch 188/240:\tDiscriminator: real loss 0.15442243218421936, fake loss 0.11395525932312012\tGenerator: loss 13.697060585021973\n","Epoch 99, batch 189/240:\tDiscriminator: real loss 0.16730491816997528, fake loss 0.17344258725643158\tGenerator: loss 15.253686904907227\n","Epoch 99, batch 190/240:\tDiscriminator: real loss 0.11421771347522736, fake loss 0.27555492520332336\tGenerator: loss 14.651141166687012\n","Epoch 99, batch 191/240:\tDiscriminator: real loss 0.11972471326589584, fake loss 0.20722907781600952\tGenerator: loss 13.488041877746582\n","Epoch 99, batch 192/240:\tDiscriminator: real loss 0.19844180345535278, fake loss 0.10305748879909515\tGenerator: loss 14.642533302307129\n","Epoch 99, batch 193/240:\tDiscriminator: real loss 0.267732709646225, fake loss 0.2354995310306549\tGenerator: loss 12.712793350219727\n","Epoch 99, batch 194/240:\tDiscriminator: real loss 0.07707752287387848, fake loss 0.23475904762744904\tGenerator: loss 12.120126724243164\n","Epoch 99, batch 195/240:\tDiscriminator: real loss 0.08838628977537155, fake loss 0.1755315661430359\tGenerator: loss 11.836182594299316\n","Epoch 99, batch 196/240:\tDiscriminator: real loss 0.09231057018041611, fake loss 0.07102309912443161\tGenerator: loss 11.537712097167969\n","Epoch 99, batch 197/240:\tDiscriminator: real loss 0.162696972489357, fake loss 0.11603964120149612\tGenerator: loss 11.074467658996582\n","Epoch 99, batch 198/240:\tDiscriminator: real loss 0.1795622706413269, fake loss 0.2870154082775116\tGenerator: loss 12.402088165283203\n","Epoch 99, batch 199/240:\tDiscriminator: real loss 0.0547524131834507, fake loss 0.24666030704975128\tGenerator: loss 15.287500381469727\n","Epoch 99, batch 200/240:\tDiscriminator: real loss 0.09735532850027084, fake loss 0.18037468194961548\tGenerator: loss 16.508216857910156\n","Epoch 99, batch 201/240:\tDiscriminator: real loss 0.26264312863349915, fake loss 0.11370737105607986\tGenerator: loss 13.599505424499512\n","Epoch 99, batch 202/240:\tDiscriminator: real loss 0.07363659888505936, fake loss 0.2199292927980423\tGenerator: loss 12.341506004333496\n","Epoch 99, batch 203/240:\tDiscriminator: real loss 0.1529952436685562, fake loss 0.15712794661521912\tGenerator: loss 12.030959129333496\n","Epoch 99, batch 204/240:\tDiscriminator: real loss 0.07031499594449997, fake loss 0.12653714418411255\tGenerator: loss 12.459329605102539\n","Epoch 99, batch 205/240:\tDiscriminator: real loss 0.11113225668668747, fake loss 0.11148790270090103\tGenerator: loss 12.577506065368652\n","Epoch 99, batch 206/240:\tDiscriminator: real loss 0.11519673466682434, fake loss 0.2382320612668991\tGenerator: loss 12.944549560546875\n","Epoch 99, batch 207/240:\tDiscriminator: real loss 0.18331950902938843, fake loss 0.10370966047048569\tGenerator: loss 13.869793891906738\n","Epoch 99, batch 208/240:\tDiscriminator: real loss 0.09209530055522919, fake loss 0.1782039850950241\tGenerator: loss 13.773900032043457\n","Epoch 99, batch 209/240:\tDiscriminator: real loss 0.062013138085603714, fake loss 0.13594688475131989\tGenerator: loss 14.624222755432129\n","Epoch 99, batch 210/240:\tDiscriminator: real loss 0.1633661836385727, fake loss 0.12417163699865341\tGenerator: loss 12.61307144165039\n","Epoch 99, batch 211/240:\tDiscriminator: real loss 0.14934700727462769, fake loss 0.15683192014694214\tGenerator: loss 11.380932807922363\n","Epoch 99, batch 212/240:\tDiscriminator: real loss 0.08014386892318726, fake loss 0.20922954380512238\tGenerator: loss 9.80184555053711\n","Epoch 99, batch 213/240:\tDiscriminator: real loss 0.18884390592575073, fake loss 0.1498289704322815\tGenerator: loss 10.0754976272583\n","Epoch 99, batch 214/240:\tDiscriminator: real loss 0.10087347030639648, fake loss 0.15281836688518524\tGenerator: loss 9.772175788879395\n","Epoch 99, batch 215/240:\tDiscriminator: real loss 0.10351958870887756, fake loss 0.08120764046907425\tGenerator: loss 10.33305549621582\n","Epoch 99, batch 216/240:\tDiscriminator: real loss 0.1043994128704071, fake loss 0.17887701094150543\tGenerator: loss 10.169633865356445\n","Epoch 99, batch 217/240:\tDiscriminator: real loss 0.06005246192216873, fake loss 0.15080511569976807\tGenerator: loss 10.547259330749512\n","Epoch 99, batch 218/240:\tDiscriminator: real loss 0.24051494896411896, fake loss 0.19778020679950714\tGenerator: loss 12.337685585021973\n","Epoch 99, batch 219/240:\tDiscriminator: real loss 0.09484484046697617, fake loss 0.2018282115459442\tGenerator: loss 11.839122772216797\n","Epoch 99, batch 220/240:\tDiscriminator: real loss 0.06127556785941124, fake loss 0.1581863909959793\tGenerator: loss 11.537945747375488\n","Epoch 99, batch 221/240:\tDiscriminator: real loss 0.1523154228925705, fake loss 0.21957221627235413\tGenerator: loss 10.88431167602539\n","Epoch 99, batch 222/240:\tDiscriminator: real loss 0.20505103468894958, fake loss 0.23104189336299896\tGenerator: loss 9.518070220947266\n","Epoch 99, batch 223/240:\tDiscriminator: real loss 0.10042273253202438, fake loss 0.28897830843925476\tGenerator: loss 10.975005149841309\n","Epoch 99, batch 224/240:\tDiscriminator: real loss 0.09709776937961578, fake loss 0.08228650689125061\tGenerator: loss 10.776264190673828\n","Epoch 99, batch 225/240:\tDiscriminator: real loss 0.20080119371414185, fake loss 0.10744311660528183\tGenerator: loss 11.3362455368042\n","Epoch 99, batch 226/240:\tDiscriminator: real loss 0.1069941595196724, fake loss 0.2155754715204239\tGenerator: loss 10.869847297668457\n","Epoch 99, batch 227/240:\tDiscriminator: real loss 0.09763079881668091, fake loss 0.19502726197242737\tGenerator: loss 10.140301704406738\n","Epoch 99, batch 228/240:\tDiscriminator: real loss 0.1601770520210266, fake loss 0.15050910413265228\tGenerator: loss 11.742863655090332\n","Epoch 99, batch 229/240:\tDiscriminator: real loss 0.09674828499555588, fake loss 0.08473747223615646\tGenerator: loss 11.613852500915527\n","Epoch 99, batch 230/240:\tDiscriminator: real loss 0.07205146551132202, fake loss 0.43107473850250244\tGenerator: loss 13.482807159423828\n","Epoch 99, batch 231/240:\tDiscriminator: real loss 0.10732236504554749, fake loss 0.10935048013925552\tGenerator: loss 15.082952499389648\n","Epoch 99, batch 232/240:\tDiscriminator: real loss 0.23941367864608765, fake loss 0.11523731052875519\tGenerator: loss 14.085134506225586\n","Epoch 99, batch 233/240:\tDiscriminator: real loss 0.12642927467823029, fake loss 0.14494818449020386\tGenerator: loss 14.69601821899414\n","Epoch 99, batch 234/240:\tDiscriminator: real loss 0.10477163642644882, fake loss 0.15907709300518036\tGenerator: loss 14.580256462097168\n","Epoch 99, batch 235/240:\tDiscriminator: real loss 0.05530134588479996, fake loss 0.2661019265651703\tGenerator: loss 16.065425872802734\n","Epoch 99, batch 236/240:\tDiscriminator: real loss 0.12493495643138885, fake loss 0.12347962707281113\tGenerator: loss 13.365035057067871\n","Epoch 99, batch 237/240:\tDiscriminator: real loss 0.10516996681690216, fake loss 0.15726323425769806\tGenerator: loss 12.76228141784668\n","Epoch 99, batch 238/240:\tDiscriminator: real loss 0.13394765555858612, fake loss 0.11880487203598022\tGenerator: loss 15.331185340881348\n","Epoch 99, batch 239/240:\tDiscriminator: real loss 0.05805700644850731, fake loss 0.21695812046527863\tGenerator: loss 15.734850883483887\n","Epoch 99, batch 240/240:\tDiscriminator: real loss 0.11065173894166946, fake loss 0.08063334226608276\tGenerator: loss 12.388890266418457\n","Epoch 100, batch 1/240:\tDiscriminator: real loss 0.22716820240020752, fake loss 0.07302651554346085\tGenerator: loss 11.333671569824219\n","Epoch 100, batch 2/240:\tDiscriminator: real loss 0.04291834309697151, fake loss 0.21389298141002655\tGenerator: loss 9.892477035522461\n","Epoch 100, batch 3/240:\tDiscriminator: real loss 0.08330920338630676, fake loss 0.21311090886592865\tGenerator: loss 10.18894100189209\n","Epoch 100, batch 4/240:\tDiscriminator: real loss 0.21434246003627777, fake loss 0.13940227031707764\tGenerator: loss 12.071457862854004\n","Epoch 100, batch 5/240:\tDiscriminator: real loss 0.07993482798337936, fake loss 0.16734722256660461\tGenerator: loss 11.81200885772705\n","Epoch 100, batch 6/240:\tDiscriminator: real loss 0.08214930444955826, fake loss 0.22541503608226776\tGenerator: loss 10.742864608764648\n","Epoch 100, batch 7/240:\tDiscriminator: real loss 0.11099269241094589, fake loss 0.21076428890228271\tGenerator: loss 11.497653007507324\n","Epoch 100, batch 8/240:\tDiscriminator: real loss 0.14800424873828888, fake loss 0.14556027948856354\tGenerator: loss 11.811817169189453\n","Epoch 100, batch 9/240:\tDiscriminator: real loss 0.15149472653865814, fake loss 0.12281610816717148\tGenerator: loss 13.929119110107422\n","Epoch 100, batch 10/240:\tDiscriminator: real loss 0.10217517614364624, fake loss 0.08093569427728653\tGenerator: loss 15.790780067443848\n","Epoch 100, batch 11/240:\tDiscriminator: real loss 0.1059127151966095, fake loss 0.25162020325660706\tGenerator: loss 17.124801635742188\n","Epoch 100, batch 12/240:\tDiscriminator: real loss 0.24267995357513428, fake loss 0.13441969454288483\tGenerator: loss 12.813543319702148\n","Epoch 100, batch 13/240:\tDiscriminator: real loss 0.049188923090696335, fake loss 0.23636172711849213\tGenerator: loss 15.225637435913086\n","Epoch 100, batch 14/240:\tDiscriminator: real loss 0.07819849997758865, fake loss 0.10817821323871613\tGenerator: loss 16.751108169555664\n","Epoch 100, batch 15/240:\tDiscriminator: real loss 0.14867635071277618, fake loss 0.043331678956747055\tGenerator: loss 15.786260604858398\n","Epoch 100, batch 16/240:\tDiscriminator: real loss 0.11983911693096161, fake loss 0.24122880399227142\tGenerator: loss 15.736331939697266\n","Epoch 100, batch 17/240:\tDiscriminator: real loss 0.13435722887516022, fake loss 0.15732553601264954\tGenerator: loss 13.551556587219238\n","Epoch 100, batch 18/240:\tDiscriminator: real loss 0.08143720030784607, fake loss 0.22592954337596893\tGenerator: loss 14.405752182006836\n","Epoch 100, batch 19/240:\tDiscriminator: real loss 0.07249253988265991, fake loss 0.13148771226406097\tGenerator: loss 15.403115272521973\n","Epoch 100, batch 20/240:\tDiscriminator: real loss 0.14756187796592712, fake loss 0.23837213218212128\tGenerator: loss 13.243572235107422\n","Epoch 100, batch 21/240:\tDiscriminator: real loss 0.20496785640716553, fake loss 0.1796526461839676\tGenerator: loss 13.007555961608887\n","Epoch 100, batch 22/240:\tDiscriminator: real loss 0.10254182666540146, fake loss 0.09745825827121735\tGenerator: loss 13.834173202514648\n","Epoch 100, batch 23/240:\tDiscriminator: real loss 0.09789535403251648, fake loss 0.18561261892318726\tGenerator: loss 13.636707305908203\n","Epoch 100, batch 24/240:\tDiscriminator: real loss 0.13123324513435364, fake loss 0.23609234392642975\tGenerator: loss 14.162036895751953\n","Epoch 100, batch 25/240:\tDiscriminator: real loss 0.08586855977773666, fake loss 0.10599204897880554\tGenerator: loss 15.478109359741211\n","Epoch 100, batch 26/240:\tDiscriminator: real loss 0.10240719467401505, fake loss 0.05924645811319351\tGenerator: loss 14.22062873840332\n","Epoch 100, batch 27/240:\tDiscriminator: real loss 0.08426299691200256, fake loss 0.10381763428449631\tGenerator: loss 14.155184745788574\n","Epoch 100, batch 28/240:\tDiscriminator: real loss 0.07114820182323456, fake loss 0.038050804287195206\tGenerator: loss 14.320221900939941\n","Epoch 100, batch 29/240:\tDiscriminator: real loss 0.04713769257068634, fake loss 0.1717587262392044\tGenerator: loss 15.996888160705566\n","Epoch 100, batch 30/240:\tDiscriminator: real loss 0.07569969445466995, fake loss 0.13163991272449493\tGenerator: loss 16.285825729370117\n","Epoch 100, batch 31/240:\tDiscriminator: real loss 0.11465764790773392, fake loss 0.17712777853012085\tGenerator: loss 17.349946975708008\n","Epoch 100, batch 32/240:\tDiscriminator: real loss 0.09832291305065155, fake loss 0.13151781260967255\tGenerator: loss 16.484609603881836\n","Epoch 100, batch 33/240:\tDiscriminator: real loss 0.07975824177265167, fake loss 0.1664004772901535\tGenerator: loss 17.086687088012695\n","Epoch 100, batch 34/240:\tDiscriminator: real loss 0.18819190561771393, fake loss 0.07629858702421188\tGenerator: loss 15.819409370422363\n","Epoch 100, batch 35/240:\tDiscriminator: real loss 0.14733409881591797, fake loss 0.2598475515842438\tGenerator: loss 16.81006622314453\n","Epoch 100, batch 36/240:\tDiscriminator: real loss 0.1405484676361084, fake loss 0.09941566735506058\tGenerator: loss 16.917123794555664\n","Epoch 100, batch 37/240:\tDiscriminator: real loss 0.13120350241661072, fake loss 0.1935712844133377\tGenerator: loss 16.712871551513672\n","Epoch 100, batch 38/240:\tDiscriminator: real loss 0.07355285435914993, fake loss 0.09702213108539581\tGenerator: loss 17.229595184326172\n","Epoch 100, batch 39/240:\tDiscriminator: real loss 0.10397198796272278, fake loss 0.21418987214565277\tGenerator: loss 16.539522171020508\n","Epoch 100, batch 40/240:\tDiscriminator: real loss 0.12072831392288208, fake loss 0.10806678980588913\tGenerator: loss 18.07010269165039\n","Epoch 100, batch 41/240:\tDiscriminator: real loss 0.05261797457933426, fake loss 0.12460314482450485\tGenerator: loss 16.749061584472656\n","Epoch 100, batch 42/240:\tDiscriminator: real loss 0.09565164893865585, fake loss 0.07147403806447983\tGenerator: loss 17.515836715698242\n","Epoch 100, batch 43/240:\tDiscriminator: real loss 0.06889882683753967, fake loss 0.163568377494812\tGenerator: loss 20.20937156677246\n","Epoch 100, batch 44/240:\tDiscriminator: real loss 0.07207594066858292, fake loss 0.1252586841583252\tGenerator: loss 19.326984405517578\n","Epoch 100, batch 45/240:\tDiscriminator: real loss 0.11148639768362045, fake loss 0.05407312512397766\tGenerator: loss 16.48900604248047\n","Epoch 100, batch 46/240:\tDiscriminator: real loss 0.16007877886295319, fake loss 0.19958552718162537\tGenerator: loss 16.880352020263672\n","Epoch 100, batch 47/240:\tDiscriminator: real loss 0.06269659847021103, fake loss 0.1064789742231369\tGenerator: loss 16.6817684173584\n","Epoch 100, batch 48/240:\tDiscriminator: real loss 0.1985868662595749, fake loss 0.1514524221420288\tGenerator: loss 16.72822380065918\n","Epoch 100, batch 49/240:\tDiscriminator: real loss 0.08966711908578873, fake loss 0.17030473053455353\tGenerator: loss 19.043977737426758\n","Epoch 100, batch 50/240:\tDiscriminator: real loss 0.12443678081035614, fake loss 0.07681424170732498\tGenerator: loss 16.165111541748047\n","Epoch 100, batch 51/240:\tDiscriminator: real loss 0.05642510950565338, fake loss 0.2568962872028351\tGenerator: loss 18.399951934814453\n","Epoch 100, batch 52/240:\tDiscriminator: real loss 0.07391271740198135, fake loss 0.11625391244888306\tGenerator: loss 17.871652603149414\n","Epoch 100, batch 53/240:\tDiscriminator: real loss 0.10480087250471115, fake loss 0.09229427576065063\tGenerator: loss 17.911964416503906\n","Epoch 100, batch 54/240:\tDiscriminator: real loss 0.19950687885284424, fake loss 0.11666066944599152\tGenerator: loss 16.788461685180664\n","Epoch 100, batch 55/240:\tDiscriminator: real loss 0.10916148126125336, fake loss 0.444306880235672\tGenerator: loss 15.883845329284668\n","Epoch 100, batch 56/240:\tDiscriminator: real loss 0.23810146749019623, fake loss 0.1888653188943863\tGenerator: loss 17.265722274780273\n","Epoch 100, batch 57/240:\tDiscriminator: real loss 0.1107063889503479, fake loss 0.05194704979658127\tGenerator: loss 17.141887664794922\n","Epoch 100, batch 58/240:\tDiscriminator: real loss 0.1111014112830162, fake loss 0.22608046233654022\tGenerator: loss 15.301004409790039\n","Epoch 100, batch 59/240:\tDiscriminator: real loss 0.11037807166576385, fake loss 0.09760941565036774\tGenerator: loss 17.2115478515625\n","Epoch 100, batch 60/240:\tDiscriminator: real loss 0.14218400418758392, fake loss 0.12375310063362122\tGenerator: loss 17.604825973510742\n","Epoch 100, batch 61/240:\tDiscriminator: real loss 0.0789223164319992, fake loss 0.20694288611412048\tGenerator: loss 17.07931900024414\n","Epoch 100, batch 62/240:\tDiscriminator: real loss 0.0930982232093811, fake loss 0.1014835387468338\tGenerator: loss 18.156465530395508\n","Epoch 100, batch 63/240:\tDiscriminator: real loss 0.1449539065361023, fake loss 0.17597316205501556\tGenerator: loss 16.703594207763672\n","Epoch 100, batch 64/240:\tDiscriminator: real loss 0.10133522748947144, fake loss 0.1848604828119278\tGenerator: loss 16.198434829711914\n","Epoch 100, batch 65/240:\tDiscriminator: real loss 0.11498648673295975, fake loss 0.2091657966375351\tGenerator: loss 19.140092849731445\n","Epoch 100, batch 66/240:\tDiscriminator: real loss 0.13518209755420685, fake loss 0.1899251937866211\tGenerator: loss 20.373794555664062\n","Epoch 100, batch 67/240:\tDiscriminator: real loss 0.20070946216583252, fake loss 0.19386719167232513\tGenerator: loss 18.183637619018555\n","Epoch 100, batch 68/240:\tDiscriminator: real loss 0.10255349427461624, fake loss 0.14201480150222778\tGenerator: loss 14.333263397216797\n","Epoch 100, batch 69/240:\tDiscriminator: real loss 0.0734596997499466, fake loss 0.114738829433918\tGenerator: loss 12.446930885314941\n","Epoch 100, batch 70/240:\tDiscriminator: real loss 0.17538589239120483, fake loss 0.20747192203998566\tGenerator: loss 13.926002502441406\n","Epoch 100, batch 71/240:\tDiscriminator: real loss 0.14166711270809174, fake loss 0.18168029189109802\tGenerator: loss 14.101702690124512\n","Epoch 100, batch 72/240:\tDiscriminator: real loss 0.220859095454216, fake loss 0.13435567915439606\tGenerator: loss 12.89912223815918\n","Epoch 100, batch 73/240:\tDiscriminator: real loss 0.11370819807052612, fake loss 0.15658390522003174\tGenerator: loss 12.599456787109375\n","Epoch 100, batch 74/240:\tDiscriminator: real loss 0.055742062628269196, fake loss 0.11224287003278732\tGenerator: loss 14.1771821975708\n","Epoch 100, batch 75/240:\tDiscriminator: real loss 0.10697484761476517, fake loss 0.17528948187828064\tGenerator: loss 13.982321739196777\n","Epoch 100, batch 76/240:\tDiscriminator: real loss 0.13899579644203186, fake loss 0.10677623748779297\tGenerator: loss 16.312223434448242\n","Epoch 100, batch 77/240:\tDiscriminator: real loss 0.12880565226078033, fake loss 0.158065065741539\tGenerator: loss 16.367311477661133\n","Epoch 100, batch 78/240:\tDiscriminator: real loss 0.07810583710670471, fake loss 0.20517539978027344\tGenerator: loss 18.030210494995117\n","Epoch 100, batch 79/240:\tDiscriminator: real loss 0.07504937052726746, fake loss 0.23412567377090454\tGenerator: loss 18.947093963623047\n","Epoch 100, batch 80/240:\tDiscriminator: real loss 0.24559564888477325, fake loss 0.12220969051122665\tGenerator: loss 17.019559860229492\n","Epoch 100, batch 81/240:\tDiscriminator: real loss 0.16266225278377533, fake loss 0.08842489123344421\tGenerator: loss 15.255278587341309\n","Epoch 100, batch 82/240:\tDiscriminator: real loss 0.09076976776123047, fake loss 0.08987896144390106\tGenerator: loss 14.783899307250977\n","Epoch 100, batch 83/240:\tDiscriminator: real loss 0.05929180979728699, fake loss 0.2893665134906769\tGenerator: loss 17.16666030883789\n","Epoch 100, batch 84/240:\tDiscriminator: real loss 0.12488958984613419, fake loss 0.22413520514965057\tGenerator: loss 18.545730590820312\n","Epoch 100, batch 85/240:\tDiscriminator: real loss 0.12746372818946838, fake loss 0.06656984984874725\tGenerator: loss 18.47998809814453\n","Epoch 100, batch 86/240:\tDiscriminator: real loss 0.21706165373325348, fake loss 0.1561208963394165\tGenerator: loss 14.044103622436523\n","Epoch 100, batch 87/240:\tDiscriminator: real loss 0.05812789127230644, fake loss 0.13129086792469025\tGenerator: loss 14.612751007080078\n","Epoch 100, batch 88/240:\tDiscriminator: real loss 0.15547865629196167, fake loss 0.2331068217754364\tGenerator: loss 15.523067474365234\n","Epoch 100, batch 89/240:\tDiscriminator: real loss 0.10583179444074631, fake loss 0.17764586210250854\tGenerator: loss 15.968040466308594\n","Epoch 100, batch 90/240:\tDiscriminator: real loss 0.13429608941078186, fake loss 0.15448080003261566\tGenerator: loss 16.795412063598633\n","Epoch 100, batch 91/240:\tDiscriminator: real loss 0.09107188135385513, fake loss 0.2782731354236603\tGenerator: loss 18.914936065673828\n","Epoch 100, batch 92/240:\tDiscriminator: real loss 0.1999705731868744, fake loss 0.07110521197319031\tGenerator: loss 20.835830688476562\n","Epoch 100, batch 93/240:\tDiscriminator: real loss 0.07665269821882248, fake loss 0.1535744071006775\tGenerator: loss 19.880149841308594\n","Epoch 100, batch 94/240:\tDiscriminator: real loss 0.13241519033908844, fake loss 0.23233208060264587\tGenerator: loss 19.093313217163086\n","Epoch 100, batch 95/240:\tDiscriminator: real loss 0.23224444687366486, fake loss 0.10330649465322495\tGenerator: loss 18.135347366333008\n","Epoch 100, batch 96/240:\tDiscriminator: real loss 0.09749186784029007, fake loss 0.32786625623703003\tGenerator: loss 17.190753936767578\n","Epoch 100, batch 97/240:\tDiscriminator: real loss 0.1585652381181717, fake loss 0.16094644367694855\tGenerator: loss 17.407594680786133\n","Epoch 100, batch 98/240:\tDiscriminator: real loss 0.11166040599346161, fake loss 0.12406492233276367\tGenerator: loss 18.376861572265625\n","Epoch 100, batch 99/240:\tDiscriminator: real loss 0.15462486445903778, fake loss 0.14477379620075226\tGenerator: loss 16.7392520904541\n","Epoch 100, batch 100/240:\tDiscriminator: real loss 0.09190770983695984, fake loss 0.11991892755031586\tGenerator: loss 16.524452209472656\n","Epoch 100, batch 101/240:\tDiscriminator: real loss 0.1138777807354927, fake loss 0.15430408716201782\tGenerator: loss 17.93761444091797\n","Epoch 100, batch 102/240:\tDiscriminator: real loss 0.07783626765012741, fake loss 0.09653270989656448\tGenerator: loss 17.950345993041992\n","Epoch 100, batch 103/240:\tDiscriminator: real loss 0.0889403223991394, fake loss 0.17536413669586182\tGenerator: loss 16.027610778808594\n","Epoch 100, batch 104/240:\tDiscriminator: real loss 0.10409665107727051, fake loss 0.2063913345336914\tGenerator: loss 17.099870681762695\n","Epoch 100, batch 105/240:\tDiscriminator: real loss 0.1237110123038292, fake loss 0.08541515469551086\tGenerator: loss 16.370332717895508\n","Epoch 100, batch 106/240:\tDiscriminator: real loss 0.12293285131454468, fake loss 0.1516544371843338\tGenerator: loss 14.007984161376953\n","Epoch 100, batch 107/240:\tDiscriminator: real loss 0.1218014732003212, fake loss 0.1083972379565239\tGenerator: loss 13.509634971618652\n","Epoch 100, batch 108/240:\tDiscriminator: real loss 0.11034057289361954, fake loss 0.16308940947055817\tGenerator: loss 14.536834716796875\n","Epoch 100, batch 109/240:\tDiscriminator: real loss 0.09455440193414688, fake loss 0.15919159352779388\tGenerator: loss 14.227148056030273\n","Epoch 100, batch 110/240:\tDiscriminator: real loss 0.0821218490600586, fake loss 0.11732364445924759\tGenerator: loss 14.206269264221191\n","Epoch 100, batch 111/240:\tDiscriminator: real loss 0.12354404479265213, fake loss 0.15222735702991486\tGenerator: loss 16.1486759185791\n","Epoch 100, batch 112/240:\tDiscriminator: real loss 0.06708232313394547, fake loss 0.16677799820899963\tGenerator: loss 19.3259220123291\n","Epoch 100, batch 113/240:\tDiscriminator: real loss 0.19409961998462677, fake loss 0.11380092799663544\tGenerator: loss 16.42666244506836\n","Epoch 100, batch 114/240:\tDiscriminator: real loss 0.11893133074045181, fake loss 0.3676697015762329\tGenerator: loss 17.721965789794922\n","Epoch 100, batch 115/240:\tDiscriminator: real loss 0.1567085087299347, fake loss 0.11660919338464737\tGenerator: loss 18.679622650146484\n","Epoch 100, batch 116/240:\tDiscriminator: real loss 0.06530754268169403, fake loss 0.11439242959022522\tGenerator: loss 17.298904418945312\n","Epoch 100, batch 117/240:\tDiscriminator: real loss 0.1986970156431198, fake loss 0.15420424938201904\tGenerator: loss 16.889558792114258\n","Epoch 100, batch 118/240:\tDiscriminator: real loss 0.1325780153274536, fake loss 0.1504611074924469\tGenerator: loss 17.170413970947266\n","Epoch 100, batch 119/240:\tDiscriminator: real loss 0.09328426420688629, fake loss 0.14036940038204193\tGenerator: loss 16.130767822265625\n","Epoch 100, batch 120/240:\tDiscriminator: real loss 0.16055627167224884, fake loss 0.1076042428612709\tGenerator: loss 17.45871353149414\n","Epoch 100, batch 121/240:\tDiscriminator: real loss 0.05118820071220398, fake loss 0.19492290914058685\tGenerator: loss 17.820228576660156\n","Epoch 100, batch 122/240:\tDiscriminator: real loss 0.11290954798460007, fake loss 0.07642292231321335\tGenerator: loss 17.44174575805664\n","Epoch 100, batch 123/240:\tDiscriminator: real loss 0.08275378495454788, fake loss 0.1730654388666153\tGenerator: loss 17.423429489135742\n","Epoch 100, batch 124/240:\tDiscriminator: real loss 0.08704838901758194, fake loss 0.20529936254024506\tGenerator: loss 17.998044967651367\n","Epoch 100, batch 125/240:\tDiscriminator: real loss 0.10754421353340149, fake loss 0.2039567232131958\tGenerator: loss 19.418983459472656\n","Epoch 100, batch 126/240:\tDiscriminator: real loss 0.16116710007190704, fake loss 0.04599865525960922\tGenerator: loss 20.650558471679688\n","Epoch 100, batch 127/240:\tDiscriminator: real loss 0.10269645601511002, fake loss 0.18765097856521606\tGenerator: loss 19.35711669921875\n","Epoch 100, batch 128/240:\tDiscriminator: real loss 0.19702644646167755, fake loss 0.053579386323690414\tGenerator: loss 20.250761032104492\n","Epoch 100, batch 129/240:\tDiscriminator: real loss 0.0516417995095253, fake loss 0.22696296870708466\tGenerator: loss 19.164588928222656\n","Epoch 100, batch 130/240:\tDiscriminator: real loss 0.03782099112868309, fake loss 0.12946517765522003\tGenerator: loss 22.264097213745117\n","Epoch 100, batch 131/240:\tDiscriminator: real loss 0.1801479011774063, fake loss 0.13470178842544556\tGenerator: loss 22.303102493286133\n","Epoch 100, batch 132/240:\tDiscriminator: real loss 0.15362542867660522, fake loss 0.08960703760385513\tGenerator: loss 20.646425247192383\n","Epoch 100, batch 133/240:\tDiscriminator: real loss 0.08733609318733215, fake loss 0.12553104758262634\tGenerator: loss 19.414670944213867\n","Epoch 100, batch 134/240:\tDiscriminator: real loss 0.1300564706325531, fake loss 0.1621607542037964\tGenerator: loss 16.383472442626953\n","Epoch 100, batch 135/240:\tDiscriminator: real loss 0.06016121432185173, fake loss 0.20097751915454865\tGenerator: loss 18.275161743164062\n","Epoch 100, batch 136/240:\tDiscriminator: real loss 0.1321631819009781, fake loss 0.05290228873491287\tGenerator: loss 15.292890548706055\n","Epoch 100, batch 137/240:\tDiscriminator: real loss 0.14174850285053253, fake loss 0.1500585675239563\tGenerator: loss 16.455646514892578\n","Epoch 100, batch 138/240:\tDiscriminator: real loss 0.19268916547298431, fake loss 0.051056668162345886\tGenerator: loss 13.266539573669434\n","Epoch 100, batch 139/240:\tDiscriminator: real loss 0.06296345591545105, fake loss 0.2914217710494995\tGenerator: loss 15.74060344696045\n","Epoch 100, batch 140/240:\tDiscriminator: real loss 0.05203821137547493, fake loss 0.13557277619838715\tGenerator: loss 17.53437614440918\n","Epoch 100, batch 141/240:\tDiscriminator: real loss 0.14850398898124695, fake loss 0.11018453538417816\tGenerator: loss 18.002290725708008\n","Epoch 100, batch 142/240:\tDiscriminator: real loss 0.09925577044487, fake loss 0.3126642107963562\tGenerator: loss 18.14284896850586\n","Epoch 100, batch 143/240:\tDiscriminator: real loss 0.20066097378730774, fake loss 0.09614551812410355\tGenerator: loss 14.617788314819336\n","Epoch 100, batch 144/240:\tDiscriminator: real loss 0.1465986669063568, fake loss 0.17205147445201874\tGenerator: loss 14.377477645874023\n","Epoch 100, batch 145/240:\tDiscriminator: real loss 0.1540658324956894, fake loss 0.17908839881420135\tGenerator: loss 15.339882850646973\n","Epoch 100, batch 146/240:\tDiscriminator: real loss 0.08137579262256622, fake loss 0.16773436963558197\tGenerator: loss 16.13928985595703\n","Epoch 100, batch 147/240:\tDiscriminator: real loss 0.10036230087280273, fake loss 0.13444006443023682\tGenerator: loss 13.795453071594238\n","Epoch 100, batch 148/240:\tDiscriminator: real loss 0.06800634413957596, fake loss 0.056095190346241\tGenerator: loss 12.956194877624512\n","Epoch 100, batch 149/240:\tDiscriminator: real loss 0.14868181943893433, fake loss 0.16710452735424042\tGenerator: loss 13.494851112365723\n","Epoch 100, batch 150/240:\tDiscriminator: real loss 0.14719824492931366, fake loss 0.1117832213640213\tGenerator: loss 13.712837219238281\n","Epoch 100, batch 151/240:\tDiscriminator: real loss 0.08048435300588608, fake loss 0.19761084020137787\tGenerator: loss 16.01559829711914\n","Epoch 100, batch 152/240:\tDiscriminator: real loss 0.2658272087574005, fake loss 0.16744999587535858\tGenerator: loss 11.974339485168457\n","Epoch 100, batch 153/240:\tDiscriminator: real loss 0.16993330419063568, fake loss 0.25078386068344116\tGenerator: loss 10.551307678222656\n","Epoch 100, batch 154/240:\tDiscriminator: real loss 0.08401267230510712, fake loss 0.1659831553697586\tGenerator: loss 13.109195709228516\n","Epoch 100, batch 155/240:\tDiscriminator: real loss 0.12712784111499786, fake loss 0.13177894055843353\tGenerator: loss 12.320992469787598\n","Epoch 100, batch 156/240:\tDiscriminator: real loss 0.28310343623161316, fake loss 0.2274172157049179\tGenerator: loss 13.916651725769043\n","Epoch 100, batch 157/240:\tDiscriminator: real loss 0.1611776500940323, fake loss 0.12174692004919052\tGenerator: loss 12.539837837219238\n","Epoch 100, batch 158/240:\tDiscriminator: real loss 0.08439798653125763, fake loss 0.29373982548713684\tGenerator: loss 14.188272476196289\n","Epoch 100, batch 159/240:\tDiscriminator: real loss 0.18543697893619537, fake loss 0.10960465669631958\tGenerator: loss 13.158402442932129\n","Epoch 100, batch 160/240:\tDiscriminator: real loss 0.14420486986637115, fake loss 0.028259506449103355\tGenerator: loss 12.367733001708984\n","Epoch 100, batch 161/240:\tDiscriminator: real loss 0.06980649381875992, fake loss 0.14702433347702026\tGenerator: loss 11.584040641784668\n","Epoch 100, batch 162/240:\tDiscriminator: real loss 0.15476283431053162, fake loss 0.23594783246517181\tGenerator: loss 11.942399978637695\n","Epoch 100, batch 163/240:\tDiscriminator: real loss 0.06288079917430878, fake loss 0.16708019375801086\tGenerator: loss 12.594642639160156\n","Epoch 100, batch 164/240:\tDiscriminator: real loss 0.1088101863861084, fake loss 0.13479091227054596\tGenerator: loss 12.409948348999023\n","Epoch 100, batch 165/240:\tDiscriminator: real loss 0.08908002823591232, fake loss 0.13617347180843353\tGenerator: loss 11.312170028686523\n","Epoch 100, batch 166/240:\tDiscriminator: real loss 0.09223675727844238, fake loss 0.16899074614048004\tGenerator: loss 9.198942184448242\n","Epoch 100, batch 167/240:\tDiscriminator: real loss 0.17148615419864655, fake loss 0.1777753382921219\tGenerator: loss 10.943878173828125\n","Epoch 100, batch 168/240:\tDiscriminator: real loss 0.08827377110719681, fake loss 0.1920921355485916\tGenerator: loss 11.91983413696289\n","Epoch 100, batch 169/240:\tDiscriminator: real loss 0.15621693432331085, fake loss 0.11338202655315399\tGenerator: loss 11.606025695800781\n","Epoch 100, batch 170/240:\tDiscriminator: real loss 0.1317054033279419, fake loss 0.1316506415605545\tGenerator: loss 11.326648712158203\n","Epoch 100, batch 171/240:\tDiscriminator: real loss 0.09009845554828644, fake loss 0.05256309360265732\tGenerator: loss 11.682838439941406\n","Epoch 100, batch 172/240:\tDiscriminator: real loss 0.07183140516281128, fake loss 0.17145004868507385\tGenerator: loss 11.125789642333984\n","Epoch 100, batch 173/240:\tDiscriminator: real loss 0.12729118764400482, fake loss 0.13308823108673096\tGenerator: loss 12.546548843383789\n","Epoch 100, batch 174/240:\tDiscriminator: real loss 0.0598500594496727, fake loss 0.07797451317310333\tGenerator: loss 12.122381210327148\n","Epoch 100, batch 175/240:\tDiscriminator: real loss 0.06769631057977676, fake loss 0.10542381554841995\tGenerator: loss 12.5884370803833\n","Epoch 100, batch 176/240:\tDiscriminator: real loss 0.18083804845809937, fake loss 0.09590516984462738\tGenerator: loss 11.94311237335205\n","Epoch 100, batch 177/240:\tDiscriminator: real loss 0.08197245746850967, fake loss 0.20728294551372528\tGenerator: loss 13.3953275680542\n","Epoch 100, batch 178/240:\tDiscriminator: real loss 0.11001911759376526, fake loss 0.12334251403808594\tGenerator: loss 12.34919548034668\n","Epoch 100, batch 179/240:\tDiscriminator: real loss 0.12051636725664139, fake loss 0.180745929479599\tGenerator: loss 12.3339262008667\n","Epoch 100, batch 180/240:\tDiscriminator: real loss 0.09477993100881577, fake loss 0.10589612275362015\tGenerator: loss 13.157303810119629\n","Epoch 100, batch 181/240:\tDiscriminator: real loss 0.1155945211648941, fake loss 0.11544257402420044\tGenerator: loss 15.314133644104004\n","Epoch 100, batch 182/240:\tDiscriminator: real loss 0.12498870491981506, fake loss 0.13795441389083862\tGenerator: loss 14.501276016235352\n","Epoch 100, batch 183/240:\tDiscriminator: real loss 0.08258023113012314, fake loss 0.1656782031059265\tGenerator: loss 15.834568977355957\n","Epoch 100, batch 184/240:\tDiscriminator: real loss 0.08118627220392227, fake loss 0.04361145943403244\tGenerator: loss 15.542993545532227\n","Epoch 100, batch 185/240:\tDiscriminator: real loss 0.08644908666610718, fake loss 0.09386453032493591\tGenerator: loss 16.55902671813965\n","Epoch 100, batch 186/240:\tDiscriminator: real loss 0.0756952092051506, fake loss 0.2122717797756195\tGenerator: loss 17.373123168945312\n","Epoch 100, batch 187/240:\tDiscriminator: real loss 0.12032581120729446, fake loss 0.14961034059524536\tGenerator: loss 18.44768714904785\n","Epoch 100, batch 188/240:\tDiscriminator: real loss 0.17219573259353638, fake loss 0.07609296590089798\tGenerator: loss 17.552541732788086\n","Epoch 100, batch 189/240:\tDiscriminator: real loss 0.05808630958199501, fake loss 0.12867139279842377\tGenerator: loss 19.017810821533203\n","Epoch 100, batch 190/240:\tDiscriminator: real loss 0.12423865497112274, fake loss 0.12923800945281982\tGenerator: loss 19.006563186645508\n","Epoch 100, batch 191/240:\tDiscriminator: real loss 0.11873752623796463, fake loss 0.17228268086910248\tGenerator: loss 19.477510452270508\n","Epoch 100, batch 192/240:\tDiscriminator: real loss 0.14480938017368317, fake loss 0.23385685682296753\tGenerator: loss 18.566801071166992\n","Epoch 100, batch 193/240:\tDiscriminator: real loss 0.14806300401687622, fake loss 0.1345055252313614\tGenerator: loss 17.514265060424805\n","Epoch 100, batch 194/240:\tDiscriminator: real loss 0.09739364683628082, fake loss 0.059890929609537125\tGenerator: loss 18.101985931396484\n","Epoch 100, batch 195/240:\tDiscriminator: real loss 0.12955200672149658, fake loss 0.11660905927419662\tGenerator: loss 17.28380584716797\n","Epoch 100, batch 196/240:\tDiscriminator: real loss 0.06393551081418991, fake loss 0.23787841200828552\tGenerator: loss 17.165973663330078\n","Epoch 100, batch 197/240:\tDiscriminator: real loss 0.06721163541078568, fake loss 0.07163087278604507\tGenerator: loss 18.512060165405273\n","Epoch 100, batch 198/240:\tDiscriminator: real loss 0.12018179148435593, fake loss 0.09616538882255554\tGenerator: loss 17.855253219604492\n","Epoch 100, batch 199/240:\tDiscriminator: real loss 0.1268957108259201, fake loss 0.24482916295528412\tGenerator: loss 19.985502243041992\n","Epoch 100, batch 200/240:\tDiscriminator: real loss 0.15581390261650085, fake loss 0.05796069651842117\tGenerator: loss 18.210115432739258\n","Epoch 100, batch 201/240:\tDiscriminator: real loss 0.07149502635002136, fake loss 0.0829085037112236\tGenerator: loss 17.310487747192383\n","Epoch 100, batch 202/240:\tDiscriminator: real loss 0.11039961874485016, fake loss 0.17324942350387573\tGenerator: loss 20.3064022064209\n","Epoch 100, batch 203/240:\tDiscriminator: real loss 0.14036214351654053, fake loss 0.15829676389694214\tGenerator: loss 19.469743728637695\n","Epoch 100, batch 204/240:\tDiscriminator: real loss 0.09089912474155426, fake loss 0.121073417365551\tGenerator: loss 18.54291534423828\n","Epoch 100, batch 205/240:\tDiscriminator: real loss 0.08464560657739639, fake loss 0.18347185850143433\tGenerator: loss 20.488780975341797\n","Epoch 100, batch 206/240:\tDiscriminator: real loss 0.06777399778366089, fake loss 0.08812358230352402\tGenerator: loss 20.079999923706055\n","Epoch 100, batch 207/240:\tDiscriminator: real loss 0.131138876080513, fake loss 0.04619447886943817\tGenerator: loss 18.735912322998047\n","Epoch 100, batch 208/240:\tDiscriminator: real loss 0.07513919472694397, fake loss 0.11934567242860794\tGenerator: loss 19.17335319519043\n","Epoch 100, batch 209/240:\tDiscriminator: real loss 0.10659933090209961, fake loss 0.14951203763484955\tGenerator: loss 19.293243408203125\n","Epoch 100, batch 210/240:\tDiscriminator: real loss 0.10709241032600403, fake loss 0.11626039445400238\tGenerator: loss 18.3465576171875\n","Epoch 100, batch 211/240:\tDiscriminator: real loss 0.07463517785072327, fake loss 0.1605427861213684\tGenerator: loss 18.17414093017578\n","Epoch 100, batch 212/240:\tDiscriminator: real loss 0.0705687627196312, fake loss 0.05559534579515457\tGenerator: loss 18.334327697753906\n","Epoch 100, batch 213/240:\tDiscriminator: real loss 0.07978507876396179, fake loss 0.3368568420410156\tGenerator: loss 18.175613403320312\n","Epoch 100, batch 214/240:\tDiscriminator: real loss 0.2927037477493286, fake loss 0.14472194015979767\tGenerator: loss 18.194095611572266\n","Epoch 100, batch 215/240:\tDiscriminator: real loss 0.18190118670463562, fake loss 0.13978932797908783\tGenerator: loss 17.704010009765625\n","Epoch 100, batch 216/240:\tDiscriminator: real loss 0.15961986780166626, fake loss 0.1094946563243866\tGenerator: loss 14.229918479919434\n","Epoch 100, batch 217/240:\tDiscriminator: real loss 0.038777824491262436, fake loss 0.11759267747402191\tGenerator: loss 13.77511215209961\n","Epoch 100, batch 218/240:\tDiscriminator: real loss 0.0628872886300087, fake loss 0.1265280395746231\tGenerator: loss 11.734431266784668\n","Epoch 100, batch 219/240:\tDiscriminator: real loss 0.1135023981332779, fake loss 0.14664241671562195\tGenerator: loss 11.345524787902832\n","Epoch 100, batch 220/240:\tDiscriminator: real loss 0.09165039658546448, fake loss 0.09227985143661499\tGenerator: loss 11.126883506774902\n","Epoch 100, batch 221/240:\tDiscriminator: real loss 0.11177986115217209, fake loss 0.3192729949951172\tGenerator: loss 11.735036849975586\n","Epoch 100, batch 222/240:\tDiscriminator: real loss 0.09783806651830673, fake loss 0.02486455626785755\tGenerator: loss 11.337486267089844\n","Epoch 100, batch 223/240:\tDiscriminator: real loss 0.12513767182826996, fake loss 0.3398429751396179\tGenerator: loss 11.811585426330566\n","Epoch 100, batch 224/240:\tDiscriminator: real loss 0.12243663519620895, fake loss 0.11952684074640274\tGenerator: loss 12.36791706085205\n","Epoch 100, batch 225/240:\tDiscriminator: real loss 0.15045705437660217, fake loss 0.15356117486953735\tGenerator: loss 12.75946044921875\n","Epoch 100, batch 226/240:\tDiscriminator: real loss 0.23487678170204163, fake loss 0.0706591010093689\tGenerator: loss 12.448700904846191\n","Epoch 100, batch 227/240:\tDiscriminator: real loss 0.0897168517112732, fake loss 0.29568660259246826\tGenerator: loss 12.69186019897461\n","Epoch 100, batch 228/240:\tDiscriminator: real loss 0.06800803542137146, fake loss 0.1464352011680603\tGenerator: loss 13.714154243469238\n","Epoch 100, batch 229/240:\tDiscriminator: real loss 0.17191246151924133, fake loss 0.10845914483070374\tGenerator: loss 12.578142166137695\n","Epoch 100, batch 230/240:\tDiscriminator: real loss 0.0629354938864708, fake loss 0.16242022812366486\tGenerator: loss 13.33169174194336\n","Epoch 100, batch 231/240:\tDiscriminator: real loss 0.11254385113716125, fake loss 0.27015554904937744\tGenerator: loss 11.410222053527832\n","Epoch 100, batch 232/240:\tDiscriminator: real loss 0.1531953364610672, fake loss 0.04351910203695297\tGenerator: loss 9.321565628051758\n","Epoch 100, batch 233/240:\tDiscriminator: real loss 0.16978275775909424, fake loss 0.13652600347995758\tGenerator: loss 9.88248348236084\n","Epoch 100, batch 234/240:\tDiscriminator: real loss 0.156236469745636, fake loss 0.29890739917755127\tGenerator: loss 14.029288291931152\n","Epoch 100, batch 235/240:\tDiscriminator: real loss 0.19283905625343323, fake loss 0.1141745075583458\tGenerator: loss 13.342501640319824\n","Epoch 100, batch 236/240:\tDiscriminator: real loss 0.10012935847043991, fake loss 0.1646217405796051\tGenerator: loss 13.224814414978027\n","Epoch 100, batch 237/240:\tDiscriminator: real loss 0.1009875014424324, fake loss 0.07678783684968948\tGenerator: loss 13.906899452209473\n","Epoch 100, batch 238/240:\tDiscriminator: real loss 0.11871957778930664, fake loss 0.04734368622303009\tGenerator: loss 13.106257438659668\n","Epoch 100, batch 239/240:\tDiscriminator: real loss 0.05761897563934326, fake loss 0.22176195681095123\tGenerator: loss 12.390275955200195\n","Epoch 100, batch 240/240:\tDiscriminator: real loss 0.08760379999876022, fake loss 0.1192147433757782\tGenerator: loss 12.351945877075195\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"laEh7WNfwRQL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":513},"outputId":"a7ab4e6d-512f-4ecc-919a-1b854ae6b353","executionInfo":{"status":"ok","timestamp":1587123983722,"user_tz":-330,"elapsed":5480,"user":{"displayName":"","photoUrl":"","userId":""}}},"source":["def show_plot(examples, n):\n","    for i in range(n*n):\n","        plt.subplot(n, n, i+1)\n","        plt.axis('off')\n","        plt.imshow(examples[i,:,:,0], cmap='gray_r')\n","    plt.show()\n","\n","model = load_model('generator.h5')\n","noise, _ = generate_latent_noise(100, 100)\n","labels = np.asarray([x for _ in range(10) for x in range(10)])\n","X = model.predict([noise, labels])\n","# scale from [-1, 1] to [0, 1]\n","X = (X + 1) / 2.0\n","show_plot(X, 10)\n","X[0].shape\n","for i in range(90):\n","    x = np.squeeze(X[i])\n","    plt.imshow(x)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 100 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"PCpE5ZHFwRQO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
